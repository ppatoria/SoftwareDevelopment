<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"><HTML>
<HEAD>
<TITLE></TITLE>
</HEAD>
<BODY>
<A name=1></a><IMG src="CLRviaCsharp-1_1.jpg"><br>
<hr>
<A name=2></a>PUBLISHED BY<br>Microsoft Press<br>A Division of Microsoft Corporation<br>One Microsoft Way<br>Redmond, Washington 98052-6399<br>
Copyright © 2010 by Jeffrey Richter<br>
All rights reserved. No part of the contents of this book may be reproduced or transmitted in any form or by any means <br>without the written permission of the publisher.<br>
Library of Congress Control Number: 2009943026<br>
Printed and bound in the United States of America.<br>
1 2 3 4 5 6 7 8 9   WCT   5 4 3 2 1 0 <br>
A CIP catalogue record for this book is available from the British Library.<br>
Microsoft Press books are available through booksellers and distributors worldwide. For further infor mation about <br>
fax (425) 936-7329. Visit our Web site at www.microsoft.com/mspress. Send comments to msinput@microsoft.com.<br>
Microsoft, Microsoft Press, Active Accessibility, Active Directory, ActiveX, Authenticode, DirectX, Excel, IntelliSense, <br>Internet Explorer, MSDN, Outlook, SideShow, Silverlight, SQL Server, Visual Basic, Visual Studio, Win32, Windows, <br>Windows Live, Windows Media, Windows NT, Windows Server and Windows Vista are either registered trademarks <br>or trademarks of the Microsoft group of companies. Other product and company names mentioned herein may be the <br>trademarks of their respective owners.<br>
The example companies, organizations, products, domain names, e-mail addresses, logos, people, places, and events <br>
logo, person, place, or event is intended or should be inferred.<br>
This book expresses the author's views and opinions. The information contained in this book is provided without any <br>express, statutory, or implied warranties. Neither the authors, Microsoft Corporation, nor its resellers, or distributors will <br>be held liable for any damages caused or alleged to be caused either directly or indirectly by this book.<br>
<b>Acquisitions Editor:</b> Ben Ryan<br><b>Developmental Editor: </b>Devon Musgrave<b> <br>Project Editor: </b>Valerie Woolley<b> <br>Editorial Production: </b>Custom Editorial Productions, Inc.<b> <br>Technical Reviewer: </b>Christophe Nasarre; Technical Review services provided by Content Master, a member of CM <br>Group, Ltd.<b> <br>Cover: </b>Tom Draper Design <br>
Body Part No. X16-61995<br>
<hr>
<A name=3></a><b>Table of Contents</b><br>
<b>Foreward . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xiii<br>Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xv</b><br>
<b>Part I  CLR Basics<br> </b><br>
<b>1  The CLR's Execution Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1</b><br>
Compiling Source Code into Managed Modules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1<br>Combining Managed Modules into Assemblies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5<br>Loading the Common Language Runtime. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6<br>Executing Your Assembly's Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9<br>
IL and Verification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15<br>Unsafe Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16<br>
The Native Code Generator Tool: NGen.exe . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18<br>The Framework Class Library . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20<br>The Common Type System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22<br>The Common Language Specification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25<br>Interoperability with Unmanaged Code. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29<br>
<b> </b><br>
<b>2  Building, Packaging, Deploying, and Administering Applications  </b><br>
<b>   and Types. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31</b><br>
.NET Framework Deployment Goals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32<br>Building Types into a Module. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33<br>
Response Files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .34<br>
A Brief Look at Metadata  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36<br>Combining Modules to Form an Assembly . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43<br>
Adding Assemblies to a Project by Using the Visual Studio IDE. . . . . . . . . . . . . . . 49<br>Using the Assembly Linker. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50<br>Adding Resource Files to an Assembly . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52<br>
Assembly Version Resource Information . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53<br>
Version Numbers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57<br>
Culture  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58<br>Simple Application Deployment (Privately Deployed Assemblies) . . . . . . . . . . . . . . . . . . 59<br>Simple Administrative Control (Configuration) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61<br>
<b>What do you think of this book? We want to hear from you!</b><br>
<b>Microsoft is interested in hearing your feedback so we can continually improve our books and learning  <br>resources for you. To participate in a brief online survey, please visit: </b><br>
<b>www.microsoft.com/learning/booksurvey/</b><br>
<b> </b><br>
<b> </b><br>
<b>iii</b><br>
<hr>
<A name=4></a><b>iv </b><br>
<b>Table of Contents</b><br>
<b> </b><br>
<b>3  Shared Assemblies and Strongly Named Assemblies  . . . . . . . . . . . . . . 65</b><br>
Two Kinds of Assemblies, Two Kinds of Deployment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .66<br>Giving an Assembly a Strong Name . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67<br>The Global Assembly Cache . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73<br>Building an Assembly That References a Strongly Named Assembly . . . . . . . . . . . . . . . . 75<br>Strongly Named Assemblies Are Tamper-Resistant . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76<br>Delayed Signing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .77<br>Privately Deploying Strongly Named Assemblies. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .80<br>How the Runtime Resolves Type References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81<br>Advanced Administrative Control (Configuration) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .84<br>
Publisher Policy Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87<br>
<b>Part II  Designing Types<br> </b><br>
<b>4  Type Fundamentals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91</b><br>
All Types Are Derived from System.Object . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91<br>Casting Between Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93<br>
Casting with the C# is and as Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95<br>
Namespaces and Assemblies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97<br>How Things Relate at Runtime . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .102<br>
<b> </b><br>
<b>5  Primitive, Reference, and Value Types . . . . . . . . . . . . . . . . . . . . . . . . . . 113</b><br>
Programming Language Primitive Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .113<br>
Checked and Unchecked Primitive Type Operations . . . . . . . . . . . . . . . . . . . . . . . 117<br>
Reference Types and Value Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .121<br>Boxing and Unboxing Value Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .127<br>
Changing Fields in a Boxed Value Type by Using Interfaces (and Why You  <br>   Shouldn't Do This) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .140<br>Object Equality and Identity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .143<br>
Object Hash Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .146<br>The dynamic Primitive Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .148<br>
<b> </b><br>
<b>6  Type and Member Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155</b><br>
The Different Kinds of Type Members . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .155<br>Type Visibility. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .158<br>
Friend Assemblies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .159<br>
Member Accessibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .160<br>Static Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .162<br>Partial Classes, Structures, and Interfaces  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .164<br>Components, Polymorphism, and Versioning. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .165<br>
How the CLR Calls Virtual Methods, Properties, and Events . . . . . . . . . . . . . . . . .167<br>Using Type Visibility and Member Accessibility Intelligently  . . . . . . . . . . . . . . . .172<br>Dealing with Virtual Methods When Versioning Types . . . . . . . . . . . . . . . . . . . . . 175<br>
<b> </b><br>
<b>7  Constants and Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181</b><br>
Constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .181<br>Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .183<br>
<hr>
<A name=5></a><b> </b><br>
<b>Table of Contents </b><br>
<b>v</b><br>
<b> </b><br>
<b>8  Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187</b><br>
Instance Constructors and Classes (Reference Types) . . . . . . . . . . . . . . . . . . . . . . . . . . . .187<br>Instance Constructors and Structures (Value Types)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . .191<br>Type Constructors. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .194<br>
Type Constructor Performance. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .198<br>
Operator Overload Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .200<br>
Operators and Programming Language Interoperability . . . . . . . . . . . . . . . . . . .203<br>
Conversion Operator Methods. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .204<br>Extension Methods. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .207<br>
Rules and Guidelines. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .210<br>Extending Various Types with Extension Methods . . . . . . . . . . . . . . . . . . . . . . . . .211<br>The Extension Attribute . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .213<br>
Partial Methods. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .213<br>
Rules and Guidelines. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .216<br>
<b> </b><br>
<b>9  Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219</b><br>
Optional and Named Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219<br>
Rules and Guidelines. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .220<br>The DefaultParameterValue and Optional Attributes . . . . . . . . . . . . . . . . . .222<br>
Implicitly Typed Local Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .223<br>Passing Parameters by Reference to a Method. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .225<br>Passing a Variable Number of Arguments to a Method . . . . . . . . . . . . . . . . . . . . . . . . . .231<br>Parameter and Return Type Guidelines  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .233<br>Const-ness. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .235<br>
<b>  10  Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237</b><br>
Parameterless Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .237<br>
Automatically Implemented Properties  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241<br>Defining Properties Intelligently. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .242<br>Object and Collection Initializers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .245<br>Anonymous Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247<br>The System.Tuple Type. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .250<br>
Parameterful Properties  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .252<br>The Performance of Calling Property Accessor Methods . . . . . . . . . . . . . . . . . . . . . . . . .257<br>Property Accessor Accessibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .258<br>Generic Property Accessor Methods. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .258<br>
<b>  11  Events  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259</b><br>
Designing a Type That Exposes an Event . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .260<br>
Step #1: Define a type that will hold any additional information  <br>   that should be sent to receivers of the event notification . . . . . . . . . . . . . . . . .261<br>Step #2: Define the event member  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .262<br>Step #3: Define a method responsible for raising the event to  <br>   notify registered objects that the event has occurred . . . . . . . . . . . . . . . . . . . .263<br>Step #4: Define a method that translates the input into the desired event . . . .266<br>
How the Compiler Implements an Event . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .266<br>
<hr>
<A name=6></a><b>vi </b><br>
<b>Table of Contents</b><br>
Designing a Type That Listens for an Event . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .269<br>Explicitly Implementing an Event. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .271<br>
<b>  12  Generics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275</b><br>
Generics in the Framework Class Library . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .280<br>Wintellect's Power Collections Library . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .281<br>Generics Infrastructure  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .282<br>
Open and Closed Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .283<br>Generic Types and Inheritance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .285<br>Generic Type Identity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .287<br>Code Explosion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .288<br>
Generic Interfaces. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .289<br>Generic Delegates. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .290<br>Delegate and Interface Contravariant and Covariant Generic Type Arguments. . . . . .291<br>Generic Methods  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .293<br>
Generic Methods and Type Inference . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .294<br>
Generics and Other Members  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .296<br>Verifiability and Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .296<br>
Primary Constraints. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .299<br>Secondary Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .300<br>Constructor Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .301<br>Other Verifiability Issues  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .302<br>
<b>  13  Interfaces  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307</b><br>
Class and Interface Inheritance  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .308<br>Defining an Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .308<br>Inheriting an Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .310<br>More About Calling Interface Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .312<br>Implicit and Explicit Interface Method Implementations (What's Happening  <br>   Behind the Scenes) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .314<br>Generic Interfaces. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .315<br>Generics and Interface Constraints . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .318<br>Implementing Multiple Interfaces That Have the Same Method Name  <br>   and Signature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .319<br>Improving Compile-Time Type Safety with Explicit Interface Method  <br>   Implementations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .320<br>Be Careful with Explicit Interface Method Implementations . . . . . . . . . . . . . . . . . . . . . .322<br>Design: Base Class or Interface? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .325<br>
<b>Part III  Essential Types<br>  14  Chars, Strings, and Working with Text . . . . . . . . . . . . . . . . . . . . . . . . . . 327</b><br>
Characters  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .327<br>The System.String Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .330<br>
Constructing Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .330<br>Strings Are Immutable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .333<br>Comparing Strings  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .334<br>
<hr>
<A name=7></a><b> </b><br>
<b>Table of Contents </b><br>
<b>vii</b><br>
String Interning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .340<br>String Pooling  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .343<br>Examining a String's Characters and Text Elements . . . . . . . . . . . . . . . . . . . . . . . .343<br>Other String Operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .346<br>
Constructing a String Efficiently. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .346<br>
Constructing a StringBuilder Object . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .347<br>StringBuilder Members. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .348<br>
Obtaining a String Representation of an Object: ToString . . . . . . . . . . . . . . . . . . . . . . . .350<br>
Specific Formats and Cultures. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 351<br>Formatting Multiple Objects into a Single String . . . . . . . . . . . . . . . . . . . . . . . . . .355<br>Providing Your Own Custom Formatter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .356<br>
Parsing a String to Obtain an Object: Parse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .359<br>Encodings: Converting Between Characters and Bytes . . . . . . . . . . . . . . . . . . . . . . . . . . .361<br>
Encoding and Decoding Streams of Characters and Bytes . . . . . . . . . . . . . . . . . .367<br>Base-64 String Encoding and Decoding . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .368<br>
Secure Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .369<br>
<b>  15  Enumerated Types and Bit Flags . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373</b><br>
Enumerated Types  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .373<br>Bit Flags  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .379<br>Adding Methods to Enumerated Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .383<br>
<b>  16  Arrays. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385</b><br>
Initializing Array Elements. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .388<br>Casting Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .390<br>All Arrays Are Implicitly Derived from System.Array . . . . . . . . . . . . . . . . . . . . . . . . . . .392<br>All Arrays Implicitly Implement IEnumerable, ICollection, and IList. . . . . . . . . .393<br>Passing and Returning Arrays. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .394<br>Creating Non-Zero­Lower Bound Arrays. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .395<br>Array Access Performance. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .396<br>Unsafe Array Access and Fixed-Size Array . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .401<br>
<b>  17  Delegates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405</b><br>
A First Look at Delegates. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .405<br>Using Delegates to Call Back Static Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .408<br>Using Delegates to Call Back Instance Methods. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .409<br>Demystifying Delegates. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410<br>Using Delegates to Call Back Many Methods (Chaining)  . . . . . . . . . . . . . . . . . . . . . . . . . 415<br>
C#'s Support for Delegate Chains  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419<br>Having More Control over Delegate Chain Invocation . . . . . . . . . . . . . . . . . . . . . 419<br>
Enough with the Delegate Definitions Already (Generic Delegates). . . . . . . . . . . . . . . .422<br>C#'s Syntactical Sugar for Delegates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .423<br>
Syntactical Shortcut #1: No Need to Construct a Delegate Object. . . . . . . . . . .424<br>Syntactical Shortcut #2: No Need to Define a Callback Method . . . . . . . . . . . . .424<br>Syntactical Shortcut #3: No Need to Wrap Local Variables in a Class  <br>   Manually to Pass Them to a Callback Method . . . . . . . . . . . . . . . . . . . . . . . . . . .428<br>
Delegates and Reflection  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .431<br>
<hr>
<A name=8></a><b>viii </b><br>
<b>Table of Contents</b><br>
<b>  18  Custom Attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435</b><br>
Using Custom Attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .435<br>Defining Your Own Attribute Class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .439<br>Attribute Constructor and Field/Property Data Types. . . . . . . . . . . . . . . . . . . . . . . . . . . .443<br>Detecting the Use of a Custom Attribute. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .444<br>Matching Two Attribute Instances Against Each Other . . . . . . . . . . . . . . . . . . . . . . . . . . .448<br>Detecting the Use of a Custom Attribute Without Creating Attribute-Derived  <br>   Objects  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .451<br>Conditional Attribute Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .454<br>
<b>  19  Nullable Value Types. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 457</b><br>
C#'s Support for Nullable Value Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .459<br>C#'s Null-Coalescing Operator. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .462<br>The CLR Has Special Support for Nullable Value Types . . . . . . . . . . . . . . . . . . . . . . . . . . .463<br>
Boxing Nullable Value Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .463<br>Unboxing Nullable Value Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .463<br>Calling GetType via a Nullable Value Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .464<br>Calling Interface Methods via a Nullable Value Type . . . . . . . . . . . . . . . . . . . . . . .464<br>
<b>Part IV  Core Facilities<br>  20  Exceptions and State Management . . . . . . . . . . . . . . . . . . . . . . . . . . . . 465</b><br>
Defining "Exception"  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .466<br>Exception-Handling Mechanics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .467<br>
The try Block  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .468<br>The catch Block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .469<br>The finally Block . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .470<br>
The System.Exception Class. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 474<br>FCL-Defined Exception Classes. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .478<br>Throwing an Exception  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .480<br>Defining Your Own Exception Class  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .481<br>Trading Reliability for Productivity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .484<br>Guidelines and Best Practices. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .492<br>
Use finally Blocks Liberally . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .492<br>Don't Catch Everything. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .494<br>Recovering Gracefully from an Exception. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .495<br>Backing Out of a Partially Completed Operation When an Unrecoverable  <br>   Exception Occurs--Maintaining State . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .496<br>Hiding an Implementation Detail to Maintain a "Contract" . . . . . . . . . . . . . . . . .497<br>
Unhandled Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .500<br>Debugging Exceptions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .504<br>Exception-Handling Performance Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .506<br>Constrained Execution Regions (CERs) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .509<br>Code Contracts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .512<br>
<hr>
<A name=9></a><b> </b><br>
<b>Table of Contents </b><br>
<b>ix</b><br>
<b>  21  Automatic Memory Management (Garbage Collection). . . . . . . . . . . 519</b><br>
Understanding the Basics of Working in a Garbage-Collected Platform. . . . . . . . . . . .520<br>
Allocating Resources from the Managed Heap. . . . . . . . . . . . . . . . . . . . . . . . . . . .521<br>
The Garbage Collection Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .523<br>Garbage Collections and Debugging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .527<br>Using Finalization to Release Native Resources  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .530<br>
Guaranteed Finalization Using CriticalFinalizerObject Types  . . . . . . . . .532<br>Interoperating with Unmanaged Code by Using SafeHandle Types. . . . . . . . .535<br>
Using Finalization with Managed Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .537<br>What Causes Finalize Methods to Be Called?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .540<br>Finalization Internals  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .541<br>The Dispose Pattern: Forcing an Object to Clean Up. . . . . . . . . . . . . . . . . . . . . . . . . . . . .544<br>Using a Type That Implements the Dispose Pattern  . . . . . . . . . . . . . . . . . . . . . . . . . . . . .548<br>C#'s using Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 551<br>An Interesting Dependency Issue . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .554<br>Monitoring and Controlling the Lifetime of Objects Manually . . . . . . . . . . . . . . . . . . . . 555<br>Resurrection. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .566<br>Generations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .568<br>Other Garbage Collection Features for Use with Native Resources  . . . . . . . . . . . . . . . . 574<br>Predicting the Success of an Operation that Requires a Lot of Memory . . . . . . . . . . . .578<br>Programmatic Control of the Garbage Collector . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .580<br>Thread Hijacking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .583<br>Garbage Collection Modes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .585<br>Large Objects  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .588<br>Monitoring Garbage Collections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .589<br>
<b>  22  CLR Hosting and AppDomains  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 591</b><br>
CLR Hosting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .592<br>AppDomains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .594<br>
Accessing Objects Across AppDomain Boundaries. . . . . . . . . . . . . . . . . . . . . . . . .597<br>
AppDomain Unloading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .609<br>AppDomain Monitoring  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .610<br>AppDomain First-Chance Exception Notifications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .612<br>How Hosts Use AppDomains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .612<br>
Executable Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .612<br>Microsoft Silverlight Rich Internet Applications  . . . . . . . . . . . . . . . . . . . . . . . . . . .613<br>Microsoft ASP.NET Web Forms and XML Web Services Applications . . . . . . . . .613<br>Microsoft SQL Server . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .614<br>Your Own Imagination . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .614<br>
Advanced Host Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .615<br>
Managing the CLR by Using Managed Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .615<br>Writing a Robust Host Application  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .616<br>How a Host Gets Its Thread Back . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 617<br>
<hr>
<A name=10></a><b>x </b><br>
<b>Table of Contents</b><br>
<b>  23  Assembly Loading and Reflection. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 621</b><br>
Assembly Loading. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .621<br>Using Reflection to Build a Dynamically Extensible Application . . . . . . . . . . . . . . . . . . .626<br>Reflection Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .627<br>
Discovering Types Defined in an Assembly . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .628<br>What Exactly Is a Type Object?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .628<br>Building a Hierarchy of Exception-Derived Types . . . . . . . . . . . . . . . . . . . . . . . . . .631<br>Constructing an Instance of a Type . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .632<br>
Designing an Application That Supports Add-Ins  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .634<br>Using Reflection to Discover a Type's Members . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .637<br>
Discovering a Type's Members . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .638<br>BindingFlags: Filtering the Kinds of Members That Are Returned  . . . . . . . . .643<br>Discovering a Type's Interfaces. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .644<br>Invoking a Type's Members. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .646<br>Bind Once, Invoke Multiple Times . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .650<br>Using Binding Handles to Reduce Your Process's Memory Consumption . . . . .658<br>
<b>  24  Runtime Serialization  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 661</b><br>
Serialization/Deserialization Quick Start  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .662<br>Making a Type Serializable . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .667<br>Controlling Serialization and Deserialization. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .668<br>How Formatters Serialize Type Instances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .672<br>Controlling the Serialized/Deserialized Data. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .673<br>
How to Define a Type That Implements ISerializable when the Base  <br>   Type Doesn't Implement This Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .678<br>
Streaming Contexts  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .680<br>Serializing a Type as a Different Type and Deserializing an Object as a  <br>   Different Object. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .682<br>Serialization Surrogates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .684<br>
Surrogate Selector Chains . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .688<br>
Overriding the Assembly and/or Type When Deserializing an Object . . . . . . . . . . . . . .689<br>
<b>Part V  Threading<br>  25  Thread Basics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 691</b><br>
Why Does Windows Support Threads?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .691<br>Thread Overhead . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .692<br>Stop the Madness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .696<br>CPU Trends. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .699<br>NUMA Architecture Machines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .700<br>CLR Threads and Windows Threads  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .703<br>Using a Dedicated Thread to Perform an Asynchronous Compute-Bound  <br>   Operation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .704<br>Reasons to Use Threads. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .706<br>Thread Scheduling and Priorities. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .708<br>Foreground Threads versus Background Threads  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .713<br>What Now?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .715<br>
<hr>
<A name=11></a><b> </b><br>
<b>Table of Contents </b><br>
<b>xi</b><br>
<b>  26  Compute-Bound Asynchronous Operations . . . . . . . . . . . . . . . . . . . . . 717</b><br>
Introducing the CLR's Thread Pool  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .718<br>Performing a Simple Compute-Bound Operation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .719<br>Execution Contexts. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .721<br>Cooperative Cancellation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .722<br>Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .726<br>
Waiting for a Task to Complete and Getting Its Result  . . . . . . . . . . . . . . . . . . . . .727<br>Cancelling a Task . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .729<br>Starting a New Task Automatically When Another Task Completes . . . . . . . . . .731<br>A Task May Start Child Tasks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .733<br>Inside a Task . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .733<br>Task Factories . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .735<br>Task Schedulers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .737<br>
Parallel's Static For, ForEach, and Invoke Methods. . . . . . . . . . . . . . . . . . . . . . . . . .739<br>Parallel Language Integrated Query . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 743<br>Performing a Periodic Compute-Bound Operation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 747<br>
So Many Timers, So Little Time. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 749<br>
How the Thread Pool Manages Its Threads . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .750<br>
Setting Thread Pool Limits. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .750<br>How Worker Threads Are Managed  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .751<br>
Cache Lines and False Sharing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .752<br>
<b>  27  I/O-Bound Asynchronous Operations . . . . . . . . . . . . . . . . . . . . . . . . . . 755</b><br>
How Windows Performs I/O Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .755<br>The CLR's Asynchronous Programming Model (APM). . . . . . . . . . . . . . . . . . . . . . . . . . . . 761<br>The AsyncEnumerator Class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .765<br>The APM and Exceptions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .769<br>Applications and Their Threading Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .770<br>Implementing a Server Asynchronously. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .773<br>The APM and Compute-Bound Operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .774<br>APM Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .776<br>
Using the APM Without the Thread Pool . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .776<br>Always Call the EndXxx Method, and Call It Only Once . . . . . . . . . . . . . . . . . . . .777<br>Always Use the Same Object When Calling the EndXxx Method . . . . . . . . . . . .778<br>Using ref, out, and params Arguments with BeginXxx and  <br>   EndXxx Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .778<br>You Can't Cancel an Asynchronous I/O-Bound Operation . . . . . . . . . . . . . . . . . .778<br>Memory Consumption . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .778<br>Some I/O Operations Must Be Done Synchronously . . . . . . . . . . . . . . . . . . . . . . .779<br>FileStream-Specific Issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .780<br>
I/O Request Priorities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .780<br>Converting the IAsyncResult APM to a Task . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .783<br>The Event-Based Asynchronous Pattern. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .784<br>
Converting the EAP to a Task  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .786<br>Comparing the APM and the EAP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .788<br>
Programming Model Soup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .788<br>
<hr>
<A name=12></a><b>xii </b><br>
<b>Table of Contents</b><br>
<b>  28  Primitive Thread Synchronization Constructs. . . . . . . . . . . . . . . . . . . . 791</b><br>
Class Libraries and Thread Safety  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .793<br>Primitive User-Mode and Kernel-Mode Constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .794<br>User-Mode Constructs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .796<br>
Volatile Constructs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .797<br>Interlocked Constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .803<br>Implementing a Simple Spin Lock . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .807<br>The Interlocked Anything Pattern . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .811<br>
Kernel-Mode Constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .813<br>
Event Constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 817<br>Semaphore Constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .819<br>Mutex Constructs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .820<br>Calling a Method When a Single Kernel Construct Becomes Available . . . . . . .822<br>
<b>  29  Hybrid Thread Synchronization Constructs. . . . . . . . . . . . . . . . . . . . . . 825</b><br>
A Simple Hybrid Lock. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .826<br>Spinning, Thread Ownership, and Recursion. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .827<br>A Potpourri of Hybrid Constructs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .829<br>
The ManualResetEventSlim and SemaphoreSlim Classes . . . . . . . . . . . . . . . .830<br>The Monitor Class and Sync Blocks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .830<br>The ReaderWriterLockSlim Class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .836<br>The OneManyLock Class. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .838<br>The CountdownEvent Class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .841<br>The Barrier Class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .841<br>Thread Synchronization Construct Summary. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .842<br>
The Famous Double-Check Locking Technique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .844<br>The Condition Variable Pattern . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .848<br>Using Collections to Avoid Holding a Lock for a Long Time  . . . . . . . . . . . . . . . . . . . . . .851<br>The Concurrent Collection Classes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .856<br>
<b>Index  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 861</b><br>
<b>What do you think of this book? We want to hear from you!</b><br>
<b>Microsoft is interested in hearing your feedback so we can continually improve our books and learning  <br>resources for you. To participate in a brief online survey, please visit: </b><br>
<b>www.microsoft.com/learning/booksurvey/</b><br>
<hr>
<A name=13></a><b>Foreword</b><br>
At first, when Jeff asked me to write the foreword for his book, I was so flattered! He must <br>really respect me, I thought. Ladies, this is a common thought process error--trust me, he <br>doesn't respect you. It turns out that I was about #14 on his list of potential foreword writ-<br>ers and he had to settle for me. Apparently, none of the other candidates (Bill Gates, Steve <br>Ballmer, Catherine Zeta-Jones, . . .) were that into him. At least he bought me dinner.<br>
But no one can tell you more about this book than I can. I mean, Catherine could give you a <br>mobile makeover, but I know all kinds of stuff about reflection and exceptions and C# lan-<br>guage updates because he has been talking on and on about it for years. This is standard <br>dinner conversation in our house! Other people talk about the weather or stuff they heard at <br>the water cooler, but we talk about .NET. Even Aidan, our six-year-old, asks questions about <br>Jeff's book. Mostly about when he will be done writing it so they can play something "cool." <br>Grant (age 2) doesn't talk yet, but his first word will probably be "Sequential."<br>
In fact, if you want to know how this all started, it goes something like this. About 10 years <br>ago, Jeff went to a "Secret Summit" at Microsoft. They pulled in a bunch of industry experts <br>(Really, how do you get this title? Believe me, this isn't Jeff's college degree), and unveiled <br>the new COM. Late that night in bed (in our house, this is what we discuss in bed), he talked <br>about how COM is dead. And he was enchanted. Lovestruck, actually. In a matter of days <br>he was hanging around the halls of Building 42 on Microsoft's Redmond campus, hoping to <br>learn more about this wonderful .NET. The affair hasn't ended, and this book is what he has <br>to show for it.<br>
For years, Jeff has told me about threading. He really likes this topic. One time, in New <br>Orleans, we went on a two-hour walk, alone, holding hands, and he spoke the whole time <br>about how he had enough content for a threading book: The art of threading. How misun-<br>derstood threading in Windows is. It breaks his heart, all those threads out there. Where do <br>they all go? Why were they created if no one had a plan for them? These are the questions of <br>the universe to Jeff, the deeper meanings in life. Finally, in this book, he has written it down. <br>It is all here. Believe me folks, if you want to know about threading, no one has thought <br>about it more or worked with it more than Jeff has. And all those wasted hours of his life (he <br>can't get them back) are here at your disposal. Please read it. Then send him an e-mail about <br>how that information changed your life. Otherwise, he is just another tragic literary figure <br>whose life ended without meaning or fulfillment. He will drink himself to death on diet soda.<br>
This edition of the book even includes a new chapter about the runtime serializer. Turns out, <br>this is not a new breakfast food for kids. When I figured out it was more computer talk and <br>not something to put on my grocery list, I tuned it out. So I don't know what it says, but it is <br>in here and you should read it (with a glass of milk).<br>
<b> </b><br>
<b> </b><br>
<b>xiii</b><br>
<hr>
<A name=14></a><IMG src="CLRviaCsharp-14_1.jpg"><br>
<b>xiv </b><br>
<b>Foreword</b><br>
My hope is that now he is finished talking about garbage collection in theory and can get on <br>with actually collecting our garbage and putting it on the curb. Seriously people, how hard is <br>that?<br>
Folks, here is the clincher--this is Jeffrey Richter's magnum opus. This is it. There will be no <br>more books. Of course, we say this every time he finishes one, but this time we really mean <br>it. So, 13 books (give or take) later, this is the best and the last. Get it fast, because there are <br>only a limited number and once they are gone--poof. No more. Just like QVC or something. <br>Back to real life for us, where we can discuss the important things, like what the kids broke <br>today and whose turn is it to change the diapers.<br>
<i>Kristin Trace (Jeffrey's wife)</i><br>
<i>November 24, 2009</i><br>
A typical family breakfast at the Richter household<br>
<hr>
<A name=15></a><b>Introduction</b><br>
It was October 1999 when some people at Microsoft first demonstrated the Microsoft .NET <br>Framework, the common language runtime (CLR), and the C# programming language to me. <br>The moment I saw all of this, I was impressed and I knew that it was going to change the way <br>I wrote software in a very significant way. I was asked to do some consulting for the team and <br>immediately agreed. At first, I thought that the .NET Framework was an abstraction layer over <br>the Win32 API and COM. As I invested more and more of my time into it, however, I realized <br>that it was much bigger. In a way, it is its own operating system. It has its own memory man-<br>ager, its own security system, its own file loader, its own error handling mechanism, its own <br>application isolation boundaries (AppDomains), its own threading models, and more. This <br>book explains all these topics so that you can effectively design and implement software  <br>applications and components for this platform.<br>
I have spent a good part of my life focusing on threading, concurrent execution, parallelism, <br>synchronization, and so on. Today, with multicore computers becoming so prevalent, these <br>subjects are becoming increasingly important. A few years ago, I decided to create a book <br>dedicated to threading topics. However, one thing led to another and I never produced the <br>book. When it came time to revise this book, I decided to incorporate all the threading  <br>information in here. So this book covers the .NET Framework's CLR and the C# programming <br>language, and it also has my threading book embedded inside it (see Part V, "Threading").<br>
It is October 2009 as I write this text, making it 10 years now that I've worked with the .NET <br>Framework and C#. Over the 10 years, I have built all kinds of applications and, as a consul-<br>tant to Microsoft, have contributed quite a bit to the .NET Framework itself. As a partner in <br>my own company, Wintellect (<i>http://Wintellect.com</i>), I have worked with numerous customers <br>to help them design software, debug software, performance-tune software, and solve issues <br>they have with the .NET Framework. All these experiences have really helped me learn the <br>spots that people have trouble with when trying to be productive with the .NET Framework. <br>I have tried to sprinkle knowledge from these experiences through all the topics presented in <br>this book.<br>
<b>Who This Book Is For</b><br>
The purpose of this book is to explain how to develop applications and reusable classes for <br>the .NET Framework. Specifically, this means that I intend to explain how the CLR works and <br>the facilities that it offers. I'll also discuss various parts of the Framework Class Library (FCL). <br>No book could fully explain the FCL--it contains literally thousands of types now, and this <br>number continues to grow at an alarming rate. Therefore, here I'm concentrating on the core <br>types that every developer needs to be aware of. And while this book isn't specifically about <br>Windows Forms, Windows Presentation Foundation (WPF), Silverlight, XML Web services, <br>
<b> </b><br>
<b> </b><br>
<b>xv</b><br>
<hr>
<A name=16></a><IMG src="CLRviaCsharp-16_1.jpg"><br>
<b>xvi </b><br>
<b>Introduction</b><br>
Web Forms, and so on, the technologies presented in the book are applicable to <i>all</i> these <br>application types.<br>
The book addresses Microsoft Visual Studio 2010, .NET Framework version 4.0, and version 4.0 <br>of the C# programming language. Since Microsoft tries to maintain a large degree of back-<br>ward compatibility when releasing a new version of these technologies, many of the things  <br>I discuss in this book apply to earlier versions as well. All the code samples use the C#  <br>programming language as a way to demonstrate the behavior of the various facilities. But, <br>since the CLR is usable by many programming languages, the book's content is still quite  <br>applicable for the non-C# programmer. <br>
<b>Note  </b>You can download the code shown in the book from Wintellect's Web site  <br>(<i>http://Wintellect.com</i>). In some parts of the book, I describe classes in my own Power  <br>Threading Library. This library is available free of charge and can also be downloaded from <br>Wintellect's Web site.<br>
Today, Microsoft offers several versions of the CLR. There is the desktop/server version, which <br>runs on 32-bit x86 versions of Microsoft Windows as well as 64-bit x64 and IA64 versions <br>of Windows. There is the Silverlight version, which is produced from the same source code <br>base as the desktop/server version of the .NET Framework's CLR. Therefore, everything in this <br>book applies to building Silverlight applications, with the exception of some differences in <br>how Silverlight loads assemblies. There is also a "lite" version of the .NET Framework called <br>the .NET Compact Framework, which is available for Windows Mobile phones and other  <br>devices running the Windows CE operating system. Much of the information presented in <br>this book is applicable to developing applications for the .NET Compact Framework, but this <br>platform is not the primary focus of this book.<br>
On December 13, 2001, ECMA International (<i>http://www.ecma-international.org/</i>) accepted <br>the C# programming language, portions of the CLR, and portions of the FCL as standards. <br>The standards documents that resulted from this have allowed other organizations to build <br>ECMA-compliant versions of these technologies for other CPU architectures, as well as other <br>operating systems. In fact, Novell produces Moonlight (<i>http://www.mono-project.com <br>/Moonlight</i>), an open-source implementation of Silverlight (<i>http://Silverlight.net</i>) that is  <br>primarily for Linux and other UNIX/X11-based operating systems. Moonlight is based on the <br>ECMA specifications. Much of the content in this book is about these standards; therefore, <br>many will find this book useful for working with any runtime/library implementation that ad-<br>heres to the ECMA standard.<br>
<hr>
<A name=17></a><IMG src="CLRviaCsharp-17_1.jpg"><br>
<b> </b><br>
<b>Introduction </b><br>
<b>xvii</b><br>
<b>Note  </b> My editors and I have worked hard to bring you the most accurate, up-to-date, in-depth, <br>
easy-to-read, painless-to-understand, bug-free information. Even with this fantastic team  <br>assembled, however, things inevitably slip through the cracks. If you find any mistakes in this <br>book (especially bugs) or have some constructive feedback, I would greatly appreciate it if you <br>would contact me at <i>JeffreyR@Wintellect.com</i>.<br>
<b>Dedication</b><br>
<b>To Kristin  </b>Words cannot express how I feel about our life together. I cherish our family and <br>all our adventures. I'm filled each day with love for you.<br>
<b>To Aidan (age 6) and Grant (age 2)  </b>You both have been an inspiration to me and have <br>taught me to play and have fun. Watching the two of you grow up has been so rewarding <br>and enjoyable for me. I am lucky to be able to partake in your lives. I love and appreciate you <br>more than you could ever know.<br>
<b>Acknowledgments</b><br>
I couldn't have written this book without the help and technical assistance of many people. <br>In particular, I'd like to thank my family. The amount of time and effort that goes into writing <br>a book is hard to measure. Al  I know is that I could not have produced this book without the <br>support of my wife, Kristin, and my two sons, Aidan and Grant. There were many times when <br>we wanted to spend time together but were unable to due to book obligations. Now that the <br>book project is completed, I really look forward to adventures we will all share together.<br>
For this book revision, I truly had some fantastic people helping me. Christophe Nasarre, <br>who I've worked with on several book projects, has done just a phenomenal job of verifying <br>my work and making sure that I'd said everything the best way it could possibly be said. He <br>has truly had a significant impact on the quality of this book. As always, the Microsoft Press <br>editorial team is a pleasure to work with. I'd like to extend a special thank you to Ben Ryan, <br>Valerie Woolley, and Devon Musgrave. Also, thanks to Jean Findley and Sue McClung for <br>their editing and production support.<br>
<b>Support for This Book</b><br>
Every effort has been made to ensure the accuracy of this book. As corrections or changes <br>are collected, they will be added to a Microsoft Knowledge Base article accessible via the <br>Microsoft Help and Support site. Microsoft Press provides support for books, including  <br>instructions for finding Knowledge Base articles, at the following Web site:<br>
<i>http://www.microsoft.com/learning/support/books/</i><br>
<hr>
<A name=18></a><IMG src="CLRviaCsharp-18_1.jpg"><br>
<b>xviii </b><br>
<b>Introduction</b><br>
If you have questions regarding the book that are not answered by visiting the site above  <br>or viewing a Knowledge Base article, send them to Microsoft Press via e-mail to  <br>mspinput@microsoft.com.<br>
Please note that Microsoft software product support is not offered through these addresses.<br>
<b>We Want to Hear from You</b><br>
We welcome your feedback about this book. Please share your comments and ideas via the <br>following short survey:<br>
<i>http://www.microsoft.com/learning/booksurvey</i><br>
Your participation will help Microsoft Press create books that better meet your needs and <br>standards. <br>
<b>Note</b>  We hope that you will give us detailed feedback via our survey. If you have questions <br>about our publishing program, upcoming titles, or Microsoft Press in general, we encourage you <br>to interact with us via Twitter at <i>http://twitter.com/MicrosoftPress</i>. For support issues, use only the <br>e-mail address shown above.<br>
<hr>
<A name=19></a>Chapter 1<br><b>The CLR's Execution Model</b><br>
<b>In this chapter:<br>Compiling Source Code into Managed Modules. . . . . . . . . . . . . . . . . . . . . . . . . . . . 1<br>Combining Managed Modules into Assemblies  . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5<br>Loading the Common Language Runtime . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6<br>Executing Your Assembly's Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9<br>The Native Code Generator Tool: NGen.exe. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18<br>The Framework Class Library. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20<br>The Common Type System  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22<br>The Common Language Specification. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25<br>Interoperability with Unmanaged Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29</b><br>
The Microsoft .NET Framework introduces many new concepts, technologies, and terms. My <br>goal in this chapter is to give you an overview of how the .NET Framework is designed, intro-<br>duce you to some of the new technologies the framework includes, and define many of the <br>terms you'll be seeing when you start using it. I'll also take you through the process of build-<br>ing your source code into an application or a set of redistributable components (files) that <br>contain types (classes, structures, etc.) and then explain how your application will execute.<br>
<b>Compiling Source Code into Managed Modules</b><br>
OK, so you've decided to use the .NET Framework as your development platform. Great! Your <br>first step is to determine what type of application or component you intend to build. Let's <br>just assume that you've completed this minor detail; everything is designed, the specifica-<br>tions are written, and you're ready to start development.<br>
Now you must decide which programming language to use. This task is usually difficult  <br>because different languages offer different capabilities. For example, in unmanaged C/C++, <br>you have pretty low-level control of the system. You can manage memory exactly the way <br>you want to, create threads easily if you need to, and so on. Microsoft Visual Basic 6, on the <br>other hand, allows you to build UI applications very rapidly and makes it easy for you to  <br>control COM objects and databases.<br>
The common language runtime (CLR) is just what its name says it is: a runtime that is usable by <br>different and varied programming languages. The core features of the CLR (such as memory <br>
<b> </b><br>
<b> </b><br>
<b>1</b><br>
<hr>
<A name=20></a><b>2 </b><br>
<b>Part I  CLR Basics</b><br>
management, assembly loading, security, exception handling, and thread synchronization) <br>are available to any and all programming languages that target it--period. For example, the <br>runtime uses exceptions to report errors, so all languages that target the runtime also get <br>errors reported via exceptions. Another example is that the runtime also allows you to create <br>a thread, so any language that targets the runtime can create a thread.<br>
In fact, at runtime, the CLR has no idea which programming language the developer used for <br>the source code. This means that you should choose whatever programming language allows <br>you to express your intentions most easily. You can develop your code in any programming <br>language you desire as long as the compiler you use to compile your code targets the CLR.<br>
So, if what I say is true, what is the advantage of using one programming language over  <br>another? Well, I think of compilers as syntax checkers and "correct code" analyzers. They  <br>examine your source code, ensure that whatever you've written makes some sense, and then <br>output code that describes your intention. Different programming languages allow you to <br>develop using different syntax. Don't underestimate the value of this choice. For mathemati-<br>cal or financial applications, expressing your intentions by using APL syntax can save many <br>days of development time when compared to expressing the same intention by using Perl <br>syntax, for example.<br>
Microsoft has created several language compilers that target the runtime: C++/CLI, C# (pro-<br>nounced "C sharp"), Visual Basic, F# (pronounced "F sharp"), Iron Python, Iron Ruby, and an <br>Intermediate Language (IL) Assembler. In addition to Microsoft, several other companies, col-<br>leges, and universities have created compilers that produce code to target the CLR. I'm aware <br>of compilers for Ada, APL, Caml, COBOL, Eiffel, Forth, Fortran, Haskell, Lexico, LISP, LOGO, <br>Lua, Mercury, ML, Mondrian, Oberon, Pascal, Perl, Php, Prolog, RPG, Scheme, Smalltalk, and <br>Tcl/Tk.<br>
Figure 1-1 shows the process of compiling source code files. As the figure shows, you can cre-<br>ate source code files written in any programming language that supports the CLR. Then you <br>use the corresponding compiler to check the syntax and analyze the source code. Regardless <br>of which compiler you use, the result is a <i>managed module</i>. A managed module is a standard <br>32-bit Microsoft Windows portable executable (PE32) file or a standard 64-bit Windows  <br>portable executable (PE32+) file that requires the CLR to execute. By the way, managed  <br>assemblies always take advantage of Data Execution Prevention (DEP) and Address Space <br>Layout Randomization (ASLR) in Windows; these two features improve the security of your <br>whole system.<br>
<hr>
<A name=21></a><b> </b><br>
<b>Chapter 1  The CLR's Execution Model </b><br>
<b>3</b><br>
C#<br>
Basic<br>
IL <br>
source code<br>
source code<br>
source code<br>
file(s)<br>
file(s)<br>
file(s)<br>
C#<br>
Basic<br>
IL<br>
compiler<br>
compiler<br>
Assembler<br>
Managed module<br>
Managed module<br>
Managed module<br>
(IL and metadata)<br>
(IL and metadata)<br>
(IL and metadata)<br>
<b>FIGURE 1-1</b>  Compiling source code into managed modules<br>
Table 1-1 describes the parts of a managed module.<br>
<b>TABLE 1-1  Parts of a Managed Module</b><br>
<b>Part</b><br>
<b>Description</b><br>
PE32 or PE32+ header<br>
The standard Windows PE file header, which is similar to the Common <br>Object File Format (COFF) header. If the header uses the PE32 format, <br>the file can run on a 32-bit or 64-bit version of Windows. If the header <br>uses the PE32+ format, the file requires a 64-bit version of Windows <br>to run. This header also indicates the type of file: GUI, CUI, or DLL, and <br>contains a timestamp indicating when the file was built. For modules <br>that contain only IL code, the bulk of the information in the PE32(+) <br>header is ignored. For modules that contain native CPU code, this <br>header contains information about the native CPU code.<br>
CLR header<br>
Contains the information (interpreted by the CLR and utilities) that <br>makes this a managed module. The header includes the version of the <br>CLR required, some flags, the MethodDef metadata token of the  <br>managed module's entry point method (Main method), and the  <br>location/size of the module's metadata, resources, strong name, some <br>flags, and other less interesting stuff.<br>
Metadata<br>
Every managed module contains metadata tables. There are two main <br>types of tables: tables that describe the types and members defined <br>in your source code and tables that describe the types and members <br>referenced by your source code.<br>
IL code<br>
Code the compiler produced as it compiled the source code. At  <br>runtime, the CLR compiles the IL into native CPU instructions.<br>
Native code compilers produce code targeted to a specific CPU architecture, such as x86, <br>x64, or IA64. All CLR-compliant compilers produce IL code instead. (I'll go into more detail <br>about IL code later in this chapter.) IL code is sometimes referred to as <i>managed code </i> <br>because the CLR manages its execution.<br>
<hr>
<A name=22></a><b>4 </b><br>
<b>Part I  CLR Basics</b><br>
In addition to emitting IL, every compiler targeting the CLR is required to emit full <i>metadata</i> <br>into every managed module. In brief, metadata is a set of data tables that describe what <br>is defined in the module, such as types and their members. In addition, metadata also has <br>tables indicating what the managed module references, such as imported types and their <br>members. Metadata is a superset of older technologies such as COM's Type Libraries and <br>Interface Definition Language (IDL) files. The important thing to note is that CLR metadata is <br>far more complete. And, unlike Type Libraries and IDL, metadata is always associated with the <br>file that contains the IL code. In fact, the metadata is always embedded in the same EXE/DLL <br>as the code, making it impossible to separate the two. Because the compiler produces the <br>metadata and the code at the same time and binds them into the resulting managed module, <br>the metadata and the IL code it describes are never out of sync with one another.<br>
Metadata has many uses. Here are some of them:<br>
  Metadata removes the need for native C/C++ header and library files when compiling <br>
because all the information about the referenced types/members is contained in the <br>file that has the IL that implements the type/members. Compilers can read metadata <br>directly from managed modules.<br>
  Microsoft Visual Studio uses metadata to help you write code. Its IntelliSense feature <br>
parses metadata to tell you what methods, properties, events, and fields a type offers, <br>and in the case of a method, what parameters the method expects.<br>
  The CLR's code verification process uses metadata to ensure that your code performs <br>
only "type-safe" operations. (I'll discuss verification shortly.)<br>
  Metadata allows an object's fields to be serialized into a memory block, sent to another <br>
machine, and then deserialized, re-creating the object's state on the remote machine.<br>
  Metadata allows the garbage collector to track the lifetime of objects. For any object, <br>
the garbage collector can determine the type of the object and, from the metadata, <br>know which fields within that object refer to other objects.<br>
In Chapter 2, "Building, Packaging, Deploying, and Administering Applications and Types," I'll <br>describe metadata in much more detail.<br>
Microsoft's C#, Visual Basic, F#, and the IL Assembler always produce modules that contain <br>managed code (IL) and managed data (garbage-collected data types). End users must have <br>the CLR (presently shipping as part of the .NET Framework) installed on their machine in  <br>order to execute any modules that contain managed code and/or managed data in the same <br>way that they must have the Microsoft Foundation Class (MFC) library or Visual Basic DLLs <br>installed to run MFC or Visual Basic 6 applications.<br>
By default, Microsoft's C++ compiler builds EXE/DLL modules that contain unmanaged  <br>(native) code and manipulate unmanaged data (native memory) at runtime. These modules <br>don't require the CLR to execute. However, by specifying the /CLR command-line switch, the <br>C++ compiler produces modules that contain managed code, and of course, the CLR must <br>
<hr>
<A name=23></a><b> </b><br>
<b>Chapter 1  The CLR's Execution Model </b><br>
<b>5</b><br>
then be installed to execute this code. Of all of the Microsoft compilers mentioned, C++ is <br>unique in that it is the only compiler that allows the developer to write both managed and <br>unmanaged code and have it emitted into a single module. It is also the only Microsoft  <br>compiler that allows developers to define both managed and unmanaged data types in their <br>source code. The flexibility provided by Microsoft's C++ compiler is unparalleled by other <br>compilers because it allows developers to use their existing native C/C++ code from man-<br>aged code and to start integrating the use of managed types as they see fit.<br>
<b>Combining Managed Modules into Assemblies</b><br>
The CLR doesn't actually work with modules, it works with assemblies. An <i>assembly</i> is an  <br>abstract concept that can be difficult to grasp initially. First, an assembly is a logical grouping <br>of one or more modules or resource files. Second, an assembly is the smallest unit of reuse, <br>security, and versioning. Depending on the choices you make with your compilers or tools, <br>you can produce a single-file or a multifile assembly. In the CLR world, an assembly is what <br>we would call a <i>component</i>.<br>
In Chapter 2, I'll go over assemblies in great detail, so I don't want to spend a lot of time on <br>them here. All I want to do now is make you aware that there is this extra conceptual notion <br>that offers a way to treat a group of files as a single entity.<br>
Figure 1-2 should help explain what assemblies are about. In this figure, some managed <br>modules and resource (or data) files are being processed by a tool. This tool produces a single <br>PE32(+) file that represents the logical grouping of files. What happens is that this PE32(+) file <br>contains a block of data called the <i>manifest</i>. The manifest is simply another set of metadata <br>tables. These tables describe the files that make up the assembly, the publicly exported types <br>implemented by the files in the assembly, and the resource or data files that are associated <br>with the assembly.<br>
Managed module<br>
Assembly<br>
(IL and metadata)<br>
Tool combining multiple<br>
(Manifest: describes the<br>
managed modules and<br>
set of files in the assembly)<br>
Managed module<br>
resource files into<br>
(IL and metadata)<br>
an assembly<br>
Managed module<br>
(IL and metadata)<br>
C# compiler<br>
Managed module<br>
(CSC.exe),<br>
(IL and metadata)<br>
Visual Basic compiler<br>
Resource file<br>
Resource file<br>
(VBC.exe),<br>
(.jpeg, .gif, .html, etc.)<br>
(.jpeg, .gif, .html, etc.)<br>
Assembly Linker<br>
Resource file<br>
(AL.exe)<br>
(.jpeg, .gif, .html, etc.)<br>
Resource file<br>
(.jpeg, .gif, .html, etc.)<br>
<b>FIGURE 1-2</b>  Combining managed modules into assemblies<br>
<hr>
<A name=24></a><b>6 </b><br>
<b>Part I  CLR Basics</b><br>
By default, compilers actually do the work of turning the emitted managed module into an <br>assembly; that is, the C# compiler emits a managed module that contains a manifest. The <br>manifest indicates that the assembly consists of just the one file. So, for projects that have <br>just one managed module and no resource (or data) files, the assembly will be the managed <br>module, and you don't have any additional steps to perform during your build process. If you <br>want to group a set of files into an assembly, you'll have to be aware of more tools (such as <br>the assembly linker, AL.exe) and their command-line options. I'll explain these tools and  <br>options in Chapter 2.<br>
An assembly allows you to decouple the logical and physical notions of a reusable, securable, <br>versionable component. How you partition your code and resources into different files is <br>completely up to you. For example, you could put rarely used types or resources in separate <br>files that are part of an assembly. The separate files could be downloaded on demand from <br>the Web as they are needed at runtime. If the files are never needed, they're never down-<br>loaded, saving disk space and reducing installation time. Assemblies allow you to break up <br>the deployment of the files while still treating all of the files as a single collection.<br>
An assembly's modules also include information about referenced assemblies (including their <br>version numbers). This information makes an assembly <i>self-describing</i>. In other words, the CLR <br>can determine the assembly's immediate dependencies in order for code in the assembly to <br>execute. No additional information is required in the registry or in Active Directory Domain <br>Services (AD DS). Because no additional information is needed, deploying assemblies is much <br>easier than deploying unmanaged components.<br>
<b>Loading the Common Language Runtime</b><br>
Each assembly you build can be either an executable application or a DLL containing a set <br>of types for use by an executable application. Of course, the CLR is responsible for man-<br>aging the execution of code contained within these assemblies. This means that the .NET <br>Framework must be installed on the host machine. Microsoft has created a redistribution <br>package that you can freely ship to install the .NET Framework on your customers' machines. <br>Some versions of Windows ship with the .NET Framework already installed.<br>
You can tell if the .NET Framework has been installed by looking for the MSCorEE.dll file <br>in the %SystemRoot%\System32 directory. The existence of this file tells you that the .NET <br>Framework is installed. However, several versions of the .NET Framework can be installed on <br>a single machine simultaneously. If you want to determine exactly which versions of the .NET <br>Framework are installed, examine the subkeys under the following registry key:<br>
HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\NET Framework Setup\NDP<br>
The .NET Framework SDK includes a command-line utility called CLRVer.exe that shows all of <br>the CLR versions installed on a machine. This utility can also show which version of the CLR is <br>
<hr>
<A name=25></a><IMG src="CLRviaCsharp-25_1.jpg"><br>
<b> </b><br>
<b>Chapter 1  The CLR's Execution Model </b><br>
<b>7</b><br>
being used by processes currently running on the machine by using the <b>­all</b> switch or passing <br>the ID of the process you are interested in.<br>
Before we start looking at how the CLR loads, we need to spend a moment discussing 32-bit <br>and 64-bit versions of Windows. If your assembly files contain only type-safe managed code, <br>you are writing code that should work on both 32-bit and 64-bit versions of Windows. No <br>source code changes are required for your code to run on either version of Windows. In fact, <br>the resulting EXE/DLL file produced by the compiler will run on 32-bit Windows as well as the <br>x64 and IA64 versions of 64-bit Windows! In other words, the one file wil  run on any machine <br>that has a version of the .NET Framework installed on it.<br>
On extremely rare occasions, developers want to write code that works only on a specific ver-<br>sion of Windows. Developers might do this when using unsafe code or when interoperating <br>with unmanaged code that is targeted to a specific CPU architecture. To aid these developers, <br>the C# compiler offers a /platform command-line switch. This switch allows you to specify <br>whether the resulting assembly can run on x86 machines running 32-bit Windows versions <br>only, x64 machines running 64-bit Windows only, or Intel Itanium machines running 64-bit <br>Windows only. If you don't specify a platform, the default is anycpu, which indicates that  <br>the resulting assembly can run on any version of Windows. Users of Visual Studio can set a <br>project's target platform by displaying the project's property pages, clicking the Build tab, <br>and then selecting an option in the Platform Target list (see Figure 1-3).<br>
<b>FIGURE 1-3</b>  Setting the platform target by using Visual Studio<br>
Depending on the platform switch, the C# compiler will emit an assembly that contains either <br>a PE32 or PE32+ header, and the compiler will also emit the desired CPU architecture (or  <br>
<hr>
<A name=26></a><b>8 </b><br>
<b>Part I  CLR Basics</b><br>
agnostic) into the header as well. Microsoft ships two SDK command-line utilities, DumpBin.<br>exe and CorFlags.exe, that you can use to examine the header information emitted in a  <br>managed module by the compiler.<br>
When running an executable file, Windows examines this EXE file's header to determine <br>whether the application requires a 32-bit or 64-bit address space. A file with a PE32 header <br>can run with a 32-bit or 64-bit address space, and a file with a PE32+ header requires a 64-bit <br>address space. Windows also checks the CPU architecture information embedded inside the <br>header to ensure that it matches the CPU type in the computer. Lastly, 64-bit versions of <br>Windows offer a technology that allows 32-bit Windows applications to run. This technology <br>is called <i>WoW64</i> (for Windows on Windows64). This technology even allows 32-bit applica-<br>tions with x86 native code in them to run on an Itanium machine, because the WoW64 tech-<br>nology can emulate the x86 instruction set; albeit with a significant performance cost.<br>
Table 1-2 shows two things. First, it shows what kind of managed module you get when you <br>specify various /platform command-line switches to the C# compiler. Second, it shows how <br>that application will run on various versions of Windows.<br>
<b>TABLE 1-2  Effects of </b>/platform<b> on Resulting Module and at Runtime</b><br>
<b>/platform </b><br>
<b>Resulting  </b><br>
<b>Switch</b><br>
<b>Managed Module</b><br>
<b>x86 Windows</b><br>
<b>x64 Windows</b><br>
<b>IA64 Windows</b><br>
anycpu<br>
PE32/agnostic<br>
Runs as a 32-bit <br>
Runs as a 64-bit  <br>
Runs as a 64-bit <br>
(the default)<br>
application<br>
application<br>
application<br>
x86<br>
PE32/x86<br>
Runs as a 32-bit <br>
Runs as a WoW64 <br>
Runs as a WoW64 <br>
application<br>
application<br>
application<br>
x64<br>
PE32+/x64<br>
Doesn't run<br>
Runs as a 64-bit  <br>
Doesn't run<br>
application<br>
Itanium<br>
PE32+/Itanium<br>
Doesn't run<br>
Doesn't run<br>
Runs as a 64-bit <br>application<br>
After Windows has examined the EXE file's header to determine whether to create a 32-bit <br>process, a 64-bit process, or a WoW64 process, Windows loads the x86, x64, or IA64 version of <br>MSCorEE.dll into the process's address space. On an x86 version of Windows, the x86 version <br>of MSCorEE.dll can be found in the C:\Windows\System32 directory. On an x64 or IA64 ver-<br>sion of Windows, the x86 version of MSCorEE.dll can be found in the C:\Windows\SysWow64 <br>directory, whereas the 64-bit version (x64 or IA64) can be found in the C:\Windows\System32 <br>directory (for backward compatibility reasons). Then, the process's primary thread calls a <br>method defined inside MSCorEE.dll. This method initializes the CLR, loads the EXE assembly, <br>and then calls its entry point method (Main). At this point, the managed application is up and <br>running.1<br>
1  Your code can query Environment's Is64BitOperatingSystem property to determine if it is running on a  <br>
64-bit version of Windows. Your code can also query Environment's Is64BitProcess property to determine if  <br>it is running in a 64-bit address space.<br>
<hr>
<A name=27></a><IMG src="CLRviaCsharp-27_1.jpg"><br>
<b> </b><br>
<b>Chapter 1  The CLR's Execution Model </b><br>
<b>9</b><br>
 <br>
<b>Note</b>  Assemblies built by using version 1.0 or 1.1 of Microsoft's C# compiler contain a PE32 <br>header and are CPU-architecture agnostic. However, at load time, the CLR considers these  <br>assemblies to be x86 only. For executable files, this improves the likelihood of the application  <br>actually working on a 64-bit system because the executable file will load in WoW64, giving the <br>process an environment very similar to what it would have on a 32-bit x86 version of Windows.<br>
If an unmanaged application calls LoadLibrary to load a managed assembly, Windows <br>knows to load and initialize the CLR (if not already loaded) in order to process the code con-<br>tained within the assembly. Of course, in this scenario, the process is already up and running, <br>and this may limit the usability of the assembly. For example, a managed assembly compiled <br>with the /platform:x86 switch will not be able to load into a 64-bit process at all, whereas <br>an executable file compiled with this same switch would have loaded in WoW64 on a com-<br>puter running a 64-bit version of Windows.<br>
<b>Executing Your Assembly's Code</b><br>
As mentioned earlier, managed assemblies contain both metadata and IL. IL is a CPU-<br>independent machine language created by Microsoft after consultation with several external <br>commercial and academic language/compiler writers. IL is a much higher-level language than <br>most CPU machine languages. IL can access and manipulate object types and has instructions <br>to create and initialize objects, call virtual methods on objects, and manipulate array elements <br>directly. It even has instructions to throw and catch exceptions for error handling. You can <br>think of IL as an object-oriented machine language.<br>
Usually, developers will program in a high-level language, such as C#, C++/CLI, or Visual <br>Basic. The compilers for these high-level languages produce IL. However, as any other  <br>machine language, IL can be written in assembly language, and Microsoft does provide an IL <br>Assembler, ILAsm.exe. Microsoft also provides an IL Disassembler, ILDasm.exe.<br>
Keep in mind that any high-level language will most likely expose only a subset of the facili-<br>ties offered by the CLR. However, the IL assembly language allows a developer to access all <br>of the CLR's facilities. So, should your programming language of choice hide a facility the CLR <br>offers that you really want to take advantage of, you can choose to write that portion of your <br>code in IL assembly or perhaps another programming language that exposes the CLR feature <br>you seek.<br>
The only way for you to know what facilities the CLR offers is to read documentation specific to <br>the CLR itself. In this book, I try to concentrate on CLR features and how they are exposed or <br>not exposed by the C# language. I suspect that most other books and articles wil  present the <br>CLR via a language perspective, and that most developers wil  come to believe that the CLR  <br>offers only what the developer's chosen language exposes. As long as your language al ows <br>you to accomplish what you're trying to get done, this blurred perspective isn't a bad thing.<br>
<hr>
<A name=28></a><IMG src="CLRviaCsharp-28_1.jpg"><br>
<b>10 </b><br>
<b>Part I  CLR Basics</b><br>
<b>Important  </b>I think this ability to switch programming languages easily with rich integration  <br>between languages is an awesome feature of the CLR. Unfortunately, I also believe that develop-<br>ers will often overlook this feature. Programming languages such as C# and Visual Basic are  <br>excellent languages for performing I/O operations. APL is a great language for performing  <br>advanced engineering or financial calculations. Through the CLR, you can write the I/O portions <br>of your application in C# and then write the engineering calculations part in APL. The CLR offers <br>a level of integration between these languages that is unprecedented and really makes mixed-<br>language programming worthy of consideration for many development projects.<br>
To execute a method, its IL must first be converted to native CPU instructions. This is the job <br>of the CLR's JIT (just-in-time) compiler.<br>
Figure 1-4 shows what happens the first time a method is called.<br>
Console<br>
Managed EXE<br>
static void WriteLine()<br>
JITCompiler<br>
static void Main() {<br>   Console.WriteLine("Hello");<br>   Console.WriteLine("Goodbye");<br>
}<br>
static void WriteLine(string)<br>
JITCompiler<br>
Native CPU<br>
instructions<br>
(remaining members)<br>
...<br>
MSCorEE.dll<br>
JITCompiler function {<br>
1.  In the assembly that implements the type<br>
 (Console), look up the method (WriteLine) <br> being called in the metadata.<br>
2.  From the metadata, get the IL for this method.<br>3.  Allocate a block of memory.<br>4.  Compile the IL into native CPU instructions;<br>
 the native code is saved in the memory<br> allocated in step 3.<br>
5.  Modify the method's entry in the Type's table so<br>
 that it now points to the memory block allocated<br> in step 3.<br>
6.  Jump to the native code contained inside the<br>
 memory block.<br>
}<br>
<b>FIGURE 1-4</b>  Calling a method for the first time<br>
<hr>
<A name=29></a><IMG src="CLRviaCsharp-29_1.jpg"><br>
<b> </b><br>
<b>Chapter 1  The CLR's Execution Model </b><br>
<b>11</b><br>
Just before the Main method executes, the CLR detects all of the types that are referenced <br>by Main's code. This causes the CLR to allocate an internal data structure that is used to man-<br>age access to the referenced types. In Figure 1-4, the Main method refers to a single type, <br>Console, causing the CLR to allocate a single internal structure. This internal data structure <br>contains an entry for each method defined by the Console type. Each entry holds the ad-<br>dress where the method's implementation can be found. When initializing this structure, the <br>CLR sets each entry to an internal, undocumented function contained inside the CLR itself. I <br>call this function JITCompiler.<br>
When Main makes its first call to WriteLine, the JITCompiler function is called. The <br>JITCompiler function is responsible for compiling a method's IL code into native CPU  <br>instructions. Because the IL is being compiled "just in time," this component of the CLR is  <br>frequently referred to as a <i>JITter </i>or a <i>JIT compiler</i>.<br>
<b>Note  </b>If the application is running on an x86 version of Windows or in WoW64, the JIT compiler <br>produces x86 instructions. If your application is running as a 64-bit application on an x64 or <br>Itanium version of Windows, the JIT compiler produces x64 or IA64 instructions, respectively.<br>
When called, the JITCompiler function knows what method is being called and what type <br>defines this method. The JITCompiler function then searches the defining assembly's  <br>metadata for the called method's IL. JITCompiler next verifies and compiles the IL code <br>into native CPU instructions. The native CPU instructions are saved in a dynamically allocated <br>block of memory. Then, JITCompiler goes back to the entry for the called method in the <br>type's internal data structure created by the CLR and replaces the reference that called it in <br>the first place with the address of the block of memory containing the native CPU instructions <br>it just compiled. Finally, the JITCompiler function jumps to the code in the memory block. <br>This code is the implementation of the WriteLine method (the version that takes a String <br>parameter). When this code returns, it returns to the code in Main, which continues execution <br>as normal.<br>
Main now calls WriteLine a second time. This time, the code for WriteLine has already <br>been verified and compiled. So the call goes directly to the block of memory, skipping the <br>JITCompiler function entirely. After the WriteLine method executes, it returns to Main. <br>Figure 1-5 shows what the process looks like when WriteLine is called the second time.<br>
<hr>
<A name=30></a><b>12 </b><br>
<b>Part I  CLR Basics</b><br>
Console<br>
Managed EXE<br>
static void WriteLine()<br>
JITCompiler<br>
static void Main() {<br>   Console.WriteLine("Hello");<br>   Console.WriteLine("Goodbye");<br>
}<br>
static void WriteLine(string)<br>
Native<br>
Native CPU<br>
instructions<br>
(remaining members)<br>
...<br>
MSCorEE.dll<br>
JITCompiler function {<br>
1.  In the assembly that implements the typ<br>
bly that implements t<br>
e<br>
 (Console), look up the metho<br>
, look up the method ( iteLine<br>
Writ<br>
) <br>
 being called in the metadata.<br>
alled in the<br>
2.  From the metadata, get the IL for this method.<br>
the metadata, get the IL for this me<br>
3.  Allocate a block of<br>
ate a block   memor<br>
of mem y.<br>
4.  Compile the IL into native CPU instructions<br>
pile the IL into native CPU instruction ;<br>
 the native code is saved in the memo<br>
ative code is saved in the memory<br>
 allocated in step 3.<br>
ated in<br>
5.  Modify the method'<br>
fy<br>
s entr<br>
 the method'<br>
y in the Type'<br>
y in the T<br>
s table so<br>
ype's t<br>
 that it now points to the memor<br>
now points to the memory block allocate<br>
y block a<br>
d<br>
 in step 3.<br>
6.  Jump to the native code contained inside th<br>
e native code contained in<br>
e<br>
 memory blockk.<br>
}<br>
<b>FIGURE 1-5</b>  Calling a method for the second time<br>
A performance hit is incurred only the first time a method is called. All subsequent calls to <br>the method execute at the full speed of the native code because verification and compilation <br>to native code don't need to be performed again.<br>
The JIT compiler stores the native CPU instructions in dynamic memory. This means that the <br>compiled code is discarded when the application terminates. So if you run the application <br>again in the future or if you run two instances of the application simultaneously (in two  <br>different operating system processes), the JIT compiler will have to compile the IL to native <br>instructions again.<br>
For most applications, the performance hit incurred by JIT compiling isn't significant. Most <br>applications tend to call the same methods over and over again. These methods will take the <br>performance hit only once while the application executes. It's also likely that more time is <br>spent inside the method than calling the method.<br>
<hr>
<A name=31></a><b> </b><br>
<b>Chapter 1  The CLR's Execution Model </b><br>
<b>13</b><br>
You should also be aware that the CLR's JIT compiler optimizes the native code just as the <br>back end of an unmanaged C++ compiler does. Again, it may take more time to produce the <br>optimized code, but the code will execute with much better performance than if it hadn't <br>been optimized.<br>
There are two C# compiler switches that impact code optimization: /optimize and /debug. <br>The following table shows the impact these switches have on the quality of the IL code gen-<br>erated by the C# compiler and the quality of the native code generated by the JIT compiler:<br>
<b>Compiler Switch Settings</b><br>
<b>C# IL Code Quality</b><br>
<b>JIT Native Code Quality</b><br>
/optimize- /debug-<br>
Unoptimized<br>
Optimized<br>
(this is the default)<br>
/optimize- /debug(+/full/pdbonly)<br>
Unoptimized<br>
Unoptimized<br>
/optimize+ /debug(-/+/full/pdbonly)<br>
Optimized<br>
Optimized<br>
With /optimize-, the unoptimized IL code produced by the C# compiler contains many <br>no-operation (NOP) instructions and also branches that jump to the next line of code. These <br>instructions are emitted to enable the edit-and-continue feature of Visual Studio while de-<br>bugging and the extra instructions also make code easier to debug by allowing breakpoints <br>to be set on control flow instructions such as for, while, do, if, else, try, catch, and finally <br>statement blocks. When producing optimized IL code, the C# compiler will remove these <br>extraneous NOP and branch instructions, making the code harder to single-step through in <br>a debugger as control flow will be optimized. Also, some function evaluations may not work <br>when performed inside the debugger. However, the IL code is smaller, making the resulting <br>EXE/DLL file smaller, and the IL tends to be easier to read for those of you (like me) who  <br>enjoy examining the IL to understand what the compiler is producing.<br>
Furthermore, the compiler produces a Program Database (PDB) file only if you specify the  <br>/debug(+/full/pdbonly) switch. The PDB file helps the debugger find local variables and <br>map the IL instructions to source code. The /debug:full switch tells the JIT compiler that <br>you intend to debug the assembly, and the JIT compiler will track what native code came <br>from each IL instruction. This allows you to use the just-in-time debugger feature of Visual <br>Studio to connect a debugger to an already-running process and debug the code easily. <br>Without the /debug:full switch, the JIT compiler does not, by default, track the IL to  <br>native code information which makes the JIT compiler run a little faster and also uses a little <br>less memory. If you start a process with the Visual Studio debugger, it forces the JIT compiler <br>to track the IL to native code information (regardless of the /debug switch) unless you turn <br>off the Suppress JIT Optimization On Module Load (Managed Only) option in Visual Studio.<br>
When you create a new C# project in Visual Studio, the Debug configuration of the project <br>has /optimize- and /debug:full switches, and the Release configuration has /optimize+ <br>and /debug:pdbonly switches specified.<br>
<hr>
<A name=32></a><b>14 </b><br>
<b>Part I  CLR Basics</b><br>
For those developers coming from an unmanaged C or C++ background, you're probably <br>thinking about the performance ramifications of all this. After all, unmanaged code is com-<br>piled for a specific CPU platform, and, when invoked, the code can simply execute. In this <br>managed environment, compiling the code is accomplished in two phases. First, the compiler <br>passes over the source code, doing as much work as possible in producing IL. But to execute <br>the code, the IL itself must be compiled into native CPU instructions at runtime, requiring <br>more memory to be allocated and requiring additional CPU time to do the work.<br>
Believe me, since I approached the CLR from a C/C++ background myself, I was quite skepti-<br>cal and concerned about this additional overhead. The truth is that this second compilation <br>stage that occurs at runtime does hurt performance, and it does allocate dynamic memory. <br>However, Microsoft has done a lot of performance work to keep this additional overhead to a <br>minimum.<br>
If you too are skeptical, you should certainly build some applications and test the performance <br>for yourself. In addition, you should run some nontrivial managed applications Microsoft <br>or others have produced, and measure their performance. I think you'll be surprised at how <br>good the performance actually is.<br>
You'll probably find this hard to believe, but many people (including me) think that managed <br>applications could actually outperform unmanaged applications. There are many reasons <br>to believe this. For example, when the JIT compiler compiles the IL code into native code at <br>runtime, the compiler knows more about the execution environment than an unmanaged <br>compiler would know. Here are some ways that managed code can outperform unmanaged <br>code:<br>
  A JIT compiler can determine if the application is running on an Intel Pentium 4 CPU <br>
and produce native code that takes advantage of any special instructions offered by <br>the Pentium 4. Usually, unmanaged applications are compiled for the lowest-common-<br>denominator CPU and avoid using special instructions that would give the application a <br>performance boost.<br>
  A JIT compiler can determine when a certain test is always false on the machine that it <br>
is running on. For example, consider a method that contains the following code:<br>
if (numberOfCPUs &gt; 1) {  <br> ...  <br>}<br>
This code could cause the JIT compiler to not generate any CPU instructions if the host <br>machine has only one CPU. In this case, the native code would be fine-tuned for the <br>host machine; the resulting code is smaller and executes faster.<br>
  The CLR could profile the code's execution and recompile the IL into native code while <br>
the application runs. The recompiled code could be reorganized to reduce incorrect <br>branch predictions depending on the observed execution patterns. Current versions of <br>the CLR do not do this, but future versions might.<br>
<hr>
<A name=33></a><b> </b><br>
<b>Chapter 1  The CLR's Execution Model </b><br>
<b>15</b><br>
These are only a few of the reasons why you should expect future managed code to execute <br>better than today's unmanaged code. As I said, the performance is currently quite good for <br>most applications, and it promises to improve as time goes on.<br>
If your experiments show that the CLR's JIT compiler doesn't offer your application the kind <br>of performance it requires, you may want to take advantage of the NGen.exe tool that ships <br>with the .NET Framework SDK. This tool compiles all of an assembly's IL code into native code <br>and saves the resulting native code to a file on disk. At runtime, when an assembly is loaded, <br>the CLR automatically checks to see whether a precompiled version of the assembly also ex-<br>ists, and if it does, the CLR loads the precompiled code so that no compilation is required at <br>runtime. Note that NGen.exe must be conservative about the assumptions it makes regard-<br>ing the actual execution environment, and for this reason, the code produced by NGen.exe <br>will not be as highly optimized as the JIT compiler­produced code. I'll discuss NGen.exe in <br>more detail later in this chapter.<br>
<b>IL and Verification<br></b>IL is stack-based, which means that all of its instructions push operands onto an execution <br>stack and pop results off the stack. Because IL offers no instructions to manipulate registers, <br>it is easy for people to create new languages and compilers that produce code targeting the <br>CLR.<br>
IL instructions are also typeless. For example, IL offers an add instruction that adds the last <br>two operands pushed on the stack. There are no separate 32-bit and 64-bit versions of the <br>add instruction. When the add instruction executes, it determines the types of the operands <br>on the stack and performs the appropriate operation.<br>
In my opinion, the biggest benefit of IL isn't that it abstracts away the underlying CPU. The <br>biggest benefit IL provides is application robustness and security. While compiling IL into <br>native CPU instructions, the CLR performs a process called <i>verification</i>. Verification examines <br>the high-level IL code and ensures that everything the code does is safe. For example, verifi-<br>cation checks that every method is called with the correct number of parameters, that each <br>parameter passed to every method is of the correct type, that every method's return value is <br>used properly, that every method has a return statement, and so on. The managed module's <br>metadata includes all of the method and type information used by the verification process.<br>
In Windows, each process has its own virtual address space. Separate address spaces are nec-<br>essary because you can't trust an application's code. It is entirely possible (and unfortunately, <br>all too common) that an application will read from or write to an invalid memory address. By <br>placing each Windows process in a separate address space, you gain robustness and stability; <br>one process can't adversely affect another process.<br>
By verifying the managed code, however, you know that the code doesn't improperly access <br>memory and can't adversely affect another application's code. This means that you can run <br>multiple managed applications in a single Windows virtual address space.<br>
<hr>
<A name=34></a><IMG src="CLRviaCsharp-34_1.jpg"><br>
<b>16 </b><br>
<b>Part I  CLR Basics</b><br>
Because Windows processes require a lot of operating system resources, having many of <br>them can hurt performance and limit available resources. Reducing the number of processes <br>by running multiple applications in a single OS process can improve performance, require <br>fewer resources, and be just as robust as if each application had its own process. This is  <br>another benefit of managed code as compared to unmanaged code.<br>
The CLR does, in fact, offer the ability to execute multiple managed applications in a single <br>OS process. Each managed application executes in an AppDomain. By default, every managed <br>EXE file will run in its own separate address space that has just the one AppDomain. However, <br>a process hosting the CLR (such as Internet Information Services [IIS] or Microsoft SQL Server) <br>can decide to run AppDomains in a single OS process. I'll devote part of Chapter 22, "CLR <br>Hosting and AppDomains," to a discussion of AppDomains.<br>
<b>Unsafe Code</b><br>
By default, Microsoft's C# compiler produces safe code. <i>Safe code</i> is code that is verifiably <br>safe. However, Microsoft's C# compiler allows developers to write unsafe code. Unsafe code <br>is allowed to work directly with memory addresses and can manipulate bytes at these  <br>addresses. This is a very powerful feature and is typically useful when interoperating with  <br>unmanaged code or when you want to improve the performance of a time-critical algorithm.<br>
However, using unsafe code introduces a significant risk: unsafe code can corrupt data struc-<br>tures and exploit or even open up security vulnerabilities. For this reason, the C# compiler <br>requires that all methods that contain unsafe code be marked with the unsafe keyword. In <br>addition, the C# compiler requires you to compile the source code by using the /unsafe <br>compiler switch.<br>
When the JIT compiler attempts to compile an unsafe method, it checks to see if the assem-<br>bly containing the method has been granted the System.Security.Permissions.Security <br>Permission with the System.Security.Permissions.SecurityPermissionFlag's <br>SkipVerification flag set. If this flag is set, the JIT compiler will compile the unsafe code <br>and allow it to execute. The CLR is trusting this code and is hoping the direct address and  <br>byte manipulations do not cause any harm. If the flag is not set, the JIT compiler throws  <br>either a System.InvalidProgramException or a System.Security.VerificationException, <br>preventing the method from executing. In fact, the whole application will probably terminate <br>at this point, but at least no harm can be done.<br>
<b>Note  </b>By default, assemblies that load from the local machine or via network shares are granted <br>full trust, meaning that they can do anything, which includes executing unsafe code. However, by <br>default, assemblies executed via the Internet are not granted the permission to execute unsafe <br>code. If they contain unsafe code, one of the aforementioned exceptions is thrown. An adminis-<br>trator/end user can change these defaults; however, the administrator is taking full responsibility <br>for the code's behavior.<br>
<hr>
<A name=35></a><hr>
<A name=36></a><b>18 </b><br>
<b>Part I  CLR Basics</b><br>
<b>The Native Code Generator Tool: NGen.exe</b><br>
The NGen.exe tool that ships with the .NET Framework can be used to compile IL code to  <br>native code when an application is installed on a user's machine. Since the code is compiled <br>at install time, the CLR's JIT compiler does not have to compile the IL code at runtime, and <br>this <i>can</i> improve the application's performance. The NGen.exe tool is interesting in two <br>scenarios:<br>
<b>  Improving an application's startup time  </b>Running NGen.exe can improve startup time <br>
because the code will already be compiled into native code so that compilation doesn't <br>have to occur at runtime.<br>
<b>  Reducing an application's working set  </b>If you believe that an assembly will be loaded <br>
into multiple processes simultaneously, running NGen.exe on that assembly can reduce <br>the applications' working set. The reason is because the NGen.exe tool compiles the IL <br>to native code and saves the output in a separate file. This file can be memory-mapped <br>into multiple-process address spaces simultaneously, allowing the code to be shared; <br>not every process needs its own copy of the code.<br>
When a setup program invokes NGen.exe on an application or a single assembly, all of the <br>assemblies for that application or the one specified assembly have their IL code compiled <br>into native code. A new assembly file containing only this native code instead of IL code is  <br>created by NGen.exe. This new file is placed in a folder under the directory with a name like <br>C:\Windows\Assembly\NativeImages_v4.0.#####_64. The directory name includes the  <br>version of the CLR and information denoting whether the native code is compiled for x86 <br>(32-bit version of Windows), x64, or Itanium (the latter two for 64-bit versions of Windows).<br>
Now, whenever the CLR loads an assembly file, the CLR looks to see if a corresponding <br>NGen'd native file exists. If a native file cannot be found, the CLR JIT compiles the IL code as <br>usual. However, if a corresponding native file does exist, the CLR will use the compiled code <br>contained in the native file, and the file's methods will not have to be compiled at runtime.<br>
On the surface, this sounds great! It sounds as if you get all of the benefits of managed code <br>(garbage collection, verification, type safety, and so on) without all of the performance prob-<br>lems of managed code (JIT compilation). However, the reality of the situation is not as rosy as <br>it would first seem. There are several potential problems with respect to NGen'd files:<br>
<b>  No intellectual property protection  </b>Many people believe that it might be possible <br>
to ship NGen'd files without shipping the files containing the original IL code, thereby <br>keeping their intellectual property a secret. Unfortunately, this is not possible. At  <br>runtime, the CLR requires access to the assembly's metadata (for functions such as  <br>reflection and serialization); this requires that the assemblies that contain IL and  <br>metadata be shipped. In addition, if the CLR can't use the NGen'd file for some reason <br>(described below), the CLR gracefully goes back to JIT compiling the assembly's IL code, <br>which must be available.<br>
<hr>
<A name=37></a><b> </b><br>
<b>Chapter 1  The CLR's Execution Model </b><br>
<b>19</b><br>
<b>  NGen'd files can get out of sync  </b>When the CLR loads an NGen'd file, it compares a <br>
number of characteristics about the previously compiled code and the current execu-<br>tion environment. If any of the characteristics don't match, the NGen'd file cannot be <br>used, and the normal JIT compiler process is used instead. Here is a partial list of char-<br>acteristics that must match:<br>
  CLR version: this changes with patches or service packs<br>
  CPU type: this changes if you upgrade your processor hardware<br>
  Windows OS version: this changes with a new service pack update<br>
  Assembly's identity module version ID (MVID): this changes when recompiling<br>
  Referenced assembly's version IDs: this changes when you recompile a referenced <br>
assembly<br>
  Security: this changes when you revoke permissions (such as declarative inheri-<br>
tance, declarative link-time, SkipVerification, or UnmanagedCode permissions), <br>that were once granted<br>
Note that it is possible to run NGen.exe in update mode. This tells the tool to run <br>NGen.exe on all of the assemblies that had previously been NGen'd. Whenever an end <br>user installs a new service pack of the .NET Framework, the service pack's installation <br>program will run NGen.exe in update mode automatically so that NGen'd files are kept <br>in sync with the version of the CLR installed.<br>
<b>  Inferior execution-time performance  </b>When compiling code, NGen can't make as <br>
many assumptions about the execution environment as the JIT compiler can. This <br>causes NGen.exe to produce inferior code. For example, NGen won't optimize the <br>use of certain CPU instructions; it adds indirections for static field access because the <br>actual address of the static fields isn't known until runtime. NGen inserts code to call <br>class constructors everywhere because it doesn't know the order in which the code will <br>execute and if a class constructor has already been called. (See Chapter 8, "Methods," <br>for more about class constructors.) Some NGen'd applications actually perform about <br>5 percent slower when compared to their JIT-compiled counterpart. So, if you're con-<br>sidering using NGen.exe to improve the performance of your application, you should <br>compare NGen'd and non-NGen'd versions to be sure that the NGen'd version doesn't <br>actually run slower! For some applications, the reduction in working set size improves <br>performance, so using NGen can be a net win.<br>
Due to all of the issues just listed, you should be very cautious when considering the use of <br>NGen.exe. For server-side applications, NGen.exe makes little or no sense because only the <br>first client request experiences a performance hit; future client requests run at high speed. In <br>addition, for most server applications, only one instance of the code is required, so there is <br>no working set benefit. Also, note that NGen'd images cannot be shared across AppDomains, <br>so there is no benefit to NGen'ing an assembly that will be used in a cross-AppDomain sce-<br>nario (such as ASP.NET).<br>
<hr>
<A name=38></a><b>20 </b><br>
<b>Part I  CLR Basics</b><br>
For client applications, NGen.exe might make sense to improve startup time or to reduce <br>working set if an assembly is used by multiple applications simultaneously. Even in a case in <br>which an assembly is not used by multiple applications, NGen'ing an assembly could improve <br>working set. Moreover, if NGen.exe is used for all of a client application's assemblies, the CLR <br>will not need to load the JIT compiler at all, reducing working set even further. Of course, if <br>just one assembly isn't NGen'd or if an assembly's NGen'd file can't be used, the JIT compiler <br>will load, and the application's working set increases.<br>
<b>The Framework Class Library</b><br>
The .NET Framework includes the <i>Framework Class Library (FCL).</i> The FCL is a set of DLL as-<br>semblies that contain several thousand type definitions in which each type exposes some <br>functionality. Microsoft is producing additional libraries such as the Windows SideShow <br>Managed API SDK2 and the DirectX SDK. These additional libraries provide even more types, <br>exposing even more functionality for your use. In fact, Microsoft is producing many libraries <br>at a phenomenal rate, making it easier than ever for developers to use various Microsoft <br>technologies.<br>
Here are just some of the kinds of applications developers can create by using these <br>assemblies:<br>
<b>  Web services</b>  Methods that can process messages sent over the Internet very eas-<br>
ily using Microsoft's ASP.NET XML Web Service technology or Microsoft's Windows <br>Communication Foundation (WCF) technology.<br>
<b>  Web Forms HTML-based applications (Web sites)</b>  Typically, ASP.NET Web Forms  <br>
applications will make database queries and Web service calls, combine and filter the <br>returned information, and then present that information in a browser by using a rich <br>HTML-based user interface.<br>
<b>  Rich Windows GUI applications</b>  Instead of using a Web Forms page to create your <br>
application's UI, you can use the more powerful, higher-performance functionality of-<br>fered by the Windows desktop via Microsoft's Windows Forms technology or Windows <br>Presentation Foundation (WPF) technology. GUI applications can take advantage of <br>controls, menus, and mouse and keyboard events, and they can exchange information <br>directly with the underlying operating system. Windows Forms applications can also <br>make database queries and consume Web services.<br>
<b>  Rich Internet Applications (RIAs)</b>  Using Microsoft's Silverlight technology, you can <br>
build rich GUI applications that are deployed via the Internet. These applications can <br>run inside or outside of a Web browser. They also run on non-Windows operating sys-<br>tems, and on mobile devices.<br>
2  Incidentally, I personally was contracted by Microsoft to develop this SDK.<br>
<hr>
<A name=39></a><b> </b><br>
<b>Chapter 1  The CLR's Execution Model </b><br>
<b>21</b><br>
<b>  Windows console applications</b>  For applications with very simple UI demands, a  <br>
console application provides a quick and easy way to build an application. Compilers, <br>utilities, and tools are typically implemented as console applications.<br>
<b>  Windows services</b>  Yes, it is possible to build service applications that are controllable <br>
via the Windows Service Control Manager (SCM) by using the .NET Framework.<br>
<b>  Database stored procedures</b>  Microsoft's SQL Server, IBM's DB2, and Oracle's  <br>
database servers allow developers to write their stored procedures using the .NET <br>Framework.<br>
<b>  Component library</b>  The .NET Framework allows you to build stand-alone assemblies <br>
(components) containing types that can be easily incorporated into any of the previ-<br>ously mentioned application types.<br>
Because the FCL contains literally thousands of types, a set of related types is presented to <br>the developer within a single namespace. For example, the System namespace (which you <br>should become most familiar with) contains the Object base type, from which all other types <br>ultimately derive. In addition, the System namespace contains types for integers, characters, <br>strings, exception handling, and console I/O as well as a bunch of utility types that convert <br>safely between data types, format data types, generate random numbers, and perform vari-<br>ous math functions. All applications will use types from the System namespace.<br>
To access any of the framework's features, you need to know which namespace contains the <br>types that expose the facilities you're after. A lot of types allow you to customize their  <br>behavior; you do so by simply deriving your own type from the desired FCL type. The <br>object-oriented nature of the platform is how the .NET Framework presents a consistent <br>programming paradigm to software developers. Also, developers can easily create their own <br>namespaces containing their own types. These namespaces and types merge seamlessly into <br>the programming paradigm. Compared to Win32 programming paradigms, this new  <br>approach greatly simplifies software development.<br>
Most of the namespaces in the FCL present types that can be used for any kind of applica-<br>tion. Table 1-3 lists some of the more general namespaces and briefly describes what the <br>types in that namespace are used for. This is a very small sampling of the namespaces avail-<br>able. Please see the documentation that accompanies the various Microsoft SDKs to gain  <br>familiarity with the ever-growing set of namespaces that Microsoft is producing.<br>
<b>TABLE 1-3  Some General FCL Namespaces</b><br>
<b>Namespace</b><br>
<b>Description of Contents</b><br>
System<br>
All of the basic types used by every application<br>
System.Data<br>
Types for communicating with a database and process-<br>ing data<br>
System.IO<br>
Types for doing stream I/O and walking directories and <br>files<br>
<hr>
<A name=40></a><IMG src="CLRviaCsharp-40_1.jpg"><br>
<b>22 </b><br>
<b>Part I  CLR Basics</b><br>
<b>Namespace</b><br>
<b>Description of Contents</b><br>
System.Net<br>
Types that allow for low-level network communications <br>and working with some common Internet protocols.<br>
System.Runtime.InteropServices<br>
Types that allow managed code to access unmanaged  <br>OS platform facilities such as COM components and <br>functions in Win32 or custom DLLs<br>
System.Security<br>
Types used for protecting data and resources<br>
System.Text<br>
Types to work with text in different encodings, such as <br>ASCII and Unicode<br>
System.Threading<br>
Types used for asynchronous operations and synchroniz-<br>ing access to resources<br>
System.Xml<br>
Types used for processing Extensible Markup Language <br>(XML) schemas and data<br>
This book is about the CLR and about the general types that interact closely with the CLR. So <br>the content of this book is applicable to all programmers writing applications or components <br>that target the CLR. Many other good books exist that cover specific application types such <br>as Web Services, Web Forms, Windows Forms, etc. These other books will give you an excel-<br>lent start at helping you build your application. I tend to think of these application-specific <br>books as helping you learn from the top down because they concentrate on the application <br>type and not on the development platform. In this book, I'll offer information that will help <br>you learn from the bottom up. After reading this book and an application-specific book, you <br>should be able to easily and proficiently build any kind of application you desire.<br>
<b>The Common Type System</b><br>
By now, it should be obvious to you that the CLR is all about types. Types expose functional-<br>ity to your applications and other types. Types are the mechanism by which code written in <br>one programming language can talk to code written in a different programming language. <br>Because types are at the root of the CLR, Microsoft created a formal specification--the <br>Common Type System (CTS)--that describes how types are defined and how they behave.<br>
<b>Note  </b>In fact, Microsoft has been submitting the CTS as well as other parts of the .NET <br>Framework, including file formats, metadata, IL, and access to the underlying platform (P/Invoke) <br>to ECMA for the purpose of standardization. The standard is called the Common Language <br>Infrastructure (CLI) and is the ECMA-335 specification. In addition, Microsoft has also submitted <br>portions of the FCL, the C# programming language (ECMA-334), and the C++/CLI program-<br>ming language. For information about these industry standards, please go to the ECMA Web <br>site that pertains to Technical Committee 39: <i>www.ecma-international.org/</i>. You can also refer to <br>Microsoft's own Web site: <i>http://msdn.microsoft.com/en-us/netframework/aa569283.aspx.</i> In  <br>addition, Microsoft has applied their Community Promise to the ECMA-334 and ECMA-335 speci-<br>fications. For more information about this, see <i>http://www.microsoft.com/interop/cp/default.mspx</i>.<br>
<hr>
<A name=41></a><b> </b><br>
<b>Chapter 1  The CLR's Execution Model </b><br>
<b>23</b><br>
The CTS specification states that a type can contain zero or more members. In Part II, <br>"Designing Types," I'll cover all of these members in great detail. For now, I want just to give <br>you a brief introduction to them:<br>
<b>  Field  </b>A data variable that is part of the object's state. Fields are identified by their <br>
name and type.<br>
<b>  Method  </b>A function that performs an operation on the object, often changing the <br>
object's state. Methods have a name, a signature, and modifiers. The signature specifies <br>the number of parameters (and their sequence), the types of the parameters, whether <br>a value is returned by the method, and if so, the type of the value returned by the <br>method.<br>
<b>  Property  </b>To the caller, this member looks like a field. But to the type implementer, it <br>
looks like a method (or two). Properties allow an implementer to validate input param-<br>eters and object state before accessing the value and/or calculating a value only when <br>necessary. They also allow a user of the type to have simplified syntax. Finally, proper-<br>ties allow you to create read-only or write-only "fields.&quot;<br>
<b>  Event  </b>An event allows a notification mechanism between an object and other inter-<br>
ested objects. For example, a button could offer an event that notifies other objects <br>when the button is clicked.<br>
The CTS also specifies the rules for type visibility and access to the members of a type. For <br>example, marking a type as <i>public</i> (called public) exports the type, making it visible and  <br>accessible to any assembly. On the other hand, marking a type as <i>assembly </i>(called internal <br>in C#) makes the type visible and accessible to code within the same assembly only. Thus, the <br>CTS establishes the rules by which assemblies form a boundary of visibility for a type, and the <br>CLR enforces the visibility rules.<br>
A type that is visible to a caller can further restrict the ability of the caller to access the type's <br>members. The following list shows the valid options for controlling access to a member:<br>
<b>  Private  </b>The member is accessible only by other members in the same class type.<br>
<b>  Family  </b>The member is accessible by derived types, regardless of whether they are <br>
within the same assembly. Note that many languages (such as C++ and C#) refer to <br>family as protected.<br>
<b>  Family and assembly  </b>The member is accessible by derived types, but only if the <br>
derived type is defined in the same assembly. Many languages (such as C# and <br>Visual Basic) don't offer this access control. Of course, IL Assembly language makes it <br>available.<br>
<b>  Assembly  </b>The member is accessible by any code in the same assembly. Many  <br>
languages refer to <i>assembly</i> as internal.<br>
<hr>
<A name=42></a><b>24 </b><br>
<b>Part I  CLR Basics</b><br>
<b>  Family or assembly  </b>The member is accessible by derived types in any assembly. The <br>
member is also accessible by any types in the same assembly. C# refers to <i>family</i> <i>or  <br>assembly</i> as protected internal.<br>
<b>  Public  </b>The member is accessible by any code in any assembly.<br>
In addition, the CTS defines the rules governing type inheritance, virtual methods, object life-<br>time, and so on. These rules have been designed to accommodate the semantics expressible <br>in modern-day programming languages. In fact, you won't even need to learn the CTS rules <br>per se because the language you choose will expose its own language syntax and type rules <br>in the same way that you're familiar with today. And it will map the language-specific syntax <br>into IL, the "language" of the CLR, when it emits the assembly during compilation.<br>
When I first started working with the CLR, I soon realized that it is best to think of the lan-<br>guage and the behavior of your code as two separate and distinct things. Using C++, you can <br>define your own types with their own members. Of course, you could have used C# or Visual <br>Basic to define the same type with the same members. Sure, the syntax you use for defining <br>the type is different depending on the language you choose, but the behavior of the type <br>will be identical regardless of the language because the CLR's CTS defines the behavior of the <br>type.<br>
To help clarify this idea, let me give you an example. The CTS allows a type to derive from <br>only one base class. So, while the C++ language supports types that can inherit from mul-<br>tiple base types, the CTS can't accept and operate on any such type. To help the developer, <br>Microsoft's C++/CLI compiler reports an error if it detects that you're attempting to create <br>managed code that includes a type deriving from multiple base types.<br>
Here's another CTS rule. All types must (ultimately) inherit from a predefined type:  <br>System.Object. As you can see, Object is the name of a type defined in the System <br>namespace. This Object is the root of all other types and therefore guarantees that every <br>type instance has a minimum set of behaviors. Specifically, the System.Object type allows <br>you to do the following:<br>
  Compare two instances for equality.<br>
  Obtain a hash code for the instance.<br>
  Query the true type of an instance.<br>
  Perform a shallow (bitwise) copy of the instance.<br>
  Obtain a string representation of the instance object's current state.<br>
<hr>
<A name=43></a><b> </b><br>
<b>Chapter 1  The CLR's Execution Model </b><br>
<b>25</b><br>
<b>The Common Language Specification</b><br>
COM allows objects created in different languages to communicate with one another. On the <br>other hand, the CLR now integrates all languages and allows objects created in one language <br>to be treated as equal citizens by code written in a completely different language. This inte-<br>gration is possible because of the CLR's standard set of types, metadata (self-describing type <br>information), and common execution environment.<br>
While this language integration is a fantastic goal, the truth of the matter is that program-<br>ming languages are very different from one another. For example, some languages don't <br>treat symbols with case-sensitivity, and some don't offer unsigned integers, operator over-<br>loading, or methods to support a variable number of arguments.<br>
If you intend to create types that are easily accessible from other programming languages, <br>you need to use only features of your programming language that are guaranteed to be <br>available in all other languages. To help you with this, Microsoft has defined a Common <br>Language Specification (CLS) that details for compiler vendors the minimum set of features <br>their compilers must support if these compilers are to generate types compatible with other <br>components written by other CLS-compliant languages on top of the CLR.<br>
The CLR/CTS supports a lot more features than the subset defined by the CLS, so if you don't <br>care about interlanguage operability, you can develop very rich types limited only by the <br>language's feature set. Specifically, the CLS defines rules that externally visible types and <br>methods must adhere to if they are to be accessible from any CLS-compliant programming <br>language. Note that the CLS rules don't apply to code that is accessible only within the  <br>defining assembly. Figure 1-6 summarizes the ideas expressed in this paragraph.<br>
CLR/CTS<br>
Visual<br>
C#<br>
   Basic<br>
CLS<br>
Fortran<br>
<b>FIGURE 1-6</b>  Languages offer a subset of the CLR/CTS  <br>and a superset of the CLS (but not necessarily the same superset)<br>
<hr>
<A name=44></a><b>26 </b><br>
<b>Part I  CLR Basics</b><br>
As Figure 1-6 shows, the CLR/CTS offers a set of features. Some languages expose a large <br>subset of the CLR/CTS. A programmer willing to write in IL assembly language, for example, <br>is able to use all of the features the CLR/CTS offers. Most other languages, such as C#, Visual <br>Basic, and Fortran, expose a subset of the CLR/CTS features to the programmer. The CLS  <br>defines the minimum set of features that all languages must support.<br>
If you're designing a type in one language, and you expect that type to be used by another <br>language, you shouldn't take advantage of any features that are outside of the CLS in its <br>public and protected members. Doing so would mean that your type's members might not <br>be accessible by programmers writing code in other programming languages.<br>
In the following code, a CLS-compliant type is being defined in C#. However, the type has a <br>few non­CLS-compliant constructs causing the C# compiler to complain about the code.<br>
using System;  <br>  <br>// Tell compiler to check for CLS compliance  <br>[assembly: CLSCompliant(true)]  <br>  <br>namespace SomeLibrary {  <br>   // Warnings appear because the class is public  <br>   public sealed class SomeLibraryType {  <br>  <br>      // Warning: Return type of 'SomeLibrary.SomeLibraryType.Abc()'  <br>      // is not CLS-compliant  <br>      public UInt32 Abc() { return 0; }  <br>  <br>      // Warning: Identifier 'SomeLibrary.SomeLibraryType.abc()'  <br>      // differing only in case is not CLS-compliant  <br>      public void abc() { }  <br>  <br>      // No warning: this method is private  <br>      private UInt32 ABC() { return 0; }  <br>   }  <br>}<br>
In this code, the [assembly:CLSCompliant(true)] attribute is applied to the assembly. <br>This attribute tells the compiler to ensure that any publicly exposed type doesn't have any <br>construct that would prevent the type from being accessed from any other programming <br>language. When this code is compiled, the C# compiler emits two warnings. The first warning <br>is reported because the method Abc returns an unsigned integer; some other programming <br>languages can't manipulate unsigned integer values. The second warning is because this type <br>exposes two public methods that differ only by case and return type: Abc and abc. Visual <br>Basic and some other languages can't call both of these methods.<br>
Interestingly, if you were to delete public from in front of 'sealed class <br>SomeLibraryType' and recompile, both warnings would go away. The reason is that the <br>SomeLibraryType type would default to internal and would therefore no longer be  <br>exposed outside of the assembly. For a complete list of CLS rules, refer to the "Cross-<br>
<hr>
<A name=45></a><b> </b><br>
<b>Chapter 1  The CLR's Execution Model </b><br>
<b>27</b><br>
Language Interoperability" section in the .NET Framework SDK documentation  <br>(<i>http://msdn.microsoft.com/en-us/library/730f1wy3.aspx</i>).<br>
Let me distill the CLS rules to something very simple. In the CLR, every member of a type is <br>either a field (data) or a method (behavior). This means that every programming language <br>must be able to access fields and call methods. Certain fields and certain methods are used in <br>special and common ways. To ease programming, languages typically offer additional abstrac-<br>tions to make coding these common programming patterns easier. For example, languages <br>expose concepts such as enums, arrays, properties, indexers, delegates, events, constructors, <br>finalizers, operator overloads, conversion operators, and so on. When a compiler comes across <br>any of these things in your source code, it must translate these constructs into fields and <br>methods so that the CLR and any other programming language can access the construct.<br>
Consider the following type definition, which contains a constructor, a finalizer, some over-<br>loaded operators, a property, an indexer, and an event. Note that the code shown is there <br>just to make the code compile; it doesn't show the correct way to implement a type.<br>
using System;  <br>  <br>internal sealed class Test {  <br>   // Constructor  <br>   public Test() {}  <br>  <br>   // Finalizer  <br>   ~Test() {}  <br>  <br>   // Operator overload  <br>   public static Boolean operator == (Test t1, Test t2) {  <br>      return true;  <br>   }  <br>   public static Boolean operator != (Test t1, Test t2) {  <br>      return false;  <br>   }  <br>  <br>   // An operator overload  <br>   public static Test operator + (Test t1, Test t2) { return null; }  <br>  <br>   // A property  <br>   public String AProperty {  <br>      get { return null; }  <br>      set { }  <br>   }  <br>  <br>   // An indexer  <br>   public String this[Int32 x] {  <br>      get { return null; }  <br>      set { }  <br>   }  <br>  <br>   // An event  <br>   public event EventHandler AnEvent;  <br>}<br>
<hr>
<A name=46></a><b>28 </b><br>
<b>Part I  CLR Basics</b><br>
When the compiler compiles this code, the result is a type that has a number of fields and <br>methods defined in it. You can easily see this by using the IL Disassembler tool (ILDasm.exe) <br>provided with the .NET Framework SDK to examine the resulting managed module, which is <br>shown in Figure 1-7.<br>
<b>FIGURE 1-7</b>  ILDasm showing Test type's fields and methods (obtained from metadata)<br>
Table 1-4 shows how the programming language constructs got mapped to the equivalent <br>CLR fields and methods.<br>
<b>TABLE 1-4  Test Type's Fields and Methods (Obtained from Metadata)</b><br>
<b>Type Member</b><br>
<b>Member Type</b><br>
<b>Equivalent Programming Language Construct</b><br>
AnEvent<br>
Field<br>
Event; the name of the field is AnEvent and its type <br>is System.EventHandler.<br>
.ctor<br>
Method<br>
Constructor.<br>
Finalize<br>
Method<br>
Finalizer.<br>
add_AnEvent<br>
Method<br>
Event add accessor method.<br>
get_AProperty<br>
Method<br>
Property get accessor method.<br>
get_Item<br>
Method<br>
Indexer get accessor method.<br>
op_Addition<br>
Method<br>
+ operator.<br>
op_Equality<br>
Method<br>
== operator.<br>
op_Inequality<br>
Method<br>
!= operator.<br>
remove_AnEvent<br>
Method<br>
Event remove accessor method.<br>
set_AProperty<br>
Method<br>
Property set accessor method.<br>
set_Item<br>
Method<br>
Indexer set accessor method.<br>
The additional nodes under the Test type that aren't mentioned in Table 1-4--.class, <br>.custom, AnEvent, AProperty, and Item--identify additional metadata about the type. <br>These nodes don't map to fields or methods; they just offer some additional information <br>
<hr>
<A name=47></a><IMG src="CLRviaCsharp-47_1.jpg"><br>
<b> </b><br>
<b>Chapter 1  The CLR's Execution Model </b><br>
<b>29</b><br>
about the type that the CLR, programming languages, or tools can get access to. For example, <br>a tool can see that the Test type offers an event, called AnEvent, which is exposed via the <br>two methods (add_AnEvent and remove_AnEvent).<br>
<b>Interoperability with Unmanaged Code</b><br>
The .NET Framework offers a ton of advantages over other development platforms. However, <br>very few companies can afford to redesign and re-implement all of their existing code. <br>Microsoft realizes this and has constructed the CLR so that it offers mechanisms that allow an <br>application to consist of both managed and unmanaged parts. Specifically, the CLR supports <br>three interoperability scenarios:<br>
<b>  Managed code can call an unmanaged function in a DLL</b>  Managed code can easily <br>
call functions contained in DLLs by using a mechanism called P/Invoke (for Platform <br>Invoke). After all, many of the types defined in the FCL internally call functions exported <br>from Kernel32.dll, User32.dll, and so on. Many programming languages will expose a <br>mechanism that makes it easy for managed code to call out to unmanaged functions <br>contained in DLLs. For example, a C# application can call the CreateSemaphore func-<br>tion exported from Kernel32.dll.<br>
<b>  Managed code can use an existing COM component (server)</b>  Many companies have <br>
already implemented a number of unmanaged COM components. Using the type library <br>from these components, a managed assembly can be created that describes the COM <br>component. Managed code can access the type in the managed assembly just as any <br>other managed type. See the TlbImp.exe tool that ships with the .NET Framework SDK <br>for more information. At times, you might not have a type library or you might want <br>to have more control over what TlbImp.exe produces. In these cases, you can manually <br>build a type in source code that the CLR can use to achieve the proper interoperability. <br>For example, you could use DirectX COM components from a C# application.<br>
<b>  Unmanaged code can use a managed type (server)</b>  A lot of existing unmanaged <br>
code requires that you supply a COM component for the code to work correctly. It's <br>much easier to implement these components by using managed code so that you can <br>avoid all of the code having to do with reference counting and interfaces. For example, <br>you could create an ActiveX control or a shell extension in C#. See the TlbExp.exe and <br>RegAsm.exe tools that ship with the .NET Framework SDK for more information.<br>
<b>Note</b>  Microsoft now makes available the source code for the Type Library Importer tool and a <br>P/Invoke Interop Assistant tool to help developers needing to interact with native code. These <br>tools and their source code can be downloaded from <i>http://CLRInterop.CodePlex.com/</i>.<br>
<hr>
<A name=48></a><hr>
<A name=49></a>Chapter 2<br><b>Building, Packaging, Deploying, and </b><br>
<b>Administering Applications and Types</b><br>
<b>In this chapter:<br>.NET Framework Deployment Goals  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32<br>Building Types into a Module . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33<br>A Brief Look at Metadata. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36<br>Combining Modules to Form an Assembly. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43<br>Assembly Version Resource Information. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53<br>Culture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58<br>Simple Application Deployment (Privately Deployed Assemblies). . . . . . . . . . . . 59<br>Simple Administrative Control (Configuration) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61</b><br>
Before we get into the chapters that explain how to develop programs for the Microsoft <br>.NET Framework, let's discuss the steps required to build, package, and deploy your applica-<br>tions and their types. In this chapter, I'll focus on the basics of how to build assemblies that <br>are for your application's sole use. In Chapter 3, "Shared Assemblies and Strongly Named <br>Assemblies," I'll cover the more advanced concepts you'll need to understand, including how <br>to build and use assemblies containing types that will be shared by multiple applications. In <br>both chapters, I'll also talk about the ways an administrator can affect the execution of an <br>application and its types.<br>
Today, applications consist of several types, which are typically created by you and Microsoft. <br>In addition, there are many component vendors creating and selling types that other compa-<br>nies can use to reduce a software project's development time. If these types are developed <br>using any language that targets the common language runtime (CLR), they can all work  <br>together seamlessly; a type written in one language can use another type as its base class <br>without concern for the language the base type was developed in.<br>
In this chapter, I'll also explain how these types are built and packaged into files for deploy-<br>ment. In the process, I'll take you on a brief historical tour of some of the problems that the  <br>.NET Framework is solving.<br>
<b> </b><br>
<b> </b><br>
<b>31</b><br>
<hr>
<A name=50></a><b>32 </b><br>
<b>Part I  CLR Basics</b><br>
<b>.NET Framework Deployment Goals</b><br>
Over the years, Microsoft Windows has gotten a reputation for being unstable and compli-<br>cated. This reputation, whether deserved or not, is the result of many different factors. First, <br>all applications use dynamic-link libraries (DLLs) from Microsoft or other vendors. Because <br>an application executes code from various vendors, the developer of any one piece of code <br>can't be 100 percent sure how someone else is going to use it. Although this kind of interac-<br>tion can potentially cause all kinds of trouble, in practice, these problems don't typically arise <br>because applications are tested and debugged before they are deployed.<br>
Users, however, frequently run into problems when one company decides to update its code <br>and ships new files to them. These new files are supposed to be backward-compatible with <br>the previous files, but who knows for sure? In fact, when one vendor updates its code, it  <br>usually finds it impossible to retest and debug all of the already-shipped applications to  <br>ensure that the changes will have no undesirable effect.<br>
I'm sure that everyone reading this book has experienced some variation of this problem: <br>when installing a new application, you discover that it has somehow corrupted an already-<br>installed application. This predicament is known as "DLL hell." This type of instability puts fear <br>into the hearts and minds of the typical computer user. The end result is that users have to <br>carefully consider whether to install new software on their machines. Personally, I've decided <br>not to try out certain applications out of fear that it might adversely affect some application I <br>really rely on.<br>
The second reason that contributed to the aforementioned reputation of Windows is instal-<br>lation complexities. Today, when most applications are installed, they affect all parts of the <br>system. For example, installing an application causes files to be copied to various directories, <br>updates registry settings, and installs shortcuts on your desktop and Start menu. The prob-<br>lem with this is that the application isn't isolated as a single entity. You can't easily back up <br>the application since you must copy the application's files and also the relevant parts of the <br>registry. In addition, you can't easily move the application from one machine to another; you <br>must run the installation program again so that all files and registry settings are set properly. <br>Finally, you can't easily uninstall or remove the application without having this nasty feeling <br>that some part of the application is still lurking on your machine.<br>
The third reason has to do with security. When applications are installed, they come with all <br>kinds of files, many of them written by different companies. In addition, Web applications <br>frequently have code (like ActiveX controls) that is downloaded in such a way that users <br>don't even realize that code is being installed on their machine. Today, this code can perform <br>any operation, including deleting files or sending e-mail. Users are right to be terrified of <br>installing new applications because of the potential damage they can cause. To make users <br>comfortable, security must be built into the system so that the users can explicitly allow or <br>disallow code developed by various companies to access their system's resources.<br>
<hr>
<A name=51></a><b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>33</b><br>
The .NET Framework addresses the DLL hell issue in a big way, as you'll see while reading this <br>chapter and Chapter 3. It also goes a long way toward fixing the problem of having an appli-<br>cation's state scattered all over a user's hard disk. For example, unlike COM, types no longer <br>require settings in the registry. Unfortunately, applications still require shortcut links. As for <br>security, the .NET Framework includes a security model called <i>code access security</i>. Whereas <br>Windows security is based on a user's identity, code access security is based on permissions <br>that host applications that loading components can control. A host application like Microsoft <br>Silverlight can grant just a few permissions to downloaded code, while a locally installed <br>(self-hosting) application could run with full trust (all permissions). As you'll see, the .NET <br>Framework enables users to control what gets installed and what runs, and in general, to <br>control their machines, more than Windows ever did.<br>
<b>Building Types into a Module</b><br>
In this section, I'll show you how to turn your source file, containing various types, into a file <br>that can be deployed. Let's start by examining the following simple application:<br>
public sealed class Program {  <br>   public static void Main() {  <br>      System.Console.WriteLine(&quot;Hi&quot;);  <br>   }  <br>}<br>
This application defines a type, called Program. This type has a single public, static  <br>method called Main. Inside Main is a reference to another type called  <br>System.Console. System.Console is a type implemented by Microsoft, and the <br>Intermediate Language (IL) code that implements this type's methods is in the MSCorLib.dll <br>file. So our application defines a type and also uses another company's type.<br>
To build this sample application, put the preceding code into a source code file, say,  <br>Program.cs, and then execute the following command line:<br>
csc.exe /out:Program.exe /t:exe /r:MSCorLib.dll Program.cs<br>
This command line tells the C# compiler to emit an executable file called Program.exe  <br>(/out:Program.exe). The type of file produced is a Win32 console application <br>(/t[arget]:exe).<br>
When the C# compiler processes the source file, it sees that the code references the  <br>System.Console type's WriteLine method. At this point, the compiler wants to ensure that <br>this type exists somewhere, that it has a WriteLine method, and that the argument being <br>passed to this method matches the parameter the method expects. Since this type is not <br>defined in the C# source code, to make the C# compiler happy, you must give it a set of as-<br>semblies that it can use to resolve references to external types. In the command line above, <br>
<hr>
<A name=52></a><b>34 </b><br>
<b>Part I  CLR Basics</b><br>
I've included the /r[eference]:MSCorLib.dll switch, which tells the compiler to look for <br>external types in the assembly identified by the MSCorLib.dll file.<br>
MSCorLib.dll is a special file in that it contains all the core types: Byte, Char, String, Int32, <br>and many more. In fact, these types are so frequently used that the C# compiler automati-<br>cally references the MSCorLib.dll assembly. In other words, the following command line (with <br>the /r switch omitted) gives the same results as the line shown earlier:<br>
csc.exe /out:Program.exe /t:exe Program.cs<br>
Furthermore, because the /out:Program.exe and the /t:exe command-line switches also <br>match what the C# compiler would choose as defaults, the following command line gives the <br>same results too:<br>
csc.exe Program.cs<br>
If, for some reason, you really don't want the C# compiler to reference the MSCorLib.dll  <br>assembly, you can use the /nostdlib switch. Microsoft uses this switch when building the <br>MSCorLib.dll assembly itself. For example, the following command line will generate an error <br>when CSC.exe attempts to compile the Program.cs file because the System.Console type is <br>defined in MSCorLib.dll:<br>
csc.exe /out:Program.exe /t:exe /nostdlib Program.cs<br>
Now, let's take a closer look at the Program.exe file produced by the C# compiler. What  <br>exactly is this file? Well, for starters, it is a standard portable executable (PE) file. This means <br>that a machine running 32-bit or 64-bit versions of Windows should be able to load this file <br>and do something with it. Windows supports two types of applications, those with a console <br>user interface (CUI) and those with a graphical user interface (GUI). Because I specified the <br>/t:exe switch, the C# compiler produced a CUI application. You'd use the /t:winexe switch <br>to cause the C# compiler to produce a GUI application.<br>
<b>Response Files</b><br>
Before leaving the discussion about compiler switches, I'd like to spend a moment talking <br>about <i>response files</i>. A response file is a text file that contains a set of compiler command-<br>line switches. When you execute CSC.exe, the compiler opens response files and uses any <br>switches that are specified in them as though the switches were passed to CSC.exe on the <br>command line. You instruct the compiler to use a response file by specifying its name on the <br>command line prepended by an @ sign. For example, you could have a response file called <br>MyProject.rsp that contains the following text:<br>
/out:MyProject.exe <br>/target:winexe<br>
<hr>
<A name=53></a><b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>35</b><br>
To cause CSC.exe to use these settings, you'd invoke it as follows:<br>
csc.exe @MyProject.rsp CodeFile1.cs CodeFile2.cs<br>
This tells the C# compiler what to name the output file and what kind of target to create. As <br>you can see, response files are very convenient because you don't have to manually express <br>the desired command-line arguments each time you want to compile your project.<br>
The C# compiler supports multiple response files. In addition to the files you explicitly specify <br>on the command line, the compiler automatically looks for files called CSC.rsp. When you <br>run CSC.exe, it looks in the current directory for a local CSC.rsp file--you should place any <br>project-specific settings in this file. The compiler also looks in the directory containing the <br>CSC.exe file for a global CSC.rsp file. Settings that you want applied to all of your projects <br>should go in this file. The compiler aggregates and uses the settings in all of these response <br>files. If you have conflicting settings in the local and global response files, the settings in the <br>local file override the settings in the global file. Likewise, any settings explicitly passed on the <br>command line override the settings taken from a local response file.<br>
When you install the .NET Framework, it installs a default global CSC.rsp file in the <br>%SystemRoot%\Microsoft.NET\Framework\v<i>X.X.X</i>directory (where <i>X.X.X</i> is the version of <br>the .NET Framework you have installed). The 4.0 version of this file contains the following <br>switches:<br>
# This file contains command-line options that the C# <br># command line compiler (CSC) will process as part <br># of every compilation, unless the &quot;/noconfig&quot; option <br># is specified.  <br> <br># Reference the common Framework libraries <br>/r:Accessibility.dll <br>/r:Microsoft.CSharp.dll <br>/r:System.Configuration.dll <br>/r:System.Configuration.Install.dll <br>/r:System.Core.dll <br>/r:System.Data.dll <br>/r:System.Data.DataSetExtensions.dll <br>/r:System.Data.Linq.dll <br>/r:System.Deployment.dll <br>/r:System.Device.dll <br>/r:System.DirectoryServices.dll <br>/r:System.dll <br>/r:System.Drawing.dll <br>/r:System.EnterpriseServices.dll <br>/r:System.Management.dll <br>/r:System.Messaging.dll <br>/r:System.Numerics.dll <br>/r:System.Runtime.Remoting.dll <br>/r:System.Runtime.Serialization.dll <br>/r:System.Runtime.Serialization.Formatters.Soap.dll <br>/r:System.Security.dll <br>
<hr>
<A name=54></a><IMG src="CLRviaCsharp-54_1.jpg"><br>
<b>36 </b><br>
<b>Part I  CLR Basics</b><br>
/r:System.ServiceModel.dll <br>/r:System.ServiceProcess.dll <br>/r:System.Transactions.dll <br>/r:System.Web.Services.dll <br>/r:System.Windows.Forms.Dll <br>/r:System.Xml.dll <br>/r:System.Xml.Linq.dll<br>
Because the global CSC.rsp file references all of the assemblies listed, you do not need to <br>explicitly reference these assemblies by using the C# compiler's /reference switch. This <br>response file is a big convenience for developers because it allows them to use types and <br>namespaces defined in various Microsoft-published assemblies without having to specify a  <br>/reference compiler switch for each when compiling.<br>
Referencing all of these assemblies could slow the compiler down a bit. But if your source <br>code doesn't refer to a type or member defined by any of these assemblies, there is no  <br>impact to the resulting assembly file, nor to run-time execution performance.<br>
<b>Note  </b>When you use the /reference compiler switch to reference an assembly, you can  <br>specify a complete path to a particular file. However, if you do not specify a path, the compiler <br>will search for the file in the following places (in the order listed):<br>
  Working directory.<br>
  The directory that contains the CSC.exe file itself. MSCorLib.dll is always obtained from this <br>
directory. The path looks something like this: %SystemRoot%\Microsoft.NET\Framework <br>\v4.0.<i>#####.</i><br>
  Any directories specified using the /lib compiler switch.<br>  Any directories specified using the LIB environment variable.<br>
Of course, you're welcome to add your own switches to the global CSC.rsp file if you want to <br>make your life even easier, but this makes it more difficult to replicate the build environment <br>on different machines: you have to remember to update the CSC.rsp the same way on each <br>build machine. Also, you can tell the compiler to ignore both local and global CSC.rsp files by <br>specifying the /noconfig command-line switch.<br>
<b>A Brief Look at Metadata</b><br>
Now we know what kind of PE file we've created. But what exactly is in the Program.exe file? <br>A managed PE file has four main parts: the PE32(+) header, the CLR header, the metadata, <br>and the IL. The PE32(+) header is the standard information that Windows expects. The CLR <br>header is a small block of information that is specific to modules that require the CLR (man-<br>aged modules). The header includes the major and minor version number of the CLR that the <br>module was built for: some flags, a MethodDef token (described later) indicating the module's <br>entry point method if this module is a CUI or GUI executable, and an optional strong-name <br>
<hr>
<A name=55></a><b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>37</b><br>
digital signature (discussed in Chapter 3). Finally, the header contains the size and offsets of <br>certain metadata tables contained within the module. You can see the exact format of the <br>CLR header by examining the IMAGE_COR20_HEADER defined in the CorHdr.h header file.<br>
The metadata is a block of binary data that consists of several tables. There are three cat-<br>egories of tables: definition tables, reference tables, and manifest tables. Table 2-1 describes <br>some of the more common definition tables that exist in a module's metadata block.<br>
<b>TABLE 2-1  Common Definition Metadata Tables</b><br>
<b>Metadata Definition <br>Table Name</b><br>
<b>Description</b><br>
ModuleDef<br>
Always contains one entry that identifies the module. The entry includes <br>the module's file name and extension (without path) and a module version <br>ID (in the form of a GUID created by the compiler). This allows the file to be <br>renamed while keeping a record of its original name. However, renaming a <br>file is strongly discouraged and can prevent the CLR from locating an  <br>assembly at runtime, so don't do this.<br>
TypeDef<br>
Contains one entry for each type defined in the module. Each entry  <br>includes the type's name, base type, and flags (public, private, etc.) and <br>contains indexes to the methods it owns in the MethodDef table, the fields <br>it owns in the FieldDef table, the properties it owns in the PropertyDef <br>table, and the events it owns in the EventDef table.<br>
MethodDef<br>
Contains one entry for each method defined in the module. Each entry  <br>includes the method's name, flags (private, public, virtual, abstract, <br>static, final, etc.), signature, and offset within the module where its IL <br>code can be found. Each entry can also refer to a ParamDef table entry in <br>which more information about the method's parameters can be found.<br>
FieldDef<br>
Contains one entry for every field defined in the module. Each entry  <br>includes flags (private, public, etc.), type, and name.<br>
ParamDef<br>
Contains one entry for each parameter defined in the module. Each entry <br>includes flags (in, out, retval, etc.), type, and name.<br>
PropertyDef<br>
Contains one entry for each property defined in the module. Each entry <br>includes flags, type, and name.<br>
EventDef<br>
Contains one entry for each event defined in the module. Each entry  <br>includes flags and name.<br>
As the compiler compiles your source code, everything your code defines causes an entry to <br>be created in one of the tables described in Table 2-1. Metadata table entries are also created <br>as the compiler detects the types, fields, methods, properties, and events that the source <br>code references. The metadata created includes a set of reference tables that keep a record <br>of the referenced items. Table 2-2 shows some of the more common reference metadata <br>tables.<br>
<hr>
<A name=56></a><b>38 </b><br>
<b>Part I  CLR Basics</b><br>
<b>TABLE 2-2  Common Reference Metadata Tables</b><br>
<b>Metadata Reference <br>Table Name</b><br>
<b>Description</b><br>
AssemblyRef<br>
Contains one entry for each assembly referenced by the module. Each <br>entry includes the information necessary to bind to the assembly: the <br>assembly's name (without path and extension), version number, culture, <br>and public key token (normally a small hash value generated from the <br>publisher's public key, identifying the referenced assembly's publisher). <br>Each entry also contains some flags and a hash value. This hash value was <br>intended to be a checksum of the referenced assembly's bits. The CLR <br>completely ignores this hash value and will probably continue to do so in <br>the future.<br>
ModuleRef<br>
Contains one entry for each PE module that implements types refer-<br>enced by this module. Each entry includes the module's file name and <br>extension (without path). This table is used to bind to types that are <br>implemented in different modules of the calling assembly's module.<br>
TypeRef<br>
Contains one entry for each type referenced by the module. Each entry  <br>includes the type's name and a reference to where the type can be <br>found. If the type is implemented within another type, the reference will <br>indicate a TypeRef entry. If the type is implemented in the same module, <br>the reference will indicate a ModuleDef entry. If the type is implemented <br>in another module within the calling assembly, the reference will indicate <br>a ModuleRef entry. If the type is implemented in a different assembly, <br>the reference will indicate an AssemblyRef entry.<br>
MemberRef<br>
Contains one entry for each member (fields and methods, as well as <br>property and event methods) referenced by the module. Each entry <br>includes the member's name and signature and points to the TypeRef <br>entry for the type that defines the member.<br>
There are many more tables than what I listed in Tables 2-1 and 2-2, but I just wanted to give <br>you a sense of the kind of information that the compiler emits to produce the metadata in-<br>formation. Earlier I mentioned that there is also a set of manifest metadata tables; I'll discuss <br>these a little later in the chapter.<br>
Various tools allow you to examine the metadata within a managed PE file. My personal  <br>favorite is ILDasm.exe, the IL Disassembler. To see the metadata tables, execute the following <br>command line:<br>
ILDasm Program.exe<br>
This causes ILDasm.exe to run, loading the Program.exe assembly. To see the metadata in a <br>nice, human-readable form, select the View/MetaInfo/Show! menu item (or press CTRL+M). <br>This causes the following information to appear:<br>
<hr>
<A name=57></a><b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>39</b><br>
===========================================================  <br>ScopeName : Program.exe  <br>MVID      : {CA73FFE8-0D42-4610-A8D3-9276195C35AA}  <br>===========================================================  <br>Global functions  <br>-------------------------------------------------------  <br> <br>Global fields  <br>-------------------------------------------------------  <br> <br>Global MemberRefs <br>-------------------------------------------------------  <br> <br>TypeDef #1 (02000002)  <br>-------------------------------------------------------  <br>   TypDefName: Program  (02000002)  <br>   Flags     : [Public] [AutoLayout] [Class] [Sealed] [AnsiClass]  <br>               [BeforeFieldInit]  (00100101)  <br>   Extends   : 01000001 [TypeRef] System.Object <br>   Method #1 (06000001) [ENTRYPOINT]  <br>   -------------------------------------------------------  <br>      MethodName: Main (06000001)  <br>      Flags     : [Public] [Static] [HideBySig] [ReuseSlot]  (00000096)  <br>      RVA       : 0x00002050  <br>      ImplFlags : [IL] [Managed]  (00000000)  <br>      CallCnvntn: [DEFAULT]  <br>      ReturnType: Void  <br>      No arguments.  <br> <br>   Method #2 (06000002)   <br>   -------------------------------------------------------  <br>      MethodName: .ctor (06000002)  <br>      Flags     : [Public] [HideBySig] [ReuseSlot] [SpecialName]  <br>                  [RTSpecialName] [.ctor]  (00001886)  <br>      RVA       : 0x0000205c  <br>      ImplFlags : [IL] [Managed]  (00000000)  <br>      CallCnvntn: [DEFAULT]  <br>      hasThis   <br>      ReturnType: Void  <br>      No arguments.  <br> <br> <br>TypeRef #1 (01000001)  <br>-------------------------------------------------------  <br>Token:             0x01000001  <br>ResolutionScope:   0x23000001  <br>TypeRefName:       System.Object <br>   MemberRef #1 (0a000004)  <br>   -------------------------------------------------------  <br>      Member: (0a000004) .ctor:   <br>      CallCnvntn: [DEFAULT]  <br>      hasThis   <br>      ReturnType: Void  <br>      No arguments.  <br> <br>TypeRef #2 (01000002)  <br>
<hr>
<A name=58></a><b>40 </b><br>
<b>Part I  CLR Basics</b><br>
-------------------------------------------------------  <br>Token:             0x01000002  <br>ResolutionScope:   0x23000001  <br>TypeRefName:       System.Runtime.CompilerServices.CompilationRelaxationsAttribute  <br>   MemberRef #1 (0a000001)  <br>   -------------------------------------------------------  <br>      Member: (0a000001) .ctor:   <br>      CallCnvntn: [DEFAULT]  <br>      hasThis   <br>      ReturnType: Void  <br>      1 Arguments  <br>         Argument #1:  I4  <br> <br>TypeRef #3 (01000003)  <br>-------------------------------------------------------  <br>Token:             0x01000003  <br>ResolutionScope:   0x23000001  <br>TypeRefName:       System.Runtime.CompilerServices.RuntimeCompatibilityAttribute  <br>   MemberRef #1 (0a000002)  <br>   -------------------------------------------------------  <br>      Member: (0a000002) .ctor:   <br>      CallCnvntn: [DEFAULT]  <br>      hasThis   <br>      ReturnType: Void  <br>      No arguments.  <br>TypeRef #4 (01000004)  <br>-------------------------------------------------------  <br>Token:             0x01000004  <br>ResolutionScope:   0x23000001  <br>TypeRefName:       System.Console <br>   MemberRef #1 (0a000003)  <br>   -------------------------------------------------------  <br>      Member: (0a000003) WriteLine:   <br>      CallCnvntn: [DEFAULT]  <br>      ReturnType: Void  <br>      1 Arguments  <br>         Argument #1:  String  <br> <br>Assembly  <br>-------------------------------------------------------  <br>   Token: 0x20000001  <br>   Name : Program  <br>   Public Key    :  <br>   Hash Algorithm : 0x00008004  <br>   Version: 0.0.0.0  <br>   Major Version: 0x00000000  <br>   Minor Version: 0x00000000  <br>   Build Number: 0x00000000  <br>   Revision Number: 0x00000000  <br>   Locale: &lt;null&gt; <br>   Flags : [none] (00000000)  <br>   CustomAttribute #1 (0c000001)  <br>   -------------------------------------------------------  <br>      CustomAttribute Type: 0a000001  <br>      CustomAttributeName:   <br>
<hr>
<A name=59></a><b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>41</b><br>
        System.Runtime.CompilerServices.CompilationRelaxationsAttribute ::   <br>          instance void .ctor(int32)  <br>      Length: 8  <br>      Value : 01 00 08 00 00 00 00 00                          &gt;                &lt; <br>      ctor args: (8)  <br> <br>   CustomAttribute #2 (0c000002)  <br>   -------------------------------------------------------  <br>      CustomAttribute Type: 0a000002  <br>      CustomAttributeName: System.Runtime.CompilerServices.RuntimeCompatibilityAttribute ::  <br>          instance void .ctor()  <br>      Length: 30  <br>      Value : 01 00 01 00 54 02 16 57  72 61 70 4e 6f 6e 45 78 &gt;    T  WrapNonEx&lt; <br>            : 63 65 70 74 69 6f 6e 54  68 72 6f 77 73 01       &gt;ceptionThrows   &lt; <br>      ctor args: ()  <br> <br>AssemblyRef #1 (23000001)  <br>-------------------------------------------------------  <br>   Token: 0x23000001  <br>   Public Key or Token: b7 7a 5c 56 19 34 e0 89   <br>   Name: mscorlib <br>   Version: 4.0.0.0  <br>   Major Version: 0x00000004  <br>   Minor Version: 0x00000000  <br>   Build Number: 0x00000000  <br>   Revision Number: 0x00000000  <br>   Locale: &lt;null&gt; <br>   HashValue Blob:  <br>   Flags: [none] (00000000)  <br> <br> <br>User Strings  <br>-------------------------------------------------------  <br>70000001 : ( 2) L&quot;Hi&quot;  <br> <br> <br>Coff symbol name overhead:  0  <br>===========================================================  <br>===========================================================  <br>===========================================================<br>
Fortunately, ILDasm processes the metadata tables and combines information where  <br>appropriate so that you don't have to parse the raw table information. For example, in the <br>dump above, you see that when ILDasm shows a TypeDef entry, the corresponding member <br>definition information is shown with it before the first TypeRef entry is displayed.<br>
You don't need to fully understand everything you see here. The important thing to remem-<br>ber is that Program.exe contains a TypeDef whose name is Program. This type identifies a <br>public sealed class that is derived from System.Object (a type referenced from another  <br>assembly). The Program type also defines two methods: Main and .ctor (a constructor).<br>
Main is a public, static method whose code is IL (as opposed to native CPU code, such as x86). <br>Main has a void return type and takes no arguments. The constructor method (always shown <br>
<hr>
<A name=60></a><b>42 </b><br>
<b>Part I  CLR Basics</b><br>
with a name of .ctor) is public, and its code is also IL. The constructor has a void return <br>type, has no arguments, and has a this pointer, which refers to the object's memory that is <br>to be constructed when the method is called.<br>
I strongly encourage you to experiment with using ILDasm. It can show you a wealth of infor-<br>mation, and the more you understand what you're seeing, the better you'll understand the <br>CLR and its capabilities. As you'll see, I'll use ILDasm quite a bit more in this book.<br>
Just for fun, let's look at some statistics about the Program.exe assembly. When you select <br>ILDasm's View/Statistics menu item, the following information is displayed:<br>
File size            : 3584 <br> PE header size       : 512 (496 used)    (14.29%) <br> PE additional info   : 1415              (39.48%) <br> Num.of PE sections   : 3 <br> CLR header size     : 72                 ( 2.01%) <br> CLR meta-data size  : 612                (17.08%) <br> CLR additional info : 0                  ( 0.00%) <br> CLR method headers  : 2                  ( 0.06%) <br> Managed code         : 18                ( 0.50%) <br> Data                 : 2048              (57.14%) <br> Unaccounted          : -1095             (-30.55%) <br> <br> Num.of PE sections   : 3 <br>   .text    - 1024 <br>   .rsrc    - 1536 <br>   .reloc   - 512 <br> <br> CLR meta-data size  : 612 <br>   Module        -    1 (10 bytes) <br>   TypeDef       -    2 (28 bytes)      0 interfaces, 0 explicit layout <br>   TypeRef       -    4 (24 bytes) <br>   MethodDef     -    2 (28 bytes)      0 abstract, 0 native, 2 bodies <br>   MemberRef     -    4 (24 bytes) <br>   ParamDef      -    2 (12 bytes) <br>   CustomAttribute-    2 (12 bytes) <br>   Assembly      -    1 (22 bytes) <br>   AssemblyRef   -    1 (20 bytes) <br>   Strings       -   184 bytes <br>   Blobs         -    68 bytes <br>   UserStrings   -     8 bytes <br>   Guids         -    16 bytes <br>   Uncategorized -   168 bytes <br> <br> CLR method headers : 2 <br>   Num.of method bodies  - 2 <br>   Num.of fat headers    - 0 <br>   Num.of tiny headers   - 2 <br> <br> Managed code : 18 <br>   Ave method size - 9<br>
<hr>
<A name=61></a><IMG src="CLRviaCsharp-61_1.jpg"><br>
<b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>43</b><br>
Here you can see the size (in bytes) of the file and the size (in bytes and percentages) of the <br>various parts that make up the file. For this very small Program.cs application, the PE header <br>and the metadata occupy the bulk of the file's size. In fact, the IL code occupies just 18 bytes. <br>Of course, as an application grows, it will reuse most of its types and references to other <br>types and assemblies, causing the metadata and header information to shrink considerably <br>as compared to the overall size of the file.<br>
<b>Note  </b>By the way, ILDasm.exe does have a bug in it that affects the file size information shown. <br>In particular, you cannot trust the Unaccounted information.<br>
<b>Combining Modules to Form an Assembly</b><br>
The Program.exe file discussed in the previous section is more than just a PE file with meta-<br>data; it is also an <i>assembly</i>. An assembly is a collection of one or more files containing type <br>definitions and resource files. One of the assembly's files is chosen to hold a <i>manifest</i>. The <br>manifest is another set of metadata tables that basically contain the names of the files that <br>are part of the assembly. They also describe the assembly's version, culture, publisher,  <br>publicly exported types, and all of the files that comprise the assembly.<br>
The CLR operates on assemblies; that is, the CLR always loads the file that contains the mani-<br>fest metadata tables first and then uses the manifest to get the names of the other files that <br>are in the assembly. Here are some characteristics of assemblies that you should remember:<br>
  An assembly defines the reusable types.<br>
  An assembly is marked with a version number.<br>
  An assembly can have security information associated with it.<br>
An assembly's individual files don't have these attributes--except for the file that contains <br>the manifest metadata tables.<br>
To package, version, secure, and use types, you must place them in modules that are part of <br>an assembly. In most cases, an assembly consists of a single file, as the preceding Program.<br>exe example does. However, an assembly can also consist of multiple files: some PE files with <br>metadata and some resource files such as .gif or .jpg files. It might help you to think of an <br>assembly as a logical EXE or a DLL.<br>
I'm sure that many of you reading this are wondering why Microsoft has introduced this new <br>assembly concept. The reason is that an assembly allows you to decouple the logical and <br>physical notions of reusable types. For example, an assembly can consist of several types. <br>You could put the frequently used types in one file and the less frequently used types in <br>another file. If your assembly is deployed by downloading it via the Internet, the file with <br>
<hr>
<A name=62></a><b>44 </b><br>
<b>Part I  CLR Basics</b><br>
the infrequently used types might not ever have to be downloaded to the client if the client <br>never accesses the types. For example, an independent software vendor (ISV) specializing in <br>UI controls might choose to implement Active Accessibility types in a separate module (to <br>satisfy Microsoft's Logo requirements). Only users who require the additional accessibility <br>features would require this module to be downloaded.<br>
You configure an application to download assembly files by specifying a codeBase element <br>(discussed in Chapter 3) in the application's configuration file. The codeBase element identifies <br>a URL pointing to where all of an assembly's files can be found. When attempting to load an <br>assembly's file, the CLR obtains the codeBase element's URL and checks the machine's down-<br>load cache to see if the file is present. If it is, the file is loaded. If the file isn't in the cache, the <br>CLR downloads the file into the cache from the location the URL points to. If the file can't be <br>found, the CLR throws a FileNotFoundException exception at runtime.<br>
I've identified three reasons to use multifile assemblies:<br>
  You can partition your types among separate files, allowing for files to be incrementally <br>
downloaded as described in the Internet download scenario. Partitioning the types into <br>separate files also allows for partial or piecemeal packaging and deployment for appli-<br>cations you purchase and install.<br>
  You can add resource or data files to your assembly. For example, you could have a <br>
type that calculates some insurance information. This type might require access to <br>some actuarial tables to make its computations. Instead of embedding the actuarial <br>tables in your source code, you could use a tool (such as the Assembly Linker, AL.exe, <br>discussed later) so that the data file is considered to be part of the assembly. By the <br>way, this data file can be in any format--a text file, a Microsoft Office Excel spreadsheet, <br>a Microsoft Office Word table, or whatever you like--as long as your application knows <br>how to parse the file's contents.<br>
  You can create assemblies consisting of types implemented in different programming <br>
languages. For example, you can implement some types in C#, some types in Microsoft <br>Visual Basic, and other types in other languages. When you compile the types written <br>with C# source code, the compiler produces a module. When you compile other types <br>written with Visual Basic source code, the compiler produces a separate module. You can <br>then use a tool to combine all of these modules into a single assembly. To developers <br>using the assembly, the assembly appears to contain just a bunch of types; developers <br>won't even know that different programming languages were used. By the way, if you <br>prefer, you can run ILDasm.exe on each of the modules to obtain an IL source code file. <br>Then you can run ILAsm.exe and pass it all of the IL source code files. ILAsm.exe will <br>produce a single file containing all of the types. This technique requires your source <br>code compiler to produce IL-only code.<br>
<hr>
<A name=63></a><IMG src="CLRviaCsharp-63_1.jpg"><br>
<b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>45</b><br>
<b>Important  </b>To summarize, an assembly is a unit of reuse, versioning, and security. It allows you <br>to partition your types and resources into separate files so that you, and consumers of your as-<br>sembly, get to determine which files to package together and deploy. Once the CLR loads the file <br>containing the manifest, it can determine which of the assembly's other files contain the types and <br>resources the application is referencing. Anyone consuming the assembly is required to know only <br>the name of the file containing the manifest; the file partitioning is then abstracted away from the <br>consumer and can change in the future without breaking the application's behavior.<br>
If you have multiple types that can share a single version number and security settings, it is  <br>recommended that you place all of the types in a single file rather than spread the types out  <br>over separate files, let alone separate assemblies. The reason is performance. Loading a  <br>file/assembly takes the CLR and Windows time to find the assembly, load it, and initialize it.  <br>The fewer files/assemblies loaded the better, because loading fewer assemblies helps reduce <br>working set and also reduces fragmentation of a process's address space. Finally, nGen.exe  <br>can perform better optimizations when processing larger files.<br>
To build an assembly, you must select one of your PE files to be the keeper of the manifest. <br>Or you can create a separate PE file that contains nothing but the manifest. Table 2-3 shows <br>the manifest metadata tables that turn a managed module into an assembly.<br>
<b>TABLE 2-3  Manifest Metadata Tables</b><br>
<b>Manifest Metadata <br>Table Name</b><br>
<b>Description</b><br>
AssemblyDef<br>
Contains a single entry if this module identifies an assembly. The entry <br>includes the assembly's name (without path and extension), version  <br>(major, minor, build, and revision), culture, flags, hash algorithm, and the <br>publisher's public key (which can be null).<br>
FileDef<br>
Contains one entry for each PE and resource file that is part of the assem-<br>bly (except the file containing the manifest since it appears as the single <br>entry in the AssemblyDef table). The entry includes the file's name and <br>extension (without path), hash value, and flags. If this assembly consists <br>only of its own file, the FileDef table has no entries.<br>
ManifestResourceDef<br>
Contains one entry for each resource that is part of the assembly. The <br>entry includes the resource's name, flags (public if visible outside the as-<br>sembly and private otherwise), and an index into the FileDef table indi-<br>cating the file that contains the resource file or stream. If the resource isn't <br>a stand-alone file (such as .jpg or a .gif), the resource is a stream contained <br>within a PE file. For an embedded resource, the entry also includes an off-<br>set indicating the start of the resource stream within the PE file.<br>
ExportedTypesDef<br>
Contains one entry for each public type exported from all of the  <br>assembly's PE modules. The entry includes the type's name, an index into <br>the FileDef table (indicating which of this assembly's files implements <br>the type), and an index into the TypeDef table. <i>Note</i>: To save file space, <br>types exported from the file containing the manifest are not repeated in <br>this table because the type information is available using the metadata's <br>TypeDef table.<br>
<hr>
<A name=64></a><IMG src="CLRviaCsharp-64_1.jpg"><br>
<IMG src="CLRviaCsharp-64_2.jpg"><br>
<b>46 </b><br>
<b>Part I  CLR Basics</b><br>
The existence of a manifest provides a level of indirection between consumers of the assembly <br>and the partitioning details of the assembly and makes assemblies self-describing. Also, note <br>that the file containing the manifest has metadata information that indicates which files are <br>part of the assembly, but the individual files themselves do not have metadata information <br>that specifies that they are part of the assembly.<br>
<b>Note  </b>The assembly file that contains the manifest also has an AssemblyRef table in it. This table <br>contains an entry for all of the assemblies referenced by all of the assembly's files. This allows <br>tools to open an assembly's manifest and see its set of referenced assemblies without having to <br>open the assembly's other files. Again, the entries in the AssemblyRef table exist to make an  <br>assembly self-describing.<br>
The C# compiler produces an assembly when you specify any of the following command-line <br>switches: /t[arget]:exe, /t[arget]:winexe, or /t[arget]:library. All of these switches <br>cause the compiler to generate a single PE file that contains the manifest metadata tables. <br>The resulting file is either a CUI executable, a GUI executable, or a DLL, respectively.<br>
In addition to these switches, the C# compiler supports the /t[arget]:module switch. This <br>switch tells the compiler to produce a PE file that doesn't contain the manifest metadata  <br>tables. The PE file produced is always a DLL PE file, and this file must be added to an assem-<br>bly before the CLR can access any types within it. When you use the /t:module switch, the <br>C# compiler, by default, names the output file with an extension of .netmodule.<br>
<b>Important  </b>Unfortunately, the Microsoft Visual Studio integrated development environment <br>(IDE) doesn't natively support the ability for you to create multifile assemblies. If you want to  <br>create multifile assemblies, you must resort to using command-line tools.<br>
There are many ways to add a module to an assembly. If you're using the C# compiler to <br>build a PE file with a manifest, you can use the /addmodule switch. To understand how to <br>build a multifile assembly, let's assume that we have two source code files:<br>
  RUT.cs, which contains rarely used types<br>
  FUT.cs, which contains frequently used types<br>
Let's compile the rarely used types into their own module so that users of the assembly won't <br>need to deploy this module if they never access the rarely used types:<br>
csc /t:module RUT.cs<br>
This line causes the C# compiler to create a RUT.netmodule file. This file is a standard DLL PE <br>file, but, by itself, the CLR can't load it.<br>
<hr>
<A name=65></a><b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>47</b><br>
Next let's compile the frequently used types into their own module. We'll make this module <br>the keeper of the assembly's manifest because the types are used so often. In fact, because <br>this module will now represent the entire assembly, I'll change the name of the output file to <br>JeffTypes.dll instead of calling it FUT.dll:<br>
csc /out:JeffTypes.dll /t:library /addmodule:RUT.netmodule FUT.cs<br>
This line tells the C# compiler to compile the FUT.cs file to produce the JeffTypes.dll file. <br>Because /t:library is specified, a DLL PE file containing the manifest metadata tables is <br>emitted into the JeffTypes.dll file. The /addmodule:RUT.netmodule switch tells the compiler <br>that RUT.netmodule is a file that should be considered part of the assembly. Specifically, the <br>/addmodule switch tells the compiler to add the file to the FileDef manifest metadata table <br>and to add RUT.netmodule's publicly exported types to the ExportedTypesDef manifest <br>metadata table.<br>
Once the compiler has finished all of its processing, the two files shown in Figure 2-1 are  <br>created. The module on the right contains the manifest.<br>
RUT.netmodule<br>
JeffTypes.dll<br>
IL compiled from RUT.cs<br>
IL compiled from FUT.cs<br>
Metadata<br>
Metadata<br>
Types, methods, and so on<br>
Types, methods, and so on<br>
defined by RUT.cs<br>
defined by FUT.cs<br>
 <br>
 <br>
Types, methods, and so on<br>
Types, methods, and so on<br>
referenced by RUT.cs<br>
referenced by FUT.cs<br>
Manifest<br>
Assembly files<br>
(self and RUT.netmodule)<br>
 <br>
Public assembly types<br>
(self and RUT.netmodule)<br>
<b>FIGURE 2-1  </b>A multifile assembly consisting of two managed modules, one with a manifest<br>
The RUT.netmodule file contains the IL code generated by compiling RUT.cs. This file also <br>contains metadata tables that describe the types, methods, fields, properties, events, and so <br>on that are defined by RUT.cs. The metadata tables also describe the types, methods, and <br>so on that are referenced by RUT.cs. The JeffTypes.dll is a separate file. Like RUT.netmodule, <br>this file includes the IL code generated by compiling FUT.cs and also includes similar defini-<br>tion and reference metadata tables. However, JeffTypes.dll contains the additional manifest <br>metadata tables, making JeffTypes.dll an assembly. The additional manifest metadata tables <br>describe all of the files that make up the assembly (the JeffTypes.dll file itself and the  <br>RUT.netmodule file). The manifest metadata tables also include all of the public types  <br>exported from JeffTypes.dll and RUT.netmodule.<br>
<hr>
<A name=66></a><IMG src="CLRviaCsharp-66_1.jpg"><br>
<IMG src="CLRviaCsharp-66_2.jpg"><br>
<b>48 </b><br>
<b>Part I  CLR Basics</b><br>
<b>Note  </b>In reality, the manifest metadata tables don't actually include the types that are exported <br>from the PE file that contains the manifest. The purpose of this optimization is to reduce the <br>number of bytes required by the manifest information in the PE file. So statements like "The <br>manifest metadata tables also include all the public types exported from JeffTypes.dll and  <br>RUT.netmodule" aren't 100 percent accurate. However, this statement does accurately reflect <br>what the manifest is logically exposing.<br>
Once the JeffTypes.dll assembly is built, you can use ILDasm.exe to examine the metadata's <br>manifest tables to verify that the assembly file does in fact have references to the  <br>RUT.netmodule file's types. Here is what the FileDef and ExportedTypesDef metadata  <br>tables look like:<br>
File #1 (26000001)  <br>-------------------------------------------------------  <br>   Token: 0x26000001  <br>   Name : RUT.netmodule <br>   HashValue Blob : e6 e6 df 62 2c a1 2c 59  97 65 0f 21 44 10 15 96  f2 7e db c2   <br>   Flags : [ContainsMetaData]  (00000000)  <br> <br> <br>ExportedType #1 (27000001)  <br>-------------------------------------------------------  <br>   Token: 0x27000001  <br>   Name: ARarelyUsedType <br>   Implementation token: 0x26000001  <br>   TypeDef token: 0x02000002  <br>   Flags     : [Public] [AutoLayout] [Class] [Sealed] [AnsiClass]  <br>               [BeforeFieldInit](00100101)<br>
From this, you can see that RUT.netmodule is a file considered to be part of the assembly <br>with the token 0x26000001. From the ExportedTypesDef table, you can see that there is <br>a publicly exported type, ARarelyUsedType. The implementation token for this type is <br>0x26000001, which indicates that the type's IL code is contained in the RUT.netmodule file.<br>
<b>Note  </b>For the curious, metadata tokens are 4-byte values. The high byte indicates the type of <br>token (0x01=TypeRef, 0x02=TypeDef, 0x23=AssemblyRef, 0x26=FileRef, 0x27=ExportedType). For <br>the complete list, see the CorTokenType enumerated type in the CorHdr.h file included with the <br>.NET Framework SDK. The three lower bytes of the token simply identify the row in the  <br>corresponding metadata table. For example, the implementation token 0x26000001 refers to  <br>the first row of the FileRef table. For most tables, rows are numbered starting with 1, not 0. For <br>the TypeDef table, rows actually start with 2.<br>
Any client code that consumes the JeffTypes.dll assembly's types must be built using the <br>/r[eference]:JeffTypes.dll compiler switch. This switch tells the compiler to load the <br>JeffTypes.dll assembly and all of the files listed in its FileDef table when searching for an  <br>external type. The compiler requires all of the assembly's files to be installed and accessible. If <br>
<hr>
<A name=67></a><b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>49</b><br>
you were to delete the RUT.netmodule file, the C# compiler would produce the fol owing error: <br>"fatal error CS0009: Metadata file 'C:\JeffTypes.dll' could not be opened--<br>'Error importing module 'RUT.netmodule' of assembly 'C:\JeffTypes.dll'--The <br>system cannot find the file specified'". This means that to build a new assembly, all <br>of the files from a referenced assembly <i>must</i> be present.<br>
As the client code executes, it calls methods. When a method is called for the first time, the <br>CLR detects the types that the method references as a parameter, a return value, or as a  <br>local variable. The CLR then attempts to load the referenced assembly's file that contains the <br>manifest. If the type being accessed is in this file, the CLR performs its internal bookkeeping, <br>allowing the type to be used. If the manifest indicates that the referenced type is in a differ-<br>ent file, the CLR attempts to load the necessary file, performs its internal bookkeeping, and <br>allows the type to be accessed. The CLR loads assembly files only when a method referencing <br>a type in an unloaded assembly is called. This means that to run an application, all of the files <br>from a referenced assembly <i>do not</i> need to be present.<br>
<b>Adding Assemblies to a Project by Using the Visual Studio IDE</b><br>
If you're using the Visual Studio IDE to build your project, you'll have to add any assemblies <br>that you want to reference to your project. To do so, open Solution Explorer, right-click the <br>project you want to add a reference to, and then select the Add Reference menu item. This <br>causes the Add Reference dialog box, shown in Figure 2-2, to appear.<br>
<b>FIGURE 2-2  </b>The Add Reference dialog box in Visual Studio<br>
<hr>
<A name=68></a><b>50 </b><br>
<b>Part I  CLR Basics</b><br>
To have your project reference an assembly, select the desired assembly from the list. If  <br>the assembly you want isn't in the list, click the Browse tab to navigate to the desired  <br>assembly (file containing a manifest) to add the assembly reference. The COM tab on the <br>Add Reference dialog box allows an unmanaged COM server to be accessed from within <br>managed source code via a managed proxy class automatically generated by Visual Studio. <br>The Projects tab allows the current project to reference an assembly that is created by  <br>another project in the same solution. The Recent tab allows you to select an assembly that <br>you recently added to another project.<br>
To make your own assemblies appear in the .NET tab's list, add the following subkey to the <br>registry:<br>
<i>HKEY_LOCAL_MACHINE\SOFTWARE\Microsoft\.NETFramework\AssemblyFolders\MyLibName</i><br>
<i>MyLibName</i> is a unique name that you create--Visual Studio doesn't display this name. <br>After creating the subkey, change its default string value so that it refers to a directory path <br>(such as C:\Program Files\MyLibPath) containing your assembly's files. Using HKEY_LOCAL_<br>MACHINE adds the assemblies for all users on a machine; use HKEY_CURRENT_USER instead <br>to add the assemblies for a specific user.<br>
<b>Using the Assembly Linker</b><br>
Instead of using the C# compiler, you might want to create assemblies by using the Assembly <br>Linker utility, AL.exe. The Assembly Linker is useful if you want to create an assembly consist-<br>ing of modules built from different compilers (if your compiler doesn't support the equivalent <br>of C#'s /addmodule switch) or perhaps if you just don't know your assembly packaging  <br>requirements at build time. You can also use AL.exe to build resource-only assemblies, called <br><i>satellite</i> assemblies, which are typically used for localization purposes. I'll talk about satellite <br>assemblies later in the chapter.<br>
The AL.exe utility can produce an EXE or a DLL PE file that contains only a manifest describ-<br>ing the types in other modules. To understand how AL.exe works, let's change the way the <br>JeffTypes.dll assembly is built:<br>
csc /t:module RUT.cs <br>csc /t:module FUT.cs <br>al  /out:JeffTypes.dll /t:library FUT.netmodule RUT.netmodule<br>
Figure 2-3 shows the files that result from executing these statements.<br>
<hr>
<A name=69></a><b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>51</b><br>
RUT.netmodule<br>
FUT.netmodule<br>
IL compiled from RUT.cs<br>
IL compiled from FUT.cs<br>
Metadata<br>
Metadata<br>
Types, methods, and so on<br>
Types, methods, and so on<br>
defined by RUT.cs<br>
defined by FUT.cs<br>
 <br>
 <br>
Types, methods, and so on<br>
Types, methods, and so on<br>
referenced by RUT.cs<br>
referenced by FUT.cs<br>
JeffTypes.dll<br>
(no IL)<br>
Metadata<br>
(No definition or reference tables)<br>
Manifest<br>
Assembly files<br>
(self, RUT.netmodule, and FUT.netmodule)<br>
 <br>
Public assembly types<br>
(RUT.netmodule and FUT.netmodule)<br>
<b>FIGURE 2-3  </b>A multifile assembly consisting of three managed modules, one with a manifest<br>
In this example, two separate modules, RUT.netmodule and FUT.netmodule, are created. <br>Neither module is an assembly because they don't contain manifest metadata tables. <br>Then a third file is produced: JeffTypes.dll, which is a small DLL PE file (because of the <br>/t[arget]:library switch) that contains no IL code but has manifest metadata tables  <br>indicating that RUT.netmodule and FUT.netmodule are part of the assembly. The resulting  <br>assembly consists of three files: JeffTypes.dll, RUT.netmodule, and FUT.netmodule. The <br>Assembly Linker has no way to combine multiple files into a single file.<br>
The AL.exe utility can also produce CUI and GUI PE files by using the /t[arget]:exe or <br>/t[arget]:winexe command-line switches. But this is very unusual since it would mean that <br>you'd have an EXE PE file with just enough IL code in it to call a method in another module. <br>You can specify which method in a module should be used as an entry point by adding the  <br>/main command-line switch when invoking AL.exe. The following is an example of how to <br>call the Assembly Linker, AL.exe, by using the /main command-line switch:<br>
csc /t:module /r:JeffTypes.dll Program.cs <br>al /out:Program.exe /t:exe /main:Program.Main Program.netmodule<br>
<hr>
<A name=70></a><b>52 </b><br>
<b>Part I  CLR Basics</b><br>
Here the first line builds the Program.cs file into a Program.netmodule file. The second line <br>produces a small Program.exe PE file that contains the manifest metadata tables. In addition, <br>there is a small global function named __EntryPoint that is emitted by AL.exe because of <br>the /main:Program.Main command-line switch. This function, __EntryPoint, contains the <br>following IL code:<br>
.method privatescope static void __EntryPoint$PST06000001() cil managed  <br>{  <br>  .entrypoint <br>  // Code size       8 (0x8)  <br>  .maxstack  8  <br>  IL_0000:  tail.  <br>  IL_0002:  call       void [.module 'Program.netmodule']Program::Main()  <br>  IL_0007:  ret  <br>} // end of method 'Global Functions'::__EntryPoint<br>
As you can see, this code simply calls the Main method contained in the Program type  <br>defined in the Program.netmodule file. The /main switch in AL.exe isn't that useful because <br>it's unlikely that you'd ever create an assembly for an application that didn't have its entry <br>point in the PE file that contains the manifest metadata tables. I mention the switch here only <br>to make you aware of its existence.<br>
With the code that accompanies this book, I have created a Ch02-3-BuildMultiFileLibrary.bat  <br>file that encapsulates all the steps required to build a multifile assembly. The  <br>Ch02-4-AppUsingMultiFileLibrary project in Visual Studio invokes this batch file as a  <br>prebuild command-line step. You can examine this project to see how to integrate building <br>and referencing a multifile assembly from within Visual Studio.<br>
<b>Adding Resource Files to an Assembly</b><br>
When using AL.exe to create an assembly, you can add a file as a resource to the assembly by <br>using the /embed[resource] switch. This switch takes a file (any file) and embeds the file's <br>contents into the resulting PE file. The manifest's ManifestResourceDef table is updated to <br>reflect the existence of the resources.<br>
AL.exe also supports a /link[resource] switch, which also takes a file containing resources. <br>However, the /link[resource] switch updates the manifest's ManifestResourceDef and <br>FileDef tables, indicating that the resource exists and identifying which of the assembly's files <br>contains it. The resource file is not embedded into the assembly PE file; it remains separate <br>and must be packaged and deployed with the other assembly files.<br>
Like AL.exe, CSC.exe also allows you to combine resources into an assembly produced by <br>the C# compiler. The C# compiler's /resource switch embeds the specified resource file <br>into the resulting assembly PE file, updating the ManifestResourceDef table. The compiler's <br>/linkresource switch adds an entry to the ManifestResourceDef and the FileDef manifest <br>tables to refer to a stand-alone resource file.<br>
<hr>
<A name=71></a><IMG src="CLRviaCsharp-71_1.jpg"><br>
<b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>53</b><br>
One last note about resources: it's possible to embed standard Win32 resources into an as-<br>sembly. You can do this easily by specifying the pathname of a .res file with the /win32res <br>switch when using either AL.exe or CSC.exe. In addition, you can quickly and easily embed <br>a standard Win32 icon resource into an assembly file by specifying the pathname of the .ico <br>file with the /win32icon switch when using either AL.exe or CSC.exe. Within Visual Studio, <br>you can add resource files to your assembly by displaying your project's properties and then <br>clicking the Application tab. The typical reason an icon is embedded is so that Windows <br>Explorer can show an icon for a managed executable file.<br>
<b>Note  </b>Managed assembly files also contain Win32 manifest resource information in them. By <br>default, the C# compiler automatically produces this manifest information but you can tell it not <br>to by using the /nowin32manifest switch. The default manifest produced by the C# compiler <br>looks like this:<br>
&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; standalone=&quot;yes&quot;?&gt; <br>&lt;assembly xmlns=&quot;urn:schemas-microsoft-com:asm.v1&quot; manifestVersion=&quot;1.0&quot;&gt; <br>   &lt;assemblyIdentity version=&quot;1.0.0.0&quot; name=&quot;MyApplication.app&quot; /&gt; <br>      &lt;trustInfo xmlns=&quot;urn:schemas-microsoft-com:asm.v2&quot;&gt; <br>         &lt;security&gt; <br>            &lt;requestedPrivileges xmlns=&quot;urn:schemas-microsoft-com:asm.v3&quot;&gt; <br>               &lt;requestedExecutionLevel level=&quot;asInvoker&quot; uiAccess=&quot;false&quot;/&gt; <br>            &lt;/requestedPrivileges&gt; <br>         &lt;/security&gt; <br>      &lt;/trustInfo&gt; <br>&lt;/assembly&gt;<br>
<b>Assembly Version Resource Information</b><br>
When AL.exe or CSC.exe produces a PE file assembly, it also embeds into the PE file a  <br>standard Win32 version resource. Users can examine this resource by viewing the file's  <br>properties. Application code can also acquire and examine this information at runtime by <br>calling System.Diagnostics.FileVersionInfo's static GetVersionInfo method.  <br>Figure 2-4 shows the Details tab of the JeffTypes.dll Properties dialog box.<br>
<hr>
<A name=72></a><b>54 </b><br>
<b>Part I  CLR Basics</b><br>
<b>FIGURE 2-4  </b>The Details tab of the JeffTypes.dll Properties dialog box<br>
When building an assembly, you should set the version resource fields by using custom  <br>attributes that you apply at the assembly level in your source code. Here's what the code  <br>that produced the version information in Figure 2-4 looks like:<br>
using System.Reflection; <br> <br>// FileDescription version information: <br>[assembly: AssemblyTitle(&quot;JeffTypes.dll&quot;)] <br> <br>// Comments version information: <br>[assembly: AssemblyDescription(&quot;This assembly contains Jeff's types&quot;)] <br> <br>// CompanyName version information: <br>[assembly: AssemblyCompany(&quot;Wintellect&quot;)] <br> <br>// ProductName version information: <br>[assembly: AssemblyProduct(&quot;Wintellect (R) Jeff's Type Library&quot;)] <br> <br>// LegalCopyright version information: <br>[assembly: AssemblyCopyright(&quot;Copyright (c) Wintellect 2010&quot;)] <br> <br>// LegalTrademarks version information: <br>[assembly:AssemblyTrademark(&quot;JeffTypes is a registered trademark of Wintellect&quot;)] <br> <br>// AssemblyVersion version information: <br>[assembly: AssemblyVersion(&quot;3.0.0.0&quot;)] <br> <br>
<hr>
<A name=73></a><IMG src="CLRviaCsharp-73_1.jpg"><br>
<b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>55</b><br>
// FILEVERSION/FileVersion version information: <br>[assembly: AssemblyFileVersion(&quot;1.0.0.0&quot;)] <br> <br>// PRODUCTVERSION/ProductVersion version information: <br>[assembly: AssemblyInformationalVersion(&quot;2.0.0.0&quot;)] <br> <br>// Set the Language field (discussed later in the &quot;Culture&quot; section) <br>[assembly:AssemblyCulture(&quot;&quot;)]<br>
<b>Important  </b>Unfortunately, the Windows Explorer Properties dialog box is missing entries for <br>some of the attributes. In particular, it would be great if the value of the AssemblyVersion  <br>attribute were shown because the CLR uses this value when loading assemblies, as we'll discuss  <br>in Chapter 3.<br>
Table 2-4 shows the version resource fields and the custom attributes that correspond to <br>them. If you're using AL.exe to build your assembly, you can use command-line switches to <br>set this information instead of using the custom attributes. The second column in Table 2-4 <br>shows the AL.exe command-line switch that corresponds to each version resource field. Note <br>that the C# compiler doesn't offer these command-line switches and that, in general, using <br>custom attributes is the preferred way to set this information.<br>
<b>TABLE 2-4  Version Resource Fields and Their Corresponding AL.exe Switches and <br>Custom Attributes</b><br>
<b>Version Resource</b><br>
<b>AL.exe Switch</b><br>
<b>Custom Attribute/Comment</b><br>
FILEVERSION<br>
/fileversion<br>
System.Reflection.<br>AssemblyFileVersionAttribute.<br>
PRODUCTVERSION /productversion<br>
System.Reflection. <br>AssemblyInformationalVersionAttribute.<br>
FILEFLAGSMASK<br>
(none)<br>
Always set to VS_FFI_FILEFLAGSMASK (defined in <br>WinVer.h as 0x0000003F).<br>
FILEFLAGS<br>
(none)<br>
Always 0.<br>
FILEOS<br>
(none)<br>
Currently always VOS__WINDOWS32.<br>
FILETYPE<br>
/target<br>
Set to VFT_APP if /target:exe or /target:winexe  <br>is specified; set to VFT_DLL if /target:library is <br>specified.<br>
FILESUBTYPE<br>
(none)<br>
Always set to VFT2_UNKNOWN. (This field has no meaning <br>for VFT_APP and VFT_DLL.)<br>
AssemblyVersion<br>
/version<br>
System.Reflection.AssemblyVersionAttribute.<br>
Comments<br>
/description<br>
System.Reflection.<br>AssemblyDescriptionAttribute.<br>
CompanyName<br>
/company<br>
System.Reflection.AssemblyCompanyAttribute.<br>
FileDescription<br>
/title<br>
System.Reflection.AssemblyTitleAttribute.<br>
<hr>
<A name=74></a><IMG src="CLRviaCsharp-74_1.jpg"><br>
<b>56 </b><br>
<b>Part I  CLR Basics</b><br>
<b>Version Resource</b><br>
<b>AL.exe Switch</b><br>
<b>Custom Attribute/Comment</b><br>
FileVersion<br>
/version<br>
System.Reflection.<br>AssemblyFileVersionAttribute.<br>
InternalName<br>
/out<br>
Set to the name of the output file specified (without the <br>extension).<br>
LegalCopyright<br>
/copyright<br>
System.Reflection.AssemblyCopyrightAttribute.<br>
LegalTrademarks<br>
/trademark<br>
System.Reflection.AssemblyTrademarkAttribute.<br>
OriginalFilename<br>
/out<br>
Set to the name of the output file (without a path).<br>
PrivateBuild<br>
(none)<br>
Always blank.<br>
ProductName<br>
/product<br>
System.Reflection.AssemblyProductAttribute.<br>
ProductVersion<br>
/productversion<br>
System.Reflection. <br>AssemblyInformationalVersionAttribute.<br>
SpecialBuild<br>
(none)<br>
Always blank.<br>
<b>Important  </b>When you create a new C# project in Visual Studio, an AssemblyInfo.cs file is cre-<br>ated automatically for you. This file contains all of the assembly version attributes described in <br>this section, plus a few additional attributes that I'll cover in Chapter 3. You can simply open the <br>AssemblyInfo.cs file and modify your assembly-specific information. Visual Studio also provides a <br>dialog box that you can use to edit the assembly version information in this file. To see this dialog <br>box, in Solution Explorer, double-click your project's Properties entry, and on the Application tab, <br>click Assembly Information; you'll see a dialog box like the one shown in Figure 2-5.<br>
<b>FIGURE 2-5</b>  Visual Studio's Assembly Information dialog box<br>
<hr>
<A name=75></a><b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>57</b><br>
<b>Version Numbers</b><br>
In the previous section, you saw that several version numbers can be applied to an assembly. <br>All of these version numbers have the same format: each consists of four period-separated <br>parts, as shown in Table 2-5.<br>
<b>TABLE 2-5  Format of Version Numbers</b><br>
<b>Major Number</b><br>
<b>Minor Number</b><br>
<b>Build Number Revision Number</b><br>
Example:<br>
2<br>
5<br>
719<br>
2<br>
Table 2-5 shows an example of a version number: 2.5.719.2. The first two numbers make up <br>the public perception of the version. The public will think of this example as version 2.5 of the <br>assembly. The third number, 719, indicates the build of the assembly. If your company builds <br>its assembly every day, you should increment the build number each day as well. The last <br>number, 2, indicates the revision of the build. If for some reason your company has to build <br>an assembly twice in one day, maybe to resolve a hot bug that is halting other work, the  <br>revision number should be incremented.<br>
Microsoft uses this version-numbering scheme, and it's highly recommended that you use <br>this scheme as well. Future versions of the CLR will offer better support for loading new  <br>versions of an assembly and for rolling back to a previous version of an assembly if a new <br>version actually breaks an existing application. To accomplish this versioning support, the  <br>CLR will expect that a version of an assembly that fixes one or more bugs will have the same  <br>major/minor version, and the build/revision numbers will indicate a servicing version contain-<br>ing the update(s). When loading an assembly, the CLR will automatically find the latest  <br>installed servicing version that matches the major/minor version of the assembly being <br>requested.<br>
You'll notice that an assembly has three version numbers associated with it. This is very  <br>unfortunate and leads to a lot of confusion. Let me explain each version number's purpose <br>and how it is expected to be used:<br>
<b>  AssemblyFileVersion  </b>This version number is stored in the Win32 version resource. <br>
This number is for information purposes only; the CLR doesn't examine this version <br>number in any way. Typically, you set the major and minor parts to represent the  <br>version you want the public to see. Then you increment the build and revision parts <br>each time a build is performed. Ideally, Microsoft's tool (such as CSC.exe or AL.exe) <br>would automatically update the build and revision numbers for you (based on the date <br>and time when the build was performed), but unfortunately, they don't. This version <br>number can be seen when using Windows Explorer and is typically used to identify a <br>specific version of an assembly when troubleshooting a customer's system.<br>
<b>  AssemblyInformationalVersion  </b>This version number is also stored in the Win32  <br>
version resource, and again, this number is for information purposes only; the CLR <br>
<hr>
<A name=76></a><b>58 </b><br>
<b>Part I  CLR Basics</b><br>
doesn't examine or care about it in any way. This version number exists to indicate  <br>the version of the product that includes this assembly. For example, version 2.0 of a <br>product might contain several assemblies; one of these assemblies is marked as  <br>version 1.0 since it's a new assembly that didn't ship in version 1.0 of the same product. <br>Typically, you set the major and minor parts of this version number to represent the <br>public version of your product. Then you increment the build and revision parts each <br>time you package a complete product with all its assemblies.<br>
<b>  AssemblyVersion  </b>This version number is stored in the AssemblyDef manifest metadata <br>
table. The CLR uses this version number when binding to strongly named assemblies <br>(discussed in Chapter 3). This number is extremely important and is used to uniquely <br>identify an assembly. When starting to develop an assembly, you should set the major, <br>minor, build, and revision numbers and shouldn't change them until you're ready to  <br>begin work on the next deployable version of your assembly. When you build an <br>assembly, this version number of the referenced assembly is embedded in the <br>AssemblyRef table's entry. This means that an assembly is tightly bound to a specific <br>version of a referenced assembly. <br>
<b>Culture</b><br>
Like version numbers, assemblies also have a culture as part of their identity. For example, I <br>could have an assembly that is strictly for German, another assembly for Swiss German,  <br>another assembly for U.S. English, and so on. Cultures are identified via a string that contains <br>a primary and a secondary tag (as described in RFC 1766). Table 2-6 shows some examples.<br>
<b>TABLE 2-6  Examples of Assembly Culture Tags</b><br>
<b>Primary Tag</b><br>
<b>Secondary Tag</b><br>
<b>Culture</b><br>
de<br>
(none)<br>
German<br>
de<br>
AT<br>
Austrian German<br>
de<br>
CH<br>
Swiss German<br>
en<br>
(none)<br>
English<br>
en<br>
GB<br>
British English<br>
en<br>
US<br>
U.S. English<br>
In general, if you create an assembly that contains code, you don't assign a culture to it. This is <br>because code doesn't usually have any culture-specific assumptions built into it. An assembly <br>that isn't assigned a culture is referred to as being <i>culture neutral</i>.<br>
If you're designing an application that has some culture-specific resources to it, Microsoft <br>highly recommends that you create one assembly that contains your code and your applica-<br>tion's default (or fallback) resources. When building this assembly, don't specify a culture. This <br>is the assembly that other assemblies will reference when they create and manipulate types it <br>publicly exposes.<br>
<hr>
<A name=77></a><IMG src="CLRviaCsharp-77_1.jpg"><br>
<b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>59</b><br>
Now you can create one or more separate assemblies that contain only culture-specific  <br>resources--no code at all. Assemblies that are marked with a culture are called <i>satellite  <br>assemblies</i>. For these satellite assemblies, assign a culture that accurately reflects the culture <br>of the resources placed in the assembly. You should create one satellite assembly for each <br>culture you intend to support.<br>
You'll usually use the AL.exe tool to build a satellite assembly. You won't use a compiler  <br>because the satellite assembly should have no code contained within it. When using AL.exe, <br>you specify the desired culture by using the /c[ulture]:text switch, where text is a string <br>such as "en-US," representing U.S. English. When you deploy a satellite assembly, you should <br>place it in a subdirectory whose name matches the culture text. For example, if the applica-<br>tion's base directory is C:\MyApp, the U.S. English satellite assembly should be placed in the <br>C:\MyApp\en-US subdirectory. At runtime, you access a satellite assembly's resources by  <br>using the System.Resources.ResourceManager class.<br>
<b>Note  </b>It is possible to create a satellite assembly that contains code, though this practice is <br>discouraged. If you prefer, you can specify the culture by using the System.Reflection.<br>AssemblyCultureAttribute custom attribute instead of using AL.exe's /culture switch, for  <br>example, as shown here:<br>
// Set assembly's culture to Swiss German  <br>[assembly:AssemblyCulture(&quot;de-CH&quot;)]<br>
Normally, you shouldn't build an assembly that references a satellite assembly. In other <br>words, an assembly's AssemblyRef entries should all refer to culture-neutral assemblies. If you <br>want to access types or members contained in a satellite assembly, you should use reflection <br>techniques as discussed in Chapter 23, "Assembly Loading and Reflection."<br>
<b>Simple Application Deployment (Privately Deployed </b><br>
<b>Assemblies)</b><br>
Throughout this chapter, I've explained how you build modules and how you combine those <br>modules into an assembly. At this point, I'm ready to explain how to package and deploy all <br>of the assemblies so that users can run the application.<br>
Assemblies don't dictate or require any special means of packaging. The easiest way to  <br>package a set of assemblies is simply to copy all of the files directly. For example, you could <br>put all of the assembly files on a CD-ROM and ship it to the user with a batch file setup  <br>program that just copies the files from the CD to a directory on the user's hard drive. Because <br>the assemblies include all of the dependent assembly references and types, the user can just <br>run the application and the runtime will look for referenced assemblies in the application's <br>directory. No modifications to the registry are necessary for the application to run. To  <br>uninstall the application, just delete all the files--that's it!<br>
<hr>
<A name=78></a><IMG src="CLRviaCsharp-78_1.jpg"><br>
<b>60 </b><br>
<b>Part I  CLR Basics</b><br>
Of course, you can package and install the assembly files by using other mechanisms, such as <br>.cab files (typically used for Internet download scenarios to compress files and reduce down-<br>load times). You can also package the assembly files into an MSI file for use by the Windows <br>Installer service (MSIExec.exe). Using MSI files allows assemblies to be installed on demand <br>the first time the CLR attempts to load the assembly. This feature isn't new to MSI; it can  <br>perform the same demand-load functionality for unmanaged EXE and DLL files as well.<br>
<b>Note  </b>Using a batch file or some other simple "installation software" will get an application <br>onto the user's machine; however, you'll need more sophisticated installation software to create <br>shortcut links on the user's desktop and Start menu. Also, you can easily back up and restore the <br>application or move it from one machine to another, but the various shortcut links will require <br>special handling. <br>
Of course, Visual Studio has a built-in mechanism that you can use to publish an application <br>by displaying a project's Properties pages and clicking the Publish tab. You can use the  <br>options available on the Publish tab to cause Visual Studio to produce an MSI file and copy <br>the resulting MSI file to a Web site, FTP server, or file path. The MSI file can also install any <br>prerequisite components such as the .NET Framework or Microsoft SQL Server 2008 Express <br>Edition. Finally, the application can automatically check for updates and install them on the <br>user's machine by taking advantage of ClickOnce technology.<br>
Assemblies deployed to the same directory as the application are called <i>privately deployed <br>assemblies </i>because the assembly files aren't shared with any other application (unless the <br>other application is also deployed to the same directory). Privately deployed assemblies are a <br>big win for developers, end users, and administrators because they can simply be copied to <br>an application's base directory, and the CLR will load them and execute the code in them. In <br>addition, an application can be uninstalled by simply deleting the assemblies in its directory. <br>This allows simple backup and restore as well.<br>
This simple install/move/uninstall scenario is possible because each assembly has metadata <br>indicating which referenced assembly should be loaded; no registry settings are required. In <br>addition, the referencing assembly scopes every type. This means that an application always <br>binds to the same type it was built and tested with; the CLR can't load a different assembly <br>that just happens to provide a type with the same name. This is different from COM, in which <br>types are recorded in the registry, making them available to any application running on the <br>machine.<br>
In Chapter 3, I'll discuss how to deploy shared assemblies that are accessible by multiple <br>applications.<br>
<hr>
<A name=79></a><b> </b><br>
<b>Chapter 2  Building, Packaging, Deploying, and Administering Applications and Types </b><br>
<b>61</b><br>
<b>Simple Administrative Control (Configuration)</b><br>
The user or the administrator can best determine some aspects of an application's execution. <br>For example, an administrator might decide to move an assembly's files on the user's hard <br>disk or to override information contained in the assembly's manifest. Other scenarios also <br>exist related to versioning; I'll talk about some of these in Chapter 3.<br>
To allow administrative control over an application, a configuration file can be placed in the <br>application's directory. An application's publisher can create and package this file. The setup <br>program would then install this configuration file in the application's base directory. In ad-<br>dition, the machine's administrator or an end user could create or modify this file. The CLR <br>interprets the content of this file to alter its policies for locating and loading assembly files.<br>
These configuration files contain Extensible Markup Language (XML) and can be associated <br>with an application or with the machine. Using a separate file (vs. registry settings) allows the <br>file to be easily backed up and also allows the administrator to copy the application to another <br>machine--just copy the necessary files and the administrative policy is copied too.<br>
In Chapter 3, we'll explore this configuration file in more detail. But I want to give you a taste <br>of it now. Let's say that the publisher of an application wants its application deployed with <br>the JeffTypes assembly files in a different directory than the application's assembly file. The <br>desired directory structure looks like this:<br>
AppDir directory (contains the application's assembly files)  <br>   Program.exe  <br>   Program.exe.config (discussed below)  <br> <br>   AuxFiles subdirectory (contains JeffTypes' assembly files)   <br>      JeffTypes.dll  <br>      FUT.netmodule <br>      RUT.netmodule<br>
Since the JeffTypes files are no longer in the application's base directory, the CLR  <br>won't be able to locate and load these files; running the application will cause a  <br>System.IO.FileNotFoundException exception to be thrown. To fix this, the publisher  <br>creates an XML configuration file and deploys it to the application's base directory. The name <br>of this file must be the name of the application's main assembly file with a .config extension: <br>Program.exe.config, for this example. The configuration file should look like this:<br>
&lt;configuration&gt; <br>   &lt;runtime&gt; <br>      &lt;assemblyBinding xmlns=&quot;urn:schemas-microsoft-com:asm.v1&quot;&gt; <br>         &lt;probing privatePath=&quot;AuxFiles&quot; /&gt; <br>      &lt;/assemblyBinding&gt; <br>   &lt;/runtime&gt; <br>&lt;/configuration&gt;<br>
<hr>
<A name=80></a><hr>
<A name=81></a><hr>
<A name=82></a><b>64 </b><br>
<b>Part I  CLR Basics</b><br>
Settings in the Machine.config file represent default settings that affect all applications run-<br>ning on the machine. An administrator can create a machine-wide policy by modifying the <br>single Machine.config file. However, administrators and users should avoid modifying this file <br>because it contains many settings related to various things, making it much more difficult to <br>navigate. Plus, you want the application's settings to be backed up and restored, and keeping <br>an application's settings in the application-specific configuration file enables this.<br>
<hr>
<A name=83></a>Chapter 3<br><b>Shared Assemblies and Strongly </b><br>
<b>Named Assemblies</b><br>
<b>In this chapter:<br>Two Kinds of Assemblies, Two Kinds of Deployment . . . . . . . . . . . . . . . . . . . . . . . 66<br>Giving an Assembly a Strong Name. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67<br>The Global Assembly Cache  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73<br>Building an Assembly That References a Strongly Named Assembly  . . . . . . . . . 75<br>Strongly Named Assemblies Are Tamper-Resistant  . . . . . . . . . . . . . . . . . . . . . . . . 76<br>Delayed Signing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77<br>Privately Deploying Strongly Named Assemblies . . . . . . . . . . . . . . . . . . . . . . . . . . 80<br>How the Runtime Resolves Type References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81<br>Advanced Administrative Control (Configuration)  . . . . . . . . . . . . . . . . . . . . . . . . . 84</b><br>
In Chapter 2, "Building, Packaging, Deploying, and Administering Applications and Types," <br>I talked about the steps required to build, package, and deploy an assembly. I focused on <br>what's called private deployment, in which assemblies are placed in the application's base <br>directory (or a subdirectory thereof) for the application's sole use. Deploying assemblies pri-<br>vately gives a company a large degree of control over the naming, versioning, and behavior <br>of the assembly.<br>
In this chapter, I'll concentrate on creating assemblies that can be accessed by multiple  <br>applications. The assemblies that ship with the Microsoft .NET Framework are an excellent  <br>example of globally deployed assemblies, because all managed applications use types  <br>defined by Microsoft in the .NET Framework Class Library (FCL).<br>
As I mentioned in Chapter 2, Microsoft Windows has a reputation for being unstable. The <br>main reason for this reputation is the fact that applications are built and tested using code <br>implemented by someone else. After all, when you write an application for Windows, your <br>application is calling into code written by Microsoft developers. Also, a large number of com-<br>panies make controls that application developers can incorporate into their own applications. <br>In fact, the .NET Framework encourages this, and many control vendors have appeared over <br>time.<br>
As time marches on, Microsoft developers and control developers modify their code: they fix <br>bugs, patch security flaws, add features, and so on. Eventually, the new code makes its way <br>
<b> </b><br>
<b> </b><br>
<b>65</b><br>
<hr>
<A name=84></a><IMG src="CLRviaCsharp-84_1.jpg"><br>
<b>66 </b><br>
<b>Part I  CLR Basics</b><br>
onto the user's machine. The user's applications that were previously installed and working <br>fine are no longer using the same code that the applications were built and tested with. As a <br>result, the applications' behavior is no longer predictable, which contributes to the instability <br>of Windows.<br>
File versioning is a very difficult problem to solve. In fact, I assert that if you take a file that <br>is used by other code files and change just one bit in the file--change a 0 to a 1 or a 1 to a <br>0--there's absolutely no way to guarantee that code that used the file before it was changed <br>will now work just as well if it uses the new version of the file. One of the reasons why this <br>statement is true is that a lot of applications exploit bugs, either knowingly or unknowingly. If <br>a later version of a file fixes a bug, the application no longer runs as expected.<br>
So here's the problem: How do you fix bugs and add features to a file and also guarantee <br>that you don't break some application? I've given this question a lot of thought and have <br>come to one conclusion: It's just not possible. But, obviously, this answer isn't good enough. <br>Files will ship with bugs, and companies will always want to provide new features. There must <br>be a way to distribute new files with the hope that the applications will work just fine. And if <br>the application doesn't work fine, there has to be an <i>easy </i>way to restore the application to its <br>last-known good state.<br>
In this chapter, I'll explain the infrastructure that the .NET Framework has in place to deal with <br>versioning problems. Let me warn you: What I'm about to describe is complicated. I'm going <br>to talk about a lot of algorithms, rules, and policies that are built into the common language <br>runtime (CLR). I'm also going to mention a lot of tools and utilities that the application devel-<br>oper must use. This stuff is complicated because, as I've mentioned, the versioning problem <br>is difficult to address and to solve.<br>
<b>Two Kinds of Assemblies, Two Kinds of Deployment</b><br>
The CLR supports two kinds of assemblies: <i>weakly named assemblies </i>and <i>strongly named <br>assemblies</i>.<br>
<b>Important  </b>By the way, you won't find the term <i>weakly named assembly</i> in any of the .NET <br>Framework documentation. Why? Because I made it up. In fact, the documentation has no term <br>to identify a weakly named assembly. I decided to coin the term so that I can talk about assem-<br>blies without any ambiguity as to what kind of assembly I'm referring to.<br>
Weakly named assemblies and strongly named assemblies are structurally identical--that is, <br>they use the same portable executable (PE) file format, PE32(+) header, CLR header, metadata, <br>manifest tables, and Intermediate Language (IL) that we examined in Chapter 1, "The CLR's <br>Execution Model," and Chapter 2. And you use the same tools, such as the C# compiler and <br>AL.exe, to build both kinds of assemblies. The real difference between weakly named and <br>
<hr>
<A name=85></a><IMG src="CLRviaCsharp-85_1.jpg"><br>
<b> </b><br>
<b>Chapter 3  Shared Assemblies and Strongly Named Assemblies </b><br>
<b>67</b><br>
strongly named assemblies is that a strongly named assembly is signed with a publisher's <br>public/private key pair that uniquely identifies the assembly's publisher. This key pair allows <br>the assembly to be uniquely identified, secured, and versioned, and it allows the assembly to <br>be deployed anywhere on the user's machine or even on the Internet. This ability to uniquely <br>identify an assembly allows the CLR to enforce certain known-to-be-safe policies when an <br>application tries to bind to a strongly named assembly. This chapter is dedicated to explain-<br>ing what strongly named assemblies are and what policies the CLR applies to them.<br>
An assembly can be deployed in two ways: privately or global y. A privately deployed assembly <br>is an assembly that is deployed in the application's base directory or one of its subdirectories. <br>A weakly named assembly can be deployed only privately. I talked about privately deployed <br>assemblies in Chapter 2. A globally deployed assembly is an assembly that is deployed into <br>some well-known location that the CLR looks in when it's searching for the assembly. A <br>strongly named assembly can be deployed privately or globally. I'll explain how to create and <br>deploy strongly named assemblies in this chapter. Table 3-1 summarizes the kinds of assem-<br>blies and the ways that they can be deployed.<br>
<b>TABLE 3-1  How Weakly and Strongly Named Assemblies Can Be Deployed</b><br>
<b>Kind of Assembly</b><br>
<b>Can Be Privately Deployed</b><br>
<b>Can Be Globally Deployed</b><br>
Weakly named<br>
Yes<br>
No<br>
Strongly named<br>
Yes<br>
Yes<br>
<b>Note</b>  It is highly recommended that you strongly name all of your assemblies. In fact, it is likely <br>that future versions of the CLR will require all assemblies to be strongly named, and the ability <br>to create weakly named assemblies will be deprecated. Weakly named assemblies are a problem <br>because it is possible to have several different assemblies all with the same weak name. On the <br>other hand, giving an assembly a strong name uniquely identifies that assembly. If the CLR can <br>uniquely identify an assembly, it can apply more policies to it related to versioning or backward <br>compatibility. It is Microsoft's plan to endow future versions of the CLR with these policies to <br>make versioning simpler. In fact, just eliminating the ability to make weakly named assemblies <br>makes understanding the CLR's versioning policies simpler.<br>
<b>Giving an Assembly a Strong Name</b><br>
If multiple applications are going to access an assembly, the assembly must be placed in a <br>well-known directory, and the CLR must know to look in this directory automatically when  <br>a reference to the assembly is detected. However, we have a problem: Two (or more)  <br>companies could produce assemblies that have the same file name. Then, if both of these <br>assemblies get copied into the same well-known directory, the last one installed wins, and <br>all of the applications that were using the old assembly no longer function as desired. (This <br>is exactly why DLL hell exists today in Windows, in which shared DLLs are all just copied into <br>the System32 directory.)<br>
<hr>
<A name=86></a><IMG src="CLRviaCsharp-86_1.jpg"><br>
<b>68 </b><br>
<b>Part I  CLR Basics</b><br>
Obviously, differentiating assemblies simply by using a file name isn't good enough. The CLR <br>needs to support some mechanism that allows assemblies to be uniquely identified. This is <br>what the term <i>strongly named assembly</i> refers to. A strongly named assembly consists of four <br>attributes that uniquely identify the assembly: a file name (without an extension), a version <br>number, a culture identity, and a public key. Since public keys are very large numbers, we fre-<br>quently use a small hash value derived from a public key. This hash value is called a <i>public key <br>token</i>. The following assembly identity strings (sometimes called an <i>assembly display name</i>) <br>identify four completely different assembly files:<br>
&quot;MyTypes, Version=1.0.8123.0, Culture=neutral, PublicKeyToken=b77a5c561934e089&quot;  <br>  <br>&quot;MyTypes, Version=1.0.8123.0, Culture=&quot;en-US&quot;, PublicKeyToken=b77a5c561934e089&quot;  <br>  <br>&quot;MyTypes, Version=2.0.1234.0, Culture=neutral, PublicKeyToken=b77a5c561934e089&quot;  <br>  <br>&quot;MyTypes, Version=1.0.8123.0, Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a&quot;<br>
The first string identifies an assembly file called MyTypes.exe or MyTypes.dll (you can't actual-<br>ly determine the file extension from an assembly identity string). The company producing the <br>assembly is creating version 1.0.8123.0 of this assembly, and nothing in the assembly is sensi-<br>tive to any one culture because Culture is set to neutral. Of course, any company could <br>produce a MyTypes.dll (or MyTypes.exe) assembly file that is marked with a version number <br>of 1.0.8123.0 and a neutral culture.<br>
There must be a way to distinguish this company's assembly from another company's  <br>assembly that happens to have the same attributes. For several reasons, Microsoft chose <br>to use standard public/private key cryptographic technologies instead of any other unique <br>identification technique such as GUIDs, URLs, or URNs. Specifically, cryptographic techniques <br>provide a way to check the integrity of the assembly's bits as they are installed on a machine, <br>and they also allow permissions to be granted on a per-publisher basis. I'll discuss these tech-<br>niques later in this chapter. So a company that wants to uniquely mark its assemblies must <br>create a public/private key pair. Then the public key can be associated with the assembly. <br>No two companies should have the same public/private key pair, and this distinction is what <br>allows two companies to create assemblies that have the same name, version, and culture <br>without causing any conflict.<br>
<b>Note  </b>The System.Reflection.AssemblyName class is a helper class that makes it easy for <br>you to build an assembly name and to obtain the various parts of an assembly's name. The class <br>offers several public instance properties, such as CultureInfo, FullName, KeyPair, Name, <br>and Version. The class also offers a few public instance methods, such as GetPublicKey, <br>GetPublicKeyToken, SetPublicKey, and SetPublicKeyToken.<br>
In Chapter 2, I showed you how to name an assembly file and how to apply an assembly ver-<br>sion number and a culture. A weakly named assembly can have assembly version and culture <br>
<hr>
<A name=87></a><b> </b><br>
<b>Chapter 3  Shared Assemblies and Strongly Named Assemblies </b><br>
<b>69</b><br>
attributes embedded in the manifest metadata; however, the CLR always ignores the version <br>number and uses only the culture information when it's probing subdirectories looking for <br>the satellite assembly. Because weakly named assemblies are always privately deployed, <br>the CLR simply uses the name of the assembly (tacking on a .dll or an .exe extension) when <br>searching for the assembly's file in the application's base directory or in any of the applica-<br>tion's subdirectories specified in the Extensible Markup Language (XML) configuration file's <br>probing element's privatePath XML attribute.<br>
A strongly named assembly has a file name, an assembly version, and a culture. In addition, <br>a strongly named assembly is signed with the publisher's private key.<br>
The first step in creating a strongly named assembly is to obtain a key by using the Strong <br>Name utility, SN.exe, that ships with the .NET Framework SDK and Microsoft Visual Studio. <br>This utility offers a whole slew of features depending on the command-line switch you  <br>specify. Note that all SN.exe's command-line switches are case-sensitive. To generate a  <br>public/private key pair, you run SN.exe as follows:<br>
SN ­k MyCompany.snk<br>
This line tells SN.exe to create a file called MyCompany.snk. This file will contain the public <br>and private key numbers persisted in a binary format.<br>
Public key numbers are very big. If you want to, after creating the file that contains the public <br>and private key, you can use the SN.exe utility again to see the actual public key. To do this, <br>you must execute the SN.exe utility twice. First, you invoke SN.exe with the ­p switch to  <br>create a file that contains only the public key (MyCompany.PublicKey):<br>
SN ­p MyCompany.snk MyCompany.PublicKey<br>
Then, you invoke SN.exe, passing it the ­tp switch and the file that contains just the public <br>key:<br>
SN ­tp MyCompany.PublicKey<br>
When I execute this line, I get the following output:<br>
Microsoft (R) .NET Framework Strong Name Utility  Version 4.0.20928.1  <br>Copyright (c) Microsoft Corporation.  All rights reserved.  <br>  <br>Public key is  <br>00240000048000009400000006020000002400005253413100040000010001003f9d621b702111  <br>850be453b92bd6a58c020eb7b804f75d67ab302047fc786ffa3797b669215afb4d814a6f294010  <br>b233bac0b8c8098ba809855da256d964c0d07f16463d918d651a4846a62317328cac893626a550  <br>69f21a125bc03193261176dd629eace6c90d36858de3fcb781bfc8b817936a567cad608ae672b6  <br>1fb80eb0  <br>  <br>Public key token is 3db32f38c8b42c9a<br>
The SN.exe utility doesn't offer any way for you to display the private key.<br>
<hr>
<A name=88></a><b>70 </b><br>
<b>Part I  CLR Basics</b><br>
The size of public keys makes them difficult to work with. To make things easier for the de-<br>veloper (and for end users too), <i>public key tokens</i> were created. A public key token is a 64-bit <br>hash of the public key. SN.exe's ­tp switch shows the public key token that corresponds to <br>the complete public key at the end of its output.<br>
Now that you know how to create a public/private key pair, creating a strongly named  <br>assembly is simple. When you compile your assembly, you use the /keyfile:&lt;file&gt;  <br>compiler switch:<br>
csc /keyfile:MyCompany.snk Program.cs<br>
When the C# compiler sees this switch, the compiler opens the specified file (MyCompany.snk), <br>signs the assembly with the private key, and embeds the public key in the manifest. Note that <br>you sign only the assembly file that contains the manifest; the assembly's other files can't be <br>signed explicitly.<br>
If you are using Visual Studio, you can create a new public/private key file by displaying the <br>properties for your project, clicking the Signing tab, selecting the Sign The Assembly check <br>box, and then choosing the &lt;New...&gt; option from the Choose A Strong Name Key File com-<br>bo box. <br>
Here's what it means to sign a file: When you build a strongly named assembly, the assembly's <br>FileDef manifest metadata table includes the list of all the files that make up the assembly.  <br>As each file's name is added to the manifest, the file's contents are hashed, and this hash  <br>value is stored along with the file's name in the FileDef table. You can override the default <br>hash algorithm used with AL.exe's /algid switch or apply the assembly-level  <br>System.Reflection.AssemblyAlgorithmIdAttribute custom attribute in one of the  <br>assembly's source code files. By default, a SHA-1 algorithm is used, and this should be  <br>sufficient for almost all applications.<br>
After the PE file containing the manifest is built, the PE file's entire contents (except for any <br>Authenticode Signature, the assembly's strong name data, and the PE header checksum) are <br>hashed, as shown in Figure 3-1. The hash algorithm used here is always SHA-1 and can't be <br>overridden. This hash value is signed with the publisher's private key, and the resulting RSA <br>digital signature is stored in a reserved section (not included in the hash) within the PE file. <br>The CLR header of the PE file is updated to reflect where the digital signature is embedded <br>within the file.<br>
<hr>
<A name=89></a><IMG src="CLRviaCsharp-89_1.jpg"><br>
<b> </b><br>
<b>Chapter 3  Shared Assemblies and Strongly Named Assemblies </b><br>
<b>71</b><br>
Calculus.dll<br>
IL<br>
Hash<br>
RSA digital<br>
Metadata<br>
Hash<br>
value<br>
Signed with<br>
signature<br>
PE file<br>
private key<br>
Manifest<br>
Assembly files (self and RUT.netmodule)<br>
Exported types (self and RUT.netmodule)<br>
Public key<br>
CLR header<br>
Embedded<br>
RSA digital signature<br>
in PE file<br>
Embedded<br>in PE file<br>
Public key<br>
<b>FIGURE 3-1  </b>Signing an assembly<br>
The publisher's public key is also embedded into the AssemblyDef manifest metadata table <br>in this PE file. The combination of the file name, the assembly version, the culture, and the <br>public key gives this assembly a strong name, which is guaranteed to be unique. There is no <br>way that two companies could each produce an assembly named <i>OurLibrary</i> with the same <br>public/private keys unless the companies share this key pair with each other.<br>
At this point, the assembly and all of its files are ready to be packaged and distributed.<br>
As described in Chapter 2, when you compile your source code, the compiler detects the <br>types and members that your code references. You must specify the referenced assemblies <br>to the compiler. For the C# compiler, you use the /reference compiler switch. Part of the <br>compiler's job is to emit an AssemblyRef metadata table inside the resulting managed mod-<br>ule. Each entry in the AssemblyRef metadata table indicates the referenced assembly's name <br>(without path and extension), version number, culture, and public key information.<br>
<b>Important  </b>Because public keys are such large numbers, and a single assembly might reference <br>many assemblies, a large percentage of the resulting file's total size would be occupied with pub-<br>lic key information. To conserve storage space, Microsoft hashes the public key and takes the last <br>8 bytes of the hashed value. These reduced public key values--known as public key tokens--are <br>what are actually stored in an AssemblyRef table. In general, developers and end users will see <br>public key token values much more frequently than full public key values.<br>
Note, however, that the CLR never uses public key tokens when making security or trust decisions <br>because it is possible that several public keys could hash to a single public key token.<br>
The AssemblyRef metadata information (obtained by using ILDasm.exe) for the JeffTypes.dll <br>file that I discussed in Chapter 2 is shown here:<br>
<hr>
<A name=90></a><b>72 </b><br>
<b>Part I  CLR Basics</b><br>
AssemblyRef #1 (23000001)  <br>-------------------------------------------------------  <br>Token: 0x23000001  <br>Public Key or Token: b7 7a 5c 56 19 34 e0 89   <br>Name: mscorlib  <br>Version: 4.0.0.0  <br>Major Version: 0x00000004  <br>Minor Version: 0x00000000  <br>Build Number: 0x00000000  <br>Revision Number: 0x00000000  <br>Locale: &lt;null&gt;  <br>HashValue Blob:  <br>Flags: [none] (00000000)<br>
From this, you can see that JeffTypes.dll references a type that is contained in an assembly <br>matching the following attributes:<br>
&quot;MSCorLib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089&quot;<br>
Unfortunately, ILDasm.exe uses the term <i>Locale</i> when it really should be using <i>Culture</i>.<br>
If you look at JeffTypes.dll's AssemblyDef metadata table, you see the following:<br>
Assembly  <br>-------------------------------------------------------  <br>Token: 0x20000001  <br>Name : JeffTypes  <br>Public Key    :  <br>Hash Algorithm : 0x00008004  <br>Version: 3.0.0.0  <br>Major Version: 0x00000003  <br>Minor Version: 0x00000000  <br>Build Number: 0x00000000  <br>Revision Number: 0x00000000  <br>Locale: &lt;null&gt;  <br>Flags : [none] (00000000)<br>
This is equivalent to the following:<br>
&quot;JeffTypes, Version=3.0.0.0, Culture=neutral, PublicKeyToken=null&quot;<br>
In this line, no public key token is specified because in Chapter 2, the JeffTypes.dll assembly <br>wasn't signed with a public/private key pair, making it a weakly named assembly. If I had <br>used SN.exe to create a key file compiled with the /keyfile compiler switch, the resulting <br>assembly would have been signed. If I had then used ILDasm.exe to explore the new assem-<br>bly's metadata, the AssemblyDef entry would have bytes appearing after the Public Key field, <br>and the assembly would be strongly named. By the way, the AssemblyDef entry always stores <br>the full public key, not the public key token. The full public key is necessary to ensure that the <br>file hasn't been tampered with. I'll explain the tamper resistance of strongly named assem-<br>blies later in this chapter.<br>
<hr>
<A name=91></a><b> </b><br>
<b>Chapter 3  Shared Assemblies and Strongly Named Assemblies </b><br>
<b>73</b><br>
<b>The Global Assembly Cache</b><br>
Now that you know how to create a strongly named assembly, it's time to learn how to de-<br>ploy this assembly and how the CLR uses the information to locate and load the assembly.<br>
If an assembly is to be accessed by multiple applications, the assembly must be placed into a <br>well-known directory, and the CLR must know to look in this directory automatically when a <br>reference to the assembly is detected. This well-known location is called the global assembly <br>cache (GAC), which can usually be found in the following directory (assuming that Windows <br>is installed in the C:\Windows directory):<br>
C:\Windows\Assembly<br>
The GAC directory is structured: It contains many subdirectories, and an algorithm is used to <br>generate the names of these subdirectories. You should never manually copy assembly files <br>into the GAC; instead, you should use tools to accomplish this task. These tools know the <br>GAC's internal structure and how to generate the proper subdirectory names.<br>
While developing and testing, the most common tool for instal ing a strongly named assembly <br>into the GAC is GACUtil.exe. Running this tool without any command-line arguments yields <br>the following usage:<br>
Microsoft (R) .NET Global Assembly Cache Utility.  Version 4.0.20928.1  <br>Copyright (c) Microsoft Corporation.  All rights reserved.  <br>  <br>Usage: Gacutil &lt;command&gt; [ &lt;options&gt; ]  <br>Commands:  <br>  /i &lt;assembly_path&gt; [ /r &lt;...&gt; ] [ /f ]  <br>    Installs an assembly to the global assembly cache.  <br>  <br>  /il &lt;assembly_path_list_file&gt; [ /r &lt;...&gt; ] [ /f ]  <br>    Installs one or more assemblies to the global assembly cache.  <br>  <br>  /u &lt;assembly_display_name&gt; [ /r &lt;...&gt; ]  <br>    Uninstalls an assembly from the global assembly cache.  <br>  <br>  /ul &lt;assembly_display_name_list_file&gt; [ /r &lt;...&gt; ]  <br>    Uninstalls one or more assemblies from the global assembly cache.  <br>  <br>  /l [ &lt;assembly_name&gt; ]  <br>    List the global assembly cache filtered by &lt;assembly_name&gt;  <br>  <br>  /lr [ &lt;assembly_name&gt; ]  <br>    List the global assembly cache with all traced references.  <br>  <br>  /cdl  <br>    Deletes the contents of the download cache  <br>  <br>  /ldl  <br>    Lists the contents of the download cache  <br>  <br>
<hr>
<A name=92></a><IMG src="CLRviaCsharp-92_1.jpg"><br>
<IMG src="CLRviaCsharp-92_2.jpg"><br>
<b>74 </b><br>
<b>Part I  CLR Basics</b><br>
  /?  <br>    Displays a detailed help screen  <br>  <br> Options:  <br>  /r &lt;reference_scheme&gt; &lt;reference_id&gt; &lt;description&gt;  <br>    Specifies a traced reference to install (/i, /il) or uninstall (/u, /ul).  <br>  <br>  /f  <br>    Forces reinstall of an assembly.  <br>  <br>  /nologo  <br>    Suppresses display of the logo banner  <br>  <br>  /silent  <br>    Suppresses display of all output<br>
As you can see, you can invoke GACUtil.exe, specifying the /i switch to install an assembly <br>into the GAC, and you can use GACUtil.exe's /u switch to uninstall an assembly from the GAC. <br>Note that you can't ever place a weakly named assembly into the GAC. If you pass the file <br>name of a weakly named assembly to GACUtil.exe, it displays the following error message: <br>"Failure adding assembly to the cache: Attempt to install an assembly with-<br>out a strong name."<br>
<b>Note  </b>By default, the GAC can be manipulated only by a user belonging to the Windows <br>Administrators group. GACUtil.exe will fail to install or uninstall an assembly if the user invoking <br>the execution of the utility isn't a member of this group.<br>
Using GACUtil.exe's /i switch is very convenient for developer testing. However, if you use <br>GACUtil.exe to deploy an assembly in a production environment, it's recommended that you <br>use GACUtil.exe's /r switch in addition to specifying the /i or /u switch to install or uninstall <br>the assembly. The /r switch integrates the assembly with the Windows install and uninstall <br>engine. Basically, it tells the system which application requires the assembly and then ties <br>the application and the assembly together.<br>
<b>Note  </b>If a strongly named assembly is packaged in a cabinet (.cab) file or is compressed in  <br>some way, the assembly's file must first be decompressed to temporary file(s) before you use <br>GACUtil.exe to install the assembly's files into the GAC. Once the assembly's files have been  <br>installed, the temporary file(s) can be deleted.<br>
The GACUtil.exe tool doesn't ship with the end-user .NET Framework redistributable pack-<br>age. If your application includes some assemblies that you want deployed into the GAC, you <br>should use the Windows Installer (MSI), because MSI is the only tool that is guaranteed to be <br>on end-user machines and capable of installing assemblies into the GAC. <br>
<hr>
<A name=93></a><IMG src="CLRviaCsharp-93_1.jpg"><br>
<b> </b><br>
<b>Chapter 3  Shared Assemblies and Strongly Named Assemblies </b><br>
<b>75</b><br>
<b>Important  </b>Globally deploying assembly files into the GAC is a form of registering the assembly, <br>although the actual Windows registry isn't affected in any way. Installing assemblies into the GAC <br>breaks the goal of simple application installation, backup, restore, moving, and uninstall. So it is <br>recommended that you avoid global deployment and use private deployment whenever possible.<br>
What is the purpose of "registering" an assembly in the GAC? Well, say two companies each <br>produce an OurLibrary assembly consisting of one file: OurLibrary.dll. Obviously, both of <br>these files can't go in the same directory because the last one installed would overwrite the <br>first one, surely breaking some application. When you install an assembly into the GAC, dedi-<br>cated subdirectories are created under the C:\Windows\Assembly directory, and the assem-<br>bly files are copied into one of these subdirectories.<br>
Normally, no one examines the GAC's subdirectories, so the structure of the GAC shouldn't <br>really matter to you. As long as the tools and the CLR know the structure, all is good.<br>
<b>Building an Assembly That References a Strongly Named </b><br>
<b>Assembly</b><br>
Whenever you build an assembly, the assembly will have references to other strongly named <br>assemblies. This is true because System.Object is defined in MSCorLib.dll, which is strongly <br>named. However, it's likely that an assembly will reference types in other strongly named as-<br>semblies published either by Microsoft, a third party, or your own organization. In Chapter 2, <br>I showed you how to use CSC.exe's /reference compiler switch to specify the assembly file <br>names you want to reference. If the file name is a full path, CSC.exe loads the specified file <br>and uses its metadata information to build the assembly. As mentioned in Chapter 2, if you <br>specify a file name without a path, CSC.exe attempts to find the assembly by looking in the <br>following directories (in order of their presentation here):<br>
<b> </b><br>
<b>1.  </b>Working directory.<br>
<b> </b><br>
<b>2.  </b>The directory that contains the CSC.exe file itself. This directory also contains the CLR <br>
DLLs.<br>
<b> </b><br>
<b>3.  </b>Any directories specified using the /lib compiler switch.<br>
<b> </b><br>
<b>4.  </b>Any directories specified using the LIB environment variable.<br>
So if you're building an assembly that references Microsoft's System.Drawing.dll, you can <br>specify the /reference:System.Drawing.dll switch when invoking CSC.exe. The compiler <br>will examine the directories shown earlier and will find the System.Drawing.dll file in the  <br>directory that contains the CSC.exe file itself, which is the same directory that contains the <br>DLLs for the version of the CLR the compiler is tied to. Even though this is the directory <br>where the assembly is found at compile time, this isn't the directory where the assembly will <br>be loaded from at runtime.<br>
<hr>
<A name=94></a><IMG src="CLRviaCsharp-94_1.jpg"><br>
<IMG src="CLRviaCsharp-94_2.jpg"><br>
<b>76 </b><br>
<b>Part I  CLR Basics</b><br>
You see, when you install the .NET Framework, two copies of Microsoft's assembly files are <br>actually installed. One set is installed into the compiler/CLR directory, and another set is in-<br>stalled into a GAC subdirectory. The files in the compiler/CLR directory exist so that you can <br>easily build your assembly, whereas the copies in the GAC exist so that they can be loaded at <br>runtime.<br>
The reason that CSC.exe doesn't look in the GAC for referenced assemblies is that you'd <br>have to know the path to the assembly file and the structure of the GAC is undocumented. <br>Alternatively, CSC.exe could allow you to specify a still long but slightly nicer-looking  <br>string, such as "System.Drawing, Version=v4.0.0.0, Culture=neutral,  <br>PublicKeyToken=b03f5f7f11d50a3a." Both of these solutions were deemed worse than  <br>having the assembly files installed twice on the user's hard drive.<br>
<b>Note  </b>When building an assembly, you may want to refer to another assembly that has an x86 <br>as well as an x64 version of itself available. Fortunately, the GAC subdirectories can actually hold <br>an x86 and an x64 version of the same assembly. However, since the assemblies have the same <br>file name, you cannot have different versions of these assemblies in the compiler/CLR directory. <br>However, it shouldn't matter. When you install the .NET Framework on a machine, the x86, x64, <br>or IA64 version of the assemblies are installed in the compiler/CLR directory. When you build an <br>assembly, you can reference whatever version of the files were installed because all of the versions <br>contain identical metadata and differ only by their code. At runtime, the proper version of the <br>assembly will be loaded from the GAC. I'll discuss how the CLR determines where to load the  <br>assembly from at runtime later in this chapter.<br>
<b>Strongly Named Assemblies Are Tamper-Resistant</b><br>
Signing an assembly with a private key ensures that the holder of the corresponding public <br>key produced the assembly. When the assembly is installed into the GAC, the system hashes <br>the contents of the file containing the manifest and compares the hash value with the RSA <br>digital signature value embedded within the PE file (after unsigning it with the public key). If <br>the values are identical, the file's contents haven't been tampered with, and you know that <br>you have the public key that corresponds to the publisher's private key. In addition, the system <br>hashes the contents of the assembly's other files and compares the hash values with the hash <br>values stored in the manifest file's FileDef table. If any of the hash values don't match, at least <br>one of the assembly's files has been tampered with, and the assembly will fail to install into <br>the GAC.<br>
<b>Important  </b>This mechanism ensures only that a file's content hasn't been tampered with. The <br>mechanism doesn't allow you to tell who the publisher is unless you're absolutely positive that <br>the publisher produced the public key you have and you're sure that the publisher's private key <br>was never compromised. Another way to know the identity of the publisher is if the publisher  <br>associated its identity with the assembly by using Microsoft's Authenticode technology.<br>
<hr>
<A name=95></a><IMG src="CLRviaCsharp-95_1.jpg"><br>
<b> </b><br>
<b>Chapter 3  Shared Assemblies and Strongly Named Assemblies </b><br>
<b>77</b><br>
When an application needs to bind to an assembly, the CLR uses the referenced assembly's <br>properties (name, version, culture, and public key) to locate the assembly in the GAC. If the <br>referenced assembly can be found, its containing subdirectory is returned, and the file hold-<br>ing the manifest is loaded. Finding the assembly this way assures the caller that the assembly  <br>loaded at runtime came from the same publisher that built the assembly the code was <br>compiled against. This assurance is possible because the public key token in the referencing <br>assembly's AssemblyRef table corresponds to the public key in the referenced assembly's <br>AssemblyDef table. If the referenced assembly isn't in the GAC, the CLR looks in the appli-<br>cation's base directory and then in any of the private paths identified in the application's <br>configuration file; then, if the application was installed using MSI, the CLR asks MSI to locate <br>the assembly. If the assembly can't be found in any of these locations, the bind fails, and a <br>System.IO.FileNotFoundException is thrown.<br>
When strongly named assembly files are loaded from a location other than the GAC (via  <br>the application's base directory or via a codeBase element in a configuration file), the CLR <br>compares hash values when the assembly is loaded. In other words, a hash of the file is  <br>performed every time an application executes and loads the assembly. This performance hit <br>is a tradeoff for being certain that the assembly file's content hasn't been tampered with. <br>When the CLR detects mismatched hash values at runtime, it throws a  <br>System.IO.FileLoadException.<br>
<b>Note  </b>When a strongly named assembly is installed in the GAC, the system ensures that the file <br>containing the manifest hasn't been tampered with. This check occurs only once, at installation <br>time. In addition, to improve performance, the CLR does not check if a strongly named assembly <br>has been tampered with if the assembly is fully trusted and is being loaded into a fully trusted <br>AppDomain. On the other hand, when a strongly named assembly is loaded from a directory <br>other than the GAC, the CLR verifies the assembly's manifest file to ensure that the file's con-<br>tents have not been tampered with, causing an additional performance hit every time this file is <br>loaded.<br>
<b>Delayed Signing</b><br>
Earlier in this chapter, I discussed how the SN.exe tool can produce public/private key pairs. <br>This tool generates the keys by making calls into the Crypto API provided by Windows. These <br>keys can be stored in files or other storage devices. For example, large organizations (such as <br>Microsoft) will maintain the returned private key in a hardware device that stays locked in a <br>vault; only a few people in the company have access to the private key. This precaution pre-<br>vents the private key from being compromised and ensures the key's integrity. The public key <br>is, well, public and freely distributed.<br>
When you're ready to package your strongly named assembly, you'll have to use the secure <br>private key to sign it. However, while developing and testing your assembly, gaining access to <br>
<hr>
<A name=96></a><IMG src="CLRviaCsharp-96_1.jpg"><br>
<b>78 </b><br>
<b>Part I  CLR Basics</b><br>
the secure private key can be a hassle. For this reason, the .NET Framework supports <i>delayed <br>signing, </i>sometimes referred to as <i>partial signing</i>. Delayed signing allows you to build an as-<br>sembly by using only your company's public key; the private key isn't necessary. Using the <br>public key allows assemblies that reference your assembly to embed the correct public key <br>value in their AssemblyRef metadata entries. It also allows the assembly to be placed in the <br>GAC appropriately. If you don't sign the file with your company's private key, you lose all of <br>the tampering protection afforded to you because the assembly's files won't be hashed, and <br>a digital signature won't be embedded in the file. This loss of protection shouldn't be a prob-<br>lem, however, because you use delayed signing only while developing your own assembly, <br>not when you're ready to package and deploy the assembly.<br>
Basically, you get your company's public key value in a file and pass the file name to whatever <br>utility you use to build the assembly. (As I have shown earlier in this chapter, you can use <br>SN.exe's ­p switch to extract a public key from a file that contains a public/private key pair.) <br>You must also tell the tool that you want the assembly to be delay signed, meaning  <br>that you're not supplying a private key. For the C# compiler, you do this by specifying the  <br>/delaysign compiler switch. In Visual Studio, you display the properties for your project, <br>click the Signing tab, and then select the Delay Sign Only check box. If you're using AL.exe, <br>you can specify the /delay[sign] command-line switch.<br>
When the compiler or AL.exe detects that you're delay signing an assembly, it will emit the <br>assembly's AssemblyDef manifest entry, which will contain the assembly's public key. Again, <br>the presence of the public key allows the assembly to be placed in the GAC. It also allows you <br>to build other assemblies that reference this assembly; the referencing assemblies will have <br>the correct public key in their AssemblyRef metadata table entries. When creating the result-<br>ing assembly, space is left in the resulting PE file for the RSA digital signature. (The utility can <br>determine how much space is necessary from the size of the public key.) Note that the file's <br>contents won't be hashed at this time either.<br>
At this point, the resulting assembly doesn't have a valid signature. Attempting to install the <br>assembly into the GAC will fail because a hash of the file's contents hasn't been done--the <br>file appears to have been tampered with. On every machine on which the assembly needs to <br>be installed into the GAC, you must prevent the system from verifying the integrity of the  <br>assembly's files. To do this, you use the SN.exe utility, specifying the ­Vr command-line <br>switch. Executing SN.exe with this switch also tells the CLR to skip checking hash values for <br>any of the assembly's files when loaded at runtime. Internally, SN's ­Vr switch adds the  <br>assembly's identity under the following registry subkey: HKEY_LOCAL_MACHINE\SOFTWARE <br>\Microsoft\StrongName\Verification.<br>
<b>Important  </b>When using any utility that manipulates the registry, make sure that you run  <br>the 64-bit version of the utility on a 64-bit machine. By default, the 32-bit x86 utilities are  <br>installed in C:\Program Files (x86)\Microsoft SDKs\Windows\v7.0A\bin\NETFX 4.0 Tools, and  <br>the 64-bit x64 utilities are installed in C:\Program Files (x86)\Microsoft SDKs\Windows\v7.0A\bin <br>\NETFX 4.0 Tools\x64.<br>
<hr>
<A name=97></a><b> </b><br>
<b>Chapter 3  Shared Assemblies and Strongly Named Assemblies </b><br>
<b>79</b><br>
When you're finished developing and testing the assembly, you need to officially sign it so <br>that you can package and deploy it. To sign the assembly, use the SN.exe utility again, this <br>time with the ­R switch and the name of the file that contains the actual private key. The ­R <br>switch causes SN.exe to hash the file's contents, sign it with the private key, and embed the <br>RSA digital signature in the file where the space for it had previously been reserved. After <br>this step, you can deploy the fully signed assembly. On the developing and testing machines, <br>don't forget to turn verification of this assembly back on by using SN.exe's ­Vu or ­Vx  <br>command-line switch. The following list summarizes the steps discussed in this section to  <br>develop your assembly by using the delayed signing technique:<br>
<b> </b><br>
<b>1.  </b>While developing an assembly, obtain a file that contains only your company's public  <br>
key, and compile your assembly by using the /keyfile and /delaysign compiler <br>switches:<br>
csc /keyfile:MyCompany.PublicKey /delaysign MyAssembly.cs<br>
<b> </b><br>
<b>2.  </b>After building the assembly, execute the following line so that the CLR will trust the  <br>
assembly's bytes without performing the hash and comparison. This allows you to in-<br>stall the assembly in the GAC (if you desire). Now, you can build other assemblies that <br>reference the assembly, and you can test the assembly. Note that you have to execute <br>the following command line only once per machine; it's not necessary to perform this <br>step each time you build your assembly.<br>
SN.exe ­Vr MyAssembly.dll<br>
<b> </b><br>
<b>3.  </b>When ready to package and deploy the assembly, obtain your company's private key, <br>
and then execute the line below. You can install this new version in the GAC if you  <br>desire, but don't attempt to install it in the GAC until executing step 4.<br>
SN.exe -R MyAssembly.dll MyCompany.PrivateKey<br>
<b> </b><br>
<b>4.  </b>To test in real conditions, turn verification back on by executing the following com-<br>
mand line:<br>
SN ­Vu MyAssembly.dll<br>
At the beginning of this section, I mentioned how organizations keep their key pairs in a <br>hardware device such as a smart card. To keep these keys secure, you must make sure that <br>the key values are never persisted in a disk file. Cryptographic service providers (CSPs) offer <br>containers that abstract the location of these keys. Microsoft, for example, uses a CSP that <br>has a container that, when accessed, obtains the private key from a hardware device.<br>
If your public/private key pair is in a CSP container, you'l  have to specify different switches  <br>to the CSC.exe, AL.exe, and SN.exe programs: When compiling (CSC.exe), specify the  <br>/keycontainer switch instead of the /keyfile switch; when linking (AL.exe), specify its  <br>/keyname switch instead of its /keyfile switch; and when using the Strong Name program <br>(SN.exe) to add a private key to a delay-signed assembly, specify the ­Rc switch instead of the <br>­R switch. SN.exe offers additional switches that allow you to perform operations with a CSP.<br>
<hr>
<A name=98></a><IMG src="CLRviaCsharp-98_1.jpg"><br>
<b>80 </b><br>
<b>Part I  CLR Basics</b><br>
<b>Important  </b>Delayed signing is also useful whenever you want to perform some other operation <br>to an assembly before you package it. For example, you may want to run an obfuscator over your <br>assembly. You can't obfuscate an assembly after it's been fully signed because the hash value <br>will be incorrect. So, if you want to obfuscate an assembly file or perform any other type of post-<br>build operation, you should use delayed signing, perform the post-build operation, and then run <br>SN.exe with the ­R or ­Rc switch to complete the signing process of the assembly with all of its <br>hashing.<br>
<b>Privately Deploying Strongly Named Assemblies</b><br>
Installing assemblies into the GAC offers several benefits. The GAC enables many applications <br>to share assemblies, reducing physical memory usage on the whole. In addition, it's easy to <br>deploy a new version of the assembly into the GAC and have all applications use the new <br>version via a publisher policy (described later in this chapter). The GAC also provides side-by-<br>side management for an assembly's different versions. However, the GAC is usually secured <br>so that only an administrator can install an assembly into it. Also, installing into the GAC <br>breaks the simple copy deployment story.<br>
Although strongly named assemblies can be installed into the GAC, they certainly don't have <br>to be. In fact, it's recommended that you deploy assemblies into the GAC only if the assembly  <br>is intended to be shared by many applications. If an assembly isn't intended to be shared, it <br>should be deployed privately. Deploying privately preserves the simple copy install deploy-<br>ment story and better isolates the application and its assemblies. Also, the GAC isn't intended <br>to be the new C:\Windows\System32 dumping ground for common files. The reason is be-<br>cause new versions of assemblies don't overwrite each other; they are installed side by side, <br>eating up disk space.<br>
In addition to deploying a strongly named assembly in the GAC or privately, a strongly <br>named assembly can be deployed to some arbitrary directory that a small set of applications <br>know about. For example, you might be producing three applications, all of which want to <br>share a strongly named assembly. Upon installation, you can create three directories: one <br>for each application and an additional directory for the assembly you want shared. When <br>you install each application into its directory, also install an XML configuration file, and have <br>the shared assembly's codeBase element indicate the path of the shared assembly. Now at <br>runtime, the CLR will know to look in the strongly named assembly's directory for the shared <br>assembly. For the record, this technique is rarely used and is somewhat discouraged because <br>no single application controls when the assembly's files should be uninstalled.<br>
<hr>
<A name=99></a><IMG src="CLRviaCsharp-99_1.jpg"><br>
<b> </b><br>
<b>Chapter 3  Shared Assemblies and Strongly Named Assemblies </b><br>
<b>81</b><br>
<b>Note  </b>The configuration file's codeBase element actually identifies a URL. This URL can refer to <br>any directory on the user's machine or to a Web address. In the case of a Web address, the CLR <br>will automatically download the file and store it in the user's download cache (a subdirectory <br>under C:\Users\<i>UserName</i>\Local Settings\Application Data\Assembly, where <i>UserName</i> is the <br>name of the Windows user account currently signed on). When referenced in the future, the CLR <br>will compare the timestamp of the downloaded file with the timestamp of the file at the specified <br>URL. If the timestamp of the file at the URL is newer, the CLR will download the new version of <br>the file and load it. If the previously downloaded file is newer, the CLR will load this file and will <br>not download the file again (improving performance). An example of a configuration file con-<br>taining a codeBase element is shown later in this chapter.<br>
<b>How the Runtime Resolves Type References</b><br>
At the beginning of Chapter 2, we saw the following source code:<br>
public sealed class Program {  <br>   public static void Main() {  <br>      System.Console.WriteLine(&quot;Hi&quot;);  <br>   }  <br>}<br>
This code is compiled and built into an assembly, say Program.exe. When you run this appli-<br>cation, the CLR loads and initializes. Then the CLR reads the assembly's CLR header, looking <br>for the MethodDefToken that identifies the application's entry point method (Main). From <br>the MethodDef metadata table, the offset within the file for the method's IL code is located <br>and JIT-compiled into native code, which includes having the code verified for type safety. <br>The native code then starts executing. Following is the IL code for the Main method. To ob-<br>tain this output, I ran ILDasm.exe, chose the View menu's Show Bytes menu item, and then <br>double-clicked the Main method in the tree view.<br>
.method public hidebysig static void  Main() cil managed  <br>// SIG: 00 00 01  <br>{  <br>  .entrypoint  <br>  // Method begins at RVA 0x2050  <br>  // Code size       11 (0xb)   <br>  .maxstack  8  <br>  IL_0000:  /* 72   | (70)000001       */   <br>            ldstr      &quot;Hi&quot;  <br>  IL_0005:  /* 28   | (0A)000003       */   <br>            call       void [mscorlib]System.Console::WriteLine(string)   <br>  IL_000a:  /* 2A   |                  */   <br>            ret  <br>} // end of method Program::Main<br>
When JIT-compiling this code, the CLR detects all references to types and members and <br>loads their defining assemblies (if not already loaded). As you can see, the IL code above has <br>a reference to System.Console.WriteLine. Specifically, the IL call instruction references <br>
<hr>
<A name=100></a><IMG src="CLRviaCsharp-100_1.jpg"><br>
<IMG src="CLRviaCsharp-100_2.jpg"><br>
<b>82 </b><br>
<b>Part I  CLR Basics</b><br>
metadata token 0A000003. This token identifies entry 3 in the MemberRef metadata table <br>(table 0A). The CLR looks up this MemberRef entry and sees that one of its fields refers to an <br>entry in a TypeRef table (the System.Console type). From the TypeRef entry, the CLR  <br>is directed to an AssemblyRef entry: "mscorlib, Version=4.0.0.0, Culture=neutral,  <br>PublicKeyToken=b77a5c561934e089". At this point, the CLR knows which assembly it  <br>needs. Now the CLR must locate the assembly in order to load it.<br>
When resolving a referenced type, the CLR can find the type in one of three places:<br>
<b>  Same file  </b>Access to a type that is in the same file is determined at compile time <br>
(sometimes referred to as <i>early bound</i>). The type is loaded out of the file directly, and <br>execution continues.<br>
<b>  Different file, same assembly  </b>The runtime ensures that the file being referenced is, <br>
in fact, in the assembly's FileRef table of the current assembly's manifest. The runtime <br>then looks in the directory where the assembly's manifest file was loaded. The file is <br>loaded, its hash value is checked to ensure the file's integrity, the type's member is <br>found, and execution continues.<br>
<b>  Different file, different assembly  </b>When a referenced type is in a different assembly's <br>
file, the runtime loads the file that contains the referenced assembly's manifest. If this <br>file doesn't contain the type, the appropriate file is loaded. The type's member is found, <br>and execution continues.<br>
<b>Note  </b>The ModuleDef, ModuleRef, and FileDef metadata tables refer to files using the file's <br>name and its extension. However, the AssemblyRef metadata table refers to assemblies by file <br>name without an extension. When binding to an assembly, the system automatically appends <br>.dll and .exe file extensions while attempting to locate the file by probing the directories as men-<br>tioned in the "Simple Administrative Control (Configuration)" section in Chapter 2.<br>
If any errors occur while resolving a type reference--file can't be found, file can't be loaded, <br>hash mismatch, and so on--an appropriate exception is thrown.<br>
<b>Note  </b>If you want, your code can register callback methods with System.AppDomain's <br>AssemblyResolve, ReflectionOnlyAssemblyResolve, and TypeResolve events. In your call-<br>back methods, you can execute code that resolves the binding problem and allows the applica-<br>tion to continue running without throwing an exception.<br>
In the previous example, the CLR determines that System.Console is implemented in a dif-<br>ferent assembly than the caller. The CLR must search for the assembly and load the PE file <br>that contains the assembly's manifest. The manifest is then scanned to determine the PE file <br>that implements the type. If the manifest file contains the referenced type, all is well. If the <br>type is in another of the assembly's files, the CLR loads the other file and scans its metadata <br>
<hr>
<A name=101></a><IMG src="CLRviaCsharp-101_1.jpg"><br>
<b> </b><br>
<b>Chapter 3  Shared Assemblies and Strongly Named Assemblies </b><br>
<b>83</b><br>
to locate the type. The CLR then creates its internal data structures to represent the type, and <br>the JIT compiler completes the compilation for the Main method. Finally, the Main method <br>can start executing.<br>
Figure 3-2 illustrates how type binding occurs.<br>
IL refers to<br>
IL refers to<br>
a type<br>
a member<br>
AssemblyRef:<br>
Type is in<br>
different file,<br>
different<br>
Strongly named<br>
What does<br>
assembly<br>
What does<br>
assembly<br>
Search for<br>
TypeRef<br>
AssemblyRef<br>
assembly<br>
ModuleRef:<br>
entry<br>
entry indicate?<br>
in GAC and<br>
Type is in <br>
indicate?<br>
then AppBase<br>
different file,<br>
same<br>
Weakly named<br>
assembly<br>
assembly<br>
Search for<br>
Load file<br>
Examine<br>
assembly<br>
with manifest<br>
in AppBase<br>
ModuleRef<br>
ModuleDef:<br>
table and load<br>
Type is in<br>
appropriate file<br>
same file,<br>
same<br>
assembly<br>
Type in<br>
What does<br>
manifest file<br>
ExportedTypesDef<br>
entry indicate?<br>
Type not in<br>
manifest file<br>
Create internal<br>
type structure<br>
Load file<br>
Note: If any operation fails, an appropriate exception is thrown.<br>
<b>FIGURE 3-2  </b>Flowchart showing how, given IL code that refers to a method or type, the CLR uses metadata to <br>locate the proper assembly file that defines a type<br>
<b>Important  </b>Strictly speaking, the example just described isn't 100 percent correct. For refer-<br>ences to methods and types defined in an assembly that does not ship with the .NET Framework, <br>the discussion is correct. However, the .NET Framework assemblies (including MSCorLib.dll) <br>are closely tied to the version of the CLR that's running. Any assembly that references .NET <br>Framework assemblies always binds to the version that matches the CLR's version. This is called <br><i>unification</i>, and Microsoft does this because they test all of the .NET Framework assemblies with <br>a particular version of the CLR; therefore, unifying the code stack helps ensure that applications <br>will work correctly.<br>
So in the previous example, the reference to System.Console's WriteLine method binds to <br>whatever version of MSCorLib.dll matches the version of the CLR, regardless of what version of <br>MSCorLib.dll is referenced in the assembly's AssemblyRef metadata table.<br>
<hr>
<A name=102></a><IMG src="CLRviaCsharp-102_1.jpg"><br>
<b>84 </b><br>
<b>Part I  CLR Basics</b><br>
There is one more twist to this story: To the CLR, all assemblies are identified by name,  <br>version, culture, and public key. However, the GAC identifies assemblies using name, version, <br>culture, public key, and CPU architecture. When searching the GAC for an assembly, the CLR <br>figures out what type of process the application is currently running in: 32-bit x86 (possibly <br>using the WoW64 technology), 64-bit x64, or 64-bit IA64. Then, when searching the GAC for <br>an assembly, the CLR first searches for a CPU architecture­specific version of the assembly. <br>If it does not find a matching assembly, it then searches for a CPU-agnostic version of the <br>assembly.<br>
In this section, you saw how the CLR locates an assembly when using a default policy. <br>However, an administrator or the publisher of an assembly can override the default policy. In <br>the next two sections, I'll describe how to alter the CLR's default binding policy.<br>
<b>Note  </b>The CLR supports the ability to move a type (class, structure, enum, interface, or del-<br>egate) from one assembly to another. For example, in .NET 3.5, the System.TimeZoneInfo <br>class is defined in the System.Core.dll assembly. But in .NET 4.0, Microsoft moved this class <br>to the MSCorLib.dll assembly. Normally, moving a type from one assembly to another would <br>break applications. However, the CLR offers a System.Runtime.CompilerServices.<br>TypeForwardedToAttribute attribute, which can be applied to the original assembly (such as <br>System.Core.dll). The parameter that you pass to this attribute's constructor is of type  <br>System.Type and it indicates the new type (that is now defined in MSCorLib.dll) <br>that applications should now use. The CLR's binder uses this information. Since the <br>TypeForwardedToAttribute's constructor takes a Type, the assembly containing this  <br>attribute will be dependent on the new assembly defining the type.<br>
If you take advantage of this feature, then you should also apply the System.Runtime.<br>CompilerServices.TypeForwardedFromAttribute attribute to the type in the new assem-<br>bly and pass to this attribute's constructor a string with the full name of the assembly that used <br>to define the type. This attribute typically is used for tools, utilities, and serialization. Since the <br>TypeForwardedFromAttribute's constructor takes a String, the assembly containing this  <br>attribute is not dependent on the assembly that used to define the type.<br>
<b>Advanced Administrative Control (Configuration)</b><br>
In the section "Simple Administrative Control (Configuration)" in Chapter 2, I gave a brief <br>introduction to how an administrator can affect the way the CLR searches and binds to as-<br>semblies. In that section, I demonstrated how a referenced assembly's files can be moved to <br>a subdirectory of the application's base directory and how the CLR uses the application's XML <br>configuration file to locate the moved files.<br>
Having discussed only the probing element's privatePath attribute in Chapter 2, I'm going <br>to discuss the other XML configuration file elements in this section. Following is an XML  <br>configuration file:<br>
<hr>
<A name=103></a><b> </b><br>
<b>Chapter 3  Shared Assemblies and Strongly Named Assemblies </b><br>
<b>85</b><br>
&lt;?xml version=&quot;1.0&quot;?&gt;  <br>&lt;configuration&gt;  <br>   &lt;runtime&gt;  <br>      &lt;assemblyBinding xmlns=&quot;urn:schemas-microsoft-com:asm.v1&quot;&gt;  <br>         &lt;probing privatePath=&quot;AuxFiles;bin\subdir&quot; /&gt;  <br>  <br>         &lt;dependentAssembly&gt;  <br>  <br>            &lt;assemblyIdentity name=&quot;JeffTypes&quot;   <br>              publicKeyToken=&quot;32ab4ba45e0a69a1&quot; culture=&quot;neutral&quot;/&gt;  <br>  <br>            &lt;bindingRedirect   <br>              oldVersion=&quot;1.0.0.0&quot; newVersion=&quot;2.0.0.0&quot; /&gt;  <br>  <br>            &lt;codeBase version=&quot;2.0.0.0&quot;   <br>              href=&quot;http://www.Wintellect.com/JeffTypes.dll&quot; /&gt;  <br>  <br>         &lt;/dependentAssembly&gt;  <br>  <br>         &lt;dependentAssembly&gt;  <br>  <br>            &lt;assemblyIdentity name=&quot;TypeLib&quot;   <br>              publicKeyToken=&quot;1f2e74e897abbcfe&quot; culture=&quot;neutral&quot;/&gt;  <br>  <br>            &lt;bindingRedirect   <br>              oldVersion=&quot;3.0.0.0-3.5.0.0&quot; newVersion=&quot;4.0.0.0&quot; /&gt;  <br>  <br>            &lt;publisherPolicy apply=&quot;no&quot; /&gt;  <br>  <br>         &lt;/dependentAssembly&gt;  <br>  <br>      &lt;/assemblyBinding&gt;  <br>   &lt;/runtime&gt;  <br>&lt;/configuration&gt;<br>
This XML file gives a wealth of information to the CLR. Here's what it says:<br>
<b>  </b>probing<b> element  </b>Look in the application base directory's AuxFiles and bin\subdir <br>
subdirectories when trying to find a weakly named assembly. For strongly named as-<br>semblies, the CLR looks in the GAC or in the URL specified by the codeBase element. <br>The CLR looks in the application's private paths for a strongly named assembly only if <br>no codeBase element is specified.<br>
<b>  First </b>dependentAssembly<b>, </b>assemblyIdentity<b>, and </b>bindingRedirect<b> elements  </b> <br>
When attempting to locate version 1.0.0.0 of the culture-neutral JeffTypes assembly <br>published by the organization that controls the 32ab4ba45e0a69a1 public key token, <br>locate version 2.0.0.0 of the same assembly instead.<br>
<b>  </b>codeBase<b> element  </b>When attempting to locate version 2.0.0.0 of the culture-neutral <br>
JeffTypes assembly published by the organization that controls the 32ab4ba45e0a69a1 <br>public key token, try to find it at the following URL: <i>www.Wintellect.com/JeffTypes.dll</i>. <br>Although I didn't mention it in Chapter 2, a codeBase element can also be used with <br>
<hr>
<A name=104></a><b>86 </b><br>
<b>Part I  CLR Basics</b><br>
weakly named assemblies. In this case, the assembly's version number is ignored and <br>should be omitted from the XML's codeBase element. Also, the codeBase URL must <br>refer to a directory under the application's base directory.<br>
<b>  Second </b>dependentAssembly<b>, </b>assemblyIdentity<b>, and </b>bindingRedirect<b> elements  </b> <br>
When attempting to locate version 3.0.0.0 through version 3.5.0.0 inclusive of the  <br>culture-neutral TypeLib assembly published by the organization that controls the <br>1f2e74e897abbcfe public key token, locate version 4.0.0.0 of the same assembly instead.<br>
<b>  </b>publisherPolicy<b> element  </b>If the organization that produces the TypeLib assembly <br>
has deployed a publisher policy file (described in the next section), the CLR should  <br>ignore this file.<br>
When compiling a method, the CLR determines the types and members being referenced. <br>Using this information, the runtime determines, by looking in the referencing assembly's <br>AssemblyRef table, the assembly that was originally referenced when the calling assembly <br>was built. The CLR then looks up the assembly/version in the application's configuration <br>file and applies any version number redirections; the CLR is now looking for this assembly/<br>version.<br>
If the publisherPolicy element's apply attribute is set to yes--or if the element is omitted <br>--the CLR examines the GAC for the new assembly/version and applies any version number <br>redirections that the publisher of the assembly feels is necessary; the CLR is now looking for <br>this assembly/version. I'll talk more about publisher policy in the next section. Finally, the CLR <br>looks up the new assembly/version in the machine's Machine.config file and applies any  <br>version number redirections there.<br>
At this point, the CLR knows the version of the assembly that it should load, and it attempts <br>to load the assembly from the GAC. If the assembly isn't in the GAC, and if there is no <br>codeBase element, the CLR probes for the assembly as I described in Chapter 2. If the con-<br>figuration file that performs the last redirection also contains a codeBase element, the CLR <br>attempts to load the assembly from the codeBase element's specified URL.<br>
Using these configuration files, an administrator can really control what assembly the CLR <br>decides to load. If an application is experiencing a bug, the administrator can contact the <br>publisher of the errant assembly. The publisher can send the administrator a new assembly <br>that the administrator can install. By default, the CLR won't load this new assembly because <br>the already-built assemblies don't reference the new version. However, the administrator can <br>modify the application's XML configuration file to instruct the CLR to load the new assembly. <br>
If the administrator wants all applications on the machine to pick up the new assembly, the <br>administrator can modify the machine's Machine.config file instead, and the CLR will load <br>the new assembly whenever an application refers to the old assembly.<br>
<hr>
<A name=105></a><b> </b><br>
<b>Chapter 3  Shared Assemblies and Strongly Named Assemblies </b><br>
<b>87</b><br>
If the new assembly doesn't fix the original bug, the administrator can delete the binding  <br>redirection lines from the configuration file, and the application will behave as it did before. <br>It's important to note that the system allows the use of an assembly that doesn't exactly <br>match the assembly version recorded in the metadata. This extra flexibility is very handy.<br>
<b>Publisher Policy Control</b><br>
In the scenario described in the previous section, the publisher of an assembly simply sent a <br>new version of the assembly to the administrator, who installed the assembly and manually <br>edited the application's or machine's XML configuration files. In general, when a publisher <br>fixes a bug in an assembly, the publisher would like an easy way to package and distribute <br>the new assembly to all of the users. But the publisher also needs a way to tell each user's <br>CLR to use the new assembly version instead of the old assembly version. Sure, each user <br>could modify his or her application's or machine's XML configuration file, but this is terribly <br>inconvenient and error prone. What the publisher needs is a way to create policy information <br>that is installed on the user's computer when the new assembly is installed. In this section, I'll <br>show how an assembly's publisher can create this policy information.<br>
Let's say that you're a publisher of an assembly and that you've just created a new version <br>of your assembly that fixes some bugs. When you package your new assembly to send out <br>to all of your users, you should also create an XML configuration file. This configuration file <br>looks just like the configuration files we've been talking about. Here's an example file (called <br>JeffTypes.config) for the JeffTypes.dll assembly:<br>
&lt;configuration&gt;  <br>   &lt;runtime&gt;  <br>      &lt;assemblyBinding xmlns=&quot;urn:schemas-microsoft-com:asm.v1&quot;&gt;  <br>         &lt;dependentAssembly&gt;  <br>  <br>            &lt;assemblyIdentity name=&quot;JeffTypes&quot;   <br>              publicKeyToken=&quot;32ab4ba45e0a69a1&quot; culture=&quot;neutral&quot;/&gt;  <br>  <br>            &lt;bindingRedirect   <br>              oldVersion=&quot;1.0.0.0&quot; newVersion=&quot;2.0.0.0&quot; /&gt;  <br>  <br>            &lt;codeBase version=&quot;2.0.0.0&quot;   <br>              href=&quot;http://www.Wintellect.com/JeffTypes.dll&quot;/&gt;  <br>  <br>         &lt;/dependentAssembly&gt;  <br>      &lt;/assemblyBinding&gt;  <br>   &lt;/runtime&gt;  <br>&lt;/configuration&gt;<br>
Of course, publishers can set policies only for the assemblies that they themselves create. In <br>addition, the elements shown here are the only elements that can be specified in a publisher <br>policy configuration file; you can't specify the probing or publisherPolicy elements, for <br>example.<br>
<hr>
<A name=106></a><b>88 </b><br>
<b>Part I  CLR Basics</b><br>
This configuration file tells the CLR to load version 2.0.0.0 of the JeffTypes assembly when-<br>ever version 1.0.0.0 of the assembly is referenced. Now you, the publisher, can create an as-<br>sembly that contains this publisher policy configuration file. You create the publisher policy <br>assembly by running AL.exe as follows:<br>
AL.exe /out:Policy.1.0.JeffTypes.dll   <br>       /version:1.0.0.0   <br>       /keyfile:MyCompany.snk  <br>       /linkresource:JeffTypes.config<br>
Let me explain the meaning of AL.exe's command-line switches:<br>
<b>  </b>/out  This switch tells AL.exe to create a new PE file, called Policy.1.0.JeffTypes.dll, <br>
which contains nothing but a manifest. The name of this assembly is very important. <br>The first part of the name, <i>Policy,</i> tells the CLR that this assembly contains publisher <br>policy information. The second and third parts of the name, <i>1.0,</i> tell the CLR that this <br>publisher policy assembly is for any version of the JeffTypes assembly that has a major <br>and minor version of 1.0. Publisher policies apply to the major and minor version num-<br>bers of an assembly only; you can't create a publisher policy that is specific to individual <br>builds or revisions of an assembly. The fourth part of the name, <i>JeffTypes,</i> indicates the <br>name of the assembly that this publisher policy corresponds to. The fifth and last part <br>of the name, <i>dll,</i> is simply the extension given to the resulting assembly file.<br>
<b>  </b>/version  This switch identifies the version of the publisher policy assembly; this  <br>
version number has nothing to do with the JeffTypes assembly itself. You see, publisher <br>policy assemblies can also be versioned. Today, the publisher might create a publisher <br>policy redirecting version 1.0.0.0 of JeffTypes to version 2.0.0.0. In the future, the pub-<br>lisher might want to direct version 1.0.0.0 of JeffTypes to version 2.5.0.0. The CLR uses <br>this version number so that it knows to pick up the latest version of the publisher policy <br>assembly.<br>
<b>  </b>/keyfile  This switch causes AL.exe to sign the publisher policy assembly by using <br>
the publisher's public/private key pair. This key pair must also match the key pair used <br>for all versions of the JeffTypes assembly. After all, this is how the CLR knows that the <br>same publisher created both the JeffTypes assembly and this publisher policy file.<br>
<b>  </b>/linkresource  This switch tells AL.exe that the XML configuration file is to be  <br>
considered a separate file of the assembly. The resulting assembly consists of two files, <br>both of which must be packaged and deployed to the users along with the new version <br>of the JeffTypes assembly. By the way, you can't use AL.exe's /embedresource switch to <br>embed the XML configuration file into the assembly file, making a single file assembly, <br>because the CLR requires the XML file to be contained in its own separate file.<br>
Once this publisher policy assembly is built, it can be packaged together with the new <br>JeffTypes.dll assembly file and deployed to users. The publisher policy assembly must be in-<br>stalled into the GAC. Although the JeffTypes assembly can also be installed into the GAC, it <br>
<hr>
<A name=107></a><IMG src="CLRviaCsharp-107_1.jpg"><br>
<IMG src="CLRviaCsharp-107_2.jpg"><br>
<b> </b><br>
<b>Chapter 3  Shared Assemblies and Strongly Named Assemblies </b><br>
<b>89</b><br>
doesn't have to be. It could be deployed into an application's base directory or some other <br>directory identified by a codeBase URL.<br>
<b>Important  </b>A publisher should create a publisher policy assembly only when deploying an  <br>update or a service pack version of an assembly. When doing a fresh install of an application,  <br>no publisher policy assemblies should be installed.<br>
I want to make one last point about publisher policy. Say that a publisher distributes a pub-<br>lisher policy assembly, and for some reason, the new assembly introduces more bugs than <br>it fixes. If this happens, the administrator would like to tell the CLR to ignore the publisher <br>policy assembly. To have the runtime do this, the administrator can edit the application's  <br>configuration file and add the following publisherPolicy element:<br>
&lt;publisherPolicy apply=&quot;no&quot;/&gt;<br>
This element can be placed as a child element of the &lt;assemblyBinding&gt; element in the <br>application's configuration file so that it applies to all assemblies, or as a child element of the <br>&lt;dependantAssembly&gt; element in the application's configuration file to have it apply to a <br>specific assembly. When the CLR processes the application's configuration file, it will see that <br>the GAC shouldn't be examined for the publisher policy assembly. So the CLR will continue to <br>operate using the older version of the assembly. Note, however, that the CLR will still examine <br>and apply any policy specified in the Machine.config file.<br>
<b>Important  </b>A publisher policy assembly is a way for a publisher to make a statement about the <br>compatibility of different versions of an assembly. If a new version of an assembly isn't intended <br>to be compatible with an earlier version, the publisher shouldn't create a publisher policy assem-<br>bly. In general, use a publisher policy assembly when you build a new version of your assembly <br>that fixes a bug. You should test the new version of the assembly for backward compatibility.  <br>On the other hand, if you're adding new features to your assembly, you should consider the  <br>assembly to have no relationship to a previous version, and you shouldn't ship a publisher policy <br>assembly. In addition, there's no need to do any backward compatibility testing with such an  <br>assembly.<br>
<hr>
<A name=108></a><hr>
<A name=109></a>Chapter 4<br><b>Type Fundamentals</b><br>
<b>In this chapter:<br>All Types Are Derived from </b>System.Object<b>  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91<br>Casting Between Types  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93<br>Namespaces and Assemblies. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97<br>How Things Relate at Runtime . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102</b><br>
In this chapter, I will introduce information that is fundamental to working with types and <br>the common language runtime (CLR). In particular, I'll discuss the minimum set of behaviors <br>that you can expect every type to have. I'll also describe type safety, namespaces, assemblies, <br>and the various ways you can cast objects from one type to another. Finally, I'll conclude this <br>chapter with an explanation of how types, objects, thread stacks, and the managed heap all <br>relate to one another at runtime.<br>
<b>All Types Are Derived from </b>System.Object<br>
The runtime requires every type to ultimately be derived from the System.Object type. This <br>means that the following two type definitions are identical:<br>
// Implicitly derived from Object  <br>
 <br>
// Explicitly derived from Object <br>
class Employee {  <br>
 <br>
 <br>
 <br>
class Employee : System.Object { <br>
...  <br>
 <br>
 <br>
 <br>
 <br>
 <br>
... <br>
}  <br>
 <br>
 <br>
 <br>
 <br>
 <br>
}<br>
Because all types are ultimately derived from System.Object, you are guaranteed that every <br>object of every type has a minimum set of methods. Specifically, the System.Object class <br>offers the public instance methods listed in Table 4-1.<br>
<b> </b><br>
<b> </b><br>
<b>91</b><br>
<hr>
<A name=110></a><b>92 </b><br>
<b>Part II  Designing Types</b><br>
<b>TABLE 4-1  Public Methods of </b>System.Object<br>
<b>Public Method</b><br>
<b>Description</b><br>
Equals<br>
Returns true if two objects have the same value. For more information about <br>this method, see the "Object Equality and Identity" section in Chapter 5, <br>"Primitive, Reference, and Value Types."<br>
GetHashCode<br>
Returns a hash code for this object's value. A type should override this method if <br>its objects are to be used as a key in a hash table collection. The method should <br>provide a good distribution for its objects. It is unfortunate that this method is <br>defined in Object because most types are never used as keys in a hash table; <br>this method should have been defined in an interface. For more information <br>about this method, see the "Object Hash Codes" section in Chapter 5.<br>
ToString<br>
By default, returns the full name of the type (this.GetType().FullName). <br>However, it is common to override this method so that it returns a String object <br>containing a representation of the object's state. For example, the core types, <br>such as Boolean and Int32, override this method to return a string representa-<br>tion of their values. It is also common to override this method for debugging  <br>purposes; you can call it and get a string showing the values of the object's fields. <br>In fact, Microsoft Visual Studio's debugger calls this function automatically to <br>show you a string representation of an object. Note that ToString is expected <br>to be aware of the CultureInfo associated with the calling thread. Chapter 14, <br>"Chars, Strings, and Working with Text," discusses ToString in greater detail.<br>
GetType<br>
Returns an instance of a Type-derived object that identifies the type of the  <br>object used to call GetType. The returned Type object can be used with the <br>reflection classes to obtain metadata information about the object's type. <br>Reflection is discussed in Chapter 23, "Assembly Loading and Reflection." The <br>GetType method is nonvirtual, which prevents a class from overriding this  <br>method and lying about its type, violating type safety.<br>
In addition, types that derive from System.Object have access to the protected methods <br>listed in Table 4-2.<br>
<b>TABLE 4-2  Protected Methods of </b>System.Object<br>
<b>Protected Method</b><br>
<b>Description</b><br>
MemberwiseClone<br>
This nonvirtual method creates a new instance of the type and sets the new <br>object's instance fields to be identical to the this object's instance fields. A <br>reference to the new instance is returned.<br>
Finalize<br>
This virtual method is called when the garbage collector determines that <br>the object is garbage before the memory for the object is reclaimed. Types <br>that require cleanup when collected should override this method. I'll talk <br>about this important method in much more detail in Chapter 21, "Automatic <br>Memory Management (Garbage Collection)."<br>
The CLR requires all objects to be created using the new operator. The following line shows <br>how to create an Employee<b> </b>object:<br>
Employee e = new Employee(&quot;ConstructorParam1&quot;);<br>
<hr>
<A name=111></a><b> </b><br>
<b>Chapter 4  Type Fundamentals </b><br>
<b>93</b><br>
Here's what the new<b> </b>operator does:<br>
<b> </b><br>
<b>1.  </b>It calculates the number of bytes required by all instance fields defined in the type and <br>
all of its base types up to and including System.Object (which defines no instance <br>fields of its own). Every object on the heap requires some additional members--called <br>the type object pointer and the sync block index--used by the CLR to manage the  <br>object. The bytes for these additional members are added to the size of the object.<br>
<b> </b><br>
<b>2.  </b>It allocates memory for the object by allocating the number of bytes required for the <br>
specified type from the managed heap; all of these bytes are then set to zero (0).<br>
<b> </b><br>
<b>3.  </b>It initializes the object's type object pointer and sync block index members.<br>
<b> </b><br>
<b>4.  </b>The type's instance constructor is called, passing it any arguments (the string <br>
&quot;ConstructorParam1&quot; in the preceding example) specified in the call to new. Most <br>compilers automatically emit code in a constructor to call a base class's constructor. <br>Each constructor is responsible for initializing the instance fields defined by the type <br>whose constructor is being called. Eventually, System.Object's constructor is called, <br>and this constructor method does nothing but return. You can verify this by using <br>ILDasm.exe to load MSCorLib.dll and examine System.Object's constructor method.<br>
After new has performed all of these operations, it returns a reference (or pointer) to the <br>newly created object. In the preceding code example, this reference is saved in the variable e, <br>which is of type Employee.<br>
By the way, the new<b> </b>operator has no complementary delete<b> </b>operator; that is, there is no <br>way to explicitly free the memory allocated for an object. The CLR uses a garbage-collected <br>environment (described in Chapter 21) that automatically detects when objects are no longer <br>being used or accessed and frees the object's memory automatically.<br>
<b>Casting Between Types</b><br>
One of the most important features of the CLR is type safety. At runtime, the CLR always <br>knows what type an object is. You can always discover an object's exact type by calling the <br>GetType<b> </b>method. Because this method is nonvirtual, it is impossible for a type to spoof an-<br>other type. For example, the Employee<b> </b>type can't override the GetType<b> </b>method and have <br>it return a type of SuperHero.<br>
Developers frequently find it necessary to cast an object to various types. The CLR allows <br>you to cast an object to its type or to any of its base types. Your choice of programming lan-<br>guage dictates how to expose casting operations to the developer. For example, C# doesn't <br>require any special syntax to cast an object to any of its base types, because casts to base <br>types are considered safe implicit conversions. However, C# does require the developer to <br>explicitly cast an object to any of its derived types since such a cast could fail at runtime. The <br>following code demonstrates casting to base and derived types:<br>
<hr>
<A name=112></a><b>94 </b><br>
<b>Part II  Designing Types</b><br>
// This type is implicitly derived from System.Object.  <br>internal class Employee {  <br>   ...  <br>}  <br> <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      // No cast needed since new returns an Employee object  <br>      // and Object is a base type of Employee.  <br>      Object o = new Employee();  <br> <br>      // Cast required since Employee is derived from Object.  <br>      // Other languages (such as Visual Basic) might not require   <br>      // this cast to compile.  <br>      Employee e = (Employee) o;  <br>   }  <br>}<br>
This example shows what is necessary for your compiler to compile your code. Now I'll  <br>explain what happens at runtime. At runtime, the CLR checks casting operations to ensure <br>that casts are always to the object's actual type or any of its base types. For example, the  <br>following code will compile, but at runtime, an <b>I</b>nvalidCastException will be thrown:<br>
internal class Employee {  <br>   ...  <br>}  <br>internal class Manager : Employee {  <br>   ...  <br>}  <br> <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      // Construct a Manager object and pass it to PromoteEmployee.  <br>      // A Manager IS-A Object: PromoteEmployee runs OK.  <br>      Manager m = new Manager();  <br>      PromoteEmployee(m);  <br> <br>      // Construct a DateTime object and pass it to PromoteEmployee.  <br>      // A DateTime is NOT derived from Employee. PromoteEmployee   <br>      // throws a System.InvalidCastException exception.   <br>      DateTime newYears = new DateTime(2010, 1, 1);  <br>      PromoteEmployee(newYears);  <br>   }  <br> <br> <br>   public static void PromoteEmployee(Object o) {  <br>      // At this point, the compiler doesn't know exactly what  <br>      // type of object o refers to. So the compiler allows the   <br>      // code to compile. However, at runtime, the CLR does know   <br>      // what type o refers to (each time the cast is performed) and  <br>      // it checks whether the object's type is Employee or any type  <br>      // that is derived from Employee.  <br>
<hr>
<A name=113></a><b> </b><br>
<b>Chapter 4  Type Fundamentals </b><br>
<b>95</b><br>
      Employee e = (Employee) o;  <br>      ... <br>   }  <br>}<br>
In the Main<b> </b>method, a Manager<b> </b>object is constructed and passed to PromoteEmployee. This <br>code compiles and executes because Manager<b> </b>is ultimately derived from Object, which is <br>what PromoteEmployee<b> </b>expects. Once inside PromoteEmployee, the CLR confirms that o<b>  <br></b>refers to an object that is either an Employee<b> </b>or a type that is derived from Employee. <br>Because Manager<b> </b>is derived from Employee, the CLR performs the cast and allows <br>PromoteEmployee<b> </b>to continue executing.<br>
After PromoteEmployee<b> </b>returns, Main<b> </b>constructs a DateTime<b> </b>object and passes it to <br>PromoteEmployee. Again, DateTime<b> </b>is derived from Object,<b> </b>and the compiler compiles the <br>code that calls PromoteEmployee with no problem. However, inside PromoteEmployee, the <br>CLR checks the cast and detects that o<b> </b>refers to a DateTime<b> </b>object and is therefore not an <br>Employee<b> </b>or any type derived from Employee. At this point, the CLR can't allow the cast and <br>throws a System.InvalidCastException.<br>
If the CLR allowed the cast, there would be no type safety, and the results would be unpre-<br>dictable, including the possibility of application crashes and security breaches caused by <br>the ability of types to easily spoof other types. Type spoofing is the cause of many security <br>breaches and compromises an application's stability and robustness. Type safety is therefore <br>an extremely important part of the CLR.<br>
By the way, the proper way to declare the PromoteEmployee method would be to specify <br>an Employee type instead of an Object type as its parameter so that the compiler produces <br>a compile-time error, saving the developer from waiting until a runtime exception occurs to <br>discover a problem. I used Object so that I could demonstrate how the C# compiler and the <br>CLR deal with casting and type-safety.<br>
<b>Casting with the C# </b>is<b> and </b>as<b> Operators</b><br>
Another way to cast in the C# language is to use the is<b> </b>operator. The is<b> </b>operator checks <br>whether an object is compatible with a given type, and the result of the evaluation is a <br>Boolean:<b> </b>true<b> </b>or false.<b> </b>The is<b> </b>operator will never throw an exception. The following code <br>demonstrates:<br>
Object o = new Object();  <br>Boolean b1 = (o is Object);   // b1 is true.  <br>Boolean b2 = (o is Employee); // b2 is false.<br>
If the object reference is null,<b> </b>the is<b> </b>operator always returns false<b> </b>because there is no  <br>object available to check its type.<br>
<hr>
<A name=114></a><b>96 </b><br>
<b>Part II  Designing Types</b><br>
The <b>is</b> operator is typically used as follows:<br>
if (o is Employee) {  <br>   Employee e = (Employee) o;  <br>   // Use e within the remainder of the 'if' statement.   <br>}<br>
In this code, the CLR is actually checking the object's type twice: The is<b> </b>operator first checks <br>to see if <b>o </b>is compatible with the Employee<b> </b>type. If it is, inside the if<b> </b>statement, the CLR <br>again verifies that <b>o </b>refers to an Employee<b> </b>when performing the cast. The CLR's type checking <br>improves security, but it certainly comes at a performance cost, because the CLR must deter-<br>mine the actual type of the object referred to by the variable (o), and then the CLR must walk <br>the inheritance hierarchy, checking each base type against the specified type (Employee). <br>Because this programming paradigm is quite common, C# offers a way to simplify this code <br>and improve its performance by providing an as<b> </b>operator:<br>
Employee e = o as Employee;  <br>if (e != null) {  <br>   // Use e within the 'if' statement.  <br>}<br>
In this code, the CLR checks if <b>o </b>is compatible with the Employee<b> </b>type, and if it is, as<b> </b>returns a <br>non-null reference to the same object. If <b>o </b>is not compatible with the Employee<b> </b>type, the <b>as <br></b>operator returns null. Notice that the as<b> </b>operator causes the CLR to verify an object's type <br>just once. The if<b> </b>statement simply checks whether e<b> </b>is null; this check can be performed <br>faster than verifying an object's type.<br>
The as<b> </b>operator works just as casting does except that the as<b> </b>operator will never throw <br>an exception. Instead, if the object can't be cast, the result is null. You'll want to check to <br>see whether the resulting reference is null, or attempting to use the resulting reference will <br>cause a System.NullReferenceException<b> </b>to be thrown. The following code demonstrates:<br>
Object o = new Object();    // Creates a new Object object <br>Employee e = o as Employee; // Casts o to an Employee  <br>// The cast above fails: no exception is thrown, but e is set to null.  <br> <br>e.ToString();  // Accessing e throws a NullReferenceException.<br>
To make sure you understand everything just presented, take the following quiz. Assume that <br>these two class definitions exist:<br>
internal class B {     // Base class  <br>}  <br> <br>internal class D : B { // Derived class  <br>}<br>
Now examine the lines of C# code in Table 4-3. For each line, decide whether the line would <br>compile and execute successfully (marked OK below), cause a compile-time error (CTE), or <br>cause a run-time error (RTE).<br>
<hr>
<A name=115></a><IMG src="CLRviaCsharp-115_1.jpg"><br>
<b> </b><br>
<b>Chapter 4  Type Fundamentals </b><br>
<b>97</b><br>
<b>TABLE 4-3  Type-Safety Quiz</b><br>
<b>Statement</b><br>
<b>OK</b><br>
<b>CTE</b><br>
<b>RTE</b><br>
Object o1 = new Object();<br>
Object o2 = new B();<br>
Object o3 = new D();<br>
Object o4 = o3;<br>
B b1 = new B();<br>
B b2 = new D();<br>
D d1 = new D();<br>
B b3 = new Object();<br>
D d2 = new Object();<br>
B b4 = d1;<br>
D d3 = b2;<br>
D d4 = (D) d1;<br>
D d5 = (D) b2;<br>
D d6 = (D) b1;<br>
B b5 = (B) o1;<br>
B b6 = (D) b2;<br>
<b>Note</b>  C# allows a type to define conversion operator methods as discussed in the "Conversion <br>Operator Methods" section of Chapter 9, "Parameters." These methods are invoked only when <br>using a cast expression; they are never invoked when using C#'s as or is operator.<br>
<b>Namespaces and Assemblies</b><br>
Namespaces allow for the logical grouping of related types, and developers typically use <br>them to make it easier to locate a particular type. For example, the System.Text<b> </b>namespace <br>defines a bunch of types for performing string manipulations, and the System.IO<b> </b>namespace <br>defines a bunch of types for performing I/O operations. Here's some code that constructs a <br>System.IO.FileStream object and a System.Text.StringBuilder object:<br>
public sealed class Program {  <br>   public static void Main() {  <br>      System.IO.FileStream fs = new System.IO.FileStream(...);  <br>      System.Text.StringBuilder sb = new System.Text.StringBuilder();  <br>   }  <br>}<br>
<hr>
<A name=116></a><IMG src="CLRviaCsharp-116_1.jpg"><br>
<b>98 </b><br>
<b>Part II  Designing Types</b><br>
As you can see, the code is pretty verbose; it would be nice if there were some shorthand <br>way to refer to the FileStream and StringBuilder types to reduce typing. Fortunately, <br>many compilers do offer mechanisms to reduce programmer typing. The C# compiler  <br>provides this mechanism via the using<b> </b>directive. The following code is identical to the  <br>previous example:<br>
using System.IO;    // Try prepending &quot;System.IO.&quot;  <br>using System.Text;  // Try prepending &quot;System.Text.&quot;  <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      FileStream fs = new FileStream(...);  <br>      StringBuilder sb = new StringBuilder();  <br>   }  <br>}<br>
To the compiler, a namespace is simply an easy way of making a type's name longer and <br>more likely to be unique by preceding the name with some symbols separated by dots.  <br>So the compiler interprets the reference to FileStream in this example to mean  <br>System.IO.FileStream. Similarly, the compiler interprets the reference to StringBuilder <br>to mean System.Text.StringBuilder.<br>
Using the C# using directive is entirely optional; you're always welcome to type out the fully <br>qualified name of a type if you prefer. The C# using directive instructs the compiler to try <br>prepending different prefixes to a type name until a match is found.<br>
<b>Important  </b>The CLR doesn't know anything about namespaces. When you access a type, the <br>CLR needs to know the full name of the type (which can be a really long name containing  <br>periods) and which assembly contains the definition of the type so that the runtime can load  <br>the proper assembly, find the type, and manipulate it.<br>
In the previous code example, the compiler needs to ensure that every type referenced  <br>exists and that my code is using that type in the correct way: calling methods that exist,  <br>passing the right number of arguments to these methods, ensuring that the arguments are <br>the right type, using the method's return value correctly, and so on. If the compiler can't find <br>a type with the specified name in the source files or in any referenced assemblies, it prepends <br>System.IO<b>. </b>to the type name and checks if the generated name matches an existing type. If <br>the compiler still can't find a match, it prepends System.Text.<b> </b>to the type's name. The two <br>using<b> </b>directives shown earlier allow me to simply type FileStream<b> </b>and StringBuilder<b> </b>in <br>my code--the compiler automatically expands the references to System.IO.FileStream<b> <br></b>and System.Text.StringBuilder. I'm sure you can easily imagine how much typing this <br>saves, as well as how much cleaner your code is to read.<br>
When checking for a type's definition, the compiler must be told which assemblies to exam-<br>ine by using the /reference<b> </b>compiler switch as discussed in Chapter 2, "Building, Packaging, <br>Deploying, and Administering Applications and Types," and Chapter 3, "Shared Assemblies <br>
<hr>
<A name=117></a><b> </b><br>
<b>Chapter 4  Type Fundamentals </b><br>
<b>99</b><br>
and Strongly Named Assemblies." The compiler will scan all of the referenced assemblies <br>looking for the type's definition. Once the compiler finds the proper assembly, the assem-<br>bly information and the type information is emitted into the resulting managed module's <br>metadata. To get the assembly information, you must pass the assembly that defines any <br>referenced types to the compiler. The C# compiler, by default, automatically looks in the <br>MSCorLib.dll assembly even if you don't explicitly tell it to. The MSCorLib.dll assembly con-<br>tains the definitions of all of the core Framework Class Library (FCL) types, such as Object,<b> <br></b>Int32,<b> </b>String, and so on.<br>
As you might imagine, there are some potential problems with the way that compilers treat <br>namespaces: it's possible to have two (or more) types with the same name in different  <br>namespaces. Microsoft strongly recommends that you define unique names for types. <br>However, in some cases, it's simply not possible. The runtime encourages the reuse of com-<br>ponents. Your application might take advantage of a component that Microsoft created and <br>another component that Wintellect created. These two companies might both offer a type <br>called Widget--Microsoft's Widget<b> </b>does one thing, and Wintellect's Widget<b> </b>does something <br>entirely different. In this scenario, you had no control over the naming of the types, so you <br>can differentiate between the two widgets by using their fully qualified names when refer-<br>encing them. To reference Microsoft's Widget, you would use Microsoft.Widget,<b> </b>and to <br>reference Wintellect's Widget, you would use Wintellect.Widget. In the following code, <br>the reference to Widget<b> </b>is ambiguous, so the C# compiler generates the following message: <br>&quot;error<b> </b>CS0104:<b> </b>'Widget'<b> </b>is<b> </b>an<b> </b>ambiguous<b> </b>reference&quot;:<br>
using Microsoft;  // Try prepending &quot;Microsoft.&quot;  <br>using Wintellect; // Try prepending &quot;Wintellect.&quot;  <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      Widget w = new Widget();// An ambiguous reference  <br>   }  <br>}<br>
To remove the ambiguity, you must explicitly tell the compiler which Widget<b> </b>you want to <br>create:<br>
using Microsoft;  // Try prepending &quot;Microsoft.&quot;  <br>using Wintellect; // Try prepending &quot;Wintellect.&quot;  <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      Wintellect.Widget w = new Wintellect.Widget(); // Not ambiguous  <br>   }  <br>}<br>
There's another form of the C# using<b> </b>directive that allows you to create an alias for a single <br>type or namespace. This is handy if you have just a few types that you use from a namespace <br>and don't want to pollute the global namespace with al  of a namespace's types. The following <br>code demonstrates another way to solve the ambiguity problem shown in the preceding code:<br>
<hr>
<A name=118></a><b>100 </b><br>
<b>Part II  Designing Types</b><br>
using Microsoft;  // Try prepending &quot;Microsoft.&quot;  <br>using Wintellect; // Try prepending &quot;Wintellect.&quot;  <br> <br>// Define WintellectWidget symbol as an alias to Wintellect.Widget  <br>using WintellectWidget = Wintellect.Widget;  <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      WintellectWidget w = new WintellectWidget(); // No error now  <br>   }  <br>}<br>
These methods of disambiguating a type are useful, but in some scenarios, you need to <br>go further. Imagine that the Australian Boomerang Company (ABC) and the Alaskan Boat <br>Corporation (ABC) are each creating a type, called BuyProduct, which they intend to ship in <br>their respective assemblies. It's likely that both companies would create a namespace called <br>ABC<b> </b>that contains a type called BuyProduct. Anyone who tries to develop an application that <br>needs to buy both boomerangs and boats would be in for some trouble unless the program-<br>ming language provides a way to programmatically distinguish between the assemblies, not <br>just between the namespaces. Fortunately, the C# compiler offers a feature called <i>extern <br>aliases</i> that <i>gives</i> you a way to work around this rarely occurring problem. Extern aliases also <br>give you a way to access a single type from two (or more) different versions of the same  <br>assembly. For more information about extern aliases, see the C# Language Specification.<br>
In your library, when you're designing types that you expect third parties to use, you should <br>define these types in a namespace so that compilers can easily disambiguate them. In fact, <br>to reduce the likelihood of conflict, you should use your full company name (not an acro-<br>nym or abbreviation) to be your top-level namespace name. Referring to the Microsoft .NET <br>Framework SDK documentation, you can see that Microsoft uses a namespace of "Microsoft" <br>for Microsoft-specific types. (See the Microsoft.CSharp,<b> </b>Microsoft.VisualBasic, and <br>Microsoft.Win32<b> </b>namespaces as examples.)<br>
Creating a namespace is simply a matter of writing a namespace declaration into your code <br>as follows (in C#):<br>
namespace CompanyName {   <br>   public sealed class A {              // TypeDef: CompanyName.A  <br>   }  <br> <br>   namespace X {   <br>      public sealed class B { ... }     // TypeDef: CompanyName.X.B  <br>   }  <br>}<br>
The comment on the right of the class definitions above indicates the real name of the type <br>the compiler will emit into the type definition metadata table; this is the real name of the <br>type from the CLR's perspective.<br>
Some compilers don't support namespaces at all, and other compilers are free to define what <br>"namespace" means to a particular language. In C#, the namespace directive simply tells the <br>
<hr>
<A name=119></a><hr>
<A name=120></a><b>102 </b><br>
<b>Part II  Designing Types</b><br>
<b>How Things Relate at Runtime</b><br>
In this section, I'm going to explain the relationship at runtime between types, objects, a <br>thread's stack, and the managed heap. Furthermore, I will also explain the difference between <br>calling static methods, instance methods, and virtual methods. Let's start off with some  <br>fundamentals of computers. What I'm about to describe is not specific to the CLR at all, but <br>I'm going to describe it so that we have a working foundation, and then I'll modify the  <br>discussion to incorporate CLR-specific information.<br>
Figure 4-2 shows a single Microsoft Windows process that has the CLR loaded into it. In this <br>process there may be many threads. When a thread is created, it is allocated a 1-MB stack. <br>This stack space is used for passing arguments to a method and for local variables defined <br>within a method. In Figure 4-2, the memory for one thread's stack is shown (on the right). <br>Stacks build from high-memory addresses to low-memory addresses. In the figure, this <br>thread has been executing some code, and its stack has some data on it already (shown as the <br>shaded area at the top of the stack). Now, imagine that the thread has executed some code <br>that calls the M1 method.<br>
Thread Stack<br>
void M1() {<br>  String name = &quot;Joe&quot;;<br>  M2(name);<br>
  return;<br>}<br>
<b>FIGURE 4-2  </b>A thread's stack with the M1 method about to be called<br>
All but the simplest of methods contain some <i>prologue code</i>, which initializes a method  <br>before it can start doing its work. These methods also contain <i>epilogue code</i>, which cleans  <br>up a method after it has performed its work so that it can return to its caller. When the M1 <br>method starts to execute, its prologue code allocates memory for the local name variable <br>from the thread's stack (see Figure 4-3).<br>
<hr>
<A name=121></a><b> </b><br>
<b>Chapter 4  Type Fundamentals </b><br>
<b>103</b><br>
Thread Stack<br>
void M1() {<br>  String name = &quot;Joe&quot;;<br>  M2(name);<br>
name (String)<br>
} M1 Locals<br>
  return;<br>}<br>
<b>FIGURE 4-3  </b>Allocating M1's local variable on the thread's stack<br>
Then, M1 calls the M2 method, passing in the name local variable as an argument. This causes <br>the address in the name local variable to be pushed on the stack (see Figure 4-4). Inside <br>the M2 method, the stack location will be identified using the parameter variable named s. <br>(Note that some architectures pass arguments via registers to improve performance, but this <br>distinction is not important for this discussion.) Also, when a method is called, the address <br>indicating where the called method should return to in the calling method is pushed on the <br>stack (also shown in Figure 4-4).<br>
Thread Stack<br>
void M1() {<br>  String name = &quot;Joe&quot;;<br>  M2(name);<br>
name (String)<br>
} M1 Locals<br>
s (String)<br>
} M2 Params<br>
  return;<br>}<br>
[return address]<br>
void M2(String s) {<br>  Int32 length = s.Length;<br>  Int32 tally;<br>
  return;<br>}<br>
<b>FIGURE 4-4  </b>M1 pushes arguments and the return address on the thread's stack when calling M2.<br>
When the M2<b> </b>method starts to execute, its prologue code allocates memory for the local <br>length<b> </b>and tally<b> </b>variables from the thread's stack (see Figure 4-5). Then the code inside <br>method M2<b> </b>executes. Eventually, M2<b> </b>gets to its return statement, which causes the CPU's  <br>instruction pointer to be set to the return address in the stack, and M2's stack frame is un-<br>wound so that it looks the way it did in Figure 4-3. At this point, M1<b> </b>is continuing to execute <br>its code that immediately follows the call to M2, and its stack frame accurately reflects the <br>state needed by M1.<br>
<hr>
<A name=122></a><b>104 </b><br>
<b>Part II  Designing Types</b><br>
Eventually, M1<b> </b>will return back to its caller by setting the CPU's instruction pointer to be set to <br>the return address (not shown on the figures, but it would be just above the name<b> </b>argument <br>on the stack), and M1's stack frame is unwound so that it looks the way it did in Figure 4-2. At <br>this point, the method that called M1<b> </b>continues to execute its code that immediately follows <br>the call to M1, and its stack frame accurately reflects the state needed by that method.<br>
Thread Stack<br>
void M1()  {<br>  String name = &quot;Joe&quot;;<br>  M2(name);<br>
name (String)<br>
} M1 Locals<br>
s (String)<br>
} M2 Params<br>
  return;<br>}<br>
[return address]<br>
length (Int32)<br>
  M2 Locals<br>
tally (Int32)<br>
void M2(String s) {<br>  Int32 length = s.Length;<br>  Int32 tally;<br>
  return;<br>}<br>
<b>FIGURE 4-5  </b>Allocating M2's local variables on the thread's stack<br>
Now, let's start gearing the discussion toward the CLR. Let's say that we have these two class <br>definitions:<br>
internal class Employee {  <br>   public         Int32     GetYearsEmployed()   { ... }  <br>   public virtual String    GetProgressReport()  { ... }  <br>   public static  Employee  Lookup(String name)  { ... }  <br>}  <br> <br>internal sealed class Manager : Employee {  <br>   public override String   GetProgressReport()  { ... }  <br>}<br>
Our Windows process has started, the CLR is loaded into it, the managed heap is initialized, <br>and a thread has been created (along with its 1 MB of stack space). This thread has already <br>executed some code, and this code has decided to call the M3 method. All of this is shown in <br>Figure 4-6. The M3 method contains code that demonstrates how the CLR works; this is not <br>code that you would normally write, because it doesn't actually do anything useful.<br>
<hr>
<A name=123></a><b> </b><br>
<b>Chapter 4  Type Fundamentals </b><br>
<b>105</b><br>
Thread Stack<br>
Heap<br>
void M3()  {<br>  Employee e;<br>  Int32 year;<br>  e = new Manager();<br>  e = Employee.Lookup(&quot;Joe&quot;);<br>  year = e.GetYearsEmployed();<br>  e.GenProgressReport();<br>}<br>
<b>FIGURE 4-6  </b>The CLR loaded in a process, its heap initialized, and a thread's stack with the M3 method about <br>to be called<br>
As the just-in-time (JIT) compiler converts M3's Intermediate Language (IL) code into native <br>CPU instructions, it notices all of the types that are referred to inside M3:<b> </b>Employee,<b> </b>Int32,<b> <br></b>Manager, and String (because of <b>&quot;</b>Joe<b>&quot;</b>). At this time, the CLR ensures that the assemblies <br>that define these types are loaded. Then, using the assembly's metadata, the CLR extracts <br>information about these types and creates some data structures to represent the types  <br>themselves. The data structures for the Employee and Manager<b> </b>type objects are shown in <br>Figure 4-7. Since this thread already executed some code prior to calling M3, let's assume that <br>the Int32 and String type objects have already been created (which is likely because these <br>are commonly used types), and so I won't show them in the figure.<br>
<hr>
<A name=124></a><b>106 </b><br>
<b>Part II  Designing Types</b><br>
Thread Stack<br>
Heap<br>
Manager Type Object<br>
Type object ptr<br>Sync block index<br>Static fields<br>GenProgressReport<br>
Employee Type Object<br>
Type object ptr<br>Sync block index<br>
void M3()  {<br>
Static fields<br>
  Employee e;<br>
GetYearsEmployed<br>
  Int32 year;<br>  e = new Manager();<br>
GenProgressReport<br>
  e = Employee.Lookup(&quot;Joe&quot;);<br>
Lookup<br>
  year = e.GetYearsEmployed();<br>  e.GenProgressReport();<br>}<br>
<b>FIGURE 4-7  </b>The Employee and Manager type objects are created just as M3 is being called.<br>
Let's take a moment to discuss these type objects. As discussed earlier in this chapter, all <br>objects on the heap contain two overhead members: the type object pointer and the sync <br>block index. As you can see, the Employee<b> </b>and Manager<b> </b>type objects have both of these <br>members. When you define a type, you can define static data fields within it. The bytes that <br>back these static data fields are allocated within the type objects themselves. Finally, inside <br>each type object is a method table with one entry per method defined within the type. This <br>is the method table that was discussed in Chapter 1, "The CLR's Execution Model." Since <br>the Employee<b> </b>type defines three methods (GetYearsEmployed,<b> </b>GetProgressReport, and <br>Lookup), there are three entries in Employee's method table. Since the Manager<b> </b>type defines  <br>one method (an override of GetProgressReport), there is just one entry in Manager's  <br>method table.<br>
Now, after the CLR has ensured that all of the type objects required by the method are cre-<br>ated and the code for M3 has been compiled, the CLR allows the thread to execute M3's native <br>code. When M3's prologue code executes, memory for the local variables must be allocated <br>from the thread's stack, as shown in Figure 4-8. By the way, the CLR automatically initializes <br>all local variables to null or 0 (zero) as part of the method's prologue code. However, the C# <br>compiler issues a "Use<b> </b>of<b> </b>unassigned<b> </b>local<b> </b>variable" error message if you write code that <br>attempts to read from a local variable that you have not explicitly initialized in your source <br>code.<br>
<hr>
<A name=125></a><b> </b><br>
<b>Chapter 4  Type Fundamentals </b><br>
<b>107</b><br>
Thread Stack<br>
Heap<br>
Manager Type Object<br>
e (Employee)<br>
null<br>
Type object ptr<br>
year (int32)<br>
=   0<br>
Sync block index<br>Static fields<br>GenProgressReport<br>
Employee Type Object<br>
Type object ptr<br>Sync block index<br>
void M3()  {<br>
Static fields<br>
  Employee e;<br>
GetYearsEmployed<br>
  Int32 year;<br>  e = new Manager();<br>
GenProgressReport<br>
  e = Employee.Lookup(&quot;Joe&quot;);<br>
Lookup<br>
  year = e.GetYearsEmployed();<br>  e.GeProgressReport();<br>}<br>
<b>FIGURE 4-8  </b>Allocating M3's local variables on the thread's stack<br>
Then, M3 executes its code to construct a Manager object. This causes an instance of the <br>Manager type, a Manager object, to be created in the managed heap, as shown in Figure 4-9. <br>As you can see, the Manager object--as do all objects--has a type object pointer and sync <br>block index. This object also contains the bytes necessary to hold all of the instance data <br>fields defined by the Manager type, as well as any instance fields defined by any base classes <br>of the Manager type (in this case, Employee and Object). Whenever a new object is created  <br>on the heap, the CLR automatically initializes the internal type object pointer member to <br>refer to the object's corresponding type object (in this case, the Manager<b> </b>type object). <br>Furthermore, the CLR initializes the sync block index and sets all of the object's instance <br>fields to null or 0 (zero) prior to calling the type's constructor, a method that will likely <br>modify some of the instance data fields. The new operator returns the memory address of the <br>Manager object, which is saved in the variable e (on the thread's stack).<br>
<hr>
<A name=126></a><b>108 </b><br>
<b>Part II  Designing Types</b><br>
Thread Stack<br>
Heap<br>
Manager Object<br>
Manager Type Object<br>
e (Employee)<br>
Type object ptr<br>
Type object ptr<br>
year (int32)<br>
=   0<br>
Sync block index<br>
Sync block index<br>
Instance fields<br>
Static fields<br>GenProgressReport<br>
Employee Type Object<br>
Type object ptr<br>Sync block index<br>
void M3()  {<br>
Static fields<br>
  Employee e;<br>
GetYearsEmployed<br>
  Int32 year;<br>  e = new Manager();<br>
GenProgressReport<br>
  e = Employee.Lookup(&quot;Joe&quot;);<br>
Lookup<br>
  year = e.GetYearsEmployed();<br>  e.GenProgressReport();<br>}<br>
<b>FIGURE 4-9  </b>Allocating and initializing a Manager object<br>
The next line of code in M3 calls Employee's static Lookup method. When calling a static <br>method, the JIT compiler locates the type object that corresponds to the type that defines <br>the static method. Then, the JIT compiler locates the entry in the type object's method table <br>that refers to the method being called, JITs the method (if necessary), and calls the JITted <br>code. For our discussion, let's say that Employee's Lookup method queries a database to find <br>Joe. Let's also say that the database indicates that Joe is a manager at the company, and <br>therefore, internally, the Lookup method constructs a new Manager object on the heap,  <br>initializes it for Joe, and returns the address of this object. The address is saved in the local <br>variable e. The result of this operation is shown in Figure 4-10.<br>
Note that e no longer refers to the first Manager<b> </b>object that was created. In fact, since no <br>variable refers to this object, it is a prime candidate for being garbage collected in the future, <br>which will reclaim (free) the memory used by this object.<br>
The next line of code in M3<b> </b>calls Employee's nonvirtual instance GetYearsEmployed<b> </b>method. <br>When calling a nonvirtual instance method, the JIT compiler locates the type object that cor-<br>responds to the type of the variable being used to make the call. In this case, the variable <b>e</b> <br>is defined as an Employee. (If the Employee<b> </b>type didn't define the method being called, the <br>JIT compiler walks down the class hierarchy toward Object<b> </b>looking for this method. It can do <br>this because each type object has a field in it that refers to its base type; this information  <br>is not shown in the figures.) Then, the JIT compiler locates the entry in the type object's <br>method table that refers to the method being called, JITs the method (if necessary), and then <br>calls the JITted code. For our discussion, let's say that Employee's GetYearsEmployed<b> </b>method <br>returns <b>5</b> because Joe has been employed at the company for five years. The integer is saved <br>in the local variable year. The result of this operation is shown in Figure 4-11.<br>
<hr>
<A name=127></a><b> </b><br>
<b>Chapter 4  Type Fundamentals </b><br>
<b>109</b><br>
Thread Stack<br>
Heap<br>
Manager Object<br>
Manager Type Object<br>
e (Employee)<br>
Type object ptr<br>
Type object ptr<br>
year (int32)<br>
=   0<br>
Sync block index<br>
Sync block index<br>
Instance fields<br>
Static fields<br>GenProgressReport<br>
Manager Object<br>
Type object ptr<br>
Employee Type Object<br>
Sync block index<br>
Type object ptr<br>
Instance fields<br>
Sync block index<br>
void M3()  {<br>
Static fields<br>
  Employee e;<br>
GetYearsEmployed<br>
  Int32 year;<br>  e = new Manager();<br>
GenProgressReport<br>
  e = Employee.Lookup(&quot;Joe&quot;);<br>
Lookup<br>
  year = e.GetYearsEmployed();<br>
JITted<br>
  e.GenProgressReport();<br>
code<br>
}<br>
<b>FIGURE 4-10  </b>Employee's static Lookup method allocates and initializes a Manager object for Joe<br>
Thread Stack<br>
Heap<br>
Manager Object<br>
Manager Type Object<br>
e (Employee)<br>
Type object ptr<br>
Type object ptr<br>
year (int32)<br>
=   5<br>
Sync block index<br>
Sync block index<br>
Instance fields<br>
Static fields<br>GenProgressReport<br>
Manager Object<br>
Type object ptr<br>
Employee Type Object<br>
Sync block index<br>
Type object ptr<br>
Instance fields<br>
Sync block index<br>
void M3()  {<br>
Static fields<br>
  Employee e;<br>
JITted<br>
GetYearsEmployed<br>
  Int32 year;<br>
code<br>
  e = new Manager();<br>
GenProgressReport<br>
  e = Employee.Lookup(&quot;Joe&quot;);<br>
Lookup<br>
  year = e.GetYearsEmployed();<br>
JITted<br>
  e.GenProgressReport();<br>
code<br>
}<br>
<b>FIGURE 4-11  </b>Employee's nonvirtual instance GetYearsEmployed method is called, returning 5<br>
<hr>
<A name=128></a><b>110 </b><br>
<b>Part II  Designing Types</b><br>
The next line of code in M3 calls Employee's virtual instance GetProgressReport method. <br>When calling a virtual instance method, the JIT compiler produces some additional code in <br>the method, which will be executed each time the method is invoked. This code will first look <br>in the variable being used to make the call and then follow the address to the calling object. <br>In this case, the variable <b>e</b> points to the Manager object representing "Joe." Then, the code <br>will examine the object's internal type object pointer member; this member refers to the <br>actual type of the object. The code then locates the entry in the type object's method table <br>that refers to the method being called, JITs the method (if necessary), and calls the JITted <br>code. For our discussion, Manager's GetProgressReport implementation is called because e <br>refers to a Manager object. The result of this operation is shown in Figure 4-12.<br>
Note that if Employee's Lookup<b> </b>method had discovered that Joe was just an Employee<b> </b>and <br>not a Manager,<b> </b>Lookup<b> </b>would have internally constructed an Employee<b> </b>object whose type <br>object pointer member would have referred to the Employee<b> </b>type object, causing  <br>Employee's implementation of GetProgressReport<b> </b>to execute instead of Manager's <br>implementation.<br>
Thread Stack<br>
Heap<br>
Manager Object<br>
Manager Type Object<br>
e (Employee)<br>
Type object ptr<br>
Type object ptr<br>
year (int32)<br>
=   5<br>
Sync block index<br>
Sync block index<br>
Instance fields<br>
Static fields<br>GenProgressReport<br>
JITted<br>
code<br>
Manager Object<br>
Type object ptr<br>
Employee Type Object<br>
Sync block index<br>
Type object ptr<br>
Instance fields<br>
Sync block index<br>
void M3()  {<br>
Static fields<br>
  Employee e;<br>
JITted<br>
GetYearsEmployed<br>
  Int32 year;<br>
code<br>
  e = new Manager();<br>
GenProgressReport<br>
  e = Employee.Lookup(&quot;Joe&quot;);<br>
Lookup<br>
  year = e.GetYearsEmployed();<br>
JITted<br>
  e.GenProgressReport();<br>
code<br>
}<br>
<b>FIGURE 4-12  </b>Employee's virtual instance GetProgressReport method is called, causing Manager's over-<br>ride of this method to execute<br>
At this point, we have discussed the relationship between source code, IL, and JITted code. <br>We have also discussed the thread's stack, arguments, local variables, and how these argu-<br>ments and variables refer to objects on the managed heap. You also see how objects contain <br>a pointer to their type object (containing the static fields and method table). We have also <br>discussed how the JIT compiler determines how to call static methods, nonvirtual instance <br>methods, and virtual instance methods. All of this should give you great insight into how the <br>
<hr>
<A name=129></a><b> </b><br>
<b>Chapter 4  Type Fundamentals </b><br>
<b>111</b><br>
CLR works, and this insight should help you when architecting and implementing your types, <br>components, and applications. Before ending this chapter, I'd like to give you just a little <br>more insight as to what is going on inside the CLR.<br>
You'll notice that the Employee and Manager<b> </b>type objects both contain type object pointer <br>members. This is because type objects are actually objects themselves. When the CLR creates  <br>type objects, the CLR must initialize these members. "To what?" you might ask. Well, when <br>the CLR starts running in a process, it immediately creates a special type object for the <br>System.Type type (defined in MSCorLib.dll). The Employee and Manager<b> </b>type objects are <br>"instances" of this type, and therefore, their type object pointer members are initialized to <br>refer to the System.Type type object, as shown in Figure 4-13.<br>
Of course, the System.Type type object is an object itself and therefore also has a type  <br>object pointer member in it, and it is logical to ask what this member refers to. It refers <br>to itself because the System.Type type object is itself an "instance" of a type object. And <br>now you should understand the CLR's complete type system and how it works. By the way, <br>System.Object's GetType method simply returns the address stored in the specified object's <br>type object pointer member. In other words, the GetType method returns a pointer to an  <br>object's type object, and this is how you can determine the true type of any object in the  <br>system (including type objects).<br>
Thread Stack<br>
Heap<br>
Manager Object<br>
Manager Type Object<br>
e (Employee)<br>
Type object ptr<br>
Type object ptr<br>
year (int32)<br>
=   5<br>
Sync block index<br>
Sync block index<br>
Instance fields<br>
Static fields<br>GenProgressReport<br>
JITted<br>
code<br>
Manager Object<br>
Type object ptr<br>
Employee Type Object<br>
Sync block index<br>
Type object ptr<br>
Instance fields<br>
Sync block index<br>
void M3()  {<br>
Static fields<br>
Type Type Object<br>
  Employee e;<br>
JITted<br>
GetYearsEmployed<br>
  Int32 year;<br>
Type object ptr<br>
code<br>
  e = new Manager();<br>
GenProgressReport<br>
Sync block index<br>
  e = Employee.Lookup(&quot;Joe&quot;);<br>
Lookup<br>
  year = e.GetYearsEmployed();<br>
Static fields<br>
JITted<br>
  e.GenProgressReport();<br>
code<br>
}<br>
<b>FIGURE 4-13  </b>The Employee and Manager type objects are instances of the System.Type type.<br>
<hr>
<A name=130></a><hr>
<A name=131></a>Chapter 5<br><b>Primitive, Reference, and Value </b><br>
<b>Types</b><br>
<b>In this chapter:<br>Programming Language Primitive Types  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113<br>Reference Types and Value Types. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121<br>Boxing and Unboxing Value Types. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127<br>Object Hash Codes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146<br>The </b>dynamic<b> Primitive Type. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148</b><br>
In this chapter, I'll discuss the different kinds of types you'll run into as a Microsoft .NET <br>Framework developer. It is crucial for all developers to be familiar with the different behaviors  <br>that these types exhibit. When I was first learning the .NET Framework, I didn't fully under-<br>stand the difference between primitive, reference, and value types. This lack of clarity led me <br>to unwittingly introduce subtle bugs and performance issues into my code. By explaining the <br>differences between the types here, I'm hoping to save you some of the headaches that I  <br>experienced while getting up to speed.<br>
<b>Programming Language Primitive Types</b><br>
Certain data types are so commonly used that many compilers allow code to manipulate <br>them using simplified syntax. For example, you could allocate an integer by using the follow-<br>ing syntax:<br>
System.Int32 a = new System.Int32();<br>
But I'm sure you'd agree that declaring and initializing an integer by using this syntax is rather <br>cumbersome. Fortunately, many compilers (including C#) allow you to use syntax similar to <br>the following instead:<br>
int a = 0;<br>
This syntax certainly makes the code more readable and generates identical Intermediate <br>Language (IL) to that which is generated when System.Int32<b> </b>is used. Any data types the <br>compiler directly supports are called <i>primitive types</i>. Primitive types map directly to types <br>existing in the Framework Class Library (FCL). For example, in C#, an int<b> </b>maps directly to the <br>
<b> </b><br>
<b> </b><br>
<b>113</b><br>
<hr>
<A name=132></a><b>114 </b><br>
<b>Part II  Designing Types</b><br>
System.Int32 type. Because of this, the following four lines of code all compile correctly and <br>produce the exact same IL:<br>
int          a = 0;                   // Most convenient syntax  <br>System.Int32 a = 0;                   // Convenient syntax  <br>int          a = new int();           // Inconvenient syntax  <br>System.Int32 a = new System.Int32();  // Most inconvenient syntax<br>
Table 5-1 shows the FCL types that have corresponding primitives in C#. For the types that <br>are compliant with the Common Language Specification (CLS), other languages will offer <br>similar primitive types. However, languages aren't required to offer any support for the  <br>non­CLS-compliant types.<br>
<b> TABLE 5-1  C# Primitives with Corresponding FCL Types</b><br>
<b>Primitive Type FCL Type</b><br>
<b>CLS-Compliant</b><br>
<b>Description</b><br>
sbyte<br>
System.SByte<br>
No<br>
Signed 8-bit value<br>
byte<br>
System.Byte<br>
Yes<br>
Unsigned 8-bit value<br>
short<br>
System.Int16<br>
Yes<br>
Signed 16-bit value<br>
ushort<br>
System.Uint16<br>
No<br>
Unsigned 16-bit value<br>
int<br>
System.Int32<br>
Yes<br>
Signed 32-bit value<br>
uint<br>
System.Uint32<br>
No<br>
Unsigned 32-bit value<br>
long<br>
System.Int64<br>
Yes<br>
Signed 64-bit value<br>
ulong<br>
System.UInt64<br>
No<br>
Unsigned 64-bit value<br>
char<br>
System.Char<br>
Yes<br>
16-bit Unicode character (char never <br>represents an 8-bit value as it would in <br>unmanaged C++.)<br>
float<br>
System.Single<br>
Yes<br>
IEEE 32-bit floating point value<br>
double<br>
System.Double<br>
Yes<br>
IEEE 64-bit floating point value<br>
bool<br>
System.Boolean<br>
Yes<br>
A true/false value<br>
decimal<br>
System.Decimal<br>
Yes<br>
A 128-bit high-precision floating-point <br>value commonly used for financial <br>calculations in which rounding errors <br>can't be tolerated. Of the 128 bits, 1 <br>bit represents the sign of the value, <br>96 bits represent the value itself, and <br>8 bits represent the power of 10 to <br>divide the 96-bit value by (can be <br>anywhere from 0 to 28). The remaining <br>bits are unused.<br>
string<br>
System.String<br>
Yes<br>
An array of characters<br>
object<br>
System.Object<br>
Yes<br>
Base type of all types<br>
<hr>
<A name=133></a><b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>115</b><br>
<b>Primitive Type FCL Type</b><br>
<b>CLS-Compliant</b><br>
<b>Description</b><br>
dynamic<br>
System.Object<br>
Yes<br>
To the common language runtime <br>(CLR), dynamic is identical to object. <br>However, the C# compiler allows <br>dynamic variables to participate in <br>dynamic dispatch using a simplified <br>syntax. For more information, see "The <br>dynamic Primitive Type" section at the <br>end of this chapter.<br>
Another way to think of this is that the C# compiler automatically assumes that you have the <br>following using directives (as discussed in Chapter 4, "Type Fundamentals") in all of your <br>source code files:<br>
using sbyte  = System.SByte;  <br>using byte   = System.Byte;  <br>using short  = System.Int16;  <br>using ushort = System.UInt16;  <br>using int    = System.Int32;  <br>using uint   = System.UInt32;  <br>...<br>
The C# language specification states, "As a matter of style, use of the keyword is favored over <br>use of the complete system type name." I disagree with the language specification; I prefer <br>to use the FCL type names and completely avoid the primitive type names. In fact, I wish that <br>compilers didn't even offer the primitive type names and forced developers to use the FCL <br>type names instead. Here are my reasons:<br>
  I've seen a number of developers confused, not knowing whether to use string <br>
or String in their code. Because in C# string (a keyword) maps exactly to  <br>System.String (an FCL type), there is no difference and either can be used. Similarly, <br>I've heard some developers say that int represents a 32-bit integer when the application <br>is running on a 32-bit OS and that it represents a 64-bit integer when the application <br>is running on a 64-bit OS. This statement is absolutely false: in C#, an int always maps <br>to System.Int32, and therefore it represents a 32-bit integer regardless of the OS the <br>code is running on. If programmers would use Int32 in their code, then this potential <br>confusion is also eliminated.<br>
  In C#, long maps to System.Int64, but in a different programming language, long <br>
could map to an Int16 or Int32. In fact, C++/CLI does treat long as an Int32. <br>Someone reading source code in one language could easily misinterpret the code's <br>intention if he or she were used to programming in a different programming language. <br>In fact, most languages won't even treat long as a keyword and won't compile code <br>that uses it.<br>
<hr>
<A name=134></a><b>116 </b><br>
<b>Part II  Designing Types</b><br>
  The FCL has many methods that have type names as part of their method names. For <br>
example, the BinaryReader type offers methods such as ReadBoolean,<b> </b>ReadInt32,<b> <br></b>ReadSingle, and so on, and the System.Convert type offers methods such as <br>ToBoolean,<b> </b>ToInt32,<b> </b>ToSingle, and so on. Although it's legal to write the following <br>code, the line with float feels very unnatural to me, and it's not obvious that the line is <br>correct:<br>
BinaryReader br = new BinaryReader(...);  <br>float  val = br.ReadSingle();   // OK, but feels unnatural  <br>Single val = br.ReadSingle();   // OK and feels good<br>
  Many programmers that use C# exclusively tend to forget that other programming  <br>
languages can be used against the CLR, and because of this, C#-isms creep into the <br>class library code. For example, Microsoft's FCL is almost exclusively written in C# and <br>developers on the FCL team have now introduced methods into the library such as <br>Array's GetLongLength, which returns an Int64 value that is a long in C# but not <br>in other languages (like C++/CLI). Another example is System.Linq.Enumerable's <br>LongCount<b> </b>method.<br>
For all of these reasons, I'll use the FCL type names throughout this book.<br>
In many programming languages, you would expect the following code to compile and  <br>execute correctly:<br>
Int32  i = 5;   // A 32-bit value  <br>Int64  l = i;   // Implicit cast to a 64-bit value<br>
However, based on the casting discussion presented in Chapter 4, you wouldn't expect this <br>code to compile. After all, System.Int32 and System.Int64 are different types, and neither  <br>one is derived from the other. Well, you'll be happy to know that the C# compiler does  <br>compile this code correctly, and it runs as expected. Why? The reason is that the C# compiler <br>has intimate knowledge of primitive types and applies its own special rules when compiling <br>the code. In other words, the compiler recognizes common programming patterns and  <br>produces the necessary IL to make the written code work as expected. Specifically, the C# <br>compiler supports patterns related to casting, literals, and operators, as shown in the follow-<br>ing examples.<br>
First, the compiler is able to perform implicit or explicit casts between primitive types such as <br>these:<br>
Int32  i = 5;         // Implicit cast from Int32  to Int32  <br>Int64  l = i;         // Implicit cast from Int32  to Int64  <br>Single s = i;         // Implicit cast from Int32  to Single  <br>Byte   b = (Byte) i;  // Explicit cast from Int32  to Byte  <br>Int16  v = (Int16) s; // Explicit cast from Single to Int16<br>
C# allows implicit casts if the conversion is "safe," that is, no loss of data is possible, such as <br>converting an Int32 to an Int64. But C# requires explicit casts if the conversion is potentially <br>
<hr>
<A name=135></a><IMG src="CLRviaCsharp-135_1.jpg"><br>
<b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>117</b><br>
unsafe. For numeric types, "unsafe" means that you could lose precision or magnitude as a <br>result of the conversion. For example, converting from Int32 to Byte requires an explicit <br>cast because precision might be lost from large Int32 numbers; converting from Single to <br>Int16 requires a cast because Single can represent numbers of a larger magnitude than <br>Int16 can.<br>
Be aware that different compilers can generate different code to handle these cast operations. <br>For example, when casting a Single with a value of 6.8 to an Int32, some compilers could <br>generate code to put a 6 in the Int32, and others could perform the cast by rounding the <br>result up to 7. By the way, C# always truncates the result. For the exact rules that C# follows <br>for casting primitive types, see the "Conversions" section in the C# language specification.<br>
In addition to casting, primitive types can be written as <i>literals</i>. A literal is considered to be an <br>instance of the type itself, and therefore, you can call instance methods by using the instance <br>as shown here:<br>
Console.WriteLine(123.ToString() + 456.ToString());  // &quot;123456&quot;<br>
Also, if you have an expression consisting of literals, the compiler is able to evaluate the  <br>expression at compile time, improving the application's performance.<br>
Boolean found = false;    // Generated code sets found to 0  <br>Int32 x = 100 + 20 + 3;   // Generated code sets x to 123  <br>String s = &quot;a &quot; + &quot;bc&quot;;   // Generated code sets s to &quot;a bc&quot;<br>
Finally, the compiler automatically knows how and in what order to interpret operators (such <br>as +,<b> </b>-,<b> </b>*,<b> </b>/,<b> </b>%,<b> </b>&amp;,<b> </b>^,<b> </b>|,<b> </b>==,<b> </b>!=,<b> </b>&gt;,<b> </b>&lt;,<b> </b>&gt;=,<b> </b>&lt;=,<b> </b>&lt;&lt;,<b> </b>&gt;&gt;,<b> </b>~,<b> </b>!,<b> </b>++,<b> </b>--, and so on) when used in code:<br>
Int32 x = 100;                     // Assignment operator  <br>Int32 y = x + 23;                  // Addition and assignment operators  <br>Boolean lessThanFifty = (y &lt; 50);  // Less-than and assignment operators<br>
<b>Checked and Unchecked Primitive Type Operations</b><br>
Programmers are well aware that many arithmetic operations on primitives could result in an <br>overflow:<br>
Byte b = 100;  <br>b = (Byte) (b + 200);         // b now contains 44 (or 2C in Hex).<br>
<b>Important  </b>When performing the arithmetic operation above, the first step requires that all <br>operand values be expanded to 32-bit values (or 64-bit values if any operand requires more than <br>32 bits). So b and 200 (values requiring less than 32 bits) are first converted to 32-bit values and <br>then added together. The result is a 32-bit value (300 in decimal, or 12C in hexadecimal) that <br>must be cast to a Byte before the result can be stored back in the variable b. C# doesn't perform <br>this cast for you implicitly, which is why the Byte cast on the second line of the preceding code is <br>required.<br>
<hr>
<A name=136></a><b>118 </b><br>
<b>Part II  Designing Types</b><br>
In most programming scenarios, this silent overflow is undesirable and if not detected causes <br>the application to behave in strange and unusual ways. In some rare programming scenarios <br>(such as calculating a hash value or a checksum), however, this overflow is not only acceptable <br>but is also desired.<br>
Different languages handle overflows in different ways. C and C++ don't consider overflows <br>to be an error and allow the value to wrap; the application continues running. Microsoft <br>Visual Basic, on the other hand, always considers overflows to be errors and throws an  <br>exception when it detects one.<br>
The CLR offers IL instructions that allow the compiler to choose the desired behavior. The CLR <br>has an instruction called add<b> </b>that adds two values together. The add<b> </b>instruction performs no <br>overflow checking. The CLR also has an instruction called add.ovf<b> </b>that also adds two values <br>together. However, add.ovf<b> </b>throws a System.OverflowException<b> </b>if an overflow occurs. In <br>addition to these two IL instructions for the add operation, the CLR also has similar IL instruc-<br>tions for subtraction (sub/sub.ovf), multiplication (mul/mul.ovf), and data conversions <br>(conv/conv.ovf).<br>
C# allows the programmer to decide how overflows should be handled. By default, overflow <br>checking is turned off. This means that the compiler generates IL code by using the versions <br>of the add, subtract, multiply, and conversion instructions that don't include overflow check-<br>ing. As a result, the code runs faster--but developers must be assured that overflows won't <br>occur or that their code is designed to anticipate these overflows.<br>
One way to get the C# compiler to control overflows is to use the /checked+ compiler <br>switch. This switch tells the compiler to generate code that has the overflow-checking versions <br>of the add, subtract, multiply, and conversion IL instructions. The code executes a little slower <br>because the CLR is checking these operations to determine whether an overflow occurred. <br>If an overflow occurs, the CLR throws an OverflowException.<br>
In addition to having overflow checking turned on or off globally, programmers can control  <br>overflow checking in specific regions of their code. C# allows this flexibility by offering <br>checked and unchecked operators. Here's an example that uses the unchecked operator:<br>
UInt32 invalid = unchecked((UInt32) (-1));  // OK<br>
And here is an example that uses the checked operator:<br>
Byte b = 100;  <br>b = checked((Byte) (b + 200));    // OverflowException is thrown<br>
In this example, b and 200 are first converted to 32-bit values and are then added together; <br>the result is 300. Then 300 is converted to a Byte due to the explicit cast; this generates the <br>OverflowException. If the Byte were cast outside the checked operator, the exception <br>wouldn't occur:<br>
<hr>
<A name=137></a><IMG src="CLRviaCsharp-137_1.jpg"><br>
<b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>119</b><br>
b = (Byte) checked(b + 200);      // b contains 44; no OverflowException<br>
In addition to the checked and unchecked operators, C# also offers checked and unchecked <br>statements. The statements cause all expressions within a block to be checked or unchecked:<br>
checked {                         // Start of checked block  <br>   Byte b = 100;  <br>   b = (Byte) (b + 200);          // This expression is checked for overflow.  <br>}                                 // End of checked block<br>
In fact, if you use a checked statement block, you can now use the += operator with the <br>Byte, which simplifies the code a bit:<br>
checked {         // Start of checked block  <br>   Byte b = 100;   <br>   b += 200;      // This expression is checked for overflow.  <br>}                 // End of checked block<br>
<b>Important  </b>Because the only effect that the checked operator and statement have is to  <br>determine which versions of the add, subtract, multiply, and data conversion IL instructions are <br>produced, calling a method within a checked operator or statement has no impact on that <br>method, as the following code demonstrates:<br>
checked {  <br>   // Assume SomeMethod tries to load 400 into a Byte.  <br>   SomeMethod(400);   <br>   // SomeMethod might or might not throw an OverflowException.   <br>   // It would if SomeMethod were compiled with checked instructions.  <br>}<br>
In my experience, I've seen a lot of calculations produce surprising results. Typically, this is <br>due to invalid user input, but it can also be due to values returned from parts of the system <br>that a programmer just doesn't expect. And so, I now recommend that programmers do the <br>following:<br>
  Use signed data types (such as Int32 and Int64) instead of unsigned numeric types <br>
(such as UInt32 and UInt64) wherever possible. This allows the compiler to detect <br>more overflow/underflow errors. In addition, various parts of the class library (such <br>as Array's and String's Length properties) are hard-coded to return signed values, <br>and less casting is required as you move these values around in your code. Fewer casts <br>make source code cleaner and easier to maintain. In addition, unsigned numeric types <br>are not CLS-compliant.<br>
  As you write your code, explicitly use checked around blocks where an unwanted  <br>
overflow might occur due to invalid input data, such as processing a request with <br>data supplied from an end user or a client machine. You might want to catch <br>OverflowException as well, so that your application can gracefully recover from these <br>failures.<br>
<hr>
<A name=138></a><b>120 </b><br>
<b>Part II  Designing Types</b><br>
  As you write your code, explicitly use unchecked around blocks where an overflow is <br>
OK, such as calculating a checksum.<br>
  For any code that doesn't use checked or unchecked, the assumption is that you <i>do </i><br>
want an exception to occur on overflow, for example, calculating something (such as <br>prime numbers) where the inputs are known, and overflows are bugs.<br>
Now, as you develop your application, turn on the compiler's /checked+ switch for debug <br>builds. Your application will run more slowly because the system will be checking for over-<br>flows on any code that you didn't explicitly mark as checked or unchecked. If an exception <br>occurs, you'll easily detect it and be able to fix the bug in your code. For the release build <br>of your application, use the compiler's /checked-switch so that the code runs faster and <br>overflow exceptions won't be generated. To change the Checked setting in Microsoft Visual <br>Studio, display the properties for your project, select the Build tab, click Advanced, and then <br>select the Check For Arithmetic Overflow/underflow&quot; option, as shown in Figure 5-1.<br>
If your application can tolerate the slight performance hit of always doing checked opera-<br>tions, then I recommend that you compile with the /checked command-line option even  <br>for a release build because this can prevent your application from continuing to run with  <br>corrupted data and possible security holes. For example, you might perform a multiplication <br>to calculate an index into an array; it is much better to get an OverflowException as  <br>opposed to accessing an incorrect array element due to the math wrapping around.<br>
<b>FIGURE 5-1  </b>Changing the compiler's default setting for performing checked arithmetic using Visual Studio's <br>Advanced Build Settings dialog box<br>
<hr>
<A name=139></a><IMG src="CLRviaCsharp-139_1.jpg"><br>
<b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>121</b><br>
<b>Important  </b>The System.Decimal type is a very special type. Although many programming  <br>languages (C# and Visual Basic included) consider Decimal a primitive type, the CLR does not. <br>This means that the CLR doesn't have IL instructions that know how to manipulate a Decimal <br>value. If you look up the Decimal type in the .NET Framework SDK documentation, you'll <br>see that it has public static methods called Add,<b> </b>Subtract,<b> </b>Multiply,<b> </b>Divide, and so on. In  <br>addition, the Decimal type provides operator overload methods for +,<b> </b>-,<b> </b>*,<b> </b>/, and so on.<br>
When you compile code that uses Decimal values, the compiler generates code to call <br>Decimal's members to perform the actual operation. This means that manipulating Decimal <br>values is slower than manipulating CLR primitive values. Also, because there are no IL  <br>instructions for manipulating Decimal values, the checked and unchecked operators,  <br>statements, and compiler switches have no effect. Operations on Decimal values always throw <br>an OverflowException if the operation can't be performed safely.<br>
Similarly, the System.Numerics.BigInteger type is also special in that it internally uses an <br>array of UInt32s to represent an arbitrarily large integer whose value has no upper or lower <br>bound. Therefore, operations on a BigInteger never result in an OverflowException. <br>However, a BigInteger operation may throw an OutOfMemoryException if the value gets too <br>large and there is insufficient available memory to resize the array.<br>
<b>Reference Types and Value Types</b><br>
The CLR supports two kinds of types: <i>reference types </i>and <i>value types</i>. While most types in <br>the FCL are reference types, the types that programmers use most often are value types. <br>Reference types are always allocated from the managed heap, and the C# new operator  <br>returns the memory address of the object--the memory address refers to the object's bits. <br>You need to bear in mind some performance considerations when you're working with  <br>reference types. First, consider these facts:<br>
  The memory must be allocated from the managed heap.<br>
  Each object allocated on the heap has some additional overhead members associated <br>
with it that must be initialized.<br>
  The other bytes in the object (for the fields) are always set to zero.<br>
  Allocating an object from the managed heap could force a garbage collection to occur.<br>
If every type were a reference type, an application's performance would suffer greatly. <br>Imagine how poor performance would be if every time you used an Int32 value, a memory <br>allocation occurred! To improve performance for simple, frequently used types, the CLR  <br>offers lightweight types called <i>value types</i>. Value type instances are usually allocated on a <br>thread's stack (although they can also be embedded as a field in a reference type object). <br>The variable representing the instance doesn't contain a pointer to an instance; the variable <br>contains the fields of the instance itself. Because the variable contains the instance's fields, a <br>pointer doesn't have to be dereferenced to manipulate the instance's fields. Value type  <br>
<hr>
<A name=140></a><IMG src="CLRviaCsharp-140_1.jpg"><br>
<b>122 </b><br>
<b>Part II  Designing Types</b><br>
instances don't come under the control of the garbage collector, so their use reduces pres-<br>sure in the managed heap and reduces the number of collections an application requires <br>over its lifetime.<br>
The .NET Framework SDK documentation clearly indicates which types are reference types and <br>which are value types. When looking up a type in the documentation, any type called a <i>class</i> <br>is a reference type. For example, the System.Exception class, the System.IO.FileStream <br>class, and the System.Random class are all reference types. On the other hand, the  <br>documentation refers to each value type as a <i>structure </i>or an <i>enumeration</i>. For example,  <br>the System.Int32 structure, the System.Boolean structure, the System.Decimal  <br>structure, the System.TimeSpan structure, the System.DayOfWeek enumeration, the  <br>System.IO.FileAttributes enumeration, and the System.Drawing.FontStyle enumera-<br>tion are all value types.<br>
If you look more closely at the documentation, you'll notice that all of the structures are  <br>immediately derived from the System.ValueType abstract type. System.ValueType is itself <br>immediately derived from the System.Object type. By definition, all value types must be  <br>derived from System.ValueType. All enumerations are derived from the System.Enum  <br>abstract type, which is itself derived from System.ValueType. The CLR and all programming <br>languages give enumerations special treatment. For more information about enumerated <br>types, refer to Chapter 15, "Enumerated Types and Bit Flags."<br>
Even though you can't choose a base type when defining your own value type, a value type <br>can implement one or more interfaces if you choose. In addition, all value types are sealed, <br>which prevents a value type from being used as a base type for any other reference type or <br>value type. So, for example, it's not possible to define any new types using Boolean, Char, <br>Int32, Uint64,<b> </b>Single,<b> </b>Double,<b> </b>Decimal, and so on as base types.<br>
<b>Important  </b>For many developers (such as unmanaged C/C++ developers), reference types <br>and value types will seem strange at first. In unmanaged C/C++, you declare a type, and then <br>the code that uses the type gets to decide if an instance of the type should be allocated on the <br>thread's stack or in the application's heap. In managed code, the developer defining the type <br>indicates where instances of the type are allocated; the developer using the type has no control <br>over this.<br>
The following code and Figure 5-2 demonstrate how reference types and value types differ:<br>
// Reference type (because of 'class')  <br>class  SomeRef { public Int32 x; }  <br> <br>// Value type (because of 'struct')  <br>struct SomeVal { public Int32 x; }  <br> <br>static void ValueTypeDemo() {  <br>   SomeRef r1 = new SomeRef();   // Allocated in heap  <br>   SomeVal v1 = new SomeVal();   // Allocated on stack  <br>
<hr>
<A name=141></a><b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>123</b><br>
   r1.x = 5;                     // Pointer dereference  <br>   v1.x = 5;                     // Changed on stack  <br>   Console.WriteLine(r1.x);      // Displays &quot;5&quot;  <br>   Console.WriteLine(v1.x);      // Also displays &quot;5&quot;  <br>   // The left side of Figure 5-2 reflects the situation  <br>   // after the lines above have executed.  <br>   <br>   SomeRef r2 = r1;              // Copies reference (pointer) only  <br>   SomeVal v2 = v1;              // Allocate on stack &amp; copies members  <br>   r1.x = 8;                     // Changes r1.x and r2.x  <br>   v1.x = 9;                     // Changes v1.x, not v2.x  <br>   Console.WriteLine(r1.x);      // Displays &quot;8&quot;  <br>   Console.WriteLine(r2.x);      // Displays &quot;8&quot;  <br>   Console.WriteLine(v1.x);      // Displays &quot;9&quot;  <br>   Console.WriteLine(v2.x);      // Displays &quot;5&quot;  <br>   // The right side of Figure 5-2 reflects the situation   <br>   // after ALL of the lines above have executed.  <br>}<br>
In this code, the SomeVal type is declared using struct<b> </b>instead of the more common class. <br>In C#, types declared using struct<b> </b>are value types, and types declared using class<b> </b>are ref-<br>erence types. As you can see, the behavior of reference types and value types differs quite a <br>bit. As you use types in your code, you must be aware of whether the type is a reference type <br>or a value type because it can greatly affect how you express your intentions in the code.<br>
Situation after the first half of the<br>
Situation after the ValueTypeDemo <br>
ValueTypeDemo method executes<br>
method completely executes<br>
<b>Thread Stack</b><br>
<b>Managed Heap</b><br>
<b>Thread Stack</b><br>
<b>Managed Heap</b><br>
r1<br>
Type object ptr<br>
r1<br>
Type object ptr<br>
Sync block index<br>
Sync block index<br>
v1<br>
x=5<br>
v1<br>
x=8<br>
x=5<br>
x=9<br>
r2<br>
v2<br>
x=5<br>
<b>FIGURE 5-2  </b>Visualizing the memory as the code executes<br>
In the preceding code, you saw this line:<br>
SomeVal v1 = new SomeVal();   // Allocated on stack<br>
The way this line is written makes it look as if a SomeVal instance will be allocated on the <br>managed heap. However, the C# compiler knows that SomeVal is a value type and produces <br>code that allocates the SomeVal instance on the thread's stack. C# also ensures that all of the <br>fields in the value type instance are zeroed.<br>
<hr>
<A name=142></a><b>124 </b><br>
<b>Part II  Designing Types</b><br>
The preceding line could have been written like this instead:<br>
SomeVal v1;   // Allocated on stack<br>
This line also produces IL that allocates the instance on the thread's stack and zeroes the <br>fields. The only difference is that C# "thinks" that the instance is initialized if you use the new <br>operator. The following code will make this point clear:<br>
// These two lines compile because C# thinks that   <br>// v1's fields have been initialized to 0.  <br>SomeVal v1 = new SomeVal();  <br>Int32 a = v1.x;  <br> <br>// These two lines don't compile because C# doesn't think that   <br>// v1's fields have been initialized to 0.  <br>SomeVal v1;  <br>Int32 a = v1.x;  // error CS0170: Use of possibly unassigned field 'x'<br>
When designing your own types, consider carefully whether to define your types as value <br>types instead of reference types. In some situations, value types can give better performance. <br>In particular, you should declare a type as a value type if <i>all</i> the following statements are <br>true:<br>
  The type acts as a primitive type. Specifically, this means that it is a fairly simple  <br>
type that has no members that modify any of its instance fields. When a type offers  <br>no members that alter its fields, we say that the type is <i>immutable</i>. In fact, it is  <br>recommended that many value types mark all their fields as readonly (discussed in <br>Chapter 7, &quot;Constants and Fields&quot;).<br>
  The type doesn't need to inherit from any other type.<br>
  The type won't have any other types derived from it.<br>
The size of instances of your type is also a condition to take into account because by default, <br>arguments are passed by value, which causes the fields in value type instances to be copied, <br>hurting performance. Again, a method that returns a value type causes the fields in the  <br>instance to be copied into the memory allocated by the caller when the method returns, <br>hurting performance. So, in addition to the previous conditions, you should declare a type as <br>a value type if one of the following statements is true:<br>
  Instances of the type are small (approximately 16 bytes or less).<br>
  Instances of the type are large (greater than 16 bytes) and are not passed as method <br>
parameters or returned from methods.<br>
The main advantage of value types is that they're not allocated as objects in the managed <br>heap. Of course, value types have several limitations of their own when compared to refer-<br>ence types. Here are some of the ways in which value types and reference types differ:<br>
<hr>
<A name=143></a><IMG src="CLRviaCsharp-143_1.jpg"><br>
<b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>125</b><br>
  Value type objects have two representations: an <i>unboxed </i>form and a <i>boxed </i>form  <br>
(discussed in the next section). Reference types are always in a boxed form.<br>
  Value types are derived from System.ValueType. This type offers the same methods <br>
as defined by System.Object. However, System.ValueType overrides the Equals <br>method so that it returns true if the values of the two objects' fields match. In addition, <br>System.ValueType overrides the GetHashCode method to produce a hash code value <br>by using an algorithm that takes into account the values in the object's instance fields. <br>Due to performance issues with this default implementation, when defining your own <br>value types, you should override and provide explicit implementations for the Equals <br>and GetHashCode methods. I'll cover the Equals and GetHashCode methods at the end <br>of this chapter.<br>
  Because you can't define a new value type or a new reference type by using a value <br>
type as a base class, you shouldn't introduce any new virtual methods into a value <br>type. No methods can be abstract, and all methods are implicitly sealed (can't be <br>overridden).<br>
  Reference type variables contain the memory address of objects in the heap. By de-<br>
fault, when a reference type variable is created, it is initialized to null, indicating that <br>the reference type variable doesn't currently point to a valid object. Attempting to use <br>a null reference type variable causes a NullReferenceException to be thrown. By <br>contrast, value type variables always contain a value of the underlying type, and all <br>members of the value type are initialized to 0. Since a value type variable isn't a pointer, <br>it's not possible to generate a NullReferenceException when accessing a value type. <br>The CLR does offer a special feature that adds the notion of nullability to a value type. <br>This feature, called <i>nullable types</i>, is discussed in Chapter 19, "Nullable Value Types."<br>
  When you assign a value type variable to another value type variable, a field-by-field <br>
copy is made. When you assign a reference type variable to another reference type <br>variable, only the memory address is copied.<br>
  Because of the previous point, two or more reference type variables can refer to a <br>
single object in the heap, allowing operations on one variable to affect the object ref-<br>erenced by the other variable. On the other hand, value type variables are distinct ob-<br>jects, and it's not possible for operations on one value type variable to affect another.<br>
  Because unboxed value types aren't allocated on the heap, the storage allocated for <br>
them is freed as soon as the method that defines an instance of the type is no longer  <br>active. This means that a value type instance doesn't receive a notification (via a <br>Finalize method) when its memory is reclaimed.<br>
<b>Note  </b>In fact, it would be quite odd to define a value type with a Finalize method since the <br>method would be called only on boxed instances. For this reason, many compilers (including C#, <br>C++/CLI, and Visual Basic) don't allow you to define Finalize methods on value types. Although <br>the CLR allows a value type to define a Finalize method, the CLR won't call this method when a <br>boxed instance of the value type is garbage collected.<br>
<hr>
<A name=144></a><hr>
<A name=145></a><hr>
<A name=146></a><b>128 </b><br>
<b>Part II  Designing Types</b><br>
something else entirely? To get the answer, you must look up ArrayList's Add<b> </b>method <br>and see what type its parameter is defined as. In this case, the Add<b> </b>method is prototyped as <br>follows:<br>
public virtual Int32 Add(Object value);<br>
From this, you can plainly see that Add<b> </b>takes an Object<b> </b>as a parameter, indicating that Add<b> <br></b>requires a reference (or pointer) to an object on the managed heap as a parameter. But in <br>the preceding code, I'm passing p,<b> </b>a Point, which is a value type. For this code to work, the <br>Point<b> </b>value type must be converted into a true heap-managed object, and a reference to <br>this object must be obtained.<br>
It's possible to convert a value type to a reference type by using a mechanism called <i>boxing</i>. <br>Internally, here's what happens when an instance of a value type is boxed:<br>
<b> </b><br>
<b>1.  </b>Memory is allocated from the managed heap. The amount of memory allocated is the <br>
size required by the value type's fields plus the two additional overhead members (the <br>type object pointer and the sync block index) required by all objects on the managed <br>heap.<br>
<b> </b><br>
<b>2.  </b>The value type's fields are copied to the newly allocated heap memory.<br>
<b> </b><br>
<b>3.  </b>The address of the object is returned. This address is now a reference to an object; the <br>
value type is now a reference type.<br>
The C# compiler automatically produces the IL code necessary to box a value type instance, <br>but you still need to understand what's going on internally so that you're aware of code size <br>and performance issues.<br>
In the preceding code, the C# compiler detected that I was passing a value type to a method <br>that requires a reference type, and it automatically emitted code to box the object. So at <br>runtime, the fields currently residing in the Point value type instance p are copied into the <br>newly allocated Point object. The address of the boxed Point object (now a reference type) <br>is returned and is then passed to the Add method. The Point object will remain in the heap <br>until it is garbage collected. The Point value type variable (p) can be reused because the <br>ArrayList never knows anything about it. Note that the lifetime of the boxed value type <br>extends beyond the lifetime of the unboxed value type.<br>
<hr>
<A name=147></a><IMG src="CLRviaCsharp-147_1.jpg"><br>
<b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>129</b><br>
<b>Note  </b>It should be noted that the FCL now includes a new set of generic collection classes  <br>that make the non-generic collection classes obsolete. For example, you should use the  <br>System.Collections.Generic.List&lt;T&gt; class instead of the System.Collections.ArrayList <br>class. The generic collection classes offer many improvements over the non-generic equivalents. <br>For example, the API has been cleaned up and improved, and the performance of the collection <br>classes has been greatly improved as well. But one of the biggest improvements is that the gener-<br>ic collection classes allow you to work with collections of value types without requiring that items <br>in the collection be boxed/unboxed. This in itself greatly improves performance because far fewer <br>objects will be created on the managed heap thereby reducing the number of garbage collections <br>required by your application. Furthermore, you will get compile-time type safety, and your source <br>code will be cleaner due to fewer casts. This will all be explained in further detail in Chapter 12, <br>"Generics."<br>
Now that you know how boxing works, let's talk about unboxing. Let's say that you want to <br>grab the first element out of the ArrayList by using the following code:<br>
Point p = (Point) a[0];<br>
Here you're taking the reference (or pointer) contained in element 0 of the ArrayList and <br>trying to put it into a Point value type instance, p. For this to work, all of the fields contained <br>in the boxed Point object must be copied into the value type variable, p, which is on the <br>thread's stack. The CLR accomplishes this copying in two steps. First, the address of the Point <br>fields in the boxed Point object is obtained. This process is called <i>unboxing</i>. Then, the values <br>of these fields are copied from the heap to the stack-based value type instance.<br>
Unboxing is <i>not </i>the exact opposite of boxing. The unboxing operation is much less costly <br>than boxing. Unboxing is really just the operation of obtaining a pointer to the raw value <br>type (data fields) contained within an object. In effect, the pointer refers to the unboxed  <br>portion in the boxed instance. So, unlike boxing, unboxing doesn't involve the copying of any <br>bytes in memory. Having made this important clarification, it is important to note that an <br>unboxing operation is typically followed by copying the fields. <br>
Obviously, boxing and unboxing/copy operations hurt your application's performance in <br>terms of both speed and memory, so you should be aware of when the compiler generates <br>code to perform these operations automatically and try to write code that minimizes this <br>code generation.<br>
<hr>
<A name=148></a><b>130 </b><br>
<b>Part II  Designing Types</b><br>
Internally, here's exactly what happens when a boxed value type instance is unboxed:<br>
<b> </b><br>
<b>1.  </b>If the variable containing the reference to the boxed value type instance is null, a <br>
NullReferenceException is thrown.<br>
<b> </b><br>
<b>2.  </b>If the reference doesn't refer to an object that is a boxed instance of the desired value <br>
type, an InvalidCastException is thrown.1<br>
The second item above means that the following code will <i>not </i>work as you might expect:<br>
public static void Main() {  <br>   Int32  x = 5;  <br>   Object o = x;         // Box x; o refers to the boxed object  <br>   Int16  y = (Int16) o; // Throws an InvalidCastException  <br>}<br>
Logically, it makes sense to take the boxed Int32 that o refers to and cast it to an Int16. <br>However, when unboxing an object, the cast must be to the exact unboxed value type--<br>Int32 in this case. Here's the correct way to write this code:<br>
public static void Main() {  <br>   Int32  x = 5;  <br>   Object o = x;                // Box x; o refers to the boxed object  <br>   Int16  y = (Int16)(Int32) o; // Unbox to the correct type and cast  <br>}<br>
I mentioned earlier that an unboxing operation is frequently followed immediately by a field <br>copy. Let's take a look at some C# code demonstrating that unbox and copy operations work <br>together:<br>
public static void Main() {  <br>   Point p;  <br>   p.x = p.y = 1;  <br>   Object o = p;   // Boxes p; o refers to the boxed instance  <br> <br>   p = (Point) o;  // Unboxes o AND copies fields from boxed   <br>                   // instance to stack variable  <br>}<br>
On the last line, the C# compiler emits an IL instruction to unbox o (get the address of the <br>fields in the boxed instance) and another IL instruction to copy the fields from the heap to <br>the stack-based variable p.<br>
Now look at this code:<br>
public static void Main() {  <br>   Point p;  <br>   p.x = p.y = 1;  <br>
1  The CLR also allows you to unbox a value type into a nullable version of the same value type. This is discussed in <br>
Chapter 19.<br>
<hr>
<A name=149></a><IMG src="CLRviaCsharp-149_1.jpg"><br>
<b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>131</b><br>
   Object o = p;   // Boxes p; o refers to the boxed instance  <br> <br>   // Change Point's x field to 2  <br>   p = (Point) o;  // Unboxes o AND copies fields from boxed   <br>                   // instance to stack variable  <br>   p.x = 2;        // Changes the state of the stack variable  <br>   o = p;          // Boxes p; o refers to a new boxed instance  <br>}<br>
The code at the bottom of this fragment is intended only to change Point's x<b> </b>field from 1<b> </b>to <br>2.<b> </b>To do this, an unbox operation must be performed, followed by a field copy, followed by <br>changing the field (on the stack), followed by a boxing operation (which creates a whole new <br>boxed instance in the managed heap). Hopefully, you see the impact that boxing and unbox-<br>ing/copying operations have on your application's performance.<br>
Some languages, such as C++/CLI, allow you to unbox a boxed value type without copying <br>the fields. Unboxing returns the address of the unboxed portion of a boxed object (ignoring <br>the object's type object pointer and sync block index overhead). You can now use this point-<br>er to manipulate the unboxed instance's fields (which happen to be in a boxed object on <br>the heap). For example, the previous code would be much more efficient if written in C++/<br>CLI, because you could change the value of Point's x field within the already boxed Point <br>instance. This would avoid both allocating a new object on the heap and copying all of the <br>fields twice!<br>
<b>Important  </b>If you're the least bit concerned about your application's performance, you must be <br>aware of when the compiler produces the code that performs these operations. Unfortunately, <br>many compilers implicitly emit code to box objects, and so it is not obvious when you write code <br>that boxing is occurring. If I am concerned about the performance of a particular algorithm, I <br>always use a tool such as ILDasm.exe to view the IL code for my methods and see where the box <br>IL instructions are.<br>
Let's look at a few more examples that demonstrate boxing and unboxing:<br>
public static void Main() {  <br>   Int32  v = 5;            // Create an unboxed value type variable.  <br>   Object o = v;            // o refers to a boxed Int32 containing 5.  <br>   v = 123;                 // Changes the unboxed value to 123  <br> <br>   Console.WriteLine(v + &quot;, &quot; + (Int32) o); // Displays &quot;123, 5&quot;  <br>}<br>
In this code, can you guess how many boxing operations occur? You might be surprised to <br>discover that the answer is three! Let's analyze the code carefully to really understand what's <br>going on. To help you understand, I've included the IL code generated for the Main method <br>shown in the preceding code. I've commented the code so that you can easily see the indi-<br>vidual operations.<br>
<hr>
<A name=150></a><b>132 </b><br>
<b>Part II  Designing Types</b><br>
.method public hidebysig static void  Main() cil managed  <br>{  <br>  .entrypoint  <br>  // Code size       45 (0x2d)  <br>  .maxstack  3  <br>  .locals init (int32 V_0,  <br>           object V_1)  <br>  // Load 5 into v.   <br>  IL_0000:  ldc.i4.5  <br>  IL_0001:  stloc.0  <br> <br>  // Box v and store the reference pointer in o.  <br>  IL_0002:  ldloc.0  <br>  IL_0003:  box        [mscorlib]System.Int32  <br>  IL_0008:  stloc.1  <br> <br>  // Load 123 into v.   <br>  IL_0009:  ldc.i4.s   123  <br>  IL_000b:  stloc.0  <br> <br>  // Box v and leave the pointer on the stack for Concat.   <br>  IL_000c:  ldloc.0  <br>  IL_000d:  box        [mscorlib]System.Int32  <br> <br>  // Load the string on the stack for Concat.   <br>  IL_0012:  ldstr      &quot;, &quot;  <br> <br>  // Unbox o: Get the pointer to the In32's field on the stack.   <br>  IL_0017:  ldloc.1  <br>  IL_0018:  unbox.any  [mscorlib]System.Int32  <br> <br>  // Box the Int32 and leave the pointer on the stack for Concat.   <br>  IL_001d:  box        [mscorlib]System.Int32  <br> <br>  // Call Concat.   <br>  IL_0022:  call       string [mscorlib]System.String::Concat(object,  <br>                                                              object,  <br>                                                              object)  <br> <br>  // The string returned from Concat is passed to WriteLine.   <br>  IL_0027:  call       void [mscorlib]System.Console::WriteLine(string)  <br> <br>  // Return from Main terminating this application.   <br>  IL_002c:  ret  <br>} // end of method App::Main<br>
First, an Int32 unboxed value type instance (v) is created on the stack and initialized to 5. <br>Then a variable (o) typed as Object is created, and is initialized to point to v. But because <br>reference type variables must always point to objects in the heap, C# generated the proper <br>IL code to box and store the address of the boxed copy of v in o. Now the value 123 is placed <br>into the unboxed value type instance<b> </b>v; this has no effect on the boxed Int32 value, which <br>keeps its value of 5.<br>
<hr>
<A name=151></a><b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>133</b><br>
Next is the call to the WriteLine method. WriteLine wants a String object passed to it, <br>but there is no string object. Instead, these three items are available: an unboxed Int32 value <br>type instance (v), a String (which is a reference type), and a reference to a boxed Int32 <br>value type instance (o) that is being cast to an unboxed Int32. These must somehow be <br>combined to create a String.<br>
To create a String, the C# compiler generates code that calls the String object's static <br>Concat method. There are several overloaded versions of the Concat method, all of which <br>perform identically--the only difference is in the number of parameters. Because a string is <br>being created from the concatenation of three items, the compiler chooses the following  <br>version of the Concat method:<br>
public static String Concat(Object arg0, Object arg1, Object arg2);<br>
For the first parameter, arg0,<b> </b>v is passed. But v is an unboxed value parameter and arg0 is an <br>Object, so v must be boxed and the address to the boxed v is passed for arg0. For the arg1 <br>parameter, the &quot;,&quot; string is passed as a reference to a String object. Finally, for the arg2 <br>parameter, o (a reference to an Object) is cast to an Int32. This requires an unboxing opera-<br>tion (but no copy operation), which retrieves the address of the unboxed Int32 contained <br>inside the boxed Int32. This unboxed Int32 instance must be boxed again and the new <br>boxed instance's memory address passed for Concat's arg2 parameter.<br>
The Concat method calls each of the specified objects' ToString method and concatenates <br>each object's string representation. The String object returned from Concat is then passed <br>to WriteLine to show the final result.<br>
I should point out that the generated IL code is more efficient if the call to WriteLine is writ-<br>ten as follows:<br>
Console.WriteLine(v + &quot;, &quot; + o);// Displays &quot;123, 5&quot;<br>
This line is identical to the earlier version except that I've removed the (Int32) cast that  <br>preceded the variable<b> </b>o. This code is more efficient because o is already a reference type to <br>an Object and its address can simply be passed to the Concat method. So, removing the <br>cast saved two operations: an unbox and a box. You can easily see this savings by rebuilding <br>the application and examining the generated IL code:<br>
.method public hidebysig static void  Main() cil managed  <br>{  <br>  .entrypoint  <br>  // Code size       35 (0x23)  <br>  .maxstack  3  <br>  .locals init (int32 V_0,  <br>           object V_1)  <br> <br>  // Load 5 into v.   <br>  IL_0000:  ldc.i4.5  <br>
<hr>
<A name=152></a><b>134 </b><br>
<b>Part II  Designing Types</b><br>
  IL_0001:  stloc.0  <br> <br>  // Box v and store the reference pointer in o.  <br>  IL_0002:  ldloc.0  <br>  IL_0003:  box        [mscorlib]System.Int32  <br>  IL_0008:  stloc.1  <br> <br>  // Load 123 into v.   <br>  IL_0009:  ldc.i4.s   123  <br>  IL_000b:  stloc.0  <br> <br>  // Box v and leave the pointer on the stack for Concat.   <br>  IL_000c:  ldloc.0  <br>  IL_000d:  box        [mscorlib]System.Int32  <br> <br>  // Load the string on the stack for Concat.   <br>  IL_0012:  ldstr      &quot;, &quot;  <br> <br>  // Load the address of the boxed Int32 on the stack for Concat.  <br>  IL_0017:  ldloc.1  <br> <br>  // Call Concat.   <br>  IL_0018:  call       string [mscorlib]System.String::Concat(object,  <br>                                                              object,  <br>                                                              object)  <br> <br>  // The string returned from Concat is passed to WriteLine.   <br>  IL_001d:  call       void [mscorlib]System.Console::WriteLine(string)  <br> <br>  // Return from Main terminating this application.   <br>  IL_0022:  ret  <br>} // end of method App::Main<br>
A quick comparison of the IL for these two versions of the Main method shows that the  <br>version without the (Int32) cast is 10 bytes smaller than the version with the cast. The  <br>extra unbox/box steps in the first version are obviously generating more code. An even  <br>bigger concern, however, is that the extra boxing step allocates an additional object from the <br>managed heap that must be garbage collected in the future. Certainly, both versions give <br>identical results, and the difference in speed isn't noticeable, but extra, unnecessary boxing <br>operations occurring in a loop cause the performance and memory usage of your application <br>to be seriously degraded.<br>
You can improve the previous code even more by calling WriteLine like this:<br>
Console.WriteLine(v.ToString() + &quot;, &quot; + o);    // Displays &quot;123, 5&quot;<br>
Now ToString is called on the unboxed value type instance v, and a String is returned. <br>String objects are already reference types and can simply be passed to the Concat method <br>without requiring any boxing.<br>
Let's look at yet another example that demonstrates boxing and unboxing:<br>
<hr>
<A name=153></a><b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>135</b><br>
public static void Main() {  <br>   Int32 v = 5;                // Create an unboxed value type variable.  <br>   Object o = v;               // o refers to the boxed version of v.  <br> <br>   v = 123;                    // Changes the unboxed value type to 123  <br>   Console.WriteLine(v);       // Displays &quot;123&quot;  <br> <br>   v = (Int32) o;              // Unboxes and copies o into v  <br>   Console.WriteLine(v);       // Displays &quot;5&quot;  <br>}<br>
How many boxing operations do you count in this code? The answer is one. The reason that <br>there is only one boxing operation is that the System.Console class defines a WriteLine <br>method that accepts an Int32 as a parameter:<br>
public static void WriteLine(Int32 value);<br>
In the two calls to WriteLine above, the variable v, an Int32 unboxed value type instance, is <br>passed by value. Now it may be that WriteLine will box this Int32 internally, but you have <br>no control over that. The important thing is that you've done the best you could and have <br>eliminated the boxing from your own code.<br>
If you take a close look at the FCL, you'll notice many overloaded methods that differ based <br>on their value type parameters. For example, the System.Console type offers several over-<br>loaded versions of the WriteLine method:<br>
public static void WriteLine(Boolean);  <br>public static void WriteLine(Char);  <br>public static void WriteLine(Char[]);  <br>public static void WriteLine(Int32);  <br>public static void WriteLine(UInt32);  <br>public static void WriteLine(Int64);  <br>public static void WriteLine(UInt64);  <br>public static void WriteLine(Single);  <br>public static void WriteLine(Double);  <br>public static void WriteLine(Decimal);  <br>public static void WriteLine(Object);  <br>public static void WriteLine(String);<br>
You'll also find a similar set of overloaded methods for System.Console's Write method, <br>System.IO.BinaryWriter's Write method, System.IO.TextWriter's Write and WriteLine <br>methods, System.Runtime.Serialization.SerializationInfo's AddValue method, <br>System.Text.StringBuilder's Append and Insert methods, and so on. Most of these <br>methods offer overloaded versions for the sole purpose of reducing the number of boxing <br>operations for the common value types.<br>
If you define your own value type, these FCL classes will not have overloads of these methods <br>that accept your value type. Furthermore, there are a bunch of value types already defined <br>in the FCL for which overloads of these methods do not exist. If you call a method that does <br>not have an overload for the specific value type that you are passing to it, you will always end <br>
<hr>
<A name=154></a><b>136 </b><br>
<b>Part II  Designing Types</b><br>
up calling the overload that takes an Object. Passing a value type instance as an Object will <br>cause boxing to occur, which will adversely affect performance. If you are defining your own <br>class, you can define the methods in the class to be generic (possibly constraining the type <br>parameters to be value types). Generics give you a way to define a method that can take any <br>kind of value type without having to box it. Generics are discussed in Chapter 12.<br>
One last point about boxing: if you know that the code that you're writing is going to cause <br>the compiler to box a single value type repeatedly, your code will be smaller and faster if you <br>manually box the value type. Here's an example:<br>
using System;  <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      Int32 v = 5;   // Create an unboxed value type variable.  <br> <br>#if INEFFICIENT  <br>      // When compiling the following line, v is boxed   <br>      // three times, wasting time and memory.  <br>      Console.WriteLine(&quot;{0}, {1}, {2}&quot;, v, v, v);  <br>#else  <br>      // The lines below have the same result, execute  <br>      // much faster, and use less memory.  <br>      Object o = v;  // Manually box v (just once).  <br> <br>      // No boxing occurs to compile the following line.  <br>      Console.WriteLine(&quot;{0}, {1}, {2}&quot;, o, o, o);  <br>#endif  <br>   }  <br>}<br>
If this code is compiled with the INEFFICIENT<b> </b>symbol defined, the compiler will generate <br>code to box <b>v</b> three times, causing three objects to be allocated from the heap! This is  <br>extremely wasteful since each object will have exactly the same contents: 5. If the code is <br>compiled without the INEFFICIENT<b> </b>symbol defined, v<b> </b>is boxed just once, so only one object <br>is allocated from the heap. Then, in the call to Console.WriteLine, the reference to the <br>single boxed object is passed three times. This second version executes <i>much </i>faster and  <br>allocates less memory from the heap.<br>
In these examples, it's fairly easy to recognize when an instance of a value type requires  <br>boxing. Basically, if you want a reference to an instance of a value type, the instance must be <br>boxed. Usually this happens because you have a value type instance and you want to pass it <br>to a method that requires a reference type. However, this situation isn't the only one in which <br>you'll need to box an instance of a value type.<br>
Recall that unboxed value types are lighter-weight types than reference types for two <br>reasons:<br>
  They are not allocated on the managed heap.<br>
<hr>
<A name=155></a><b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>137</b><br>
  They don't have the additional overhead members that every object on the heap has: a <br>
type object pointer and a sync block index.<br>
Because unboxed value types don't have a sync block index, you can't have multiple  <br>threads synchronize their access to the instance by using the methods of the  <br>System.Threading.Monitor type (or by using C#'s lock statement).<br>
Even though unboxed value types don't have a type object pointer, you can still call virtual <br>methods (such as Equals,<b> </b>GetHashCode, or ToString) inherited or overridden by the type. If <br>your value type overrides one of these virtual methods, then the CLR can invoke the method <br>nonvirtually because value types are implicitly sealed and cannot have any types derived <br>from them. In addition, the value type instance being used to invoke the virtual method is <br>not boxed. However, if your override of the virtual method calls into the base type's imple-<br>mentation of the method, then the value type instance does get boxed when calling the base <br>type's implementation so that a reference to a heap object get passed to the this pointer <br>into the base method.<br>
However, calling a nonvirtual inherited method (such as GetType or MemberwiseClone<b>)  <br></b>always requires the value type to be boxed because these methods are defined by  <br>System.Object, so the methods expect the this argument to be a pointer that refers to  <br>an object on the heap.<br>
In addition, casting an unboxed instance of a value type to one of the type's interfaces  <br>requires the instance to be boxed, because interface variables must always contain a refer-<br>ence to an object on the heap. (I'll talk about interfaces in Chapter 13, "Interfaces.") The  <br>following code demonstrates:<br>
using System;  <br> <br>internal struct Point : IComparable {  <br>   private readonly Int32 m_x, m_y;  <br> <br>   // Constructor to easily initialize the fields  <br>   public Point(Int32 x, Int32 y) {  <br>      m_x = x;  <br>      m_y = y;  <br>   }  <br> <br>   // Override ToString method inherited from System.ValueType  <br>   public override String ToString() {  <br>      // Return the point as a string  <br>      return String.Format(&quot;({0}, {1})&quot;, m_x, m_y);  <br>   }   <br> <br>   // Implementation of type-safe CompareTo method  <br>   public Int32 CompareTo(Point other) {  <br>      // Use the Pythagorean Theorem to calculate   <br>      // which point is farther from the origin (0, 0)  <br>      return Math.Sign(Math.Sqrt(m_x * m_x + m_y * m_y)   <br>
<hr>
<A name=156></a><b>138 </b><br>
<b>Part II  Designing Types</b><br>
         - Math.Sqrt(other.m_x * other.m_x + other.m_y * other.m_y));   <br>   }  <br> <br>   // Implementation of IComparable's CompareTo method  <br>   public Int32 CompareTo(Object o) {  <br>      if (GetType() != o.GetType()) {  <br>         throw new ArgumentException(&quot;o is not a Point&quot;);  <br>      }  <br>      // Call type-safe CompareTo method  <br>      return CompareTo((Point) o);  <br>   }  <br>}  <br> <br> <br>public static class Program {  <br>   public static void Main() {  <br>      // Create two Point instances on the stack.  <br>      Point p1 = new Point(10, 10);  <br>      Point p2 = new Point(20, 20);  <br> <br>      // p1 does NOT get boxed to call ToString (a virtual method).  <br>      Console.WriteLine(p1.ToString());// &quot;(10, 10)&quot;  <br> <br>      // p DOES get boxed to call GetType (a non-virtual method).  <br>      Console.WriteLine(p1.GetType());// &quot;Point&quot;  <br> <br>      // p1 does NOT get boxed to call CompareTo.  <br>      // p2 does NOT get boxed because CompareTo(Point) is called.  <br>      Console.WriteLine(p1.CompareTo(p2));// &quot;-1&quot;  <br> <br>      // p1 DOES get boxed, and the reference is placed in c.  <br>      IComparable c = p1;  <br>      Console.WriteLine(c.GetType());// &quot;Point&quot;  <br> <br>      // p1 does NOT get boxed to call CompareTo.  <br>      // Since CompareTo is not being passed a Point variable,   <br>      // CompareTo(Object) is called which requires a reference to  <br>      // a boxed Point.   <br>      // c does NOT get boxed because it already refers to a boxed Point.  <br>      Console.WriteLine(p1.CompareTo(c));// &quot;0&quot;  <br> <br>      // c does NOT get boxed because it already refers to a boxed Point.  <br>      // p2 does get boxed because CompareTo(Object) is called.  <br>      Console.WriteLine(c.CompareTo(p2));// &quot;-1&quot;  <br> <br>      // c is unboxed, and fields are copied into p2.  <br>      p2 = (Point) c;  <br> <br>      // Proves that the fields got copied into p2.  <br>      Console.WriteLine(p2.ToString());// &quot;(10, 10)&quot;  <br>   }  <br>}<br>
This code demonstrates several scenarios related to boxing and unboxing:<br>
<hr>
<A name=157></a><b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>139</b><br>
<b>  Calling </b>ToString  In the call to ToString,<b> </b>p1 doesn't have to be boxed. At first, you'd <br>
think that p1 would have to be boxed because ToString is a virtual method that is <br>inherited from the base type, System.ValueType. Normally, to call a virtual method, <br>the CLR needs to determine the object's type in order to locate the type's method <br>table. Since p1 is an unboxed value type, there's no type object pointer. However, the <br>just-in-time (JIT) compiler sees that Point overrides the ToString method, and it emits <br>code that calls ToString directly (nonvirtually) without having to do any boxing. The <br>compiler knows that polymorphism can't come into play here since Point is a value <br>type, and no type can derive from it to provide another implementation of this virtual <br>method. Note that if Point's ToString<b> </b>method internally calls base.ToString(), then <br>the value type instance would be boxed when calling System.ValueType's ToString <br>method.<br>
<b>  Calling </b>GetType  In the call to the nonvirtual GetType method, p1 does have to be <br>
boxed. The reason is that the Point type inherits GetType from System.Object. So to <br>call GetType, the CLR must use a pointer to a type object, which can be obtained only <br>by boxing p1.<br>
<b>  Calling </b>CompareTo<b> (first time)</b>  In the first call to CompareTo,<b> </b>p1 doesn't have to be <br>
boxed because Point implements the CompareTo method, and the compiler can just <br>call it directly. Note that a Point variable (p2) is being passed to CompareTo, and there-<br>fore the compiler calls the overload of CompareTo that accepts a Point parameter. This <br>means that p2 will be passed by value to CompareTo and no boxing is necessary.<br>
<b>  Casting to </b>IComparable  When casting p1 to a variable (c) that is of an interface type, <br>
p1 must be boxed because interfaces are reference types by definition. So p1 is boxed, <br>and the pointer to this boxed object is stored in the variable <b>c</b>. The following call to <br>GetType proves that c does refer to a boxed Point on the heap.<br>
<b>  Calling</b>CompareTo<b> (second time)  </b>In the second call to CompareTo,<b> </b>p1 doesn't have to <br>
be boxed because Point implements the CompareTo method, and the compiler can <br>just call it directly. Note that an IComparable variable (c) is being passed to CompareTo, <br>and therefore, the compiler calls the overload of CompareTo that accepts an Object <br>parameter. This means that the argument passed must be a pointer that refers to <br>an object on the heap. Fortunately, c does refer to a boxed Point, and therefore, <br>that memory address in c can be passed to CompareTo, and no additional boxing is <br>necessary.<br>
<b>  Calling </b>CompareTo<b> (third time)  </b>In the third call to CompareTo,<b> </b>c<b> </b>already refers to a <br>
boxed Point<b> </b>object on the heap. Since c<b> </b>is of the IComparable<b> </b>interface type, you <br>can call only the interface's CompareTo<b> </b>method that requires an Object<b> </b>parameter. <br>This means that the argument passed must be a pointer that refers to an object on the <br>heap. So p2<b> </b>is boxed, and the pointer to this boxed object is passed to CompareTo.<br>
<hr>
<A name=158></a><b>140 </b><br>
<b>Part II  Designing Types</b><br>
<b>  Casting to </b>Point  When casting c to a Point, the object on the heap referred to by <b>c</b> <br>
is unboxed, and its fields are copied from the heap to p2, an instance of the Point type <br>residing on the stack.<br>
I realize that all of this information about reference types, value types, and boxing might <br>be overwhelming at first. However, a solid understanding of these concepts is critical to any <br>.NET Framework developer's long-term success. Trust me: having a solid grasp of these  <br>concepts will allow you to build efficient applications faster and easier.<br>
<b>Changing Fields in a Boxed Value Type by Using Interfaces </b><br>
<b>(and Why You Shouldn't Do This)</b><br>
Let's have some fun and see how well you understand value types, boxing, and unboxing. <br>Examine the following code, and see whether you can figure out what it displays on the <br>console:<br>
using System;  <br> <br>// Point is a value type.  <br>internal struct Point {  <br>   private Int32 m_x, m_y;  <br> <br>   public Point(Int32 x, Int32 y) {  <br>      m_x = x;  <br>      m_y = y;  <br>   }  <br> <br>   public void Change(Int32 x, Int32 y) {  <br>      m_x = x; m_y = y;  <br>   }  <br> <br>   public override String ToString() {  <br>      return String.Format(&quot;({0}, {1})&quot;, m_x, m_y);  <br>   }  <br>}  <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      Point p = new Point(1, 1);  <br> <br>      Console.WriteLine(p);  <br> <br>      p.Change(2, 2);  <br>      Console.WriteLine(p);  <br> <br>      Object o = p;  <br>      Console.WriteLine(o);  <br> <br>      ((Point) o).Change(3, 3);  <br>      Console.WriteLine(o);  <br>   }  <br>}<br>
<hr>
<A name=159></a><b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>141</b><br>
Very simply, Main<b> </b>creates an instance (p) of a Point<b> </b>value type on the stack and sets its m_x <br>and m_y fields to 1. Then, p<b> </b>is boxed before the first call to WriteLine,<b> </b>which calls ToString<b> <br></b>on the boxed Point, and (1,<b> </b>1)<b> </b>is displayed as expected. Then, p is used to call the Change<b> <br></b>method, which changes the values of p's m_x and m_y<b> </b>fields on the stack to 2. The second call <br>to WriteLine<b> </b>requires p to be boxed again and displays (2,<b> </b>2), as expected.<br>
Now, p<b> </b>is boxed a third time, and o<b> </b>refers to the boxed Point<b> </b>object. The third call to <br>WriteLine<b> </b>again shows (2,<b> </b>2), which is also expected. Finally, I want to call the Change<b> <br></b>method to update the fields in the boxed Point<b> </b>object. However, Object<b> </b>(the type of the <br>variable o) doesn't know anything about the Change<b> </b>method, so I must first cast o<b> </b>to a Point. <br>Casting o<b> </b>to a Point<b> </b>unboxes o<b> </b>and copies the fields in the boxed Point<b> </b>to a temporary <br>Point<b> </b>on the thread's stack! The m_x<b> </b>and m_y<b> </b>fields of this temporary point are changed to <br><b>3 </b>and <b>3</b>, but the boxed <b>Point</b> isn't affected by this call to Change. When WriteLine<b> </b>is called <br>the fourth time, (2,<b> </b>2) is displayed again. Many developers do <i>not</i> expect this.<br>
Some languages, such as C++/CLI, let you change the fields in a boxed value type, but C# <br>does not. However, you can fool C# into allowing this by using an interface. The following <br>code is a modified version of the previous code:<br>
using System;  <br> <br>// Interface defining a Change method  <br>internal interface IChangeBoxedPoint {  <br>   void Change(Int32 x, Int32 y);  <br>}  <br> <br> <br>// Point is a value type.  <br>internal struct Point : IChangeBoxedPoint {  <br>   private Int32 m_x, m_y;  <br> <br>   public Point(Int32 x, Int32 y) {  <br>      m_x = x;  <br>      m_y = y;  <br>   }  <br> <br>   public void Change(Int32 x, Int32 y) {  <br>      m_x = x; m_y = y;  <br>   }  <br> <br>   public override String ToString() {  <br>      return String.Format(&quot;({0}, {1})&quot;, m_x, m_y);  <br>   }  <br>}  <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      Point p = new Point(1, 1);  <br> <br>      Console.WriteLine(p);  <br> <br>
<hr>
<A name=160></a><IMG src="CLRviaCsharp-160_1.jpg"><br>
<b>142 </b><br>
<b>Part II  Designing Types</b><br>
      p.Change(2, 2);  <br>      Console.WriteLine(p);  <br> <br>      Object o = p;  <br>      Console.WriteLine(o);  <br> <br>      ((Point) o).Change(3, 3);  <br>      Console.WriteLine(o);  <br> <br>      // Boxes p, changes the boxed object and discards it  <br>      ((IChangeBoxedPoint) p).Change(4, 4);  <br>      Console.WriteLine(p);  <br> <br>      // Changes the boxed object and shows it  <br>      ((IChangeBoxedPoint) o).Change(5, 5);  <br>      Console.WriteLine(o);  <br>   }  <br>}<br>
This code is almost identical to the previous version. The main difference is that the Change<b> <br></b>method is defined by the IChangeBoxedPoint<b> </b>interface, and the Point<b> </b>type now implements <br>this interface. Inside Main, the first four calls to WriteLine<b> </b>are the same and produce the <br>same results I had before (as expected). However, I've added two more examples at the end <br>of Main.<br>
In the first example, the unboxed Point,<b> </b>p, is cast to an IChangeBoxedPoint. This cast causes <br>the value in p<b> </b>to be boxed. Change<b> </b>is called on the boxed value, which does change its m_x <br>and m_y<b> </b>fields to 4<b> </b>and 4,<b> </b>but after Change<b> </b>returns, the boxed object is immediately ready to <br>be garbage collected. So the fifth call to WriteLine<b> </b>displays (2,<b> </b>2).<b> </b>Many developers won't <br>expect this result.<br>
In the last example, the boxed Point<b> </b>referred to by o<b> </b>is cast to an IChangeBoxedPoint. No <br>boxing is necessary here because o<b> </b>is already a boxed Point. Then Change<b> </b>is called, which <br><i>does</i> change the boxed Point's m_x<b> </b>and m_y fields. The interface method Change<b> </b>has allowed <br>me to change the fields in a boxed Point<b> </b>object! Now, when WriteLine<b> </b>is called, it displays<b> <br></b>(5,<b> </b>5) as expected. The purpose of this whole example is to demonstrate how an interface <br>method is able to modify the fields of a boxed value type. In C#, this isn't possible without <br>using an interface method.<br>
<b>Important  </b>Earlier in this chapter, I mentioned that value types should be immutable: that is, <br>they should not define any members that modify any of the type's instance fields. In fact, I  <br>recommended that value types have their fields marked as readonly<b> </b>so that the compiler will <br>issue errors should you accidentally write a method that attempts to modify a field. The previous <br>example should make it very clear to you why value types should be immutable. The unexpected <br>behaviors shown in the previous example all occur when attempting to call a method that <br>modifies the value type's instance fields. If after constructing a value type, you do not call any <br>methods that modify its state, you will not get confused when all of the boxing and unboxing/<br>field copying occurs. If the value type is immutable, you will end up just copying the same state <br>around, and you will not be surprised by any of the behaviors you see.<br>
<hr>
<A name=161></a><b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>143</b><br>
A number of developers reviewed the chapters of this book. After reading through some of my <br>code samples (such as the preceding one), these reviewers would tell me that they've sworn <br>off value types. I must say that these little value type nuances have cost me days of debugging <br>time, which is why I spend time pointing them out in this book. I hope you'll remember some of <br>these nuances and that you'll be prepared for them if and when they strike you and your code. <br>Certainly, you shouldn't be scared of value types. They are useful, and they have their place. After <br>all, a program needs a little Int32<b> </b>love now and then. Just keep in mind that value types and  <br>reference types have very different behaviors depending on how they're used. In fact, you should <br>take the preceding code and declare the Point<b> </b>as a class<b> </b>instead of a struct<b> </b>to appreciate the <br>different behavior that results. Finally, you'll be very happy to know that the core value types that <br>ship in the FCL--Byte,<b> </b>Int32,<b> </b>UInt32,<b> </b>Int64,<b> </b>UInt64,<b> </b>Single,<b> </b>Double,<b> </b>Decimal,<b> </b>BigInteger, <br>Complex, all enums, and so on--are all immutable, so you should experience no surprising  <br>behavior when using any of these types.<br>
<b>Object Equality and Identity</b><br>
Frequently, developers write code to compare objects with one another. This is particularly <br>true when placing objects in a collection and you're writing code to sort, search, or compare <br>items in a collection. In this section, I'll discuss object equality and identity, and I'l  also discuss <br>how to define a type that properly implements object equality.<br>
The System.Object type offers a virtual method named Equals, whose purpose is to return <br>true if two objects contain the same value. The implementation of Object's Equals method <br>looks like this:<br>
public class Object {  <br>   public virtual Boolean Equals(Object obj) {  <br> <br>      // If both references point to the same object,   <br>      // they must have the same value.  <br>      if (this == obj) return true;  <br> <br>      // Assume that the objects do not have the same value.  <br>      return false;  <br>   }  <br>}<br>
At first, this seems like a reasonable default implementation of Equals: it returns true if <br>the this and obj arguments refer to the same exact object. This seems reasonable because <br>Equals knows that an object must have the same value as itself. However, if the arguments <br>refer to different objects, Equals can't be certain if the objects contain the same values, and <br>therefore, false<b> </b>is returned. In other words, the default implementation of Object's Equals<b> <br></b>method really implements identity, not value equality.<br>
Unfortunately, as it turns out, Object's Equals<b> </b>method is not a reasonable default, and it <br>should have never been implemented this way. You immediately see the problem when you <br>
<hr>
<A name=162></a><b>144 </b><br>
<b>Part II  Designing Types</b><br>
start thinking about class inheritance hierarchies and how to properly override Equals. Here <br>is how to properly implement an Equals<b> </b>method internally:<br>
<b> </b><br>
<b>1.  </b>If the obj<b> </b>argument is null, return false<b> </b>because the current object identified by this<b> </b><br>
is obviously not null<b> </b>when the nonstatic Equals<b> </b>method is called.<br>
<b> </b><br>
<b>2.  </b>If the this<b> </b>and obj<b> </b>arguments refer to the same object, return true.<b> </b>This step can  <br>
improve performance when comparing objects with many fields.<br>
<b> </b><br>
<b>3.  </b>If the this<b> </b>and obj<b> </b>arguments refer to objects of different types, return false. <br>
Obviously, checking if a String<b> </b>object is equal to a FileStream<b> </b>object should result in <br>a false<b> </b>result.<br>
<b> </b><br>
<b>4.  </b>For each instance field defined by the type, compare the value in the this<b> </b>object with <br>
the value in the obj<b> </b>object. If any fields are not equal, return false.<br>
<b> </b><br>
<b>5.  </b>Call the base class's Equals<b> </b>method so it can compare any fields defined by it. If the <br>
base class's Equals<b> </b>method returns false, return false;<b> </b>otherwise, return true.<br>
So Microsoft should have implemented Object's Equals<b> </b>like this:<br>
public class Object {  <br>   public virtual Boolean Equals(Object obj) {  <br>      // The given object to compare to can't be null  <br>      if (obj == null) return false;<br>
     // If objects are different types, they can't be equal.  <br>      if (this.GetType() != obj.GetType()) return false;  <br> <br>      // If objects are same type, return true if all of their fields match  <br>      // Since System.Object defines no fields, the fields match  <br>      return true;  <br>   }  <br>}<br>
But, since Microsoft didn't implement Equals this way, the rules for how to implement <br>Equals are significantly more complicated than you would think. When a type overrides <br>Equals, the override should call its base class's implementation of Equals unless it would <br>be calling Object's implementation. This also means that since a type can override Object's <br>Equals method, this Equals method can no longer be called to test for identity. To fix this, <br>Object offers a static ReferenceEquals method, which is implemented like this:<br>
public class Object {  <br>   public static Boolean ReferenceEquals(Object objA, Object objB) {  <br>      return (objA == objB);  <br>   }  <br>}<br>
You should always call ReferenceEquals if you want to check for identity (if two references <br>point to the same object). You shouldn't use the C# == operator (unless you cast both  <br>
<hr>
<A name=163></a><b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>145</b><br>
operands to Object first) because one of the operands' types could overload the  <br>== operator, giving it semantics other than identity.<br>
As you can see, the .NET Framework has a very confusing story when it comes to object <br>equality and identity. By the way, System.ValueType (the base class of all value types) does <br>override Object's Equals method and is correctly implemented to perform a value equality <br>check (not an identity check). Internally, ValueType's Equals is implemented this way:<br>
<b> </b><br>
<b>1.  </b>If the obj argument is null, return false.<br>
<b> </b><br>
<b>2.  </b>If the this and obj arguments refer to objects of different types, return false.<br>
<b> </b><br>
<b>3.  </b>For each instance field defined by the type, compare the value in the this object with <br>
the value in the obj object by calling the field's Equals method. If any fields are not <br>equal, return false.<br>
<b> </b><br>
<b>4.  </b>Return true.<b> </b>Object's Equals method is not called by ValueType's Equals method.<br>
Internally, ValueType's Equals method uses reflection (covered in Chapter 23, "Assembly <br>Loading and Reflection") to accomplish step #3 above. Since the CLR's reflection mechanism <br>is slow, when defining your own value type, you should override Equals and provide your <br>own implementation to improve the performance of value equality comparisons that use  <br>instances of your type. Of course, in your own implementation, do not call base.Equals.<br>
When defining your own type, if you decide to override Equals, you must ensure that it  <br>adheres to the four properties of equality:<br>
  Equals must be reflexive; that is, x.Equals(x) must return true.<br>
  Equals must be symmetric; that is, x.Equals(y) must return the same value as <br>
y.Equals(x).<br>
  Equals must be transitive; that is, if x.Equals(y) returns true and y.Equals(z)  <br>
returns true, then x.Equals(z) must also return true.<br>
  Equals<b> </b>must be consistent. Provided that there are no changes in the two values being <br>
compared, Equals<b> </b>should consistently return true<b> </b>or false.<br>
If your implementation of Equals<b> </b>fails to adhere to all of these rules, your application will <br>behave in strange and unpredictable ways.<br>
When overriding the Equals<b> </b>method, there are a few more things that you'll probably want <br>to do:<br>
<b>  Have the type implement the </b>System.IEquatable&lt;T&gt;<b> interface's </b>Equals<b> method  </b> <br>
This generic interface allows you to define a type-safe Equals<b> </b>method. Usually, you'll <br>implement the Equals<b> </b>method that takes an Object<b> </b>parameter to internally call the <br>type-safe Equals<b> </b>method.<br>
<hr>
<A name=164></a><b>146 </b><br>
<b>Part II  Designing Types</b><br>
<b>  Overload the </b>==<b> </b>and<b> </b>!=<b>operator methods  </b>Usually, you'll implement these operator <br>
methods to internally call the type-safe Equals<b> </b>method.<br>
Furthermore, if you think that instances of your type will be compared for the purposes of <br>sorting, you'll want your type to also implement System.IComparable's<b> </b>CompareTo<b> </b>method <br>and System.IComparable&lt;T&gt;'s type-safe CompareTo<b> </b>method. If you implement these meth-<br>ods, you'll also want to overload the various comparison operator methods (&lt;,<b> </b>&lt;=,<b> </b>&gt;,<b> </b>&gt;=) and <br>implement these methods internally to call the type-safe CompareTo<b> </b>method.<br>
<b>Object Hash Codes</b><br>
The designers of the FCL decided that it would be incredibly useful if any instance of any <br>object could be placed into a hash table collection. To this end, System.Object provides a <br>virtual GetHashCode method so that an Int32 hash code can be obtained for any and all <br>objects.<br>
If you define a type and override the Equals method, you should also override the <br>GetHashCode method. In fact, Microsoft's C# compiler emits a warning if you define a type <br>that overrides Equals without also overriding GetHashCode. For example, compiling the  <br>following type yields this warning: "warning<b> </b>CS0659:<b> </b>'Program'<b> </b>overrides<b>  <br></b>Object.Equals(object<b> </b>o)<b> </b>but<b> </b>does<b> </b>not<b> </b>override<b> </b>Object.GetHashCode()".<br>
public sealed class Program {  <br>   public override Boolean Equals(Object obj) { ... }  <br>}<br>
The reason why a type that defines Equals must also define GetHashCode is that the  <br>implementation of the System.Collections.Hashtable type, the System.Collections.<br>Generic.Dictionary<b> </b>type, and some other collections require that any two objects that are <br>equal must have the same hash code value. So if you override Equals, you should override <br>GetHashCode to ensure that the algorithm you use for calculating equality corresponds to <br>the algorithm you use for calculating the object's hash code.<br>
Basically, when you add a key/value pair to a collection, a hash code for the key object is  <br>obtained first. This hash code indicates which "bucket" the key/value pair should be stored in. <br>When the collection needs to look up a key, it gets the hash code for the specified key  <br>object. This code identifies the "bucket" that is now searched sequentially, looking for a <br>stored key object that is equal to the specified key object. Using this algorithm of storing and <br>looking up keys means that if you change a key object that is in a collection, the collection <br>will no longer be able to find the object. If you intend to change a key object in a hash table, <br>you should remove the original object/value pair, modify the key object, and then add the <br>new key object/value pair back into the hash table.<br>
<hr>
<A name=165></a><IMG src="CLRviaCsharp-165_1.jpg"><br>
<b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>147</b><br>
Defining a GetHashCode method can be easy and straightforward. But depending on your <br>data types and the distribution of data, it can be tricky to come up with a hashing algorithm <br>that returns a well-distributed range of values. Here's a simple example that will probably <br>work just fine for Point objects:<br>
internal sealed class Point {  <br>   private readonly Int32 m_x, m_y;  <br>   public override Int32 GetHashCode() {  <br>      return m_x ^ m_y;  // m_x XOR'd with m_y  <br>   }  <br>   ...  <br>}<br>
When selecting an algorithm for calculating hash codes for instances of your type, try to  <br>follow these guidelines:<br>
  Use an algorithm that gives a good random distribution for the best performance of <br>
the hash table.<br>
  Your algorithm can also call the base type's GetHashCode method, including its return <br>
value. However, you don't generally want to call Object's or ValueType's GetHashCode <br>method, because the implementation in either method doesn't lend itself to high- <br>performance hashing algorithms.<br>
  Your algorithm should use at least one instance field.<br>
  Ideally, the fields you use in your algorithm should be immutable; that is, the fields <br>
should be initialized when the object is constructed, and they should never again <br>change during the object's lifetime.<br>
  Your algorithm should execute as quickly as possible.<br>
  Objects with the same value should return the same code. For example, two String<b> </b><br>
objects with the same text should return the same hash code value.<br>
System.Object's implementation of the GetHashCode<b> </b>method doesn't know anything about <br>its derived type and any fields that are in the type. For this reason, Object's GetHashCode<b> <br></b>method returns a number that is guaranteed to uniquely identify the object within the <br>AppDomain; this number is guaranteed not to change for the lifetime of the object. After the <br>object is garbage collected, however, its unique number can be reused as the hash code for a <br>new object.<br>
<b>Note  </b>If a type overrides Object's GetHashCode<b> </b>method, you can no longer call it to get a <br>unique ID for the object. If you want to get a unique ID (within an AppDomain) for an object, <br>the FCL provides a method that you can call. In the System.Runtime.CompilerServices<b> <br></b>namespace, see the RuntimeHelpers<b> </b>class's public, static GetHashCode<b> </b>method that takes a  <br>reference to an Object<b> </b>as an argument. RuntimeHelpers' GetHashCode<b> </b>method returns a <br>unique ID for an object even if the object's type overrides Object's GetHashCode<b> </b>method. This <br>method got its name because of its heritage, but it would have been better if Microsoft had <br>named it something like GetUniqueObjectID.<br>
<hr>
<A name=166></a><IMG src="CLRviaCsharp-166_1.jpg"><br>
<b>148 </b><br>
<b>Part II  Designing Types</b><br>
System.ValueType's implementation of GetHashCode<b> </b>uses reflection (which is slow) and <br>XORs some of the type's instance fields together. This is a naïve implementation that might <br>be good for some value types, but I still recommend that you implement GetHashCode<b> </b>your-<br>self because you'll know exactly what it does, and your implementation will be faster than <br>ValueType's implementation.<br>
<b>Important  </b>If you're implementing your own hash table collection for some reason, or you're <br>implementing any piece of code in which you'll be calling GetHashCode, you should <i>never, ever <br>persist hash code values</i>. The reason is that hash code values are subject to change. For example, <br>a future version of a type might use a different algorithm for calculating the object's hash code.<br>
There is a company that was not heeding this important warning. On their Web site, users <br>could create new accounts by selecting a user name and a password. The Web site then took <br>the password String, called GetHashCode, and persisted the hash code value in a database. <br>When users logged back on to the Web site, they entered their password. The Web site <br>would call GetHashCode again and compare the hash code value with the stored value in the <br>database. If the hash codes matched, the user would be granted access. Unfortunately, when <br>the company upgraded to a new version of the CLR, String's GetHashCode method had <br>changed, and it now returned a different hash code value. The end result was that no user <br>was able to log on to the Web site anymore!<br>
<b>The </b>dynamic<b> Primitive Type</b><br>
C# is a type-safe programming language. This means that all expressions resolve into an in-<br>stance of a type and the compiler will generate only code that is attempting to perform an <br>operation that is valid for this type. The benefit of a type-safe programming language over <br>a non­type-safe programming language is that many programmer errors are detected at <br>compile time, helping to ensure that the code is correct before you attempt to execute it. In <br>addition, compile-time languages can typically produce smaller and faster code since they <br>make more assumptions at compile time and bake those assumptions into the resulting IL <br>and metadata.<br>
However, there are also many occasions when a program has to act on information that it <br>doesn't know about until it is running. While you can use type-safe programming languages <br>(like C#) to interact with this information, the syntax tends to be clumsy, especially since you <br>tend to work a lot with strings, and performance is hampered as well. If you are writing a <br>pure C# application, then the only occasion you have for working with runtime-determined <br>information is when you are using reflection (discussed in Chapter 23). However, many devel-<br>opers also use C# to communicate with components that are not implemented in C#. Some <br>of these components could be .NET-dynamic languages such as Python or Ruby, or COM <br>objects that support the IDispatch interface (possibly implemented in native C or C++), or <br>
<hr>
<A name=167></a><b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>149</b><br>
HTML Document Object Model (DOM) objects (implemented using various languages and <br>technologies). Communicating with HTML DOM objects is particularly useful when building a <br>Microsoft Silverlight application.<br>
To make it easier for developers using reflection or communicating with other components, <br>the C# compiler offers you a way to mark an expression's type as dynamic.<b> </b>You can also put <br>the result of an expression into a variable and you can mark a variable's type as dynamic.<b> <br></b>This dynamic expression/variable can then be used to invoke a member such as a field, a <br>property/indexer, a method, delegate, and unary/binary/conversion operators. When your <br>code invokes a member using a dynamic expression/variable, the compiler generates special <br>IL code that describes the desired operation. This special code is referred to as the <i>payload</i>. <br>At runtime, the payload code determines the exact operation to execute based on the actual <br>type of the object now referenced by the dynamic expression/variable.<br>
Here is some code to demonstrate what I'm talking about:<br>
Private static class DynamicDemo { <br>   public static void Main() { <br>      for (Int32 demo = 0; demo &lt; 2; demo++) { <br>         dynamic arg = (demo == 0) ? (dynamic) 5 : (dynamic) &quot;A&quot;; <br>         dynamic result = Plus(arg); <br>         M(result); <br>      } <br>   } <br> <br>   private static dynamic Plus(dynamic arg) { return arg + arg; } <br> <br>   private static void M(Int32 n) { Console.WriteLine(&quot;M(Int32): &quot; + n); } <br>   private static void M(String s) { Console.WriteLine(&quot;M(String): &quot; + s); } <br>}<br>
When I execute Main, I get the following output:<br>
M(Int32): 10 <br>M(String): AA<br>
To understand what's happening, let's start by looking at the Plus method. This method has <br>declared its parameter's type as dynamic, and inside the method, the argument is used as <br>the two operands to the binary + operator. Since arg is dynamic, the C# compiler emits  <br>payload code that will examine the actual type of arg at runtime and determine what the  <br>+ operator should actually do.<br>
The first time Plus is called, 5 (an Int32), is passed, so Plus<b> </b>will return the value 10 (also an <br>Int32) back to its caller. This puts this result in the result variable (declared as a dynamic <br>type). Then, the M method is called, passing it result.<b> </b>For the call to M, the compiler will emit <br>payload code that will, at runtime, examine the actual type of the value being passed to M <br>and determine which overload of the M method to call. When result contains an Int32, the <br>overload of M that takes an Int32 parameter is called.<br>
<hr>
<A name=168></a><b>150 </b><br>
<b>Part II  Designing Types</b><br>
The second time Plus is called, "A" (a String) is passed, so Plus will return "AA" (the result of <br>concatenating "A" with itself) back to its caller, which puts this result in the result variable. <br>Then, the M method is called again, passing it result.<b> </b>This time, the payload code determines <br>that the actual type being passed to M<b> </b>is a String and calls the overload of M that takes a <br>String parameter.<br>
When the type of a field, method parameter, method return type, or local variable, is speci-<br>fied as dynamic, the compiler converts this type to the System.Object type and applies an <br>instance of System.Runtime.CompilerServices.DynamicAttribute to the field, param-<br>eter, or return type in metadata. If a local variable is specified as dynamic, then the variable's <br>type will also be of type Object, but the DynamicAttribute is not applied to the local vari-<br>able since its usage is self-contained within the method. Since dynamic is really the same as <br>Object, you cannot write methods whose signature differs only by dynamic and Object.<br>
It is also possible to use dynamic when specifying generic type arguments to a generic class <br>(reference type), a structure (value type), an interface, a delegate, or a method. When you do <br>this, the compiler converts dynamic to Object and applies DynamicAttribute to the various <br>pieces of metadata where it makes sense. Note that the generic code that you are using has <br>already been compiled and will consider the type to be Object; no dynamic dispatch will be <br>performed because the compiler did not produce any payload code in the generic code.<br>
Any expression can implicitly be cast to dynamic since all expressions result in a type that is <br>derived from Object.2 Normally, the compiler does not allow you to write code that implicitly <br>casts an expression from Object to another type; you must use explicit cast syntax. However, <br>the compiler does allow you to cast an expression from dynamic to another type using  <br>implicit cast syntax:<br>
Object o1 = 123;        // OK: Implicit cast from Int32 to Object (boxing) <br>Int32 n1 = o;           // Error: No implicit cast from Object to Int32 <br>Int32 n2 = (Int32) o;   // OK: Explicit cast from Object to Int32 (unboxing) <br> <br>dynamic d1 = 123;       // OK: Implicit cast from Int32 to dynamic (boxing) <br>Int32 n3 = d;           // OK: Implicit cast from dynamic to Int32 (unboxing)<br>
While the compiler allows you to omit the explicit cast when casting from dynamic to <br>some other type, the CLR will validate the cast at runtime to ensure that type safety is <br>maintained. If the object's type is not compatible with the cast, the CLR will throw an <br>InvalidCastException exception.<br>
Note that the result of evaluating a dynamic expression is a dynamic expression. Examine this <br>code:<br>
dynamic d = 123; <br>var result = M(d);  // Note: 'var result' is the same as 'dynamic result'<br>
2   And, as always, value types will be boxed.<br>
<hr>
<A name=169></a><IMG src="CLRviaCsharp-169_1.jpg"><br>
<IMG src="CLRviaCsharp-169_2.jpg"><br>
<b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>151</b><br>
Here, the compiler allows the code to compile because it doesn't know at compile time which <br>M method it will call. Therefore, it also does not know what type of result M will return. And so, <br>the compiler assumes that the result variable is of type dynamic itself. You can verify this by <br>placing your mouse over var in the Visual Studio editor; the IntelliSense window will indicate <br>'dynamic:<b> </b>Represents<b> </b>an<b> </b>object<b> </b>whose<b> </b>operations<b> </b>will<b> </b>be<b> </b>resolved<b> </b>at<b> </b>runtime.' If <br>the M method invoked at runtime has a return type of void, no exception is thrown; instead,  <br>result will be assigned a value of null.<br>
<b>Important  </b>Do not confuse dynamic<b> </b>and var. Declaring a local variable using var is just a  <br>syntactical shortcut that has the compiler infer the specific data type from an expression. The  <br>var keyword can be used only for declaring local variables inside a method while the dynamic<b> <br></b>keyword can be used for local variables, fields, and arguments. You cannot cast an expression <br>to var<b> </b>but you can cast an expression to dynamic. You must explicitly initialize a variable de-<br>clared using var while you do not have to initialize a variable declared with dynamic. For more <br>information about C#'s var, see the "Implicitly Typed Local Variables" section in Chapter 9, <br>"Parameters."<br>
However, when converting from dynamic to another static type, the result's type is, of <br>course, the static type. Similarly, when constructing a type by passing one or more dynamic <br>arguments to its constructor, the result is the type of object you are constructing:<br>
dynamic d = 123; <br>var x = (Int32) d;         // Conversion: 'var x' is the same as 'Int32 x' <br>var dt = new DateTime(d);  // Construction: 'var dt' is the same as 'DateTime dt'<br>
If a dynamic expression is specified as the collection in a foreach statement or as a resource <br>in a using statement, the compiler will generate code that attempts to cast the expression <br>to the non-generic System.IEnumerable interface or to the System.IDisposable interface, <br>respectively. If the cast succeeds, the expression is used and the code runs just fine. If the cast <br>fails, a Microsoft.CSharp.RuntimeBinder.RuntimeBinderException<b> </b>exception is thrown.<br>
<b>Important  </b>A dynamic expression is really the same type as System.Object. The compiler  <br>assumes that whatever operation you attempt on the expression is legal, so the compiler will not <br>generate any warnings or errors. However, exceptions will be thrown at runtime if you attempt  <br>to execute an invalid operation. In addition, Visual Studio cannot offer any IntelliSense support to <br>help you write code against a dynamic expression. You cannot define an extension method  <br>(discussed in Chapter 8, "Methods") that extends dynamic,<b> </b>although you can define one that  <br>extends Object. And, you cannot pass a lambda expression or anonymous method (both  <br>discussed in Chapter 17, "Delegates") as an argument to a dynamic method call since the  <br>compiler cannot infer the types being used.<br>
Here is an example of some C# code that uses COM IDispatch<b> </b>to create a Microsoft Office <br>Excel workbook and places a string in cell A1:<br>
<hr>
<A name=170></a><b>152 </b><br>
<b>Part II  Designing Types</b><br>
using Microsoft.Office.Interop.Excel; <br>... <br>public static void Main() { <br>   Application excel = new Application(); <br>   excel.Visible = true; <br>   excel.Workbooks.Add(Type.Missing); <br>   ((Range)excel.Cells[1, 1]).Value = &quot;Text in cell A1&quot;; // Put this string in cell A1 <br>}<br>
Without the dynamic<b> </b>type, the value returned from excel.Cells[1,<b> </b>1] is of type Object, <br>which must be cast to the Range type before its Value<b> </b>property can be accessed. However, <br>when producing a runtime callable wrapper assembly for a COM object, any use of VARIANT <br>in the COM method is really converted to dynamic; this is called <i>dynamification</i>. Therefore, <br>since excel.Cells[1,<b> </b>1] is of type dynamic, you do not have to explicitly cast it to the <br>Range type before its Value<b> </b>property can be accessed. Dynamification can greatly simplify <br>code that interoperates with COM objects. Here is the simpler code:<br>
using Microsoft.Office.Interop.Excel; <br>... <br>public static void Main() { <br>   Application excel = new Application(); <br>   excel.Visible = true; <br>   excel.Workbooks.Add(Type.Missing); <br>   excel.Cells[1, 1].Value = &quot;Text in cell A1&quot;; // Put this string in cell A1 <br>}<br>
The code below shows how to use reflection to call a method ("Contains") on a String target <br>("Jeffrey Richter") passing it a String argument ("ff") and storing the Int32 result in a local <br>variable (result):<br>
Object target = &quot;Jeffrey Richter&quot;; <br>Object arg = &quot;ff&quot;; <br> <br>// Find a method on the target that matches the desired argument types <br>Type[] argTypes = newType[] { arg.GetType() }; <br>MethodInfo method = target.GetType().GetMethod(&quot;Contains&quot;, argTypes); <br> <br>// Invoke the method on the target passing the desired arguments <br>Object[] arguments = newObject[] { arg }; <br>Boolean result = Convert.ToBoolean(method.Invoke(target, arguments));<br>
Using C#'s dynamic type, this code can be rewritten with greatly improved syntax:<br>
dynamic target = &quot;Jeffrey Richter&quot;; <br>dynamic arg = &quot;ff&quot;; <br>Boolean result = target.Contains(arg);<br>
Earlier, I mentioned that the C# compiler emits payload code that, at runtime, figures out <br>what operation to perform based on the actual type of an object. This payload code uses a <br>class known as a <i>runtime binder</i>. Different programming languages define their own runtime <br>binders that encapsulate the rules of that language. The code for the C# runtime binder is <br>
<hr>
<A name=171></a><b> </b><br>
<b>Chapter 5  Primitive, Reference, and Value Types </b><br>
<b>153</b><br>
in the Microsoft.CSharp.dll assembly, and you must reference this assembly when you build <br>projects that use the dynamic<b> </b>keyword. This assembly is referenced in the compiler's default <br>response file, CSC.rsp. It is the code in this assembly that knows to produce code (at runtime) <br>that performs addition when the + operator is applied to two Int32<b> </b>objects and concatena-<br>tion when applied to two String<b> </b>objects.<br>
At runtime, the Microsoft.CSharp.dl  assembly wil  have to load into the AppDomain, which <br>hurts your application's performance and increases memory consumption. Microsoft.CSharp.dll <br>also loads System.dll and System.Core.dll. If you are using dynamic to help you interoperate <br>with COM components, then System.Dynamic.dll will also load. And when the payload code <br>executes, it generates dynamic code at runtime; this code will be in an in-memory assembly <br>called "Anonymously Hosted DynamicMethods Assembly." The purpose of this code is to  <br>improve the performance of dynamic dispatch in scenarios where a particular call site is  <br>making many invocations using dynamic arguments that have the same runtime type.<br>
Due to all the overhead associated with C#'s built-in dynamic evaluation feature, you should <br>consciously decide that you are getting sufficient syntax simplification from the dynamic<b> <br></b>feature to make it worth the extra performance hit of loading all these assemblies and the <br>extra memory that they consume. If you have only a couple places in your program where <br>you need dynamic behavior, it might be more efficient to just do it the old-fashioned way, by <br>calling reflection methods (for managed objects) or with manual casting (for COM objects).<br>
At runtime, the C# runtime binder resolves a dynamic operation according to the runtime  <br>type of the object. The binder first checks to see if the type implements the <br>IDynamicMetaObjectProvider interface. If the object does implement this interface, then <br>the interface's GetMetaObject method is called, which returns a DynamicMetaObject-<br>derived type. This type can process all of the member, method, and operator bindings for <br>the object. Both the IDynamicMetaObjectProvider interface and the DynamicMetaObject <br>base class are defined in the System.Dynamic namespace, and both are in the System.Core.<br>dll assembly.<br>
Dynamic languages, such as Python and Ruby, endow their types with DynamicMetaObject-<br>derived types so that they can be accessed in a way appropriate for them when manipulated <br>from other programming languages (like C#). Similarly, when accessing a COM component, <br>the C# runtime binder will use a DynamicMetaObject-derived type that knows how to  <br>communicate with a COM component. The COM DynamicMetaObject-derived type is  <br>defined in the System.Dynamic.dll assembly.<br>
If the type of the object being used in the dynamic expression does not implement the <br>IDynamicMetaObjectProvider interface, then the C# compiler treats the object like an <br>instance of an ordinary C#-defined type and performs operations on the object using <br>reflection.<br>
<hr>
<A name=172></a><hr>
<A name=173></a>Chapter 6<br><b>Type and Member Basics</b><br>
<b>In this chapter:<br>The Different Kinds of Type Members. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155<br>Type Visibility. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158<br>Member Accessibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160<br>Static Classes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162<br>Partial Classes, Structures, and Interfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164<br>Components, Polymorphism, and Versioning . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165</b><br>
In Chapters 4 and 5, I focused on types and what operations are guaranteed to exist on all <br>instances of any type. I also explained how all types fall into one of two categories: reference  <br>types and value types. In this and the subsequent chapters in this part, I'll show how to  <br>design types by using the different kinds of members that can be defined within a type. In <br>Chapters 7 through 11, I'll discuss the various members in detail.<br>
<b>The Different Kinds of Type Members</b><br>
A type can define zero or more of the following kinds of members:<br>
<b>  Constants  </b>A constant is a symbol that identifies a never-changing data value. These <br>
symbols are typically used to make code more readable and maintainable. Constants <br>are always associated with a type, not an instance of a type. Logically, constants are  <br>always static members. Discussed in Chapter 7, "Constants and Fields."<br>
<b>  Fields  </b>A field represents a read-only or read/write data value. A field can be static, in <br>
which case the field is considered part of the type's state. A field can also be instance <br>(nonstatic), in which case it's considered part of an object's state. I strongly encourage <br>you to make fields private so that the state of the type or object can't be corrupted by <br>code outside of the defining type. Discussed in Chapter 7.<br>
<b>  Instance constructors  </b>An instance constructor is a special method used to initialize a <br>
new object's instance fields to a good initial state. Discussed in Chapter 8, "Methods."<br>
<b>  Type constructors  </b>A type constructor is a special method used to initialize a type's <br>
static fields to a good initial state. Discussed in Chapter 8.<br>
<b> </b><br>
<b> </b><br>
<b>155</b><br>
<hr>
<A name=174></a><b>156 </b><br>
<b>Part II  Designing Types</b><br>
<b>  Methods  </b>A method is a function that performs operations that change or query the <br>
state of a type (static method) or an object (instance method). Methods typically read <br>and write to the fields of the type or object. Discussed in Chapter 8.<br>
<b>  Operator overloads  </b>An operator overload is a method that defines how an object <br>
should be manipulated when certain operators are applied to the object. Because not <br>all programming languages support operator overloading, operator overload methods <br>are not part of the Common Language Specification (CLS). Discussed in Chapter 8.<br>
<b>  Conversion operators  </b>A conversion operator is a method that defines how to implic-<br>
itly or explicitly cast or convert an object from one type to another type. As with opera-<br>tor overload methods, not all programming languages support conversion operators, <br>so they're not part of the CLS. Discussed in Chapter 8.<br>
<b>  Properties  </b>A property is a mechanism that allows a simple, field-like syntax for set-<br>
ting or querying part of the logical state of a type (static property) or object (instance <br>property) while ensuring that the state doesn't become corrupt. Properties can be  <br>parameterless (very common) or parameterful (fairly uncommon but used frequently <br>with collection classes). Discussed in Chapter 10, "Properties."<br>
<b>  Events  </b>A static event is a mechanism that allows a type to send a notification to one <br>
or more static or instance methods. An instance (nonstatic) event is a mechanism that <br>allows an object to send a notification to one or more static or instance methods. <br>Events are usually raised in response to a state change occurring in the type or object  <br>offering the event. An event consists of two methods that allow static or instance <br>methods to register and unregister interest in the event. In addition to the two meth-<br>ods, events typically use a delegate field to maintain the set of registered methods. <br>Discussed in Chapter 11, "Events."<br>
<b>  Types  </b>A type can define other types nested within it. This approach is typically <br>
used to break a large, complex type down into smaller building blocks to simplify the <br>implementation.<br>
Again, the purpose of this chapter isn't to describe these various members in detail but to set <br>the stage and explain what these various members all have in common.<br>
Regardless of the programming language you're using, the corresponding compiler must <br>process your source code and produce metadata and Intermediate Language (IL) code for <br>each kind of member in the preceding list. The format of the metadata is identical regardless <br>of the source programming language you use, and this feature is what makes the CLR a  <br><i>common language </i>runtime. The metadata is the common information that all languages  <br>produce and consume, enabling code in one programming language to seamlessly access <br>code written in a completely different programming language.<br>
This common metadata format is also used by the CLR, which determines how constants, <br>fields, constructors, methods, properties, and events all behave at runtime. Simply stated, <br>
<hr>
<A name=175></a><b> </b><br>
<b>Chapter 6  Type and Member Basics </b><br>
<b>157</b><br>
metadata is the key to the whole Microsoft .NET Framework development platform; it enables <br>the seamless integration of languages, types, and objects.<br>
The following C# code shows a type definition that contains an example of all the possible <br>members. The code shown here will compile (with warnings), but it isn't representative of <br>a type that you'd normally create; most of the methods do nothing of any real value. Right <br>now, I just want to show you how the compiler translates this type and its members into <br>metadata. Once again, I'll discuss the individual members in the next few chapters.<br>
using System;  <br> <br>public sealed class SomeType {                            //  1  <br> <br>   // Nested class  <br>   private class SomeNestedType { }                       //  2  <br> <br>   // Constant, read-only, and static read/write field <br>   private const    Int32  c_SomeConstant = 1;            //  3  <br>   private readonly String m_SomeReadOnlyField = &quot;2&quot;;     //  4  <br>   private static   Int32  s_SomeReadWriteField = 3;      //  5  <br> <br>   // Type constructor  <br>   static SomeType() { }                                  //  6  <br> <br>   // Instance constructors  <br>   public SomeType(Int32 x) { }                           //  7 <br>   public SomeType() { }                                  //  8 <br> <br>   // Instance and static methods  <br>   private String InstanceMethod() { return null; }       // 9 <br>   public static void Main() {}                           // 10 <br> <br>   // Instance property  <br>   public Int32 SomeProp {                                // 11  <br>      get { return 0; }                                   // 12  <br>      set { }                                             // 13  <br>   }  <br> <br>   // Instance parameterful property (indexer) <br>   public Int32 this[String s] {                          // 14  <br>      get { return 0; }                                   // 15  <br>      set { }                                             // 16  <br>   }  <br> <br>   // Instance event  <br>   public event EventHandler SomeEvent;                   // 17  <br>}<br>
If you were to compile the type just defined and examine the metadata in ILDasm.exe, you'd <br>see the output shown in Figure 6-1.<br>
<hr>
<A name=176></a><b>158 </b><br>
<b>Part II  Designing Types</b><br>
<b>FIGURE 6-1  </b>ILDasm.exe output showing metadata from preceding code<br>
Notice that all the members defined in the source code cause the compiler to emit some <br>metadata. In fact, some of the members cause the compiler to generate additional members <br>as well as additional metadata. For example, the event member (17) causes the compiler to <br>emit a field, two methods, and some additional metadata. I don't expect you to fully under-<br>stand what you're seeing here now. But as you read the next few chapters, I encourage you <br>to look back to this example to see how the member is defined and what effect that has on <br>the metadata produced by the compiler.<br>
<b>Type Visibility</b><br>
When defining a type at file scope (versus defining a type nested within another type), you <br>can specify the type's visibility as being either public or internal<b>.</b> A public type is visible <br>to all code within the defining assembly as well as all code written in other assemblies. An <br>internal type is visible to all code within the defining assembly, and the type is not visible <br>to code written in other assemblies. If you do not explicitly specify either of these when you <br>define a type, the C# compiler sets the type's visibility to internal (the more restrictive of <br>the two). Here are some examples:<br>
using System;  <br> <br>// The type below has public visibility and can be accessed by code  <br>// in this assembly as well as code written in other assemblies.  <br>public class ThisIsAPublicType { ... }  <br> <br>// The type below has internal visibility and can be accessed by code  <br>// in this assembly only.  <br>internal class ThisIsAnInternalType { ... }  <br> <br>// The type below is internal because public/internal  <br>// was not explicitly stated  <br>class ThisIsAlsoAnInternalType { ... }<br>
<hr>
<A name=177></a><b> </b><br>
<b>Chapter 6  Type and Member Basics </b><br>
<b>159</b><br>
<b>Friend Assemblies</b><br>
Imagine the following scenario: A company has one team, TeamA, that is defining a bunch of <br>utility types in one assembly, and they expect these types to be used by members in another <br>team, TeamB. For various reasons such as time schedules or geographical location, or perhaps <br>different cost centers or reporting structures, these two teams cannot build all of their types <br>into a single assembly; instead, each team produces its own assembly file.<br>
In order for TeamB's assembly to use TeamA's types, TeamA must define all of their utility <br>types as public<b>.</b> However, this means that their types are publicly visible to any and all  <br>assemblies; developers in another company could write code that uses the public utility <br>types, and this is not desirable. Maybe the utility types make certain assumptions that TeamB <br>ensures when they write code that uses TeamA's types. What we'd like to have is a way for <br>TeamA to define their types as internal while still allowing TeamB to access the types. The <br>CLR and C# support this via <i>friend assemblies</i>. This friend assembly feature is also useful when <br>you want to have one assembly containing code that performs unit tests against the internal <br>types within another assembly.<br>
When an assembly is built, it can indicate other assemblies it considers "friends" by using <br>the InternalsVisibleTo attribute defined in the System.Runtime.CompilerServices <br>namespace. The attribute has a string parameter that identifies the friend assembly's name <br>and public key (the string you pass to the attribute must not include a version, culture, or <br>processor architecture). Note that friend assemblies can access <i>all</i> of an assembly's internal <br>types as well as these type's internal members. Here is an example of how an assembly <br>can specify two other strongly named assemblies named "Wintellect" and "Microsoft" as its <br>friend assemblies:<br>
using System;  <br>using System.Runtime.CompilerServices; // For InternalsVisibleTo attribute  <br> <br>// This assembly's internal types can be accessed by any code written  <br>// in the following two assemblies (regardless of version or culture):  <br>[assembly:InternalsVisibleTo(&quot;Wintellect, PublicKey=12345678...90abcdef&quot;)]  <br>[assembly:InternalsVisibleTo(&quot;Microsoft, PublicKey=b77a5c56...1934e089&quot;)]  <br> <br>internal sealed class SomeInternalType { ... }  <br>internal sealed class AnotherInternalType { ... }<br>
Accessing the above assembly's internal types from a friend assembly is trivial. For exam-<br>ple, here's how a friend assembly called "Wintellect" with a public key of "12345678...90ab-<br>cdef" can access the internal type SomeInternalType in the assembly above:<br>
using System;  <br> <br>internal sealed class Foo {  <br>   private static Object SomeMethod() {  <br>      // This &quot;Wintellect&quot; assembly accesses the other assembly's  <br>
<hr>
<A name=178></a><IMG src="CLRviaCsharp-178_1.jpg"><br>
<b>160 </b><br>
<b>Part II  Designing Types</b><br>
      // internal type as if it were a public type  <br>      SomeInternalType sit = new SomeInternalType();  <br>      return sit;  <br>   }  <br>}<br>
Since the internal members of the types in an assembly become accessible to friend as-<br>semblies, you should think carefully about what accessibility you specify for your type's <br>members and which assemblies you declare as your friends. Note that the C# compiler re-<br>quires you to use the /out:&lt;file&gt; compiler switch when compiling the friend assembly (the <br>assembly that does not contain the InternalsVisibleTo attribute). The switch is required <br>because the compiler needs to know the name of the assembly being compiled in order to <br>determine if the resulting assembly should be considered a friend assembly. You would think <br>that the C# compiler could determine this on its own since it normally determines the output <br>file name on its own; however, the compiler doesn't decide on an output file name until it <br>is finished compiling the code. So requiring the /out:&lt;file&gt; compiler switch improves the <br>performance of compiling significantly.<br>
Also, if you are compiling a module (as opposed to an assembly) using C#'s /t:module <br>switch, and this module is going to become part of a friend assembly, you need to compile <br>the module by using the C# compiler's /moduleassemblyname:&lt;string&gt; switch as well. This <br>tells the compiler what assembly the module will be a part of so the compiler can allow code <br>in the module to access the other assembly's internal types.<br>
<b>Important  </b>The friend assembly feature should be used only by assemblies that ship on the <br>same schedule and probably even ship together. The reason is because the interdependency  <br>between friend assemblies is so high that shipping the friend assemblies on different schedules <br>will most likely cause compatibility problems. If you expect the assemblies to ship on different <br>schedules, you should try to design public classes that can be consumed by any assembly and <br>limit accessibility via a LinkDemand requesting the StrongNameIdentityPermission<b>.</b><br>
<b>Member Accessibility</b><br>
When defining a type's member (which includes nested types), you can specify the member's <br>accessibility. A member's accessibility indicates which members can be legally accessed from <br>referent code. The CLR defines the set of possible accessibility modifiers, but each program-<br>ming language chooses the syntax and term it wants developers to use when applying the <br>accessibility to a member. For example, the CLR uses the term <i>Assembly</i> to indicate that a <br>member is accessible to any code within the same assembly, whereas the C# term for this is <br>internal.<br>
Table 6-1 shows the six accessibility modifiers that can be applied to a member. The rows of <br>the table are in order from most restrictive (<i>Private</i>) to least restrictive (<i>Public</i>).<br>
<hr>
<A name=179></a><b> </b><br>
<b>Chapter 6  Type and Member Basics </b><br>
<b>161</b><br>
<b>TABLE 6-1  Member Accessibility</b><br>
<b>CLR Term</b><br>
<b>C# Term</b><br>
<b>Description</b><br>
Private<br>
private<br>
The member is accessible only by methods in <br>the defining type or any nested type.<br>
Family<br>
protected<br>
The member is accessible only by methods in <br>the defining type, any nested type, or one of its <br>derived types without regard to assembly.<br>
Family and <br>
(not supported)<br>
The member is accessible only by methods in <br>
Assembly<br>
the defining type, any nested type, or by any <br>derived types defined in the same assembly.<br>
Assembly<br>
internal<br>
The member is accessible only by methods in <br>the defining assembly.<br>
Family or Assembly protected internal<br>
The member is accessible by any nested type, <br>any derived type (regardless of assembly), or any <br>methods in the defining assembly.<br>
Public<br>
public<br>
The member is accessible to all methods in any <br>assembly.<br>
Of course, for any member to be accessible, it must be defined in a type that is visible. For <br>example, if AssemblyA defines an internal type with a public method, code in AssemblyB <br>cannot call the public method because the internal type is not visible to AssemblyB.<br>
When compiling code, the language compiler is responsible for checking that the code is <br>referencing types and members correctly. If the code references some type or member <br>incorrectly, the compiler has the responsibility of emitting the appropriate error message. <br>In addition, the just-in-time (JIT) compiler also ensures that references to fields and meth-<br>ods are legal when compiling IL code into native CPU instructions at runtime. For example, <br>if the JIT compiler detects code that is improperly attempting to access a private field or <br>method, the JIT compiler throws a FieldAccessException or a MethodAccessException, <br>respectively.<br>
Verifying the IL code ensures that a referenced member's accessibility is properly honored at <br>runtime, even if a language compiler ignored checking the accessibility. Another, more likely, <br>possibility is that the language compiler compiled code that accessed a public member in <br>another type (in another assembly); but at runtime, a different version of the assembly is <br>loaded, and in this new version, the public member has changed and is now protected or <br>private<b>.</b><br>
In C#, if you do not explicitly declare a member's accessibility, the compiler usually (but not <br>always) defaults to selecting private (the most restrictive of them all). The CLR requires <br>that all members of an interface type be public. The C# compiler knows this and forbids the <br>programmer from explicitly specifying accessibility on interface members; the compiler just <br>makes all the members public for you.<br>
<hr>
<A name=180></a><IMG src="CLRviaCsharp-180_1.jpg"><br>
<b>162 </b><br>
<b>Part II  Designing Types</b><br>
<b>More Info  </b>See the "Declared Accessibility" section in the C# Language Specification for <br>the complete set of C# rules about what accessibilities can be applied to types and members and <br>what default accessibilities C# selects based on the context in which the declaration takes place.<br>
Furthermore, you'll notice the CLR offers an accessibility called <i>Family and Assembly</i>. <br>However, C# doesn't expose this in the language. The C# team felt that this accessibility was <br>for the most part useless and decided not to incorporate it into the C# language.<br>
When a derived type is overriding a member defined in its base type, the C# compiler requires <br>that the original member and the overriding member have the same accessibility. That is, if <br>the member in the base class is protected, the overriding member in the derived class must <br>also be protected<b>.</b> However, this is a C# restriction, not a CLR restriction. When deriving <br>from a base class, the CLR allows a member's accessibility to become less restrictive but not <br>more restrictive. For example, a class can override a protected method defined in its base <br>class and make the overridden method public (more accessible). However, a class cannot <br>override a protected method defined in its base class and make the overridden method <br>private (less accessible). The reason a class cannot make a base class method more restricted <br>is because a user of the derived class could always cast to the base type and gain access to <br>the base class's method. If the CLR allowed the derived type's method to be less accessible, it <br>would be making a claim that was not enforceable.<br>
<b>Static Classes</b><br>
There are certain classes that are never intended to be instantiated, such as Console,<b> </b>Math<b>, <br></b>Environment<b>, </b>and ThreadPool<b>.</b> These classes have only static members and, in fact, the <br>classes exist simply as a way to group a set of related members together. For example, the <br>Math class defines a bunch of methods that do math-related operations. C# allows you to  <br>define non-instantiable classes by using the C# static keyword. This keyword can be  <br>applied only to classes, not structures (value types) because the CLR always allows value <br>types to be instantiated and there is no way to stop or prevent this.<br>
The compiler enforces many restrictions on a static class:<br>
  The class must be derived directly from System.Object because deriving from any <br>
other base class makes no sense since inheritance applies only to objects, and you  <br>cannot create an instance of a static class.<br>
  The class must not implement any interfaces since interface methods are callable only <br>
when using an instance of a class.<br>
  The class must define only static members (fields, methods, properties, and events). <br>
Any instance members cause the compiler to generate an error.<br>
<hr>
<A name=181></a><b> </b><br>
<b>Chapter 6  Type and Member Basics </b><br>
<b>163</b><br>
  The class cannot be used as a field, method parameter, or local variable because all of <br>
these would indicate a variable that refers to an instance, and this is not allowed. If the <br>compiler detects any of these uses, the compiler issues an error.<br>
Here is an example of a static class that defines some static members; this code compiles <br>(with a warning) but the class doesn't do anything interesting:<br>
using System;  <br> <br>public static class AStaticClass {  <br>   public static void AStaticMethod() { }  <br> <br>   public static String AStaticProperty {  <br>      get { return s_AStaticField; }  <br>      set { s_AStaticField = value; }  <br>   }  <br> <br>   private static String s_AStaticField;  <br> <br>   public static event EventHandler AStaticEvent;  <br>}<br>
If you compile the code above into a library (DLL) assembly and look at the result by using <br>ILDasm.exe, you'll see what is shown in Figure 6-2. As you can see in Figure 6-2, defining a <br>class by using the static keyword causes the C# compiler to make the class both abstract <br>and sealed. Furthermore, the compiler will not emit an instance constructor method into the <br>type. Notice that there is no instance constructor (.ctor) method shown in Figure 6-2.<br>
<b>FIGURE 6-2  </b>ILDasm.exe showing the class as abstract sealed in metadata<br>
<hr>
<A name=182></a><b>164 </b><br>
<b>Part II  Designing Types</b><br>
<b>Partial Classes, Structures, and Interfaces</b><br>
In this section, I discuss partial classes, structures, and interfaces. It should be noted that this <br>feature is offered entirely by the C# compiler (some other compilers also offer this feature); <br>the CLR knows nothing about partial classes, structures, and interfaces. <br>
The partial keyword tells the C# compiler that the source code for a single class, structure, <br>or interface definition may span one or more source code files. There are three main reasons <br>why you might want to split the source code for a type across multiple files:<br>
<b>  Source control  </b>Suppose a type's definition consists of a lot of source code, and a <br>
programmer checks it out of source control to make changes. No other programmer <br>will be able to modify the type at the same time without doing a merge later. Using the <br>partial keyword allows you to split the code for the type across multiple source code <br>files, each of which can be checked out individually so that multiple programmers can <br>edit the type at the same time.<br>
<b>  Splitting a class or structure into distinct logical units within a single file  </b>I some-<br>
times create a single type that provides multiple features so that the type can provide <br>a complete solution. To simplify my implementation, I will sometimes declare the same <br>partial type repeatedly within a single source code file. Then, in each part of the partial <br>type, I implement one feature with all its fields, methods, properties, events, and so on. <br>This allows me to easily see all the members that provide a single feature grouped to-<br>gether, which simplifies my coding. Also, I can easily comment out a part of the partial <br>type to remove a whole feature from the class and replace it with another implementa-<br>tion (via a new part of the partial type).<br>
<b>  Code spitters  </b>In Microsoft Visual Studio, when you create a new Windows Forms or <br>
Web Forms project, some source code files are created automatically as part of the <br>project. These source code files contain templates that give you a head start at building <br>these kinds of projects. When you use the Visual Studio designers and drag and drop <br>controls onto the Windows form or Web form, Visual Studio writes source code for you <br>automatically and spits this code into the source code files. This really improves your <br>productivity. Historically, the generated code was emitted into the same source code <br>file that you were working on. The problem with this is that you might edit the gener-<br>ated code accidentally and cause the designers to stop functioning correctly. Starting <br>with Visual Studio 2005, when you create a new Windows form, Web form, user control, <br>and so on, Visual Studio creates two source code files: one for your code and the other <br>for the code generated by the designer. Since the designer code is in a separate file, <br>you'll be far less likely to accidentally edit it.<br>
The partial keyword is applied to the types in al  files. When the files are compiled together, <br>the compiler combines the code to produce one type that is in the resulting .exe or .dll  <br>assembly file (or .netmodule module file). As I stated in the beginning of this section, the  <br>partial types feature is completely implemented by the C# compiler; the CLR knows nothing  <br>
<hr>
<A name=183></a><b> </b><br>
<b>Chapter 6  Type and Member Basics </b><br>
<b>165</b><br>
about partial types at all. This is why all of the source code files for the type must use the <br>same programming language, and they must all be compiled together as a single compilation <br>unit.<br>
<b>Components, Polymorphism, and Versioning</b><br>
Object-oriented programming (OOP) has been around for many, many years. When it <br>was first used in the late 1970s/early 1980s, applications were much smaller in size and all <br>the code to make the application run was written by one company. Sure, there were  <br>operating systems back then and applications did make use of what they could out of those <br>operating systems, but the operating systems offered very few features compared with the <br>operating systems of today.<br>
Today, software is much more complex and users demand that applications offer rich features <br>such as GUIs, menu items, mouse input, tablet input, printer output, networking, and so on. <br>For this reason, our operating systems and development platforms have grown substantially <br>over recent years. Furthermore, it is no longer feasible or even cost effective for application <br>developers to write all of the code necessary for their application to work the way users  <br>expect. Today, applications consist of code produced by many different companies. This code <br>is stitched together using an object-oriented paradigm.<br>
Component Software Programming (CSP) is OOP brought to this level. Here are some attri-<br>butes of a component:<br>
  A component (an assembly in .NET) has the feeling of being "published."<br>
  A component has an identity (a name, version, culture, and public key).<br>
  A component forever maintains its identity (the code in an assembly is never statically <br>
linked into another assembly; .NET always uses dynamic linking).<br>
  A component clearly indicates the components it depends upon (reference metadata <br>
tables).<br>
  A component should document its classes and members. C# offers this by allowing  <br>
in-source Extensible Markup Language (XML) documentation along with the compiler's <br>/doc command-line switch.<br>
  A component must specify the security permissions it requires. The CLR's code access <br>
security (CAS) facilities enable this.<br>
  A component publishes an interface (object model) that won't change for any servicings. <br>
A <i>servicing</i> is a new version of a component whose intention is to be backward compat-<br>ible with the original version of the component. Typically, a servicing version includes <br>bug fixes, security patches, and possibly some small feature enhancements. But a  <br>servicing cannot require any new dependencies or any additional security permissions.<br>
<hr>
<A name=184></a><IMG src="CLRviaCsharp-184_1.jpg"><br>
<b>166 </b><br>
<b>Part II  Designing Types</b><br>
As indicated by the last bullet, a big part of CSP has to do with versioning. Components will <br>change over time and components will ship on different time schedules. Versioning introduces <br>a whole new level of complexity for CSP that didn't exist with OOP, with which all code was <br>written, tested, and shipped as a single unit by a single company. In this section, I'm going to <br>focus on component versioning.<br>
In .NET, a version number consists of four parts: a <i>major</i> part, a <i>minor</i> part, a <i>build</i> part, and <br>a <i>revision</i> part. For example, an assembly whose version number is 1.2.3.4 has a major part <br>of 1, a minor part of 2, a build part of 3, and a revision part of 4. The major/minor parts are <br>typically used to represent a consistent and stable feature set for an assembly and the build/<br>revision parts are typically used to represent a servicing of this assembly's feature set.<br>
Let's say that a company ships an assembly with version 2.7.0.0. If the company later wants <br>to fix a bug in this component, they would produce a new assembly in which only the build/<br>revision parts of the version are changed, something like version 2.7.1.34. This indicates that <br>the assembly is a servicing whose intention is to be backward compatible with the original <br>component (version 2.7.0.0).<br>
On the other hand, if the company wants to make a new version of the assembly that has <br>significant changes to it and is therefore not intended to be backward compatible with the <br>original assembly, the company is really creating a new component and the new assembly <br>should be given a version number in which the major/minor parts are different from the ex-<br>isting component (version 3.0.0.0, for example).<br>
<b>Note  </b>I have just described how you should think of version numbers. Unfortunately, the CLR <br>doesn't treat version numbers this way. Today, the CLR treats a version number as an opaque <br>value, and if an assembly depends on version 1.2.3.4 of another assembly, the CLR tries to load <br>version 1.2.3.4 only (unless a binding redirection is in place). <br>
Now that we've looked at how we use version numbers to update a component's identity <br>to reflect a new version, let's take a look at some of the features offered by the CLR and <br>programming languages (such as C#) that allow developers to write code that is resilient to <br>changes that may be occurring in components that they are using.<br>
Versioning issues come into play when a type defined in a component (assembly) is used  <br>as the base class for a type in another component (assembly). Obviously, if the base class  <br>versions (changes) underneath the derived class, the behavior of the derived class changes as <br>well, probably in a way that causes the class to behave improperly. This is particularly true in <br>polymorphism scenarios in which a derived type overrides virtual methods defined by a base <br>type.<br>
C# offers five keywords that you can apply to types and/or type members that impact com-<br>ponent versioning. These keywords map directly to features supported in the CLR to support <br>
<hr>
<A name=185></a><b> </b><br>
<b>Chapter 6  Type and Member Basics </b><br>
<b>167</b><br>
component versioning. Table 6-2 contains the C# keywords related to component versioning <br>and indicates how each keyword affects a type or type member definition.<br>
<b>TABLE 6-2  C# Keywords and How They Affect Component Versioning</b><br>
<b>C# Keyword</b><br>
<b>Type</b><br>
<b>Method/Property/Event</b><br>
<b>Constant/Field</b><br>
abstract<br>
Indicates that no in-<br>
Indicates that the derived type <br>
(not allowed)<br>
stances of the type can  must override and implement this <br>be constructed<br>
member before instances of the  <br>derived type can be constructed<br>
virtual<br>
(not allowed)<br>
Indicates that this member can be <br>
(not allowed)<br>
overridden by a derived type<br>
override<br>
(not allowed)<br>
Indicates that the derived type is <br>
(not allowed)<br>
overriding the base type's member<br>
sealed<br>
Indicates that the type <br>
Indicates that the member cannot <br>
(not allowed)<br>
cannot be used as a <br>
be overridden by a derived type. <br>
base type<br>
This keyword can be applied only to <br>a method that is overriding a virtual <br>method.<br>
new<br>
When applied to a nested type, method, property, event, constant, or field, indicates <br>that the member has no relationship to a similar member that may exist in the base <br>class<br>
I will demonstrate the value and use of all these keywords in the upcoming section titled <br>"Dealing with Virtual Methods When Versioning Types." But before we get to a versioning <br>scenario, let's focus on how the CLR actually calls virtual methods.<br>
<b>How the CLR Calls Virtual Methods, Properties, and Events</b><br>
In this section, I will be focusing on methods, but this discussion is relevant to virtual proper-<br>ties and virtual events as well. Properties and events are actually implemented as methods; <br>this will be shown in their corresponding chapters.<br>
Methods represent code that performs some operation on the type (static methods) or an <br>instance of the type (nonstatic methods). All methods have a name, a signature, and a return <br>value (that may be void). The CLR allows a type to define multiple methods with the same <br>name as long as each method has a different set of parameters or a different return value. <br>So it's possible to define two methods with the same name and same parameters as long as <br>the methods have a different return type. However, except for IL assembly language, I'm not <br>aware of any language that takes advantage of this "feature"; most languages (including C#) <br>require that methods differ by parameters and ignore a method's return type when deter-<br>mining uniqueness. (C# actually relaxes this restriction when defining conversion operator <br>methods; see Chapter 8 for details.)<br>
<hr>
<A name=186></a><b>168 </b><br>
<b>Part II  Designing Types</b><br>
The Employee class shown below defines three different kinds of methods:<br>
internal class Employee {  <br>   // A nonvirtual instance method  <br>   public         Int32    GetYearsEmployed() { ... }  <br> <br>   // A virtual method (virtual implies instance)  <br>   public virtual String   GetProgressReport() { ... }  <br> <br>   // A static method  <br>   public static  Employee Lookup(String name) { ... }  <br>}<br>
When the compiler compiles this code, the compiler emits three entries in the resulting  <br>assembly's method definition table. Each entry has flags set indicating if the method is  <br>instance, virtual, or static.<br>
When code is written to call any of these methods, the compiler emitting the calling code <br>examines the method definition's flags to determine how to emit the proper IL code so that <br>the call is made correctly. The CLR offers two IL instructions for calling a method:<br>
  The call IL instruction can be used to call static, instance, and virtual methods. <br>
When the call instruction is used to call a static method, you must specify the type <br>that defines the method that the CLR should call. When the call instruction is used to <br>call an instance or virtual method, you must specify a variable that refers to an object. <br>The call instruction assumes that this variable is not null<b>. </b>In other words, the type of <br>the variable itself indicates which type defines the method that the CLR should call. If <br>the variable's type doesn't define the method, base types are checked for a matching <br>method. The call instruction is frequently used to call a virtual method nonvirtually. <br>
  The callvirt IL instruction can be used to call instance and virtual methods, not static <br>
methods. When the callvirt instruction is used to call an instance or virtual method, <br>you must specify a variable that refers to an object. When the callvirt IL instruction <br>is used to call a nonvirtual instance method, the type of the variable indicates which <br>type defines the method that the CLR should call. When the callvirt IL instruction is <br>used to call a virtual instance method, the CLR discovers the actual type of the object <br>being used to make the call and then calls the method polymorphically. In order to  <br>determine the type, the variable being used to make the call must not be null<b>.</b> In <br>other words, when compiling this call, the JIT compiler generates code that verifies that <br>the variable's value is not null<b>. </b>If it is null<b>, </b>the callvirt instruction causes the CLR to <br>throw a NullReferenceException. This additional check means that the callvirt IL <br>instruction executes slightly more slowly than the call instruction. Note that this null <br>check is performed even when the callvirt instruction is used to call a nonvirtual  <br>instance method.<br>
<hr>
<A name=187></a><b> </b><br>
<b>Chapter 6  Type and Member Basics </b><br>
<b>169</b><br>
So now, let's put this together to see how C# uses these different IL instructions:<br>
using System;  <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      Console.WriteLine(); // Call a static method  <br> <br>      Object o = new Object();  <br>      o.GetHashCode(); // Call a virtual instance method  <br>      o.GetType();     // Call a nonvirtual instance method  <br>   }  <br>}<br>
If you were to compile the code above and look at the resulting IL, you'd see the following:<br>
.method public hidebysig static void Main() cil managed {  <br> .entrypoint <br> // Code size 26 (0x1a)  <br> .maxstack 1  <br> .locals init (object V_0)  <br> IL_0000: call void System.Console::WriteLine()  <br> IL_0005: newobj instance void System.Object::.ctor()  <br> IL_000a: stloc.0  <br> IL_000b: ldloc.0  <br> IL_000c: callvirt instance int32 System.Object::GetHashCode()  <br> IL_0011: pop  <br> IL_0012: ldloc.0  <br> IL_0013: callvirt instance class System.Type System.Object::GetType()  <br> IL_0018: pop  <br> IL_0019: ret  <br>} // end of method Program::Main<br>
Notice that the C# compiler uses the call IL instruction to call Console's WriteLine method. <br>This is expected because WriteLine is a static method. Next, notice that the callvirt IL <br>instruction is used to call GetHashCode<b>.</b> This is also expected, since GetHashCode is a virtual <br>method. Finally, notice that the C# compiler also uses the callvirt IL instruction to call <br>the GetType method. This is surprising since GetType is not a virtual method. However, this <br>works because while JIT-compiling this code, the CLR will know that GetType is not a virtual <br>method, and so the JIT-compiled code will simply call GetType nonvirtually.<br>
Of course, the question is, why didn't the C# compiler simply emit the call instruction  <br>instead? The answer is because the C# team decided that the JIT compiler should generate <br>code to verify that the object being used to make the call is not null<b>.</b> This means that calls <br>to nonvirtual instance methods are a little slower than they could be. It also means that the <br>C# code shown below will cause a NullReferenceException to be thrown. In some other <br>programming languages, the intention of the code shown below would run just fine:<br>
<hr>
<A name=188></a><IMG src="CLRviaCsharp-188_1.jpg"><br>
<b>170 </b><br>
<b>Part II  Designing Types</b><br>
using System;  <br> <br>public sealed class Program {  <br>   public Int32 GetFive() { return 5; }  <br>   public static void Main() {  <br>      Program p = null;  <br>      Int32 x = p.GetFive(); // In C#, NullReferenceException is thrown  <br>   }  <br>}<br>
Theoretically, the code above is fine. Sure, the variable p is null, but when calling a nonvir-<br>tual method (GetFive), the CLR needs to know just the data type of p<b>,</b> which is Program<b>. </b>If <br>GetFive did get called, the value of the this argument would be null<b>.</b> Since the argument <br>is not used inside the GetFive method, no NullReferenceException would be thrown. <br>However, because the C# compiler emits a callvirt instruction instead of a call instruction, <br>the code above will end up throwing the NullReferenceException<b>.</b><br>
<b>Important  </b>If you define a method as nonvirtual, you should never change the method to  <br>virtual in the future. The reason is because some compilers will call the nonvirtual method by  <br>using the call instruction instead of the callvirt instruction. If the method changes from <br>nonvirtual to virtual and the referencing code is not recompiled, the virtual method will be called <br>nonvirtually, causing the application to produce unpredictable behavior. If the referencing code <br>is written in C#, this is not a problem, since C# calls all instance methods by using callvirt<b>.</b> But <br>this could be a problem if the referencing code was written using a different programming  <br>language.<br>
Sometimes, the compiler will use a call instruction to call a virtual method instead of using <br>a callvirt instruction. At first, this may seem surprising, but the code below demonstrates <br>why it is sometimes required:<br>
internal class SomeClass { <br>   // ToString is a virtual method defined in the base class: Object. <br>   public override String ToString() { <br> <br>      // Compiler uses the `call' IL instruction to call <br>      // Object's ToString method nonvirtually. <br> <br>      // If the compiler were to use `callvirt' instead of `call', this <br>      // method would call itself recursively until the stack overflowed. <br>      return base.ToString(); <br>   } <br>}<br>
When calling base.ToString (a virtual method), the C# compiler emits a call instruction <br>to ensure that the ToString method in the base type is called nonvirtually. This is required <br>because if ToString were called virtually, the call would execute recursively until the thread's <br>stack overflowed, which obviously is not desired.<br>
<hr>
<A name=189></a><b> </b><br>
<b>Chapter 6  Type and Member Basics </b><br>
<b>171</b><br>
Compilers tend to use the call instruction when calling methods defined by a value type <br>since value types are sealed. This implies that there can be no polymorphism even for their <br>virtual methods, which causes the performance of the call to be faster. In addition, the nature <br>of a value type instance guarantees it can never be null<b>, </b>so a NullReferenceException <br>will never be thrown. Finally, if you were to call a value type's virtual method virtually, the <br>CLR would need to have a reference to the value type's type object in order to refer to the <br>method table within it. This requires boxing the value type. Boxing puts more pressure on <br>the heap, forcing more frequent garbage collections and hurting performance.<br>
Regardless of whether call or callvirt is used to call an instance or virtual method, these <br>methods always receive a hidden this argument as the method's first parameter. The this <br>argument refers to the object being operated on.<br>
When designing a type, you should try to minimize the number of virtual methods you  <br>define. First, calling a virtual method is slower than calling a nonvirtual method. Second,  <br>virtual methods cannot be inlined by the JIT compiler, which further hurts performance. <br>Third, virtual methods make versioning of components more brittle, as described in the next <br>section. Fourth, when defining a base type, it is common to offer a set of convenience over-<br>loaded methods. If you want these methods to be polymorphic, the best thing to do is to <br>make the most complex method virtual and leave al  of the convenience overloaded methods <br>nonvirtual. By the way, following this guideline will also improve the ability to version a  <br>component without adversely affecting the derived types. Here is an example:<br>
public class Set {  <br>   private Int32 m_length = 0;  <br> <br>   // This convenience overload is not virtual  <br>   public Int32 Find(Object value) {  <br>      return Find(value, 0, m_length);  <br>   }  <br> <br>   // This convenience overload is not virtual  <br>   public Int32 Find(Object value, Int32 startIndex) {  <br>      return Find(value, startIndex, m_length - startIndex);  <br>   }  <br> <br>   // The most feature-rich method is virtual and can be overridden <br>   public virtual Int32 Find(Object value, Int32 startIndex, Int32 endIndex) {  <br>      // Actual implementation that can be overridden goes here...  <br>   }  <br> <br>   // Other methods go here  <br>}<br>
<hr>
<A name=190></a><b>172 </b><br>
<b>Part II  Designing Types</b><br>
<b>Using Type Visibility and Member Accessibility Intelligently</b><br>
With the .NET Framework, applications are composed of types defined in multiple assemblies <br>produced by various companies. This means that the developer has little control over the <br>components he or she is using and the types defined within those components. The developer <br>typically doesn't have access to the source code (and probably doesn't even know what pro-<br>gramming language was used to create the component), and components tend to version <br>with different schedules. Furthermore, due to polymorphism and protected members, a base <br>class developer must trust the code written by the derived class developer. And, of course, <br>the developer of a derived class must trust the code that he is inheriting from a base class. <br>These are just some of the issues that you need to really think about when designing compo-<br>nents and types.<br>
In this section, I'd like to say just a few words about how to design a type with these issues in <br>mind. Specifically, I'm going to focus on the proper way to set type visibility and member  <br>accessibility so that you'll be most successful.<br>
First, when defining a new type, compilers should make the class sealed by default so that <br>the class cannot be used as a base class. Instead, many compilers, including C#, default to <br>unsealed classes and allow the programmer to explicitly mark a class as sealed by using the <br>sealed keyword. Obviously, it is too late now, but I think that today's compilers have chosen <br>the wrong default and it would be nice if this could change with future compilers. There are <br>three reasons why a sealed class is better than an unsealed class:<br>
<b>  Versioning  </b>When a class is originally sealed, it can change to unsealed in the future  <br>
without breaking compatibility. However, once a class is unsealed, you can never <br>change it to sealed in the future as this would break all derived classes. In addition, if <br>the unsealed class defines any unsealed virtual methods, ordering of the virtual method <br>calls must be maintained with new versions or there is the potential of breaking derived <br>types in the future.<br>
<b>  Performance  </b>As discussed in the previous section, calling a virtual method doesn't <br>
perform as well as calling a nonvirtual method because the CLR must look up the type <br>of the object at runtime in order to determine which type defines the method to call. <br>However, if the JIT compiler sees a call to a virtual method using a sealed type, the JIT <br>compiler can produce more efficient code by calling the method nonvirtually. It can <br>do this because it knows there can't possibly be a derived class if the class is sealed. <br>For example, in the code below, the JIT compiler can call the virtual ToString method <br>nonvirtually:<br>
using System;  <br>public sealed class Point {  <br>   private Int32 m_x, m_y;  <br> <br>   public Point(Int32 x, Int32 y) { m_x = x; m_y = y; }  <br> <br>
<hr>
<A name=191></a><b> </b><br>
<b>Chapter 6  Type and Member Basics </b><br>
<b>173</b><br>
   public override String ToString() {  <br>      return String.Format(&quot;({0}, {1})&quot;, m_x, m_y);  <br>   }  <br> <br>   public static void Main() {  <br>      Point p = new Point(3, 4);  <br> <br>      // The C# compiler emits the callvirt instruction here but the  <br>      // JIT compiler will optimize this call and produce code that  <br>      // calls ToString nonvirtually because p's type is Point,  <br>      // which is a sealed class  <br>      Console.WriteLine(p.ToString());  <br>   }  <br>}<br>
<b>  Security and predictability  </b>A class must protect its own state and not allow itself  <br>
to ever become corrupted. When a class is unsealed, a derived class can access and  <br>manipulate the base class's state if any data fields or methods that internal y manipulate <br>fields are accessible and not private. In addition, a virtual method can be overridden by <br>a derived class, and the derived class can decide whether to call the base class's imple-<br>mentation. By making a method, property, or event virtual, the base class is giving up <br>some control over its behavior and its state. Unless carefully thought out, this can cause <br>the object to behave unpredictably, and it opens up potential security holes.<br>
The problem with a sealed class is that it can be a big inconvenience to users of the type. <br>Occasionally, developers want to create a class derived from an existing type in order to  <br>attach some additional fields or state information for their application's own use. In fact, they <br>may even want to define some helper or convenience methods on the derived type to  <br>manipulate these additional fields. Since sealed classes restrict this ability, I made a proposal <br>to the CLR team that they introduce a new class modifier called closed<b>.</b><br>
A closed class can be used as a base class, but its behavior is closed and not subject to inter-<br>ference by a derived class. Basically, a closed base class would prohibit a derived class from <br>accessing any of the base class's non-public members. This would allow the base class to <br>change with the knowledge that it will not impact a derived class. Ideally, compilers would <br>change the default access modifier for types to closed because this would be the safest <br>choice without being too restrictive. It is too early to know if this idea will make its way into <br>the CLR and programming languages. However, I am very hopeful it will someday.<br>
By the way, you could almost accomplish today what closed is designed to do; it's just that <br>it is very inconvenient. Basically, when you implement your class, make sure you seal all the <br>virtual methods you inherit (including the methods defined by System.Object). Also, don't <br>define any methods that may become a versioning burden in the future such as protected or <br>virtual methods. Here is an example:<br>
<hr>
<A name=192></a><b>174 </b><br>
<b>Part II  Designing Types</b><br>
public class SimulatedClosedClass : Object {  <br>   public sealed override Boolean Equals(Object obj) {  <br>      return base.Equals(obj);  <br>   }  <br>   public sealed override Int32 GetHashCode() {  <br>      return base.GetHashCode();  <br>   }  <br>   public sealed override String ToString() {  <br>      return base.ToString();  <br>   }  <br>   // Unfortunately, C# won't let you seal the Finalize method  <br> <br>   // Define additional public or private members here...  <br>   // Do not define any protected or virtual members  <br>}<br>
Unfortunately, the compilers and the CLR do not support closed types today. Here are the <br>guidelines I follow when I define my own classes:<br>
  When defining a class, I always explicitly make it sealed unless I truly intend for the <br>
class to be a base class that allows specialization by derived classes. As stated earlier, <br>this is the opposite of what C# and many other compilers default to today. I also default <br>to making the class internal unless I want the class to be publicly exposed outside <br>of my assembly. Fortunately, if you do not explicitly indicate a type's visibility, the C# <br>compiler defaults to internal. If I really feel that it is important to define a class that oth-<br>ers can derive but I do not want to allow specialization, I will simulate creating a closed <br>class by using the above technique of sealing the virtual methods that my class inherits.<br>
  Inside the class, I always define my data fields as private and I never waver on this. <br>
Fortunately, C# does default to making fields private<b>.</b> I'd actually prefer it if C#  <br>mandated that all fields be private and that you could not make fields protected<b>,</b>  <br>internal<b>, </b>public<b>, </b>and so on. Exposing state is the easiest way to get into problems, <br>have your object behave unpredictably, and open potential security holes. This is true <br>even if you just declare some fields as internal<b>.</b> Even within a single assembly, it is too <br>hard to track all code that references a field, especially if several developers are writing <br>code that gets compiled into the same assembly.<br>
  Inside the class, I always define my methods, properties, and events as private and <br>
nonvirtual. Fortunately, C# defaults to this as well. Certainly, I'll make a method, prop-<br>erty, or event public to expose some functionality from the type. I try to avoid making <br>any of these members protected or internal<b>,</b> as this would be exposing my type to <br>some potential vulnerability. However, I would sooner make a member protected or <br>internal than I would make a member virtual because a virtual member gives up a <br>lot of control and really relies on the proper behavior of the derived class.<br>
  There is an old OOP adage that goes like this: when things get too complicated, make <br>
more types. When an implementation of some algorithm starts to get complicated, <br>I define helper types that encapsulate discrete pieces of functionality. If I'm defining <br>
<hr>
<A name=193></a><b> </b><br>
<b>Chapter 6  Type and Member Basics </b><br>
<b>175</b><br>
these helper types for use by a single  ber-type, I'll define the helper types nested <br>within the  ber-type. This allows for scoping and also allows the code in the nested, <br>helper type to reference the private members defined in the  ber-type. However, there <br>is a design guideline rule, enforced by the Code Analysis tool (FxCopCmd.exe) in Visual <br>Studio, which indicates that publicly exposed nested types should be defined at file or <br>assembly scope and not be defined within another type. This rule exists because some <br>developers find the syntax for referencing nested types cumbersome. I appreciate this <br>rule, and I never define public nested types.<br>
<b>Dealing with Virtual Methods When Versioning Types</b><br>
As was stated earlier, in a Component Software Programming environment, versioning is a <br>very important issue. I talked about some of these versioning issues in Chapter 3, "Shared <br>Assemblies and Strongly Named Assemblies," when I explained strongly named assemblies <br>and discussed how an administrator can ensure that an application binds to the assemblies <br>that it was built and tested with. However, other versioning issues cause source code compat-<br>ibility problems. For example, you must be very careful when adding or modifying members <br>of a type if that type is used as a base type. Let's look at some examples.<br>
CompanyA has designed the following type, Phone<b>:</b><br>
namespace CompanyA {  <br>   public class Phone {  <br>      public void Dial() {  <br>         Console.WriteLine(&quot;Phone.Dial&quot;);  <br>         // Do work to dial the phone here.  <br>      }  <br>   }  <br>}<br>
Now imagine that CompanyB defines another type, BetterPhone<b>,</b> which uses CompanyA's <br>Phone type as its base:<br>
namespace CompanyB {  <br>   public class BetterPhone : CompanyA.Phone {  <br>      public void Dial() {  <br>         Console.WriteLine(&quot;BetterPhone.Dial&quot;);  <br>         EstablishConnection();  <br>         base.Dial();  <br>      }  <br> <br>      protected virtual void EstablishConnection() {  <br>         Console.WriteLine(&quot;BetterPhone.EstablishConnection&quot;);  <br>         // Do work to establish the connection.  <br>      }  <br>   }  <br>}<br>
<hr>
<A name=194></a><b>176 </b><br>
<b>Part II  Designing Types</b><br>
When CompanyB attempts to compile its code, the C# compiler issues the following  <br>message: "warning CS0108: `CompanyB.BetterPhone.Dial()' hides inherited  <br>member `CompanyA.Phone.Dial()'. Use the new keyword if hiding was intended." <br>This warning is notifying the developer that BetterPhone is defining a Dial method, which <br>will hide the Dial method defined in Phone<b>.</b> This new method could change the semantic <br>meaning of Dial (as defined by CompanyA when it originally created the Dial method).<br>
It's a very nice feature of the compiler to warn you of this potential semantic mismatch. The <br>compiler also tells you how to remove the warning by adding the new keyword before the <br>definition of Dial in the BetterPhone class. Here's the fixed BetterPhone class:<br>
namespace CompanyB {  <br>   public class BetterPhone : CompanyA.Phone {  <br> <br>      // This Dial method has nothing to do with Phone's Dial method.  <br>      public new void Dial() {  <br>         Console.WriteLine(&quot;BetterPhone.Dial&quot;);  <br>         EstablishConnection();  <br>         base.Dial();  <br>      }  <br> <br>      protected virtual void EstablishConnection() {  <br>         Console.WriteLine(&quot;BetterPhone.EstablishConnection&quot;);  <br>         // Do work to establish the connection.  <br>      }  <br>   }  <br>}<br>
At this point, CompanyB can use BetterPhone.Dial in its application. Here's some sample <br>code that CompanyB might write:<br>
public sealed class Program {  <br>   public static void Main() {  <br>      CompanyB.BetterPhone phone = new CompanyB.BetterPhone();  <br>      phone.Dial();  <br>   }  <br>}<br>
When this code runs, the following output is displayed:<br>
BetterPhone.Dial <br>BetterPhone.EstablishConnection <br>Phone.Dial<br>
This output shows that CompanyB is getting the behavior it desires. The call to Dial <br>is calling the new Dial method defined by BetterPhone<b>, </b>which calls the virtual <br>EstablishConnection method and then calls the Phone base type's Dial method.<br>
Now let's imagine that several companies have decided to use CompanyA's Phone type. Let's <br>further imagine that these other companies have decided that the ability to establish a  <br>connection in the Dial method is a really useful feature. This feedback is given to <br>CompanyA, which now revises its Phone class:<br>
<hr>
<A name=195></a><b> </b><br>
<b>Chapter 6  Type and Member Basics </b><br>
<b>177</b><br>
namespace CompanyA {  <br>   public class Phone {  <br>      public void Dial() {  <br>         Console.WriteLine(&quot;Phone.Dial&quot;);  <br>         EstablishConnection();  <br>         // Do work to dial the phone here.  <br>      }  <br> <br>      protected virtual void EstablishConnection() {  <br>         Console.WriteLine(&quot;Phone.EstablishConnection&quot;);  <br>         // Do work to establish the connection.  <br>      }  <br>   }  <br>}<br>
Now when CompanyB compiles its BetterPhone type (derived from this new version of <br>CompanyA's Phone), the compiler issues this message: "warning CS0114:  <br>`CompanyB.BetterPhone.EstablishConnection()' hides inherited member <br>`CompanyA.Phone.EstablishConnection()'. To make the current member  <br>override that implementation, add the override keyword. Otherwise, add  <br>the new keyword."<br>
The compiler is alerting you to the fact that both Phone and BetterPhone offer an <br>EstablishConnection method and that the semantics of both might not be identical;  <br>simply recompiling BetterPhone can no longer give the same behavior as it did when using <br>the first version of the Phone type.<br>
If CompanyB decides that the EstablishConnection methods are not semantically identical  <br>in both types, CompanyB can tell the compiler that the Dial and EstablishConnection <br>method defined in BetterPhone is the correct method to use and that it has no relationship <br>with the EstablishConnection method defined in the Phone base type. CompanyB informs <br>the compiler of this by adding the new keyword to the EstablishConnection method:<br>
namespace CompanyB {  <br>   public class BetterPhone : CompanyA.Phone {  <br> <br>      // Keep 'new' to mark this method as having no  <br>      // relationship to the base type's Dial method.  <br>      public new void Dial() {  <br>         Console.WriteLine(&quot;BetterPhone.Dial&quot;);  <br>         EstablishConnection();  <br>         base.Dial();  <br>      }  <br> <br>      // Add 'new' to mark this method as having no  <br>      // relationship to the base type's EstablishConnection method.  <br>      protected new virtual void EstablishConnection() {  <br>         Console.WriteLine(&quot;BetterPhone.EstablishConnection&quot;);  <br>         // Do work to establish the connection.  <br>      }  <br>   }  <br>}<br>
<hr>
<A name=196></a><IMG src="CLRviaCsharp-196_1.jpg"><br>
<b>178 </b><br>
<b>Part II  Designing Types</b><br>
In this code, the new keyword tells the compiler to emit metadata, making it clear to the <br>CLR that BetterPhone's EstablishConnection method is intended to be treated as a new <br>function that is introduced by the BetterPhone type. The CLR will know that there is no  <br>relationship between Phone's and BetterPhone's methods.<br>
When the same application code (in the Main method) executes, the output is as follows:<br>
BetterPhone.Dial <br>BetterPhone.EstablishConnection <br>Phone.Dial <br>Phone.EstablishConnection<br>
This output shows that Main's call to Dial calls the new Dial method defined by <br>BetterPhone.Dial, which in turn calls the virtual EstablishConnection method that is also <br>defined by BetterPhone. When BetterPhone's EstablishConnection method returns,  <br>Phone's Dial method is called. Phone's Dial method calls EstablishConnection<b>,</b> but <br>because BetterPhone's EstablishConnection is marked with new<b>, </b>BetterPhone's <br>EstablishConnection method isn't considered an override of Phone's virtual  <br>EstablishConnection method. As a result, Phone's Dial method calls Phone's <br>EstablishConnection method--this is the expected behavior.<br>
<b>Note  </b>If the compiler treated methods as overrides by default (as a native C++ compiler does),  <br>the developer of BetterPhone couldn't use the method names Dial and <br>EstablishConnection<b>.</b> This would most likely cause a ripple effect of changes throughout <br>the entire source code base, breaking source and binary compatibility. This type of pervasive <br>change is undesirable, especially in any moderate-to-large project. However, if changing the <br>method name causes only moderate updates in the source code, you should change the name of <br>the methods so the two different meanings of Dial and EstablishConnection don't confuse <br>other developers.<br>
Alternatively, CompanyB could have gotten the new version of CompanyA's Phone type and <br>decided that Phone's semantics of Dial and EstablishConnection are exactly what it's <br>been looking for. In this case, CompanyB would modify its BetterPhone type by removing <br>its Dial method entirely. In addition, because CompanyB now wants to tell the compiler that <br>BetterPhone's EstablishConnection method is related to Phone's EstablishConnection <br>method, the new keyword must be removed. Simply removing the new keyword isn't enough, <br>though, because now the compiler can't tell exactly what the intention is of BetterPhone's <br>EstablishConnection method. To express his intent exactly, the CompanyB developer must <br>also change BetterPhone's EstablishConnection method from virtual to override<b>.</b> The <br>following code shows the new version of BetterPhone:<br>
<hr>
<A name=197></a><b> </b><br>
<b>Chapter 6  Type and Member Basics </b><br>
<b>179</b><br>
namespace CompanyB {  <br>   public class BetterPhone : CompanyA.Phone {  <br> <br>   // Delete the Dial method (inherit Dial from base).  <br> <br>   // Remove 'new' and change 'virtual' to 'override' to  <br>   // mark this method as having a relationship to the base  <br>   // type's EstablishConnection method.  <br>   protected override void EstablishConnection() {  <br>      Console.WriteLine(&quot;BetterPhone.EstablishConnection&quot;);  <br>      // Do work to establish the connection.  <br>   }  <br> }  <br>}<br>
Now when the same application code (in the Main method) executes, the output is as <br>follows:<br>
Phone.Dial <br>BetterPhone.EstablishConnection<br>
This output shows that Main's call to Dial calls the Dial method defined by Phone and  <br>inherited by BetterPhone<b>.</b> Then when Phone's Dial method calls the virtual <br>EstablishConnection method, BetterPhone's EstablishConnection method is called  <br>because it overrides the virtual EstablishConnection method defined by Phone.<br>
<hr>
<A name=198></a><hr>
<A name=199></a>Chapter 7<br><b>Constants and Fields</b><br>
<b>In this chapter:<br>Constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181<br>Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183</b><br>
In this chapter, I'll show you how to add data members to a type. Specifically, we'll look at <br>constants and fields.<br>
<b>Constants</b><br>
A <i>constant</i> is a symbol that has a never-changing value. When defining a constant symbol, <br>its value must be determinable at compile time. The compiler then saves the constant's value <br>in the assembly's metadata. This means that you can define a constant only for types that <br>your compiler considers primitive types. In C#, the following types are primitives and can be <br>used to define constants: Boolean, Char, Byte, SByte, Int16, UInt16, Int32, UInt32, Int64, <br>UInt64, Single, Double, Decimal, and String. However, C# also allows you to define a  <br>constant variable of a non-primitive type if you set the value to null:<br>
using System;  <br> <br>public sealed class SomeType {  <br>   // SomeType is not a primitive type but C# does allow <br>   // a constant variable of this type to be set to 'null'.  <br>   public const SomeType Empty = null;  <br>}<br>
Because a constant value never changes, constants are always considered to be part of the <br>defining type. In other words, constants are always considered to be static members, not  <br>instance members. Defining a constant causes the creation of metadata.<br>
When code refers to a constant symbol, compilers look up the symbol in the metadata of the <br>assembly that defines the constant, extract the constant's value, and embed the value in the <br>emitted Intermediate Language (IL) code. Because a constant's value is embedded directly in <br>code, constants don't require any memory to be allocated for them at runtime. In addition, <br>you can't get the address of a constant and you can't pass a constant by reference. These <br>constraints also mean that constants don't have a good cross-assembly versioning story, <br>so you should use them only when you know that the value of a symbol will never change. <br>
<b> </b><br>
<b> </b><br>
<b>181</b><br>
<hr>
<A name=200></a><b>182 </b><br>
<b>Part II  Designing Types</b><br>
(Defining MaxInt16 as 32767 is a good example.) Let me demonstrate exactly what I mean. <br>First, take the following code and compile it into a DLL assembly:<br>
using System;  <br> <br>public sealed class SomeLibraryType {  <br>   // NOTE: C# doesn't allow you to specify static for constants  <br>   // because constants are always implicitly static.  <br>   public const Int32 MaxEntriesInList = 50;  <br>}<br>
Then use the following code to build an application assembly:<br>
using System;  <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      Console.WriteLine(&quot;Max entries supported in list: &quot;  <br>         + SomeLibraryType.MaxEntriesInList);  <br>   }  <br>}<br>
You'll notice that this application code references the MaxEntriesInList constant defined <br>in the SomeLibraryType class. When the compiler builds the application code, it sees that <br>MaxEntriesInList is a constant literal with a value of 50 and embeds the Int32 value of 50 <br>right inside the application's IL code, as you can see in the IL code shown below. In fact, after <br>building the application assembly, the DLL assembly isn't even loaded at runtime and can be <br>deleted from the disk.<br>
.method public hidebysig static void  Main() cil managed <br>{ <br>  .entrypoint <br>  // Code size       25 (0x19) <br>  .maxstack  8 <br>  IL_0000:  nop <br>  IL_0001:  ldstr      &quot;Max entries supported in list: &quot; <br>  IL_0006:  ldc.i4.s   50 <br>
 <br>
 <br>
  IL_0008:  box        [mscorlib]System.Int32 <br>  IL_000d:  call       string [mscorlib]System.String::Concat(object, object) <br>  IL_0012:  call       void [mscorlib]System.Console::WriteLine(string) <br>  IL_0017:  nop <br>  IL_0018:  ret <br>} // end of method Program::Main<br>
This example should make the versioning problem obvious to you. If the developer changes <br>the MaxEntriesInList constant to 1000 and only rebuilds the DLL assembly, the application <br>assembly is not affected. For the application to pick up the new value, it will have to be re-<br>compiled as well. You can't use constants if you need to have a value in one assembly picked <br>up by another assembly at runtime (instead of compile time). Instead, you can use readonly <br>fields, which I'll discuss next.<br>
<hr>
<A name=201></a><b> </b><br>
<b>Chapter 7  Constants and Fields </b><br>
<b>183</b><br>
<b>Fields</b><br>
A <i>field</i> is a data member that holds an instance of a value type or a reference to a reference <br>type. Table 7-1 shows the modifiers that can be applied to a field.<br>
<b>TABLE 7-1  Field Modifiers</b><br>
<b>CLR Term</b><br>
<b>C# Term</b><br>
<b>Description</b><br>
Static<br>
static<br>
The field is part of the type's state, as opposed to being <br>part of an object's state.<br>
Instance<br>
(default)<br>
The field is associated with an instance of the type, not <br>the type itself.<br>
InitOnly<br>
readonly<br>
The field can be written to only by code contained in a <br>constructor method.<br>
Volatile<br>
volatile<br>
Code that accessed the field is not subject to some <br>thread-unsafe optimizations that may be performed by <br>the compiler, the CLR, or by hardware. Only the follow-<br>ing types can be marked volatile: all reference types, <br>Single, Boolean, Byte, SByte, Int16, UInt16, Int32, <br>UInt32, Char, and all enumerated types with an un-<br>derlying type of Byte, SByte, Int16, UInt16, Int32, <br>or UInt32. Volatile fields are discussed in Chapter 28, <br>"Primitive Thread Synchronization Constructs."<br>
As Table 7-1 shows, the common language runtime (CLR) supports both type (static) and <br>instance (nonstatic) fields. For type fields, the dynamic memory required to hold the field's <br>data is allocated inside the type object, which is created when the type is loaded into an <br>AppDomain (see Chapter 22, "CLR Hosting and AppDomains"), which typically happens the <br>first time any method that references the type is just-in-time (JIT)­compiled. For instance <br>fields, the dynamic memory to hold the field is allocated when an instance of the type is <br>constructed.<br>
Because fields are stored in dynamic memory, their value can be obtained at runtime only. <br>Fields also solve the versioning problem that exists with constants. In addition, a field can be <br>of any data type, so you don't have to restrict yourself to your compiler's built-in primitive <br>types (as you do for constants).<br>
The CLR supports readonly fields and read/write fields. Most fields are read/write fields, <br>meaning the field's value might change multiple times as the code executes. However,  <br>readonly fields can be written to only within a constructor method (which is called only <br>once, when an object is first created). Compilers and verification ensure that readonly fields <br>are not written to by any method other than a constructor. Note that reflection can be used <br>to modify a readonly field.<br>
Let's take the example from the "Constants" section and fix the versioning problem by using <br>a static readonly field. Here's the new version of the DLL assembly's code:<br>
<hr>
<A name=202></a><b>184 </b><br>
<b>Part II  Designing Types</b><br>
using System;  <br> <br>public sealed class SomeLibraryType {  <br>   // The static is required to associate the field with the type.  <br>   public static readonly Int32 MaxEntriesInList = 50;  <br>}<br>
This is the only change you have to make; the application code doesn't have to change at <br>all, although you must rebuild it to see the new behavior. Now when the application's Main <br>method runs, the CLR will load the DLL assembly (so this assembly is now required at run <br>time) and grab the value of the MaxEntriesInList field out of the dynamic memory  <br>allocated for it. Of course, the value will be 50<b>.</b><br>
Let's say that the developer of the DLL assembly changes the 50 to 1000 and rebuilds the as-<br>sembly. When the application code is re-executed, it will automatically pick up the new value: <br>1000<b>.</b> In this case, the application code doesn't have to be rebuilt--it just works (although its <br>performance is adversely affected). A caveat: this scenario assumes that the new version of <br>the DLL assembly is not strongly named and the versioning policy of the application is such <br>that the CLR loads this new version.<br>
The following example shows how to define a readonly static field that is associated with the <br>type itself, as well as read/write static fields and readonly and read/write instance fields, <br>as shown here:<br>
public sealed class SomeType {  <br>   // This is a static read-only field; its value is calculated and  <br>   // stored in memory when this class is initialized at run time.  <br>   public static readonly Random s_random = new Random();  <br> <br>   // This is a static read/write field.  <br>   private static Int32 s_numberOfWrites = 0;  <br> <br>   // This is an instance read-only field.  <br>   public readonly String Pathname = &quot;Untitled&quot;;  <br> <br>   // This is an instance read/write field.  <br>   private System.IO.FileStream m_fs;  <br> <br>   public SomeType(String pathname) {  <br>      // This line changes a read-only field.  <br>      // This is OK because the code is in a constructor.  <br>      this.Pathname = pathname;  <br>   }  <br> <br>   public String DoSomething() {  <br>      // This line reads and writes to the static read/write field.  <br>      s_numberOfWrites = s_numberOfWrites + 1;  <br> <br>      // This line reads the read-only instance field.  <br>      return Pathname;  <br>   }  <br>}<br>
<hr>
<A name=203></a><IMG src="CLRviaCsharp-203_1.jpg"><br>
<b> </b><br>
<b>Chapter 7  Constants and Fields </b><br>
<b>185</b><br>
In this code, many of the fields are initialized inline. C# allows you to use this convenient inline <br>initialization syntax to initialize a class's constants and read/write and readonly fields. As <br>you'll see in Chapter 8, "Methods," C# treats initializing a field inline as shorthand syntax for <br>initializing the field in a constructor. Also, in C#, there are some performance issues to con-<br>sider when initializing fields by using inline syntax versus assignment syntax in a constructor. <br>These performance issues are discussed in Chapter 8 as well.<br>
<b>Important  </b>When a field is of a reference type and the field is marked as readonly, it is  <br>the reference that is immutable, not the object that the field refers to. The following code  <br>demonstrates:<br>
public sealed class AType {  <br>   // InvalidChars must always refer to the same array object  <br>   public static readonly Char[] InvalidChars = new Char[] { 'A', 'B', 'C' };  <br>}  <br> <br>public sealed class AnotherType {  <br>   public static void M() {  <br>      // The lines below are legal, compile, and successfully  <br>      // change the characters in the InvalidChars array  <br>      AType.InvalidChars[0] = 'X';  <br>      AType.InvalidChars[1] = 'Y';  <br>      AType.InvalidChars[2] = 'Z';  <br> <br>      // The line below is illegal and will not compile because  <br>      // what InvalidChars refers to cannot be changed  <br>      AType.InvalidChars = new Char[] { 'X', 'Y', 'Z' };  <br>   }  <br>}<br>
<hr>
<A name=204></a><hr>
<A name=205></a>Chapter 8<br><b>Methods</b><br>
<b>In this chapter:<br>Instance Constructors and Classes (Reference Types). . . . . . . . . . . . . . . . . . . . . . 187<br>Instance Constructors and Structures (Value Types) . . . . . . . . . . . . . . . . . . . . . . . 191<br>Type Constructors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194<br>Operator Overload Methods. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200<br>Conversion Operator Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204<br>Extension Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207<br>Partial Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213</b><br>
This chapter focuses on the various kinds of methods that you'll run into, including instance <br>constructors and type constructors, as well as how to define methods to overload operators <br>and type conversions (for implicit and explicit casting). We'll also talk about extension meth-<br>ods, which allow you to logically add your own instance methods to already existing types, <br>and partial methods, which allow you to spread a type's implementation into multiple parts.<br>
<b>Instance Constructors and Classes (Reference Types)</b><br>
Constructors are special methods that allow an instance of a type to be initialized to a good <br>state. Constructor methods are always called .ctor (for <i>constructor</i>) in a method definition <br>metadata table. When creating an instance of a reference type, memory is allocated for the <br>instance's data fields, the object's overhead fields (type object pointer and sync block index) <br>are initialized, and then the type's instance constructor is called to set the initial state of the <br>object.<br>
When constructing a reference type object, the memory allocated for the object is always <br>zeroed out before the type's instance constructor is called. Any fields that the constructor <br>doesn't explicitly overwrite are guaranteed to have a value of 0 or null.<br>
Unlike other methods, instance constructors are never inherited. That is, a class has only  <br>the instance constructors that the class itself defines. Since instance constructors are never <br>inherited, you cannot apply the following modifiers to an instance constructor: virtual, new, <br>override, sealed, or abstract. If you define a class that does not explicitly define any  <br>constructors, the C# compiler defines a default (parameterless) constructor for you whose <br>implementation simply calls the base class's parameterless constructor.<br>
<b> </b><br>
<b> </b><br>
<b>187</b><br>
<hr>
<A name=206></a><IMG src="CLRviaCsharp-206_1.jpg"><br>
<b>188 </b><br>
<b>Part II  Designing Types</b><br>
For example, if you define the following class:<br>
public class SomeType {  <br>}<br>
it is as though you wrote the code like this:<br>
public class SomeType {  <br>   public SomeType() : base() { }  <br>}<br>
If the class is abstract, the compiler-produced default constructor has protected acces-<br>sibility; otherwise, the constructor is given public accessibility. If the base class doesn't offer <br>a parameterless constructor, the derived class must explicitly call a base class constructor or <br>the compiler will issue an error. If the class is static (sealed and abstract), the compiler <br>will not emit a default constructor at all into the class definition.<br>
A type can define several instance constructors. Each constructor must have a different  <br>signature, and each can have different accessibility. For verifiable code, a class's instance  <br>constructor must call its base class's constructor before accessing any of the inherited fields <br>of the base class. The C# compiler will generate a call to the default base class's constructor  <br>automatically if the derived class's constructor does not explicitly invoke one of the base <br>class's constructors. Ultimately, System.Object<b>'</b>s public, parameterless constructor gets <br>called. This constructor does nothing--it simply returns. This is because System.Object  <br>defines no instance data fields, and therefore its constructor has nothing to do.<br>
In a few situations, an instance of a type can be created without an instance constructor <br>being called. In particular, calling Object's MemberwiseClone method allocates memory, <br>initializes the object's overhead fields, and then copies the source object's bytes to the <br>new object. Also, a constructor is usually not called when deserializing an object with the <br>runtime serializer. The deserialization code allocates memory for the object without call-<br>ing a constructor using the System.Runtime.Serialization.FormatterServices type's <br>GetUninitializedObject or GetSafeUninitializedObject methods (as discussed in <br>Chapter 24, "Runtime Serialization").<br>
<b>Important  </b>You should not call any virtual methods within a constructor that can affect the  <br>object being constructed. The reason is if the virtual method is overridden in the type being  <br>instantiated, the derived type's implementation of the overridden method will execute, but all of <br>the fields in the hierarchy have not been fully initialized. Calling a virtual method would therefore <br>result in unpredictable behavior.<br>
C# offers a simple syntax that allows the initialization of fields defined within a reference type <br>when an instance of the type is constructed:<br>
<hr>
<A name=207></a><b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>189</b><br>
internal sealed class SomeType {  <br>   private Int32 m_x = 5;  <br>}<br>
When a SomeType object is constructed, its m_x field will be initialized to 5. How does this <br>happen? Well, if you examine the Intermediate Language (IL) for SomeType's<b> </b>constructor <br>method (also called .ctor), you'll see the code shown here: <br>
.method public hidebysig specialname rtspecialname  <br>        instance void  .ctor() cil managed <br>{ <br>  // Code size       14 (0xe) <br>  .maxstack  8 <br>  IL_0000:  ldarg.0 <br>  IL_0001:  ldc.i4.5 <br>  IL_0002:  stfld      int32 SomeType::m_x <br>  IL_0007:  ldarg.0 <br>  IL_0008:  call       instance void [mscorlib]System.Object::.ctor() <br>  IL_000d:  ret <br>} // end of method SomeType::.ctor<br>
In this code, you see that SomeType's constructor contains code to store a 5 into m_x and <br>then calls the base class's constructor. In other words, the C# compiler allows the convenient <br>syntax that lets you initialize the instance fields inline and translates this to code in the con-<br>structor method to perform the initialization. This means that you should be aware of code <br>explosion, as illustrated by the following class definition:<br>
internal sealed class SomeType {  <br>   private Int32  m_x = 5;  <br>   private String m_s = &quot;Hi there&quot;;  <br>   private Double m_d = 3.14159;  <br>   private Byte   m_b;  <br>  <br>   // Here are some constructors.   <br>   public SomeType()         { ... }  <br>   public SomeType(Int32 x)  { ... }  <br>   public SomeType(String s) { ...; m_d = 10; }  <br>}<br>
When the compiler generates code for the three constructor methods, the beginning of each <br>method includes the code to initialize m_x, m_s, and m_d.<b> </b>After this initialization code, the <br>compiler inserts a call to the base class's constructor, and then the compiler appends to the <br>method the code that appears in the constructor methods. For example, the code generated <br>for the constructor that takes a String parameter includes the code to initialize m_x, m_s, <br>and m_d, call the base class's (Object's) constructor, and then overwrite m_d with the value <br>10. Note that m_b is guaranteed to be initialized to 0 even though no code exists to explicitly <br>initialize it.<br>
<hr>
<A name=208></a><IMG src="CLRviaCsharp-208_1.jpg"><br>
<b>190 </b><br>
<b>Part II  Designing Types</b><br>
<b>Note  </b>The compiler initializes any fields using the convenient syntax before calling a base class's <br>constructor to maintain the impression that these fields always have a value as the source code <br>appearance dictates. The potential problem occurs when a base class's constructor invokes a vir-<br>tual method that calls back into a method defined by the derived class. If this happens, the fields <br>initialized using the convenient syntax have been initialized before the virtual method is called.<br>
Because there are three constructors in the preceding class, the compiler generates the <br>code to initialize m_x, m_s, and m_d three times--once per constructor. If you have several <br>initialized instance fields and a lot of overloaded constructor methods, you should consider <br>defining the fields without the initialization, creating a single constructor that performs the <br>common initialization, and having each constructor explicitly call the common initialization <br>constructor. This approach will reduce the size of the generated code. Here is an example <br>using C#'s ability to explicitly have a constructor call another constructor by using the this <br>keyword:<br>
internal sealed class SomeType {  <br>   // Do not explicitly initialize the fields here  <br>   private Int32  m_x;  <br>   private String m_s;  <br>   private Double m_d;  <br>   private Byte   m_b;  <br>  <br>   // This constructor sets all fields to their default.  <br>   // All of the other constructors explicitly invoke this constructor.  <br>   public SomeType() {   <br>      m_x = 5;  <br>      m_s = &quot;Hi there&quot;;  <br>      m_d = 3.14159;  <br>      m_b = 0xff;  <br>   }  <br>  <br>   // This constructor sets all fields to their default, then changes m_x.  <br>   public SomeType(Int32 x) : this() {  <br>      m_x = x;  <br>   }  <br>  <br>   // This constructor sets all fields to their default, then changes m_s.  <br>   public SomeType(String s) : this() {  <br>      m_s = s;  <br>   }  <br>  <br>   // This constructor sets all fields to their default, then changes m_x &amp; m_s.  <br>   public SomeType(Int32 x, String s) : this() {  <br>      m_x = x;  <br>      m_s = s;  <br>   }  <br>}<br>
<hr>
<A name=209></a><b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>191</b><br>
<b>Instance Constructors and Structures (Value Types)</b><br>
Value type (struct) constructors work quite differently from reference type (class)  <br>constructors. The common language runtime (CLR) always allows the creation of value type  <br>instances, and there is no way to prevent a value type from being instantiated. For this  <br>reason, value types don't actually even need to have a constructor defined within them, and <br>the C# compiler doesn't emit default parameterless constructors for value types. Examine the <br>following code:<br>
internal struct Point {   <br>   public Int32 m_x, m_y;   <br>}  <br>internal sealed class Rectangle {   <br>   public Point m_topLeft, m_bottomRight;   <br>}<br>
To construct a Rectangle, the new operator must be used, and a constructor must be speci-<br>fied. In this case, the default constructor automatical y generated by the C# compiler is called. <br>When memory is allocated for the Rectangle, the memory includes the two instances of the <br>Point value type. For performance reasons, the CLR doesn't attempt to call a constructor <br>for each value type field contained within the reference type. But as I mentioned earlier, the <br>fields of the value types are initialized to 0/null.<br>
The CLR does allow you to define constructors on value types. The only way that these  <br>constructors will execute is if you write code to explicitly call one of them, as in Rectangle's <br>constructor, shown here:<br>
internal struct Point {   <br>   public Int32 m_x, m_y;   <br>  <br>   public Point(Int32 x, Int32 y) {  <br>      m_x = x;  <br>      m_y = y;  <br>   }  <br>}  <br>  <br>internal sealed class Rectangle {   <br>   public Point m_topLeft, m_bottomRight;   <br>  <br>   public Rectangle() {  <br>      // In C#, new on a value type calls the constructor to   <br>      // initialize the value type's fields.  <br>      m_topLeft     = new Point(1, 2);  <br>      m_bottomRight = new Point(100, 200);  <br>   }  <br>}<br>
A value type's instance constructor is executed only when explicitly called. So if Rectangle's <br>constructor didn't initialize its m_topLeft and m_bottomRight fields by using the new opera-<br>tor to call Point's constructor, the m_x and m_y fields in both Point fields would be 0.<br>
<hr>
<A name=210></a><b>192 </b><br>
<b>Part II  Designing Types</b><br>
In the Point value type defined earlier, no default parameterless constructor is defined. <br>However, let's rewrite that code as follows:<br>
internal struct Point {   <br>   public Int32 m_x, m_y;   <br>  <br>   public Point() {  <br>      m_x = m_y = 5;  <br>   }  <br>}  <br>  <br>internal sealed class Rectangle {   <br>   public Point m_topLeft, m_bottomRight;   <br>  <br>   public Rectangle() {  <br>   }  <br>}<br>
Now when a new Rectangle is constructed, what do you think the m_x and m_y fields in the <br>two Point fields, m_topLeft and m_bottomRight, would be initialized to: 0 or 5? (Hint: This <br>is a trick question.)<br>
Many developers (especially those with a C++ background) would expect the C# compiler to <br>emit code in Rectangle's constructor that automatically calls Point's default parameterless <br>constructor for the Rectangle's two fields. However, to improve the runtime performance of <br>the application, the C# compiler doesn't automatically emit this code. In fact, many compilers <br>will never emit code to call a value type's default constructor automatically, even if the value <br>type offers a parameterless constructor. To have a value type's parameterless constructor  <br>execute, the developer must add explicit code to call a value type's constructor.<br>
Based on the information in the preceding paragraph, you should expect the m_x and m_y <br>fields in Rectangle's two Point fields to be initialized to 0 in the code shown earlier because <br>there are no explicit calls to Point's constructor anywhere in the code.<br>
However, I did say that my original question was a trick question. The trick part is that C# <br>doesn't allow a value type to define a parameterless constructor. So the previous code won't <br>actually compile. The C# compiler produces the following message when attempting to <br>compile that code: &quot;error CS0568: Structs cannot contain explicit parameterless <br>constructors.&quot;<br>
C# purposely disallows value types from defining parameterless constructors to remove any <br>confusion a developer might have about when that constructor gets called. If the constructor <br>can't be defined, the compiler can never generate code to call it automatically. Without a  <br>parameterless constructor, a value type's fields are always initialized to 0/null.<br>
<hr>
<A name=211></a><IMG src="CLRviaCsharp-211_1.jpg"><br>
<b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>193</b><br>
<b>Note  </b>Strictly speaking, value type fields are guaranteed to be 0/null when the value type is a <br>field nested within a reference type. However, stack-based value type fields are not guaranteed <br>to be 0/null. For verifiability, any stack-based value type field must be written to prior to be-<br>ing read. If code could read a value type's field prior to writing to the field, a security breach is <br>possible. C# and other compilers that produce verifiable code ensure that all stack-based value <br>types have their fields zeroed out or at least written to before being read so that a verification <br>exception won't be thrown at run time. For the most part, this means that you can assume that <br>your value types have their fields initialized to 0, and you can completely ignore everything in <br>this note.<br>
Keep in mind that although C# doesn't allow value types with parameterless constructors, <br>the CLR does. So if the unobvious behavior described earlier doesn't bother you, you can use <br>another programming language (such as IL assembly language) to define your value type <br>with a parameterless constructor.<br>
Because C# doesn't allow value types with parameterless constructors, compiling the follow-<br>ing type produces the following message: &quot;error CS0573: 'SomeValType.m_x': cannot <br>have instance field initializers in structs.&quot;<br>
internal struct SomeValType {  <br>   // You cannot do inline instance field initialization in a value type  <br>   private Int32 m_x = 5;  <br>}<br>
In addition, because verifiable code requires that every field of a value type be written to <br>prior to any field being read, any constructors that you do have for a value type must initialize <br>all of the type's fields. The following type defines a constructor for the value type but fails to <br>initialize all of the fields:<br>
internal struct SomeValType {  <br>   private Int32 m_x, m_y;  <br>  <br>   // C# allows value types to have constructors that take parameters.  <br>   public SomeValType(Int32 x) {  <br>      m_x = x;     <br>      // Notice that m_y is not initialized here.  <br>   }  <br>}<br>
When compiling this type, the C# compiler produces the following message: &quot;error <br>CS0171: Field 'SomeValType.m_y' must be fully assigned before control leaves <br>the constructor.&quot; To fix the problem, assign a value (usually 0) to y in the constructor.<br>
<hr>
<A name=212></a><b>194 </b><br>
<b>Part II  Designing Types</b><br>
As an alternative way to initialize all the fields of a value type, you can actually do this:<br>
// C# allows value types to have constructors that take parameters. <br>public SomeValType(Int32 x) { <br>   // Looks strange but compiles fine and initializes all fields to 0/null <br>   this = new SomeValType(); <br> <br>   m_x = x; // Overwrite m_x's 0 with x <br>   // Notice that m_y was initialized to 0. <br>}<br>
In a value type's constructor, this represents an instance of the value type itself and you can <br>actually assign to it the result of newing up an instance of the value type, which really just  <br>zeroes out all the fields. In a reference type's constructor, this is considered read-only and <br>so you cannot assign to it at all.<br>
<b>Type Constructors</b><br>
In addition to instance constructors, the CLR also supports type constructors (also known as <br><i>static constructors</i>, <i>class constructors</i>, or <i>type initializers</i>). A type constructor can be applied to <br>interfaces (although C# doesn't allow this), reference types, and value types. Just as instance <br>constructors are used to set the initial state of an instance of a type, type constructors are <br>used to set the initial state of a type. By default, types don't have a type constructor defined <br>within them. If a type has a type constructor, it can have no more than one. In addition, type <br>constructors never have parameters. In C#, here's how to define a reference type and a value <br>type that have type constructors:<br>
internal sealed class SomeRefType {  <br>   static SomeRefType() {  <br>      // This executes the first time a SomeRefType is accessed.  <br>   }  <br>}  <br>  <br>internal struct SomeValType {  <br>   // C# does allow value types to define parameterless type constructors.  <br>   static SomeValType() {  <br>      // This executes the first time a SomeValType is accessed.  <br>   }  <br>}<br>
You'll notice that you define type constructors just as you would parameterless instance con-<br>structors, except that you must mark them as static. Also, type constructors should always <br>be private; C# makes them private for you automatically. In fact, if you explicitly mark a <br>type constructor as private (or anything else) in your source code, the C# compiler issues the <br>fol owing error: &quot;error CS0515: 'SomeValType.SomeValType()': access modifiers are <br>not allowed on static constructors.&quot; Type constructors should be private to prevent <br>
<hr>
<A name=213></a><IMG src="CLRviaCsharp-213_1.jpg"><br>
<b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>195</b><br>
any developer-written code from calling them; the CLR is always capable of calling a type <br>constructor.<br>
<b>Important  </b>While you can define a type constructor within a value type, you should never actu-<br>ally do this because there are times when the CLR will not call a value type's static type construc-<br>tor. Here is an example:<br>
internal struct SomeValType {  <br>   static SomeValType() {  <br>      Console.WriteLine(&quot;This never gets displayed&quot;);  <br>   }  <br>   public Int32 m_x;  <br>}  <br>  <br>public sealed class Program {  <br>   public static void Main() {  <br>      SomeValType[] a = new SomeValType[10];  <br>      a[0].m_x = 123;  <br>      Console.WriteLine(a[0].m_x);   // Displays 123  <br>   }  <br>}<br>
The calling of a type constructor is a tricky thing. When the just-in-time (JIT) compiler is <br>compiling a method, it sees what types are referenced in the code. If any of the types define <br>a type constructor, the JIT compiler checks if the type's type constructor has already been <br>executed for this AppDomain. If the constructor has never executed, the JIT compiler emits a <br>call to the type constructor into the native code that the JIT compiler is emitting. If the type <br>constructor for the type has already executed, the JIT compiler does not emit the call since it <br>knows that the type is already initialized. (For an example of this, see the "Type Constructor <br>Performance" section later in this chapter.)<br>
Now, after the method has been JIT-compiled, the thread starts to execute it and will eventu-<br>ally get to the code that calls the type constructor. In fact, it is possible that multiple threads <br>will be executing the same method concurrently. The CLR wants to ensure that a type's con-<br>structor executes only once per AppDomain. To guarantee this, when a type constructor is <br>called, the calling thread acquires a mutually exclusive thread synchronization lock. So if  <br>multiple threads attempt to simultaneously call a type's static constructor, only one thread <br>will acquire the lock and the other threads will block. The first thread will execute the code <br>in the static constructor. After the first thread leaves the constructor, the waiting threads will <br>wake up and will see that the constructor's code has already been executed. These threads <br>will not execute the code again; they will simply return from the constructor method. In  <br>addition, if any of these methods ever get called again, the CLR knows that the type  <br>constructor has already executed and will ensure that the constructor is not called again.<br>
<hr>
<A name=214></a><IMG src="CLRviaCsharp-214_1.jpg"><br>
<IMG src="CLRviaCsharp-214_2.jpg"><br>
<b>196 </b><br>
<b>Part II  Designing Types</b><br>
<b>Note  </b>Since the CLR guarantees that a type constructor executes only once per AppDomain and <br>is thread-safe, a type constructor is a great place to initialize any singleton objects required by <br>the type.<br>
Within a single thread, there is a potential problem that can occur if two type constructors <br>contain code that reference each other. For example, ClassA has a type constructor contain-<br>ing code that references ClassB, and ClassB has a type constructor containing code that <br>references ClassA. In this situation, the CLR still guarantees that each type constructor's code <br>executes only once; however, it cannot guarantee that ClassA's type constructor code has run <br>to completion before executing ClassB's type constructor. You should certainly try to avoid <br>writing code that sets up this scenario. In fact, since the CLR is responsible for calling type <br>constructors, you should always avoid writing any code that requires type constructors to be <br>called in a specific order.<br>
Finally, if a type constructor throws an unhandled exception, the CLR considers the type <br>to be unusable. Attempting to access any fields or methods of the type will cause a  <br>System.TypeInitializationException to be thrown.<br>
The code in a type constructor has access only to a type's static fields, and its usual purpose <br>is to initialize those fields. As it does with instance fields, C# offers a simple syntax that allows <br>you to initialize a type's static fields:<br>
internal sealed class SomeType {  <br>   private static Int32 s_x = 5;  <br>}<br>
<b>Note  </b>While C# doesn't allow a value type to use inline field initialization syntax for instance <br>fields, it does allow you to use it for static fields. In other words, if you change the SomeType <br>type above from a class to a struct, the code will compile and work as expected.<br>
When this code is built, the compiler automatically generates a type constructor for <br>SomeType. It's as if the source code had originally been written as follows:<br>
internal sealed class SomeType {  <br>   private static Int32 s_x;  <br>   static SomeType() { s_x = 5; }  <br>}<br>
Using ILDasm.exe, it's easy to verify what the compiler actually produced by examining the  <br>IL for the type constructor. Type constructor methods are always called .cctor (for <i>class  <br>constructor</i>) in a method definition metadata table.<br>
In the code below, you see that the .cctor method is private and static. In addition,  <br>notice that the code in the method does in fact load a 5 into the static field s_x.<br>
<hr>
<A name=215></a><IMG src="CLRviaCsharp-215_1.jpg"><br>
<IMG src="CLRviaCsharp-215_2.jpg"><br>
<b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>197</b><br>
.method private hidebysig specialname rtspecialname static  <br>        void  .cctor() cil managed <br>{ <br>  // Code size       7 (0x7) <br>  .maxstack  8 <br>  IL_0000:  ldc.i4.5 <br>  IL_0001:  stsfld     int32 SomeType::s_x <br>  IL_0006:  ret <br>} // end of method SomeType::.cctor<br>
Type constructors shouldn't call a base type's type constructor. Such a call isn't necessary  <br>because none of a type's static fields is shared or inherited from its base type.<br>
<b>Note  </b>Some languages, such as Java, expect that accessing a type causes its type  <br>constructor and all of its base type's type constructors to be called. In addition, interfaces  <br>implemented by the types must also have their type constructors called. The CLR doesn't  <br>offer this behavior. However, the CLR does offer compilers and developers the ability to  <br>provide this behavior via the RunClassConstructor method offered by the  <br>System.Runtime.CompilerServices.RuntimeHelpers type. Any language that requires  <br>this behavior would have its compiler emit code into a type's type constructor that calls this <br>method for all base types. When using the RunClassConstructor method to call a type  <br>constructor, the CLR knows if the type constructor has executed previously and, if it has, the  <br>CLR won't call it again.<br>
Finally, assume that you have this code:<br>
internal sealed class SomeType {  <br>   private static Int32 s_x = 5;  <br>  <br>   static SomeType() {  <br>      s_x = 10;  <br>   }  <br>}<br>
In this case, the C# compiler generates a single type constructor method. This constructor <br>first initializes s_x to 5 and then initializes s_x to 10. In other words, when the C# compiler <br>generates IL code for the type constructor, it first emits the code required to initialize the <br>static fields followed by the explicit code contained in your type constructor method.<br>
<b>Important  </b>Developers occasionally ask me if there's a way to get some code to execute when  <br>a type is unloaded. You should first know that types are unloaded only when the AppDomain  <br>unloads. When the AppDomain unloads, the object that identifies the type becomes unreachable, <br>and the garbage collector reclaims the type object's memory. This behavior leads many developers <br>to believe that they could add a static Finalize method to the type, which will automatically <br>get called when the type is unloaded. Unfortunately, the CLR doesn't support static Finalize <br>methods. All is not lost, however. If you want some code to execute when an AppDomain  <br>unloads, you can register a callback method with the System.AppDomain type's DomainUnload <br>event.<br>
<hr>
<A name=216></a><b>198 </b><br>
<b>Part II  Designing Types</b><br>
<b>Type Constructor Performance</b><br>
In the previous section, I mentioned that calling a type constructor is a tricky thing. And I <br>explained some of the trickiness about it: the JIT compiler has to decide whether to emit the <br>code to call it, and the CLR ensures that calls to it are thread-safe. As it turns out, this is the <br>just the beginning of the tricky stuff. There is more about this that is performance-related.<br>
As discussed already, when compiling a method, the JIT compiler determines whether it must <br>emit a call to execute a type constructor into the method. If the JIT compiler decides to emit <br>the call, it must decide where it should emit the call. There are two possibilities here:<br>
  The JIT compiler can emit the call immediately before code that would create the first <br>
instance of the type or immediately before code that accesses a noninherited field <br>or member of the class. This is called <i>precise</i> semantics because the CLR will call the <br>type constructor at precisely the right time.<br>
  The JIT compiler can emit the call sometime before code first accesses a static field or a <br>
static or instance method, or invokes an instance constructor. This is called <i>before-field-<br>init</i> semantics because the CLR guarantees only that the static constructor will run some <br>time before the member is accessed; it could run much earlier.<br>
The before-field-init semantics is preferred since it gives the CLR a lot of freedom as to when <br>it can call the type constructor, and the CLR takes advantage of this whenever possible to <br>produce code that executes faster. For example, the CLR might pick different times to call the <br>type constructor based on whether the type is loaded in an AppDomain or loaded domain-<br>neutral or whether the code is being JIT-compiled or NGen'd.<br>
By default, language compilers choose which of these semantics makes the most sense for <br>the type you're defining and informs the CLR of this choice by setting the beforefieldinit <br>flag in the row of the type definition metadata table. In this section, I'll focus on what the <br>C# compiler does and how this impacts performance. Let's start by examining the following <br>code:<br>
using System;  <br>using System.Diagnostics;  <br>  <br>///////////////////////////////////////////////////////////////////////////////  <br>  <br>// Since this class doesn't explicitly define a type constructor,  <br>// C# marks the type definition with BeforeFieldInit in the metadata.  <br>internal sealed class BeforeFieldInit {  <br>   public static Int32 s_x = 123;  <br>}  <br>  <br>// Since this class does explicitly define a type constructor,  <br>// C# doesn't mark the type definition with BeforeFieldInit in the metadata.  <br>internal sealed class Precise {  <br>   public static Int32 s_x;  <br>
<hr>
<A name=217></a><b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>199</b><br>
   static Precise() { s_x = 123; }  <br>}  <br>  <br>///////////////////////////////////////////////////////////////////////////////  <br>  <br>public sealed class Program {  <br>   public static void Main() {  <br>      const Int32 iterations = 1000 * 1000 * 1000;  <br>      PerfTest1(iterations);  <br>      PerfTest2(iterations);  <br>   }  <br>  <br>  <br>   // When this method is JIT compiled, the type constructors for  <br>   // the BeforeFieldInit and Precise classes HAVE NOT executed yet   <br>   // and therefore, calls to these constructors are embedded in   <br>   // this method's code, making it run slower  <br>   private static void PerfTest1(Int32 iterations) {  <br>      Stopwatch sw = Stopwatch.StartNew();  <br>      for (Int32 x = 0; x &lt; iterations; x++) {  <br>         // The JIT compiler hoists the code to call BeforeFieldInit's   <br>         // type constructor so that it executes before the loop starts  <br>         BeforeFieldInit.s_x = 1;  <br>      }  <br>      Console.WriteLine(&quot;PerfTest1: {0} BeforeFieldInit&quot;, sw.Elapsed);  <br>  <br>      sw = Stopwatch.StartNew();  <br>      for (Int32 x = 0; x &lt; iterations; x++) {  <br>         // The JIT compiler emits the code to call Precise's   <br>         // type constructor here so that it checks whether it  <br>         // has to call the constructor with each loop iteration  <br>         Precise.s_x = 1;  <br>      }  <br>      Console.WriteLine(&quot;PerfTest1: {0} Precise&quot;, sw.Elapsed);  <br>   }  <br>  <br>   // When this method is JIT compiled, the type constructors for  <br>   // the BeforeFieldInit and Precise classes HAVE executed   <br>   // and therefore, calls to these constructors are NOT embedded   <br>   // in this method's code, making it run faster  <br>   private static void PerfTest2(Int32 iterations) {  <br>      Stopwatch sw = Stopwatch.StartNew();  <br>      for (Int32 x = 0; x &lt; iterations; x++) {  <br>         BeforeFieldInit.s_x = 1;  <br>      }  <br>      Console.WriteLine(&quot;PerfTest2: {0} BeforeFieldInit&quot;, sw.Elapsed);  <br>  <br>      sw = Stopwatch.StartNew();  <br>      for (Int32 x = 0; x &lt; iterations; x++) {  <br>         Precise.s_x = 1;  <br>      }  <br>      Console.WriteLine(&quot;PerfTest2: {0} Precise&quot;, sw.Elapsed);  <br>   }  <br>}  <br>  <br>////////////////////////////// End of File ////////////////////////////////////<br>
<hr>
<A name=218></a><b>200 </b><br>
<b>Part II  Designing Types</b><br>
When I build and run the code above, I get the following output:<br>
PerfTest1: 00:00:01.9619358 BeforeFieldInit  <br>PerfTest1: 00:00:06.2374912 Precise  <br>PerfTest2: 00:00:03.1576608 BeforeFieldInit  <br>PerfTest2: 00:00:03.1557822 Precise<br>
When the C# compiler sees a class with static fields that use inline initialization (the <br>BeforeFieldInit class), the compiler emits the class's type definition table entry with <br>the BeforeFieldInit metadata flag. When the C# compiler sees a class with an explicit type <br>constructor (the Precise class), the compiler emits the class's type definition table entry <br>without the BeforeFieldInit metadata flag. The rationale behind this is as follows: initial-<br>ization of static fields needs to be done before the fields are accessed, whereas an explicit <br>type constructor can contain arbitrary code that can have observable side effects; this code <br>may need to run at a precise time.<br>
As you can see from the output, this decision comes with a huge performance impact. When <br>PerfTest1 runs, the top loop executes in about 1.96 seconds versus the bottom loop, which <br>took about 6.24 seconds to run--the bottom loop took about 3 times longer to execute. <br>When PerfTest2 runs, the times are much closer in value because the JIT compiler knew <br>that the types' constructors were already called, and therefore the native code doesn't  <br>contain any calls to the type constructor methods.<br>
It would be nice if C# gave programmers the ability to set the BeforeFieldInit flag  <br>explicitly in their source code instead of the compiler making this decision based on whether <br>a type constructor is created implicitly or explicitly. This way, developers would have more <br>direct control over the performance and semantics of their code.<br>
<b>Operator Overload Methods</b><br>
Some programming languages allow a type to define how operators should manipulate  <br>instances of the type. For example, a lot of types (such as System.String,<b> </b>System.Decimal,<b> <br></b>and<b> </b>System.DateTime) overload the equality (==) and inequality (!=) operators. The CLR <br>doesn't know anything about operator overloading because it doesn't even know what an <br>operator is. Your programming language defines what each operator symbol means and <br>what code should be generated when these special symbols appear.<br>
For example, in C#, applying the + symbol to primitive numbers causes the compiler to  <br>generate code that adds the two numbers together. When the + symbol is applied to String <br>objects, the C# compiler generates code that concatenates the two strings together. For  <br>inequality, C# uses the != symbol, while Microsoft Visual Basic uses the &lt;&gt; symbol. Finally, <br>the ^ symbol means exclusive OR (XOR) in C#, but it means exponent in Visual Basic.<br>
<hr>
<A name=219></a><b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>201</b><br>
Although the CLR doesn't know anything about operators, it does specify how languages <br>should expose operator overloads so that they can be readily consumed by code written in <br>a different programming language. Each programming language gets to decide for itself <br>whether it will support operator overloads, and if it does, the syntax for expressing and using <br>them. As far as the CLR is concerned, operator overloads are simply methods.<br>
Your choice of programming language determines whether or not you get the support of <br>operator overloading and what the syntax looks like. When you compile your source code, <br>the compiler produces a method that identifies the behavior of the operator. The CLR  <br>specification mandates that operator overload methods be public<b> </b>and static methods. In  <br>addition, C# (and many other languages) requires that at least one of the operator method's <br>parameters must be the same as the type that the operator method is defined within. The <br>reason for this restriction is that it enables the C# compiler to search for a possible operator <br>method to bind to in a reasonable amount of time.<br>
Here is an example of an operator overload method defined in a C# class definition:<br>
public sealed class Complex {  <br>   public static Complex operator+(Complex c1, Complex c2) { ... }  <br>}<br>
The compiler emits a metadata method definition entry for a method called op_Addition;<b> <br></b>the method definition entry also has the specialname<b> </b>flag set, indicating that this is a  <br>"special" method. When language compilers (including the C# compiler) see a + operator <br>specified in source code, they look to see if one of the operand's types defines a  <br>specialname method called op_Addition<b> </b>whose parameters are compatible with the  <br>operand's types. If this method exists, the compiler emits code to call this method. If no  <br>such method exists, a compilation error occurs.<br>
Tables 8-1 and 8-2 show the set of unary and binary operators that C# supports being over-<br>loaded, their symbols, and the corresponding Common Language Specification (CLS) method <br>name that the compiler emits. I'll explain the tables' third columns in the next section.<br>
<b>TABLE 8-1  C# Unary Operators and Their CLS-Compliant Method Names</b><br>
<b>C# Operator </b><br>
<b>Suggested CLS-Compliant  </b><br>
<b>Symbol</b><br>
<b>Special Method Name</b><br>
<b>Method Name</b><br>
+<br>
op_UnaryPlus<br>
Plus<br>
-<br>
op_UnaryNegation<br>
Negate<br>
!<br>
op_LogicalNot<br>
Not<br>
~<br>
op_OnesComplement<br>
OnesComplement<br>
++<br>
op_Increment<br>
Increment<br>
--<br>
op_Decrement<br>
Decrement<br>
 (none)<br>
op_True<br>
IsTrue { get; }<br>
 (none)<br>
op_False<br>
IsFalse { get; }<br>
<hr>
<A name=220></a><IMG src="CLRviaCsharp-220_1.jpg"><br>
<b>202 </b><br>
<b>Part II  Designing Types</b><br>
<b>TABLE 8-2  C# Binary Operators and Their CLS-Compliant Method Names</b><br>
<b>C# Operator </b><br>
<b>Suggested CLS-Compliant  </b><br>
<b>Symbol</b><br>
<b>Special Method Name</b><br>
<b>Method Name</b><br>
+<br>
op_Addition<br>
Add<br>
-<br>
op_Subtraction<br>
Subtract<br>
*<br>
op_Multiply<br>
Multiply<br>
/<br>
op_Division<br>
Divide<br>
%<br>
op_Modulus<br>
Mod<br>
&amp;<br>
op_BitwiseAnd<br>
BitwiseAnd<br>
|<br>
op_BitwiseOr<br>
BitwiseOr<br>
^<br>
op_ExclusiveOr<br>
Xor<br>
&lt;&lt;<br>
op_LeftShift<br>
LeftShift<br>
&gt;&gt;<br>
op_RightShift<br>
RightShift<br>
==<br>
op_Equality<br>
Equals<br>
!=<br>
op_Inequality<br>
Compare<br>
&lt;<br>
op_LessThan<br>
Compare<br>
&gt;<br>
op_GreaterThan<br>
Compare<br>
&lt;=<br>
op_LessThanOrEqual<br>
Compare<br>
&gt;=<br>
op_GreaterThanOrEqual<br>
Compare<br>
The CLR specification defines many additional operators that can be overloaded, but C# does <br>not support these additional operators. Therefore, they are not in mainstream use, so I will <br>not list them here. If you are interested in the complete list, please see the ECMA specifica-<br>tions (www.ecma-international.org/publications/standards/Ecma-335.htm) for the Common <br>Language Infrastructure (CLI), Partition I, Concepts and Architecture, Sections 10.3.1 (unary <br>operators) and 10.3.2 (binary operators).<br>
<b>Note  </b>If you examine the core numeric types (Int32,<b> </b>Int64,<b> </b>UInt32,<b> </b>and so on) in the <br>Framework Class Library (FCL), you'll see that they don't define any operator overload methods. <br>The reason they don't is that compilers look specifically for operations on these primitive types <br>and emit IL instructions that directly manipulate instances of these types. If the types were to <br>offer methods and if compilers were to emit code to call these methods, a run-time performance <br>cost would be associated with the method call. Plus, the method would ultimately have to execute <br>some IL instructions to perform the expected operation anyway. This is the reason why the core <br>FCL types don't define any operator overload methods. Here's what this means to you: If the  <br>programming language you're using doesn't support one of the core FCL types, you won't be <br>able to perform any operations on instances of that type.<br>
<hr>
<A name=221></a><hr>
<A name=222></a><hr>
<A name=223></a><b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>205</b><br>
   // Convert a Rational to an Int32  <br>   public Int32 ToInt32() { ... }  <br>  <br>   // Convert a Rational to a Single  <br>   public Single ToSingle() { ... }  <br>}<br>
By invoking these constructors and methods, a developer using any programming language <br>can convert an Int32 or a Single object to a Rational object and convert a Rational  <br>object to an Int32 or a Single object. The ability to do these conversions can be quite <br>handy, and when designing a type, you should seriously consider what conversion construc-<br>tors and methods make sense for your type.<br>
In the previous section, I discussed how some programming languages offer operator over-<br>loading. Well, some programming languages (such as C#) also offer conversion operator <br>overloading. <i>Conversion operators</i> are methods that convert an object from one type to <br>another type. You define a conversion operator method by using special syntax. The CLR <br>specification mandates that conversion overload methods be public and static methods. <br>In addition, C# (and many other languages) requires that either the parameter or the return <br>type must be the same as the type that the conversion method is defined within. The reason <br>for this restriction is that it enables the C# compiler to search for a possible operator method <br>to bind to in a reasonable amount of time. The following code adds four conversion operator <br>methods to the Rational type:<br>
public sealed class Rational {  <br>   // Constructs a Rational from an Int32  <br>   public Rational(Int32 num) { ... }  <br>  <br>   // Constructs a Rational from a Single  <br>   public Rational(Single num) { ... }  <br>  <br>   // Convert a Rational to an Int32  <br>   public Int32 ToInt32() { ... }  <br>  <br>   // Convert a Rational to a Single  <br>   public Single ToSingle() { ... } <br>   <br>   // Implicitly constructs and returns a Rational from an Int32  <br>   public static implicit operator Rational(Int32 num) {   <br>      return new Rational(num);   <br>   }  <br>  <br>   // Implicitly constructs and returns a Rational from a Single  <br>   public static implicit operator Rational(Single num) {   <br>      return new Rational(num);  <br>   }  <br>  <br>   // Explicitly returns an Int32 from a Rational  <br>   public static explicit operator Int32(Rational r) {   <br>      return r.ToInt32();   <br>   }  <br>  <br>
<hr>
<A name=224></a><b>206 </b><br>
<b>Part II  Designing Types</b><br>
   // Explicitly returns a Single from a Rational  <br>   public static explicit operator Single(Rational r) {   <br>      return r.ToSingle();  <br>   }  <br>}<br>
For conversion operator methods, you must indicate whether a compiler can emit code to <br>call a conversion operator method implicitly or whether the source code must explicitly  <br>indicate when the compiler is to emit code to call a conversion operator method. In C#, you <br>use the implicit keyword to indicate to the compiler that an explicit cast doesn't have to <br>appear in the source code in order to emit code that calls the method. The explicit<b> </b>keyword <br>allows the compiler to call the method only when an explicit cast exists in the source code.<br>
After the implicit or explicit keyword, you tell the compiler that the method is a conver-<br>sion operator by specifying the operator keyword. After the operator<b> </b>keyword, you specify <br>the type that an object is being cast to; in the parentheses, you specify the type that an  <br>object is being cast from.<br>
Defining the conversion operators in the preceding Rational<b> </b>type allows you to write code <br>like this (in C#):<br>
public sealed class Program {  <br>   public static void Main() {  <br>      Rational r1 = 5;         // Implicit cast from Int32  to Rational  <br>      Rational r2 = 2.5F;      // Implicit cast from Single to Rational  <br>  <br>      Int32  x = (Int32)  r1;  // Explicit cast from Rational to Int32  <br>      Single s = (Single) r2;  // Explicit cast from Rational to Single  <br>   }  <br>}<br>
Under the covers, the C# compiler detects the casts (type conversions) in the code and inter-<br>nally generates IL code that calls the conversion operator methods defined by the Rational<b> <br></b>type. But what are the names of these methods? Well, compiling the Rational type and <br>examining its metadata shows that the compiler produces one method for each conversion <br>operator defined. For the Rational type, the metadata for the four conversion operator <br>methods looks like this:<br>
public static Rational op_Implicit(Int32 num)  <br>public static Rational op_Implicit(Single num)  <br>public static Int32    op_Explicit(Rational r)  <br>public static Single   op_Explicit(Rational r)<br>
As you can see, methods that convert an object from one type to another are always named <br>op_Implicit or op_Explicit. You should define an implicit conversion operator only when <br>precision or magnitude isn't lost during a conversion, such as when converting an Int32 to a <br>Rational. However, you should define an explicit conversion operator if precision or magni-<br>tude is lost during the conversion, as when converting a Rational object to an Int32.<b> </b>If an <br>
<hr>
<A name=225></a><IMG src="CLRviaCsharp-225_1.jpg"><br>
<IMG src="CLRviaCsharp-225_2.jpg"><br>
<b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>207</b><br>
explicit conversion fails, you should indicate this by having your explicit conversion operator <br>method throw an OverflowException or an InvalidOperationException.<br>
<b>Note  </b>The two op_Explicit methods take the same parameter, a Rational. However, the <br>methods differ by their return value, an Int32 and a Single. This is an example of two methods <br>that differ only by their return type.  The CLR fully supports the ability for a type to define mul-<br>tiple methods that differ only by return type. However, very few languages expose this ability. As <br>you're probably aware, C++, C#, Visual Basic, and Java are all examples of languages that don't <br>support the definition of multiple methods that differ only by their return type. A few languages <br>(such as IL assembly language) allow the developer to explicitly select which of these methods <br>to call. Of course, IL assembly language programmers shouldn't take advantage of this ability <br>because the methods they define can't be callable from other programming languages. Even <br>though C# doesn't expose this ability to the C# programmer, the compiler does take advantage <br>of this ability internally when a type defines conversion operator methods.<br>
C# has full support for conversion operators. When it detects code where you're using an <br>object of one type and an object of a different type is expected, the compiler searches for an <br>implicit conversion operator method capable of performing the conversion and generates <br>code to call that method. If an implicit conversion operator method exists, the compiler emits <br>a call to it in the resulting IL code. If the compiler sees source code that is explicitly casting <br>an object from one type to another type, the compiler searches for an implicit or explicit <br>conversion operator method. If one exists, the compiler emits the call to the method. If the <br>compiler can't find an appropriate conversion operator method, it issues an error and doesn't <br>compile the code.<br>
<b>Note  </b>C# generates code to invoke explicit conversion operators when using a cast expression; <br>they are never invoked when using C#'s as or is operators.<br>
To really understand operator overload methods and conversion operator methods, I strongly <br>encourage you to examine the System.Decimal type as a role model. Decimal<b> </b>defines  <br>several constructors that allow you to convert objects from various types to a Decimal. It also <br>offers several ToXxx methods that let you convert a Decimal object to another type. Finally, <br>the type defines several conversion operators and operator overload methods as well.<br>
<b>Extension Methods</b><br>
The best way to understand C#'s <i>extension methods</i> feature is by way of an example. In the <br>"StringBuilder Members" section in Chapter 14, "Chars, Strings, and Working with Text," I <br>mention how the StringBuilder class offers fewer methods than the String class for  <br>manipulating a string and how strange this is, considering that the StringBuilder class is <br>the preferred way of manipulating a string because it is mutable. So, let's say that you would <br>
<hr>
<A name=226></a><b>208 </b><br>
<b>Part II  Designing Types</b><br>
like to define some of these missing methods yourself to operate on a StringBuilder. For <br>example, you might want to define your own IndexOf<b> </b>method as follows:<br>
public static class StringBuilderExtensions { <br>   public static Int32 IndexOf(StringBuilder sb, Char value) { <br>      for (Int32 index = 0; index &lt; sb.Length; index++) <br>         if (sb[index] == value) return index; <br>      return -1; <br>   } <br>}<br>
Now that you have defined this method, you can use it as the following code demonstrates:<br>
StringBuilder sb = new StringBuilder(&quot;Hello. My name is Jeff.&quot;);   // The initial string <br> <br>// Change period to exclamation and get # characters in 1st sentence (5). <br>Int32 index = StringBuilderExtensions.IndexOf(sb.Replace('.', '!'), '!');<br>
This code works just fine, but is it not ideal from a programmer's perspective. The first prob-<br>lem is that a programmer who wants to get the index of a character within a StringBuilder <br>must know that the StringBuilderExtensions class even exists. The second problem is <br>that the code does not reflect the order of operations that are being performed on the <br>StringBuilder object, making the code difficult to write, read, and maintain. The program-<br>mer wants to call Replace first and then call IndexOf; but when you read the last line of <br>code from left to right, IndexOf appears first on the line and Replace appears second. Of <br>course, you could alleviate this problem and make the code's behavior more understandable <br>by rewriting it like this:<br>
// First, change period to exclamation mark <br>sb.Replace(`.', `!'); <br> <br>// Now, get # characters in 1st sentence (5) <br>Int32 index = StringBuilderExtensions.IndexOf(sb, `!');<br>
However, a third problem exists with both versions of this code that affects understanding  <br>the code's behavior. The use of StringBuilderExtensions is overpowering and detracts  <br>a programmer's mind from the operation that is being performed: IndexOf.<b> </b>If the <br>StringBuilder class had defined its own IndexOf method, then we could rewrite the code <br>above as follows:<br>
// Change period to exclamation and get # characters in 1st sentence (5). <br>Int32 index = sb.Replace('.', '!').IndexOf('!');<br>
Wow, look how great this is in terms of code maintainability! In the StringBuilder object, <br>we're going to replace a period with an exclamation mark and then find the index of the  <br>exclamation mark.<br>
<hr>
<A name=227></a><b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>209</b><br>
Now, I can explain what C#'s extension methods feature does. It allows you to define a static <br>method that you can invoke using instance method syntax. Or, in other words, we can now <br>define our own IndexOf method and the three problems mentioned above go away. To turn <br>the IndexOf method into an extension method, we simply add the this keyword before the <br>first argument:<br>
public static class StringBuilderExtensions { <br>   public static Int32 IndexOf(this StringBuilder sb, Char value) { <br>      for (Int32 index = 0; index &lt; sb.Length; index++) <br>         if (sb[index] == value) return index; <br>      return -1; <br>   } <br>}<br>
Now, when the compiler sees code like this:<br>
Int32 index = sb.IndexOf('X');<br>
the compiler first checks if the StringBuilder class or any of its base classes offers an  <br>instance method called IndexOf that takes a single Char parameter. If an existing instance <br>method exists, then the compiler produces IL code to call it. If no matching instance method <br>exists, then the compiler will look at any static classes that define static methods called <br>IndexOf that take as their first parameter a type matching the type of the expression being <br>used to invoke the method. This type must also be marked with the this keyword. In this <br>example, the expression is sb,<b> </b>which is of the StringBuilder type. In this case, the compiler <br>is looking specifically for an IndexOf method that takes two parameters: a StringBuilder <br>(marked with the this keyword) and a Char.<b> </b>The compiler will find our IndexOf method and <br>produce IL code that calls our static method.<br>
OK--so this now explains how the compiler improves the last two problems related to code <br>understandability that I mentioned earlier. However, I haven't yet addressed the first problem: <br>how does a programmer know that an IndexOf method even exists that can operate on a <br>StringBuilder object? The answer to this question is found in Microsoft Visual Studio's <br>Intellisense feature. In the editor, when you type a period, Visual Studio's IntelliSense window <br>opens to show you the list of instance methods that are available. Well, that IntelliSense win-<br>dow also shows you any extension methods that exist for the type of expression you have to <br>the left of the period. Figure 8-1 shows Visual Studio's IntelliSense window; the icon for an <br>extension method has a down arrow next to it, and the tooltip next to the method indicates <br>that the method is really an extension method. This is truly awesome because it is now easy <br>to define your own methods to operate on various types of objects and have other program-<br>mers discover your methods naturally when using objects of these types.<br>
<hr>
<A name=228></a><b>210 </b><br>
<b>Part II  Designing Types</b><br>
<b>FIGURE 8-1  </b>Visual Studio's IntelliSense window, showing extension methods<br>
<b>Rules and Guidelines</b><br>
There are some additional rules and guidelines that you should know about extension <br>methods:<br>
  C# supports extension methods only; it does not offer extension properties, extension <br>
events, extension operators, and so on.<br>
  Extension methods (methods with this before their first argument) must be declared <br>
in non-generic, static classes. However, there is no restriction on the name of the class; <br>you can call it whatever you want. Of course, an extension method must have at least <br>one parameter, and only the first parameter can be marked with the this keyword.<br>
  The C# compiler looks only for extension methods defined in static classes that are <br>
themselves defined at the file scope. In other words, if you define the static class <br>nested within another class, the C# compiler will emit the following message: &quot;error <br>CS1109: Extension method must be defined in a top-level static class; <br>StringBuilderExtensions is a nested class.&quot;<br>
  Since the static classes can have any name you want, it takes the C# compiler time to <br>
find extension methods as it must look at all the file-scope static classes and scan their <br>static methods for a match. To improve performance and also to avoid considering an <br>extension method that you may not want, the C# compiler requires that you "import" <br>extension methods. For example, if someone has defined a StringBuilderExtensions <br>class in a Wintellect namespace, then a programmer who wants to have access to this <br>class's extension methods must put a using Wintellect; directive at the top of his or <br>her source code file.<br>
<hr>
<A name=229></a><b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>211</b><br>
  It is possible that multiple static classes could define the same extension method.  <br>
If the compiler detects that two or more extension methods exist, then the  <br>compiler issues the following message: &quot;error CS0121: The call is ambiguous <br>between the following methods or properties: 'StringBuilderExtensions.<br>IndexOf(string, char)' and 'AnotherStringBuilderExtensions.<br>IndexOf(string, char)'.&quot; To fix this error, you must modify your source code. <br>Specifically, you cannot use the instance method syntax to call this static method any-<br>more; instead you must now use the static method syntax where you explicitly indicate <br>the name of the static class to explicitly tell the compiler which method you want to <br>invoke.<br>
  You should use this feature sparingly, as not all programmers are familiar with it. For ex-<br>
ample, when you extend a type with an extension method, you are actually extending <br>derived types with this method as well. Therefore, you should not define an extension <br>method whose first parameter is System.Object, as this method will be callable for all <br>expression types and this will really pollute Visual Studio's IntelliSense window.<br>
  There is a potential versioning problem that exists with extension methods. If, in the <br>
future, Microsoft adds an IndexOf instance method to their StringBuilder class with <br>the same prototype as my code is attempting to call, then when I recompile my code, <br>the compiler will bind to Microsoft's IndexOf instance method instead of my static <br>IndexOf method. Because of this, my program will experience different behavior. This <br>versioning problem is another reason why this feature should be used sparingly.<br>
<b>Extending Various Types with Extension Methods</b><br>
In this chapter, I demonstrated how to define an extension method for a class, <br>StringBuilder. I'd like to point out that since an extension method is really the invocation <br>of a static method, the CLR does not emit code ensuring that the value of the expression <br>used to invoke the method is not null:<br>
// sb is null <br>StringBuilder sb = null; <br> <br>// Calling extension method: NullReferenceException will NOT be thrown when calling IndexOf <br>// NullReferenceException will be thrown inside IndexOf's for loop <br>sb.IndexOf('X'); <br> <br>// Calling instance method: NullReferenceException WILL be thrown when calling Replace <br>sb.Replace('.', '!');<br>
I'd also like to point out that you can define extension methods for interface types as the  <br>following code shows:<br>
public static void ShowItems&lt;T&gt;(this IEnumerable&lt;T&gt; collection) { <br>   foreach (var item in collection)  <br>      Console.WriteLine(item); <br>}<br>
<hr>
<A name=230></a><IMG src="CLRviaCsharp-230_1.jpg"><br>
<b>212 </b><br>
<b>Part II  Designing Types</b><br>
The extension method above can now be invoked using any expression that results in a type <br>that implements the IEnumerable&lt;T&gt; interface:<br>
public static void Main() { <br>   // Shows each Char on a separate line in the console <br>   &quot;Grant&quot;.ShowItems(); <br> <br>   // Shows each String on a separate line in the console <br>   new[] { &quot;Jeff&quot;, &quot;Kristin&quot; }.ShowItems(); <br> <br>   // Shows each Int32 value on a separate line in the console <br>   new List&lt;Int32&gt;() { 1, 2, 3 }.ShowItems(); <br>}<br>
<b>Important  </b>Extension methods are the cornerstone of Microsoft's Language Integrated Query <br>(LINQ) technology. For a great example of a class that offers many extension methods, see the <br>static System.Linq.Enumerable class and all its static extension methods in the Microsoft <br>.NET Framework SDK documentation. Every extension method in this class extends either the <br>IEnumerable or IEnumerable&lt;T&gt; interface.<br>
You can define extension methods for delegate types, too. For an example of this, turn to <br>page 278 in Chapter 11, "Events." You can also add extension methods to enumerated types. <br>I show an example of this in the "Adding Methods to Enumerated Types" section in Chapter 15, <br>"Enumerated Types and Bit Flags."<br>
And last but not least, I want to point out that the C# compiler allows you to create a delegate <br>(see Chapter 17, "Delegates," for more information) that refers to an extension method over <br>an object:<br>
public static void Main () { <br>   // Create an Action delegate that refers to the static ShowItems extension method <br>   // and has the first argument initialized to reference the "Jeff" string.  <br>   Action a = &quot;Jeff&quot;.ShowItems; <br>   . <br>   . <br>   . <br>   // Invoke the delegate which calls ShowItems passing it a reference to the "Jeff" string. <br>   a(); <br>}<br>
In the code above, the C# compiler generates IL code to construct an Action delegate. When <br>creating a delegate, the constructor is passed the method that should be called and is also <br>passed a reference to an object that should be passed to the method's hidden this  <br>parameter. Normally, when you create a delegate that refers to a static method, the object <br>reference is null since static methods don't have a this parameter. However, in this example, <br>the C# compiler generated some special code that creates a delegate that refers to a static <br>method (ShowItems) and the target object of the static method is the reference to the "Jeff" <br>string. Later, when the delegate is invoked, the CLR will call the static method and will pass to <br>
<hr>
<A name=231></a><IMG src="CLRviaCsharp-231_1.jpg"><br>
<b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>213</b><br>
it the reference to the "Jeff" string. This is a little hacky, but it works great and it feels natural <br>so long as you don't think about what is happening internally.<br>
<b>The Extension Attribute</b><br>
It would be best if this concept of extension methods was not C#-specific. Specifically, we <br>want programmers to define a set of extension methods in some programming language <br>and for people in other programming languages to take advantage of them. For this to <br>work, the compiler of choice must support searching static types and methods for potentially <br>matching extension methods. And compilers need to do this quickly so that compilation time <br>is kept to a minimum.<br>
In C#, when you mark a static method's first parameter with the this keyword, the compiler <br>internally applies a custom attribute to the method and this attribute is persisted in the  <br>resulting file's metadata. The attribute is defined in the System.Core.dll assembly, and it looks <br>like this:<br>
// Defined in the System.Runtime.CompilerServices namespace <br>[AttributeUsage(AttributeTargets.Method | AttributeTargets.Class | AttributeTargets.<br>Assembly)] <br>public sealed class ExtensionAttribute : Attribute { <br>}<br>
In addition, this attribute is applied to the metadata for any static class that contains at least <br>one extension method. And this attribute is also applied to the metadata for any assembly <br>that contains at least one static class that contains an extension method. So now, when com-<br>piling code that invokes an instance method that doesn't exist, the compiler can quickly scan <br>all the referenced assemblies to know which ones contain extension methods. Then it can <br>scan only these assemblies for static classes that contain extension methods, and it can scan <br>just the extension methods for potential matches to compile the code as quickly as possible.<br>
<b>Note  </b>The ExtensionAttribute class is defined in the System.Core.dll assembly. This means <br>that the resulting assembly produced by the compiler will have a reference to System.Core.dll <br>embedded in it even if I do not use any types from System.Core.dll and do not even reference <br>System.Core.dll when compiling my code. However, this is not too bad a problem because the <br>ExtensionAttribute is used only at compile time; at runtime, System.Core.dll will not have to <br>be loaded unless the application consumes something else in this assembly.<br>
<b>Partial Methods</b><br>
Imagine that you use a tool that produces a C# source code file containing a type definition.  <br>The tool knows that there are potential places within the code it produces where you might <br>want to customize the type's behavior. Normally, customization would be done by having <br>
<hr>
<A name=232></a><b>214 </b><br>
<b>Part II  Designing Types</b><br>
the tool-produced code invoke virtual methods. The tool-produced code would also have to <br>contain definitions for these virtual methods, and the way these methods would be imple-<br>mented is to do nothing and simply return. Now, if you want to customize the behavior of <br>the class, you'd define your own class, derive it from the base class, and then override any <br>virtual methods implementing it so that it has the behavior you desire. Here is an example:<br>
// Tool-produced code in some source code file: <br>internal class Base { <br>   private String m_name; <br> <br>   // Called before changing the m_name field <br>   protected virtual void OnNameChanging(String value) {  <br>   } <br> <br>   public String Name { <br>      get { return m_name; } <br>      set {  <br>         OnNameChanging(value.ToUpper());  // Inform class of potential change <br>         m_name = value;                   // Change the field <br>      } <br>   } <br>} <br> <br> <br>// Developer-produced code in some other source code file: <br>internal class Derived : Base { <br>   protected override void OnNameChanging(string value) { <br>      if (String.IsNullOrEmpty(value))  <br>         throw new ArgumentNullException(&quot;value&quot;); <br>   } <br>}<br>
Unfortunately, there are two problems with the code above:<br>
  The type must be a class that is not sealed. You cannot use this technique for sealed <br>
classes or for value types (because value types are implicitly sealed). In addition, you <br>cannot use this technique for static methods since they cannot be overridden.<br>
  There are efficiency problems here. A type is being defined just to override a method; <br>
this wastes a small amount of system resources. And, even if you do not want to  <br>override the behavior of OnNameChanging, the base class code still invokes a virtual  <br>method which simply does nothing but return. Also, ToUpper is called whether <br>OnNameChanging accesses the argument passed to it or not.<br>
C#'s partial methods feature allows you the option of overriding the behavior or a type while <br>fixing the aforementioned problems. The code below uses partial methods to accomplish the <br>same semantic as the previous code:<br>
<hr>
<A name=233></a><b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>215</b><br>
// Tool-produced code in some source code file: <br>internal sealed partial class Base { <br>   private String m_name; <br> <br>   // This defining-partial-method-declaration is called before changing the m_name field <br>   partial void OnNameChanging(String value); <br> <br>   public String Name { <br>      get { return m_name; } <br>      set {  <br>         OnNameChanging(value.ToUpper());  // Inform class of potential change <br>         m_name = value;                   // Change the field <br>      } <br>   } <br>} <br> <br>// Developer-produced code in some other source code file: <br>internal sealed partial class Base { <br> <br>   // This implementing-partial-method-declaration is called before m_name is changed  <br>   partial void OnNameChanging(String value) { <br>      if (String.IsNullOrEmpty(value))  <br>         throw new ArgumentNullException(&quot;value&quot;); <br>   } <br>}<br>
There are several things to notice about this new version of the code:<br>
  The class is now sealed (although it doesn't have to be). In fact, the class could be a <br>
static class or even a value type.<br>
  The tool-produced code and the developer-produced code are really two partial defi-<br>
nitions that ultimately make up one type definition. For more information about partial <br>types, see the "Partial Classes, Structures, and Interfaces" section in Chapter 6, "Type <br>and Member Basics."<br>
  The tool-produced code defined a partial method declaration. This method is marked <br>
with the partial token and it has no body.<br>
  The developer-produced code implemented the partial method declaration. This meth-<br>
od is also marked with the partial token and it has a body.<br>
Now, when you compile this code, you see the same effect as the original code I showed you. <br>Again, the big benefit here is that you can rerun the tool and produce new code in a new <br>source code file, but your code remains in a separate file and is unaffected. And, this tech-<br>nique works for sealed classes, static classes, and value types.<br>
<hr>
<A name=234></a><IMG src="CLRviaCsharp-234_1.jpg"><br>
<IMG src="CLRviaCsharp-234_2.jpg"><br>
<b>216 </b><br>
<b>Part II  Designing Types</b><br>
<b>Note  </b>In Visual Studio's editor, if you type in partial and press the spacebar, the IntelliSense <br>window shows you all the enclosing type's defined partial method declarations that do not yet <br>have matching implementing partial method declarations. You can then easily select a partial <br>method from the IntelliSense window and Visual Studio will produce the method prototype for <br>you automatically. This is a very nice feature that enhances productivity.<br>
But, there is another big improvement we get with partial methods. Let's say that you do not <br>need to modify the behavior of the tool-produced type. In this case, you do not supply your <br>source code file at all. If you just compile the tool-produced code by itself, the compiler  <br>produces IL code and metadata as if the tool-produced code looked like this:<br>
// Logical equivalent of tool-produced code if there is no  <br>// implementing partial method declaration: <br>internal sealed class Base { <br>   private String m_name; <br> <br>   public String Name { <br>      get { return m_name; } <br>      set {  <br>         m_name = value;                // Change the field <br>      } <br>   } <br>}<br>
That is, if there is no implementing partial method declaration, the compiler will not emit  <br>any metadata representing the partial method. In addition, the compiler will not emit any IL <br>instructions to call the partial method. And the compiler will not emit code that evaluates any <br>arguments that would have been passed to the partial method. In this example, the compiler <br>will not emit code to call the ToUpper method. The result is that there is less metadata/IL, <br>and the runtime performance is awesome!<br>
<b>Note  </b>Partial methods work similarly to the System.Diagnostics.ConditionalAttribute <br>attribute. However, partial methods work within a single type only while the <br>ConditionalAttribute can be used to optionally invoke methods defined in another type.<br>
<b>Rules and Guidelines</b><br>
There are some additional rules and guidelines that you should know about partial methods:<br>
  They can only be declared within a partial class or struct.<br>
  Partial methods must always have a return type of void, and they cannot have any <br>
parameters marked with the out modifier. These restrictions are in place because at <br>runtime, the method may not exist and so you can't initialize a variable to what the <br>method might return because the method might not exist. Similarly, you can't have an <br>
<hr>
<A name=235></a><b> </b><br>
<b>Chapter 8  Methods </b><br>
<b>217</b><br>
out parameter because the method would have to initialize it and the method might <br>not exist. A partial method may have ref parameters, may be generic, may be instance <br>or static, and may be marked as unsafe.<br>
  Of course, the defining partial method declaration and the implementing partial  <br>
method declaration must have identical signatures. If both have custom attributes  <br>applied to them, then the compiler combines both methods' attributes together. Any <br>attributes applied to a parameter are also combined.<br>
  If there is no implementing partial method declaration, then you cannot have any  <br>
code that attempts to create a delegate that refers to the partial method. Again, the <br>reason is that the method doesn't exist at runtime. The compiler produces this  <br>message: &quot;error CS0762: Cannot create delegate from method  <br>'Base.OnNameChanging(string)' because it is a partial method without  <br>an implementing declaration&quot;.<br>
  Partial methods are always considered to be private methods. However, the C# <br>
compiler forbids you from putting the private keyword before the partial method <br>declaration.<br>
<hr>
<A name=236></a><hr>
<A name=237></a>Chapter 9<br><b>Parameters</b><br>
<b>In this chapter:<br>Optional and Named Parameters. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219<br>Implicitly Typed Local Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223<br>Passing Parameters by Reference to a Method . . . . . . . . . . . . . . . . . . . . . . . . . . . 225<br>Passing a Variable Number of Arguments to a Method. . . . . . . . . . . . . . . . . . . . 231<br>Parameter and Return Type Guidelines . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233<br></b>Const<b>-ness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235</b><br>
This chapter focuses on the various ways of passing parameters to a method, including how <br>to optionally specify parameters, specify parameters by name, and pass parameters by  <br>reference, as well as how to define methods that accept a variable number of arguments.<br>
<b>Optional and Named Parameters</b><br>
When designing a method's parameters, you can assign default values to some of or all the <br>parameters. Then, code that calls these methods can optionally not specify some of the  <br>arguments, thereby accepting the default values. In addition, when you call a method, you <br>can specify arguments by using the name of their parameters. Here is some code that  <br>demonstrates using both optional and named parameters:<br>
public static class Program { <br>   private static Int32 s_n = 0; <br> <br>   private static void M(Int32 x = 9, String s = "A",  <br>      DateTimedt = default(DateTime), Guidguid = new Guid()) { <br> <br>      Console.WriteLine("x={0}, s={1}, dt={2}, guid={3}", x, s, dt, guid); <br>   } <br> <br>   public static void Main() { <br>      // 1. Same as: M(9, &quot;A&quot;, default(DateTime), new Guid()); <br>      M(); <br> <br>      // 2. Same as: M(8, &quot;X&quot;, default(DateTime), new Guid()); <br>      M(8, &quot;X&quot;); <br> <br>      // 3. Same as: M(5, &quot;A&quot;, DateTime.Now, Guid.NewGuid()); <br>      M(5, guid: Guid.NewGuid(), dt: DateTime.Now); <br> <br>
<b> </b><br>
<b> </b><br>
<b>219</b><br>
<hr>
<A name=238></a><b>220 </b><br>
<b>Part II  Designing Types</b><br>
      // 4. Same as: M(0, &quot;1&quot;, default(DateTime), new Guid()); <br>      M(s_n++, s_n++.ToString()); <br> <br>      // 5. Same as: String t1 = &quot;2&quot;; Int32 t2 = 3;  <br>      //             M(t2, t1, default(DateTime), new Guid()); <br>      M(s: (s_n++).ToString(), x: s_n++); <br>   } <br>}<br>
When I run this program, I get the following output:<br>
x=9, s=A, dt=1/1/0001 12:00:00 AM, guid=00000000-0000-0000-0000-000000000000 <br>x=8, s=X, dt=1/1/0001 12:00:00 AM, guid=00000000-0000-0000-0000-000000000000 <br>x=5, s=A, dt=7/2/2009 10:14:25 PM, guid=d24a59da-6009-4aae-9295-839155811309 <br>x=0, s=1, dt=1/1/0001 12:00:00 AM, guid=00000000-0000-0000-0000-000000000000 <br>x=3, s=2, dt=1/1/0001 12:00:00 AM, guid=00000000-0000-0000-0000-000000000000<br>
As you can see, whenever arguments are left out at the call site, the C# compiler embeds the <br>parameter's default value. The third and fifth calls to M use C#'s named parameter feature. In <br>the two calls, I'm explicitly passing a value for x and I'm indicating that I want to pass an  <br>argument for the parameters named guid and dt.<br>
When you pass arguments to a method, the compiler evaluates the arguments from left to <br>right. In the fourth call to M, the value in s_n (0) is passed for x, then s_n is incremented, <br>and s_n (1) is passed as a string for s and then s_n is incremented again to 2. When you <br>pass arguments by using named parameters, the compiler still evaluates the arguments from <br>left to right. In the fifth call to M,<b> </b>the value in s_n (2) is converted to a string and saved in <br>a temporary variable (t1) that the compiler creates. Next, s_n is incremented to 3 and this <br>value is saved in another temporary variable (t2) created by the compiler, and then s_n is <br>incremented again to 4. Ultimately, M is invoked, passing it t2,<b> </b>t1,<b> </b>a default DateTime, and a <br>new Guid.<br>
<b>Rules and Guidelines</b><br>
There are some additional rules and guidelines that you should know about when defining a <br>method that specifies default values for some of its parameters:<br>
  You can specify default values for the parameters of methods, constructor methods, <br>
and parameterful properties (C# indexers). You can also specify default values for  <br>parameters that are part of a delegate definition. Then, when invoking a variable of  <br>this delegate type, you can omit the arguments and accept the default values.<br>
  Parameters with default values must come after any parameters that do not have  <br>
default values. That is, once you define a parameter as having a default value, then all <br>parameters to the right of it must also have default values. For example, in the definition <br>of my M method, I would get a compiler error if I removed the default value (&quot;A&quot;) for <br>s. There is one exception to this rule: a params array parameter (discussed later in this <br>
<hr>
<A name=239></a><b> </b><br>
<b>Chapter 9  Parameters </b><br>
<b>221</b><br>
chapter) must come after all parameters (including those that have default values), and <br>the array cannot have a default value itself.<br>
  Default values must be constant values known at compile time. This means that you <br>
can set default values for parameters of types that C# considers to be primitive types, <br>as shown in Table 5-1 in Chapter 5, "Primitive, Reference, and Value Types." This also <br>includes enumerated types, and any reference type can be set to null.<b> </b>For a parameter <br>of an arbitrary value type, you can set the default value to be an instance of the value <br>type, with all its fields containing zeroes. You can use the default keyword or the new <br>keyword to express this; both syntaxes produce identical Intermediate Language (IL) <br>code. Examples of both syntaxes are used by my M method for setting the default value <br>for the dt parameter and guid parameter, respectively.<br>
  Be careful not to rename parameter variables because any callers who are passing  <br>
arguments by parameter name will have to modify their code. For example, in the  <br>declaration of my M method, if I rename the dt variable to dateTime,<b> </b>then my third  <br>call to M in the earlier code will cause the compiler to produce the following message:  <br>&quot;error CS1739: The best overload for 'M' does not have a parameter <br>named 'dt'.&quot;<br>
  Be aware that changing a parameter's default value is potentially dangerous if the <br>
method is called from outside the module. A call site embeds the default value into its <br>call. If you later change the parameter's default value and do not recompile the code <br>containing the call site, then it will call your method passing the old default value. You <br>might want to consider using a default value of 0/null as a sentinel to indicate default <br>behavior; this allows you to change your default without having to recompile all the <br>code with call sites. Here is an example:<br>
// Don't do this: <br>private static String MakePath(String filename = &quot;Untitled&quot;) { <br>   return String.Format(@&quot;C:\{0}.txt&quot;, filename); <br>} <br> <br>// Do this instead: <br>private static String MakePath(String filename = null) { <br>   // I am using the null-coalescing operator (??) here; see Chapter 19 <br>   return String.Format(@&quot;C:\{0}.txt&quot;, filename ?? &quot;Untitled&quot;); <br>}<br>
  You cannot set default values for parameters marked with either the ref or out key-<br>
words because there is no way to pass a meaningful default value for these parameters.<br>
There are some additional rules and guidelines that you should know about when calling a <br>method using optional or named parameters:<br>
  Arguments can be passed in any order; however, named arguments must always  <br>
appear at the end of the argument list.<br>
<hr>
<A name=240></a><IMG src="CLRviaCsharp-240_1.jpg"><br>
<b>222 </b><br>
<b>Part II  Designing Types</b><br>
  You can pass arguments by name to parameters that do not have default values, but  <br>
all required arguments must be passed (by position or by name) for the compiler to <br>compile the code.<br>
  C# doesn't allow you to omit arguments between commas, as in M(1, ,DateTime.Now), <br>
because this could lead to unreadable comma-counting code. Pass arguments by way <br>of their parameter name if you want to omit some arguments for parameters with  <br>default values.<br>
  To pass an argument by parameter name that requires ref/out,<b> </b>use syntax like this:<br>
// Method declaration: <br>private static void M(ref Int32 x) { ... } <br> <br>// Method invocation: <br>Int32 a = 5; <br>M(x: ref a);<br>
<b>Note  </b>C#'s optional and named parameter features are really convenient when writing C# code <br>that interoperates with the COM object model in Microsoft Office. And, when calling a COM <br>component, C# also allows you to omit ref/out when passing an argument by reference to  <br>simplify the coding even more. When not calling a COM component, C# requires that the  <br>out/ref keyword be applied to the argument.<br>
<b>The </b>DefaultParameterValue<b> and </b>Optional<b> Attributes</b><br>
It would be best if this concept of default and optional arguments was not C#-specific. <br>Specifically, we want programmers to define a method indicating which parameters are  <br>optional and what their default value should be in some programming language and then <br>give programmers working in other programming languages the ability to call them. For this <br>to work, the compiler of choice must allow the caller to omit some arguments and have a <br>way of determining what those arguments' default values should be.<br>
In C#, when you give a parameter a default value, the compiler internally applies the  <br>System.Runtime.InteropServices.OptionalAttribute custom attribute to the param-<br>eter, and this attribute is persisted in the resulting file's metadata. In addition, the compiler  <br>applies System.Runtime.InteropServices.DefaultParameterValueAttribute <br>to the parameter and persists this attribute in the resulting file's metadata. Then, <br>DefaultParameterValueAttribute's constructor is passed the constant value that you <br>specified in your source code.<br>
Now, when a compiler sees that you have code calling a method that is missing some argu-<br>ments, the compiler can ensure that you've omitted optional arguments, grab their default <br>values out of metadata, and embed the values in the call for you automatically.<br>
<hr>
<A name=241></a><b> </b><br>
<b>Chapter 9  Parameters </b><br>
<b>223</b><br>
<b>Implicitly Typed Local Variables</b><br>
C# supports the ability to infer the type of a method's local variable from the type of  <br>expression that is used to initialize it. Here is some sample code demonstrating the use of  <br>this feature:<br>
private static void ImplicitlyTypedLocalVariables() { <br>   var name = &quot;Jeff&quot;; <br>   ShowVariableType(name);    // Displays: System.String <br> <br>   // var n = null;           // Error <br>   var x = (Exception)null;   // OK, but not much value <br>   ShowVariableType(x);       // Displays: System.Exception <br> <br>   var numbers = new Int32[] { 1, 2, 3, 4 }; <br>   ShowVariableType(numbers); // Displays: System.Int32[] <br> <br>   // Less typing for complex types <br>   var collection = new Dictionary&lt;String, Single&gt;() { { &quot;.NET&quot;, 4.0f } }; <br> <br>   // Displays: System.Collections.Generic.Dictionary`2[System.String,System.Single] <br>   ShowVariableType(collection);  <br> <br>   foreach (var item in collection) { <br>      // Displays: System.Collections.Generic.KeyValuePair`2[System.String,System.Single] <br>      ShowVariableType(item); <br>   } <br>} <br> <br>private static void ShowVariableType&lt;T&gt;(T t) { <br>   Console.WriteLine(typeof(T)); <br>}<br>
The first line of code inside the ImplicitlyTypedLocalVariables method is introducing a <br>new local variable using the C# var token. To determine the type of the name variable, the <br>compiler looks at the type of the expression on the right side of the assignment operator <br>(=). Since &quot;Jeff&quot; is a string, the compiler infers that name's type must be String.<b> </b>To prove <br>that the compiler is inferring the type correctly, I wrote the ShowVariableType method. <br>This generic method infers the type of its argument, and then it shows the type that it in-<br>ferred on the console. I added what ShowVariableType displayed as comments inside the <br>ImplicitlyTypedLocalVariables method for easy reading.<br>
The second assignment (commented out) inside the ImplicitlyTypedLocalVariables <br>method would produce a compiler error (&quot;error CS0815: Cannot assign &lt;null&gt; to <br>an implicitly-typed local variable&quot;) because null is implicitly castable to any refer-<br>ence type or nullable value type; therefore, the compiler cannot infer a distinct type for it. <br>However, on the third assignment, I show that it is possible to initialize an implicitly typed <br>local variable with null if you explicitly specify a type (Exception,<b> </b>in my example). While this <br>is possible, it is not that useful because you could also write Exception x = null; to get <br>the same result.<br>
<hr>
<A name=242></a><IMG src="CLRviaCsharp-242_1.jpg"><br>
<b>224 </b><br>
<b>Part II  Designing Types</b><br>
In the fourth assignment, you see some real value of using C#'s implicitly typed local variable  <br>feature. Without this feature, you'd have to specify Dictionary&lt;String, Single&gt; on both <br>sides of the assignment operator. Not only is this a lot of typing, but if you ever decide to <br>change the collection type or any of the generic parameter types, then you would have to <br>modify your code on both sides of the assignment operator, too.<br>
In the foreach loop, I also use var to have the compiler automatically infer the type of the <br>elements inside the collection. This demonstrates that it is possible and quite useful to use <br>var with foreach, using, and for statements. It can also be useful when experimenting with <br>code. For example, you initialize an implicitly typed local variable from the return type of <br>a method, and as you develop your method, you might decide to change its return type. If <br>you do this, the compiler will automatically figure out that the return type has changed and <br>automatically change the type of the variable! This is great, but of course, other code in the <br>method that uses that variable may no longer compile if the code accesses members using <br>the variable assuming that it was the old type.<br>
In Microsoft Visual Studio, you can hold the mouse cursor over var in your source code  <br>and the editor will display a tooltip showing you the type that the compiler infers from the <br>expression. C#'s implicitly typed local variable feature must be used when working with <br>anonymous types within a method; see Chapter 10, "Properties," for more details.<br>
You cannot declare a method's parameter type using var. The reason for this should be obvi-<br>ous to you since the compiler would have to infer the parameter's type from the argument <br>being passed at a callsite and there could be no call sites or many call sites. In addition, you <br>cannot declare a type's field using var. There are many reasons why C# has this restriction. <br>One reason is that fields can be accessed by several methods and the C# team feels that this <br>contract (the type of the variable) should be stated explicitly. Another reason is that allowing <br>this would permit an anonymous type (discussed in Chapter 10) to leak outside of a single <br>method.<br>
<b>Important  </b>Do not confuse dynamic and var. Declaring a local variable using var is just a <br>syntactical shortcut that has the compiler infer the specific data type from an expression. The <br>var keyword can be used only for declaring local variables inside a method while the dynamic <br>keyword can be used for local variables, fields, and arguments. You cannot cast an expression to <br>var, but you can cast an expression to dynamic. You must explicitly initialize a variable declared <br>using var while you do not have to initialize a variable declared with dynamic. For more infor-<br>mation about C#'s dynamic type, see the "The dynamic Primitive Type" section in Chapter 5.<br>
<hr>
<A name=243></a><IMG src="CLRviaCsharp-243_1.jpg"><br>
<b> </b><br>
<b>Chapter 9  Parameters </b><br>
<b>225</b><br>
<b>Passing Parameters by Reference to a Method</b><br>
By default, the common language runtime (CLR) assumes that all method parameters are <br>passed by value. When reference type objects are passed, the reference (or pointer) to the <br>object is passed (by value) to the method. This means that the method can modify the object <br>and the caller will see the change. For value type instances, a copy of the instance is passed <br>to the method. This means that the method gets its own private copy of the value type and <br>the instance in the caller isn't affected.<br>
<b>Important  </b>In a method, you must know whether each parameter passed is a reference type or a <br>value type because the code you write to manipulate the parameter could be markedly different.<br>
The CLR allows you to pass parameters by reference instead of by value. In C#, you do this  <br>by using the out and ref keywords. Both keywords tell the C# compiler to emit metadata <br>indicating that this designated parameter is passed by reference, and the compiler uses this <br>to generate code to pass the address of the parameter rather than the parameter itself.<br>
From the CLR's perspective, out and ref are identical--that is, the same IL is produced  <br>regardless of which keyword you use, and the metadata is also identical except for 1 bit, <br>which is used to record whether you specified out or ref when declaring the method. <br>However, the C# compiler treats the two keywords differently, and the difference has to do <br>with which method is responsible for initializing the object being referred to. If a method's <br>parameter is marked with out, the caller isn't expected to have initialized the object prior <br>to calling the method. The called method can't read from the value, and the called method <br>must write to the value before returning. If a method's parameter is marked with ref, the <br>caller must initialize the parameter's value prior to calling the method. The called method <br>can read from the value and/or write to the value.<br>
Reference and value types behave very differently with out and ref. Let's look at using out <br>and ref with value types first:<br>
public sealed class Program {  <br>   public static void Main() {  <br>      Int32 x;               // x is uninitialized  <br>      GetVal(out x);         // x doesn't have to be initialized.  <br>      Console.WriteLine(x);  // Displays &quot;10&quot;  <br>   }  <br> <br>   private static void GetVal(out Int32 v) {  <br>      v = 10;  // This method must initialize v.  <br>   }  <br>}<br>
In this code, x is declared in Main's stack frame. The address of x is then passed to  <br>GetVal. GetVal's v is a pointer to the Int32 value in Main's stack frame. Inside GetVal,<b>  </b><br>
<hr>
<A name=244></a><b>226 </b><br>
<b>Part II  Designing Types</b><br>
the Int32 that v points to is changed to 10.<b> </b>When GetVal returns, Main's x has a value of <br>10, and 10 is displayed on the console. Using out with large value types is efficient because it <br>prevents instances of the value type's fields from being copied when making method calls.<br>
Now let's look at an example that uses ref instead of out:<br>
public sealed class Program {  <br>   public static void Main() {  <br>      Int32 x = 5;          // x is initialized  <br>      AddVal(ref x);        // x must be initialized.  <br>      Console.WriteLine(x); // Displays &quot;15&quot;  <br>   }  <br> <br>   private static void AddVal(ref Int32 v) {  <br>      v += 10;  // This method can use the initialized value in v.  <br>   }  <br>}<br>
In this code, x is also declared in Main's stack frame and is initialized to 5.<b> </b>The address of x <br>is then passed to AddVal.<b> </b>AddVal's v is a pointer to the Int32 value in Main's stack frame. <br>Inside AddVal,<b> </b>the Int32 that v points to is required to have a value already. So, AddVal can <br>use the initial value in any expression it desires. AddVal can also change the value, and the <br>new value will be "returned" to the caller. In this example, AddVal adds 10 to the initial value. <br>When AddVal returns, Main's x will contain 15,<b> </b>which is what gets displayed in the console.<br>
To summarize, from an IL or a CLR perspective, out and ref do exactly the same thing: they <br>both cause a pointer to the instance to be passed. The difference is that the compiler helps <br>ensure that your code is correct. The following code that attempts to pass an uninitialized <br>value to a method expecting a ref parameter produces the following message: &quot;error <br>CS0165: Use of unassigned local variable 'x'.&quot;<br>
public sealed class Program {  <br>   public static void Main() {  <br>      Int32 x;              // x is not initialized.  <br> <br>      // The following line fails to compile, producing   <br>      // error CS0165: Use of unassigned local variable 'x'.  <br>      AddVal(ref x);  <br> <br>      Console.WriteLine(x);   <br>   }  <br> <br>   private static void AddVal(ref Int32 v) {  <br>      v += 10;  // This method can use the initialized value in v.  <br>   }  <br>}<br>
<hr>
<A name=245></a><IMG src="CLRviaCsharp-245_1.jpg"><br>
<b> </b><br>
<b>Chapter 9  Parameters </b><br>
<b>227</b><br>
<b>Important  </b>I'm frequently asked why C# requires that a call to a method must specify out or <br>ref. After all, the compiler knows whether the method being called requires out or ref and <br>should be able to compile the code correctly. It turns out that the compiler can indeed do the <br>right thing automatically. However, the designers of the C# language felt that the caller should <br>explicitly state its intention. This way at the call site, it's obvious that the method being called is <br>expected to change the value of the variable being passed.<br>
In addition, the CLR allows you to overload methods based on their use of out and ref param-<br>eters. For example, in C#, the following code is legal and compiles just fine:<br>
public sealed class Point {  <br>   static void Add(Point p) { ... }  <br>   static void Add(ref Point p) { ... }  <br>}<br>
It's not legal to overload methods that differ only by out and ref because the metadata repre-<br>sentation of the method's signature for the methods would be identical. So I couldn't also define <br>the following method in the preceding Point type:<br>
static void Add(out Point p) { ... }<br>
If you attempt to include the last Add method in the Point type, the C# compiler issues this <br>message: &quot;error CS0663: 'Add' cannot define overloaded methods that differ <br>only on ref and out.&quot;<br>
Using out and ref with value types gives you the same behavior that you already get when <br>passing reference types by value. With value types, out and ref allow a method to manipu-<br>late a single value type instance. The caller must allocate the memory for the instance, and <br>the callee manipulates that memory. With reference types, the caller allocates memory for a <br>pointer to a reference object, and the callee manipulates this pointer. Because of this behavior, <br>using out and ref with reference types is useful only when the method is going to "return" a <br>reference to an object that it knows about. The following code demonstrates:<br>
using System;  <br>using System.IO;  <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      FileStream fs;   // fs is uninitialized  <br> <br>      // Open the first file to be processed.  <br>      StartProcessingFiles(out fs);  <br> <br>      // Continue while there are more files to process.  <br>      for (; fs != null; ContinueProcessingFiles(ref fs)) {  <br> <br>         // Process a file.  <br>         fs.Read(...);  <br>      }  <br>   }  <br> <br>
<hr>
<A name=246></a><b>228 </b><br>
<b>Part II  Designing Types</b><br>
   private static void StartProcessingFiles(out FileStream fs) {  <br>      fs = new FileStream(...);   // fs must be initialized in this method  <br>   }  <br> <br>   private static void ContinueProcessingFiles(ref FileStream fs) {  <br>      fs.Close();  // Close the last file worked on.  <br> <br>      // Open the next file, or if no more files, &quot;return&quot; null.   <br>      if (noMoreFilesToProcess) fs = null;  <br>      else fs = new FileStream (...);  <br>   }  <br>}<br>
As you can see, the big difference with this code is that the methods that have out or ref <br>reference type parameters are constructing an object, and the pointer to the new object is <br>returned to the caller. You'll also notice that the ContinueProcessingFiles method can <br>manipulate the object being passed into it before returning a new object. This is possible  <br>because the parameter is marked with the ref keyword. You can simplify the preceding code <br>a bit, as shown here:<br>
using System;  <br>using System.IO;  <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      FileStream fs = null;   // Initialized to null (required)  <br> <br>      // Open the first file to be processed.  <br>      ProcessFiles(ref fs);  <br> <br>      // Continue while there are more files to process.  <br>      for (; fs != null; ProcessFiles(ref fs)) {  <br> <br>         // Process a file.  <br>         fs.Read(...);  <br>      }  <br>   }  <br> <br>   private static void ProcessFiles(ref FileStream fs) {  <br>      // Close the previous file if one was open.  <br>      if (fs != null) fs.Close();  // Close the last file worked on.  <br> <br>      // Open the next file, or if no more files, &quot;return&quot; null.   <br>      if (noMoreFilesToProcess) fs = null;  <br>      else fs = new FileStream (...);  <br>   }  <br>}<br>
Here's another example that demonstrates how to use the ref keyword to implement a <br>method that swaps two reference types:<br>
<hr>
<A name=247></a><b> </b><br>
<b>Chapter 9  Parameters </b><br>
<b>229</b><br>
public static void Swap(ref Object a, ref Object b) {  <br>   Object t = b;  <br>   b = a;  <br>   a = t;  <br>}<br>
To swap references to two String objects, you'd probably think that you could write code <br>like this:<br>
public static void SomeMethod() {  <br>   String s1 = &quot;Jeffrey&quot;;  <br>   String s2 = &quot;Richter&quot;;  <br>     <br>   Swap(ref s1, ref s2);  <br>   Console.WriteLine(s1);  // Displays &quot;Richter&quot;  <br>   Console.WriteLine(s2);  // Displays &quot;Jeffrey&quot;  <br>}<br>
However, this code won't compile. The problem is that variables passed by reference to a <br>method must be of the same type as declared in the method signature. In other words,  <br>Swap expects two Object references, not two String references. To swap the two String <br>references, you must do this:<br>
public static void SomeMethod() {  <br>   String s1 = &quot;Jeffrey&quot;;  <br>   String s2 = &quot;Richter&quot;;  <br>     <br>   // Variables that are passed by reference   <br>   // must match what the method expects.  <br>   Object o1 = s1, o2 = s2;  <br>   Swap(ref o1, ref o2);  <br> <br>   // Now cast the objects back to strings.  <br>   s1 = (String) o1;  <br>   s2 = (String) o2;  <br>     <br>   Console.WriteLine(s1);  // Displays &quot;Richter&quot;  <br>   Console.WriteLine(s2);  // Displays &quot;Jeffrey&quot;  <br>}<br>
This version of SomeMethod does compile and execute as expected. The reason why the  <br>parameters passed must match the parameters expected by the method is to ensure that <br>type safety is preserved. The following code, which thankfully won't compile, shows how  <br>type safety could be compromised.<br>
internal sealed class SomeType {  <br>   public Int32 m_val;  <br>}  <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      SomeType st;  <br> <br>
<hr>
<A name=248></a><b>230 </b><br>
<b>Part II  Designing Types</b><br>
      // The following line generates error CS1503: Argument '1':   <br>      // cannot convert from 'ref SomeType' to 'ref object'.  <br>      GetAnObject(out st);  <br> <br>      Console.WriteLine(st.m_val);  <br>  }  <br> <br>   private static void GetAnObject(out Object o) {  <br>      o = new String('X', 100);  <br>   }  <br>}<br>
In this code, Main clearly expects GetAnObject to return a SomeType object. However,  <br>because GetAnObject's signature indicates a reference to an Object,<b> </b>GetAnObject is free  <br>to initialize o to an object of any type. In this example, when GetAnObject returned to  <br>Main,<b> </b>st would refer to a String,<b> </b>which is clearly not a SomeType object, and the call to <br>Console.WriteLine would certainly fail. Fortunately, the C# compiler won't compile the <br>preceding code because st is a reference to SomeType,<b> </b>but GetAnObject requires a reference <br>to an Object.<br>
You can use generics to fix these methods so that they work as you'd expect. Here is how to <br>fix the Swap method shown earlier:<br>
public static void Swap&lt;T&gt;(ref T a, ref T b) {  <br>   T t = b;  <br>   b = a;  <br>   a = t;  <br>}<br>
And now, with Swap rewritten as above, the following code (identical to that shown before) <br>will compile and run perfectly:<br>
public static void SomeMethod() {  <br>   String s1 = &quot;Jeffrey&quot;;  <br>   String s2 = &quot;Richter&quot;;  <br> <br>   Swap(ref s1, ref s2);  <br>   Console.WriteLine(s1);  // Displays &quot;Richter&quot;  <br>   Console.WriteLine(s2);  // Displays &quot;Jeffrey&quot;  <br>}<br>
For some other examples that use generics to solve this problem, see System.Threading's <br>Interlocked class with its CompareExchange and Exchange methods.<br>
<hr>
<A name=249></a><b> </b><br>
<b>Chapter 9  Parameters </b><br>
<b>231</b><br>
<b>Passing a Variable Number of Arguments to a Method</b><br>
It's sometimes convenient for the developer to define a method that can accept a variable <br>number of arguments. For example, the System.String type offers methods allowing an <br>arbitrary number of strings to be concatenated together and methods allowing the caller to <br>specify a set of strings that are to be formatted together.<br>
To declare a method that accepts a variable number of arguments, you declare the method <br>as follows:<br>
static Int32 Add(params Int32[] values) {  <br>   // NOTE: it is possible to pass the 'values'   <br>   // array to other methods if you want to.  <br> <br>   Int32 sum = 0;  <br>   if (values != null) { <br>      for (Int32 x = 0; x &lt; values.Length; x++)   <br>         sum += values[x];  <br>   } <br>   return sum;  <br>}<br>
Everything in this method should look very familiar to you except for the params keyword <br>that is applied to the last parameter of the method signature. Ignoring the params keyword <br>for the moment, it's obvious that this method accepts an array of Int32 values and iterates <br>over the array, adding up all of the values. The resulting sum is returned to the caller.<br>
Obviously, code can call this method as follows:<br>
public static void Main() {  <br>   // Displays &quot;15&quot;  <br>   Console.WriteLine(Add(new Int32[] { 1, 2, 3, 4, 5 } ));  <br>}<br>
It's clear that the array can easily be initialized with an arbitrary number of elements and <br>then passed off to Add for processing. Although the preceding code would compile and work <br>correctly, it is a little ugly. As developers, we would certainly prefer to have written the call to <br>Add as follows:<br>
public static void Main() {  <br>   // Displays &quot;15&quot;  <br>   Console.WriteLine(Add(1, 2, 3, 4, 5));  <br>}<br>
You'll be happy to know that we can do this because of the params keyword. The params <br>keyword tells the compiler to apply an instance of the System.ParamArrayAttribute  <br>custom attribute to the parameter.<br>
<hr>
<A name=250></a><b>232 </b><br>
<b>Part II  Designing Types</b><br>
When the C# compiler detects a call to a method, the compiler checks all of the methods <br>with the specified name, where no parameter has the ParamArray attribute applied. If a <br>method exists that can accept the call, the compiler generates the code necessary to call <br>the method. However, if the compiler can't find a match, it looks for methods that have a <br>ParamArray attribute to see whether the call can be satisfied. If the compiler finds a match, it <br>emits code that constructs an array and populates its elements before emitting the code that <br>calls the selected method.<br>
In the previous example, no Add method is defined that takes five Int32-compatible argu-<br>ments; however, the compiler sees that the source code has a call to Add that is being passed <br>a list of Int32 values and that there is an Add method whose array-of-Int32 parameter is <br>marked with the ParamArray attribute. So the compiler considers this a match and generates <br>code that coerces the parameters into an Int32 array and then calls the Add method. The <br>end result is that you can write the code, easily passing a bunch of parameters to Add,<b> </b>but the <br>compiler generates code as though you'd written the first version that explicitly constructs and <br>initializes the array.<br>
Only the last parameter to a method can be marked with the params keyword <br>(ParamArrayAttribute). This parameter must also identify a single-dimension array of any <br>type. It's legal to pass null or a reference to an array of 0 entries as the last parameter to the <br>method. The following call to Add compiles fine, runs fine, and produces a resulting sum of 0 <br>(as expected):<br>
public static void Main() {  <br>   // Both of these lines display &quot;0&quot;  <br>   Console.WriteLine(Add());     // passes new Int32[0] to Add <br>   Console.WriteLine(Add(null)); // passes null to Add: more efficient (no array allocated) <br>}<br>
So far, all of the examples have shown how to write a method that takes an arbitrary number <br>of Int32 parameters. How would you write a method that takes an arbitrary number of  <br>parameters where the parameters could be any type? The answer is very simple: just modify <br>the method's prototype so that it takes an Object[] instead of an Int32[]. Here's a method <br>that displays the Type of every object passed to it:<br>
public sealed class Program {  <br>   public static void Main() {  <br>      DisplayTypes(new Object(), new Random(), &quot;Jeff&quot;, 5);  <br>   }  <br> <br>   private static void DisplayTypes(params Object[] objects) {  <br>      if (objects != null) { <br>         foreach (Object o in objects)   <br>            Console.WriteLine(o.GetType());  <br>      } <br>   }  <br>}<br>
<hr>
<A name=251></a><IMG src="CLRviaCsharp-251_1.jpg"><br>
<b> </b><br>
<b>Chapter 9  Parameters </b><br>
<b>233</b><br>
Running this code yields the following output:<br>
System.Object <br>System.Random <br>System.String <br>System.Int32<br>
<b>Important  </b>Be aware that calling a method that takes a variable number of arguments incurs  <br>an additional performance hit unless you explicitly pass null. After all, an array object must be <br>allocated on the heap, the array's elements must be initialized, and the array's memory must  <br>ultimately be garbage collected. To help reduce the performance hit associated with this, you <br>may want to consider defining a few overloaded methods that do not use the params keyword. <br>For some examples, look at the System.String class's Concat method, which has the following <br>overloads:<br>
public sealed class String : Object, ... {  <br>   public static string Concat(object arg0);  <br>   public static string Concat(object arg0, object arg1);  <br>   public static string Concat(object arg0, object arg1, object arg2);  <br>   public static string Concat(params object[] args);  <br> <br>   public static string Concat(string str0, string str1);  <br>   public static string Concat(string str0, string str1, string str2);  <br>   public static string Concat(string str0, string str1, string str2, string str3);  <br>   public static string Concat(params string[] values);  <br>}<br>
As you can see, the Concat method defines several overloads that do not use the params key-<br>word. These versions of the Concat method are the most frequently called overloads, and these <br>overloads exist in order to improve performance for the most common scenarios. The overloads <br>that use the params keyword are there for the less common scenarios; these scenarios will suffer <br>a performance hit, but fortunately, they are rare.<br>
<b>Parameter and Return Type Guidelines</b><br>
When declaring a method's parameter types, you should specify the weakest type possible, <br>preferring interfaces over base classes. For example, if you are writing a method that  <br>manipulates a collection of items, it would be best to declare the method's parameter by <br>using an interface such as IEnumerable&lt;T&gt; rather than using a strong data type such as <br>List&lt;T&gt; or even a stronger interface type such as ICollection&lt;T&gt; or IList&lt;T&gt;:<br>
// Desired: This method uses a weak parameter type   <br>public void ManipulateItems&lt;T&gt;(IEnumerable&lt;T&gt; collection) { ... }  <br> <br>// Undesired: This method uses a strong parameter type   <br>public void ManipulateItems&lt;T&gt;(List&lt;T&gt; collection) { ... }<br>
<hr>
<A name=252></a><b>234 </b><br>
<b>Part II  Designing Types</b><br>
The reason, of course, is that someone can call the first method passing in an array object,  <br>a List&lt;T&gt; object, a String object, and so on--any object whose type implements <br>IEnumerable&lt;T&gt;. The second method allows only List&lt;T&gt; objects to be passed in; it will  <br>not accept an array or a String object. Obviously, the first method is better because it is <br>much more flexible and can be used in a much wider range of scenarios.<br>
Naturally, if you are writing a method that requires a list (not just any enumerable object), <br>then you should declare the parameter type as an IList&lt;T&gt;.<b> </b>You should still avoid declar-<br>ing the parameter type as List&lt;T&gt;. Using IList&lt;T&gt; allows the caller to pass arrays and any <br>other objects whose type implements IList&lt;T&gt;.<br>
Note that my examples talked about collections, which are designed using an interface archi-<br>tecture. If we were talking about classes designed using a base class architecture, the concept <br>still applies. So, for example, if I were implementing a method that processed bytes from a <br>stream, we'd have this:<br>
// Desired: This method uses a weak parameter type   <br>public void ProcessBytes(Stream someStream) { ... }  <br> <br>// Undesired: This method uses a strong parameter type   <br>public void ProcessBytes(FileStream fileStream) { ... }<br>
The first method can process bytes from any kind of stream: a FileStream, a <br>NetworkStream,<b> </b>a MemoryStream,<b> </b>and so on. The second method can operate only on a <br>FileStream,<b> </b>making it far more limited.<br>
On the flip side, it is usually best to declare a method's return type by using the strongest <br>type possible (trying not to commit yourself to a specific type). For example, it is better to <br>declare a method that returns a FileStream object as opposed to returning a Stream object:<br>
// Desired: This method uses a strong return type   <br>public FileStream OpenFile() { ... }  <br> <br>// Undesired: This method uses a weak return type   <br>public Stream OpenFile() { ... }<br>
Here, the first method is preferred because it allows the method's caller the option of treating <br>the returned object as either a FileStream object or as a Stream object. Meanwhile, the  <br>second method requires that the caller treat the returned object as a Stream object. Basically, <br>it is best to let the caller have as much flexibility as possible when calling a method, allowing <br>the method to be used in the widest range of scenarios.<br>
Sometimes you want to retain the ability to change the internal implementation of a method <br>without affecting the callers. In the example just shown, the OpenFile method is unlikely to <br>ever change its internal implementation to return anything other than a FileStream object <br>(or an object whose type is derived from FileStream). However, if you have a method that <br>returns a List&lt;String&gt; object, you might very well want to change the internal implemen-<br>tation of this method in the future so that it would instead return a String[]. In the cases <br>
<hr>
<A name=253></a><b> </b><br>
<b>Chapter 9  Parameters </b><br>
<b>235</b><br>
in which you want to leave yourself some flexibility to change what your method returns, <br>choose a weaker return type. For example:<br>
// Flexible: This method uses a weaker return type   <br>public IList&lt;String&gt; GetStringCollection() { ... }  <br> <br>// Inflexible: This method uses a stronger return type   <br>public List&lt;String&gt; GetStringCollection() { ... }<br>
In this example, even though the GetStringCollection method uses a List&lt;String&gt; <br>object internally and returns it, it is better to prototype the method as returning an <br>IList&lt;String&gt; instead. In the future, the GetStringCollection method could change its <br>internal collection to use a String[],<b> </b>and callers of the method won't be required to change <br>any of their source code. In fact, they won't even have to recompile their code. Notice in this <br>example that I'm using the strongest of the weakest types. For instance, I'm not using an <br>IEnumerable&lt;String&gt; or even ICollection&lt;String&gt;.<br>
Const<b>-ness</b><br>
In some languages, such as unmanaged C++, it is possible to declare methods or parameters <br>as a constant that forbids the code in an instance method from changing any of the object's <br>fields or prevents the code from modifying any of the objects passed into the method. The <br>CLR does not provide for this, and many programmers have been lamenting this missing fea-<br>ture. Since the CLR doesn't offer this feature, no language (including C#) can offer this feature.<br>
First, you should note that in unmanaged C++, marking an instance method or parameter as <br>const ensured only that the programmer could not write normal code that would modify <br>the object or parameter. Inside the method, it was always possible to write code that could <br>mutate the object/parameter by either casting away the const-ness or by getting the address <br>of the object/argument and then writing to the address. In a sense, unmanaged C++ lied to <br>programmers, making them believe that their constant objects/arguments couldn't be written <br>to even though they could.<br>
When designing a type's implementation, the developer can just avoid writing code that <br>manipulates the object/arguments. For example, strings are immutable because the String <br>class doesn't offer any methods that can change a string object.<br>
Also, it would be very difficult for Microsoft to endow the CLR with the ability to verify that <br>a constant object/argument isn't being mutated. The CLR would have to verify at each write <br>that the write was not occurring to a constant object, and this would hurt performance  <br>significantly. Of course, a detected violation would result in the CLR throwing an exception. <br>Furthermore, constant support adds a lot of complexity for developers. For example, if a type <br>is immutable, all derived types would have to respect this. In addition, an immutable type <br>would probably have to consist of fields that are also of immutable types.<br>
These are just some of the reasons why the CLR does not support constant objects/arguments.<br>
<hr>
<A name=254></a><hr>
<A name=255></a>Chapter 10<br><b>Properties</b><br>
<b>In this chapter:<br>Parameterless Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237<br>Parameterful Properties. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252<br>The Performance of Calling Property Accessor Methods  . . . . . . . . . . . . . . . . . . 257<br>Property Accessor Accessibility  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258<br>Generic Property Accessor Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258</b><br>
In this chapter, I'l  talk about properties. Properties al ow source code to cal  a method by using <br>a simplified syntax. The common language runtime (CLR) offers two kinds of properties: pa-<br>rameterless properties, which are simply cal ed <i>properties</i>, and parameterful properties, which <br>are cal ed different names by different programming languages. For example, C# cal s param-<br>eterful properties <i>indexers</i>, and Microsoft Visual Basic cal s them<i> default properties</i>. I'l  also talk <br>about initializing properties using object and col ection initializers as wel  as ways to package a <br>bunch of properties together using C#'s anonymous types and the System.Tuple type.<br>
<b>Parameterless Properties</b><br>
Many types define state information that can be retrieved or altered. Frequently, this state <br>information is implemented as field members of the type. For example, here's a type defini-<br>tion that contains two fields:<br>
public sealed class Employee {  <br>   public String Name; // The employee's name  <br>   public Int32  Age;  // The employee's age  <br>}<br>
If you were to create an instance of this type, you could easily get or set any of this state  <br>information with code similar to the following:<br>
Employee e = new Employee();  <br>e.Name = &quot;Jeffrey Richter&quot;;  // Set the employee's Name.   <br>e.Age  = 45;                 // Set the employee's Age.  <br> <br>Console.WriteLine(e.Name);   // Displays &quot;Jeffrey Richter&quot;<br>
Querying and setting an object's state information in the way I just demonstrated is very <br>common. However, I would argue that the preceding code should never be implemented as <br>
<b> </b><br>
<b> </b><br>
<b>237</b><br>
<hr>
<A name=256></a><b>238 </b><br>
<b>Part II  Designing Types</b><br>
shown. One of the hal marks of object-oriented design and programming is <i>data encapsulation</i>. <br>Data encapsulation means that your type's fields should never be publicly exposed because <br>it's too easy to write code that improperly uses the fields, corrupting the object's state. For <br>example, a developer could easily corrupt an Employee object with code like this:<br>
e.Age = -5; // How could someone be ­5 years old?<br>
There are additional reasons for encapsulating access to a type's data field. For example, you <br>might want access to a field to execute some side effect, cache some value, or lazily create <br>some internal object. You might also want access to the field to be thread-safe. Or perhaps <br>the field is a logical field whose value isn't represented by bytes in memory but whose value <br>is instead calculated using some algorithm.<br>
For any of these reasons, when designing a type, I strongly suggest that all of your fields be <br>private. Then, to allow a user of your type to get or set state information, you expose meth-<br>ods for that specific purpose. Methods that wrap access to a field are typically called accessor <br>methods. These accessor methods can optionally perform sanity checking and ensure that <br>the object's state is never corrupted. For example, I'd rewrite the previous class as follows:<br>
public sealed class Employee {  <br>   private String m_Name;    // Field is now private  <br>   private Int32  m_Age;     // Field is now private  <br> <br>   public String GetName() {  <br>      return(m_Name);  <br>   }  <br> <br>   public void SetName(String value) {  <br>      m_Name = value;  <br>   }  <br> <br>   public Int32 GetAge() {  <br>      return(m_Age);  <br>   }  <br> <br>   public void SetAge(Int32 value) {  <br>      if (value &lt; 0)  <br>         throw new ArgumentOutOfRangeException(&quot;value&quot;,  value.ToString(),  <br>            &quot;The value must be greater than or equal to 0&quot;);  <br>      m_Age = value;  <br>   }  <br>}<br>
Although this is a simple example, you should still be able to see the enormous benefit <br>you get from encapsulating the data fields. You should also be able to see how easy it is to <br>make read-only or write-only properties: just don't implement one of the accessor methods. <br>Alternatively, you could allow only derived types to modify the value by marking the SetXxx <br>method as protected.<br>
<hr>
<A name=257></a><b> </b><br>
<b>Chapter 10  Properties </b><br>
<b>239</b><br>
Encapsulating the data as shown earlier has two disadvantages. First, you have to write more <br>code because you now have to implement additional methods. Second, users of the type <br>must now call methods rather than simply refer to a single field name.<br>
e.SetName(&quot;Jeffrey Richter&quot;);      // updates the employee's name   <br>String EmployeeName = e.GetName(); // retrieves the employee's name   <br>e.SetAge(41);                      // Updates the employee's age  <br>e.SetAge(-5);                      // Throws ArgumentOutOfRangeException  <br>Int32 EmployeeAge = e.GetAge();    // retrieves the employee's age<br>
Personally, I think these disadvantages are quite minor. Nevertheless, programming languages <br>and the CLR offer a mechanism called <i>properties</i> that alleviates the first disadvantage a little <br>and removes the second disadvantage entirely.<br>
The class shown here uses properties and is functionally identical to the class shown earlier:<br>
public sealed class Employee {  <br>   private String m_Name;  <br>   private Int32  m_Age;  <br> <br>   public String Name {  <br>      get { return(m_Name); }  <br>      set { m_Name = value; } // The 'value' keyword always identifies the new value. <br>   }  <br> <br>   public Int32 Age {  <br>      get { return(m_Age); }  <br>      set {  <br>         if (value &lt; 0)    // The 'value' keyword always identifies the new value. <br>            throw new ArgumentOutOfRangeException(&quot;value&quot;,  value.ToString(),  <br>               &quot;The value must be greater than or equal to 0&quot;);  <br>         m_Age = value;  <br>      }  <br>   }  <br>}<br>
As you can see, properties complicate the definition of the type slightly, but the fact that <br>they allow you to write your code as follows more than compensates for the extra work:<br>
e.Name = &quot;Jeffrey Richter&quot;;   // &quot;sets&quot; the employee name  <br>String EmployeeName = e.Name; // &quot;gets&quot; the employee's name  <br>e.Age = 41;                   // &quot;sets&quot; the employee's age  <br>e.Age = -5;                   // Throws ArgumentOutOfRangeException  <br>Int32 EmployeeAge = e.Age;    // &quot;gets&quot; the employee's age<br>
You can think of properties as <i>smart fields</i>: fields with additional logic behind them. The <br>CLR supports static, instance, abstract, and virtual properties. In addition, properties can be <br>marked with any accessibility modifier (discussed in Chapter 6, "Type and Member Basics") <br>and defined within an interface (discussed in Chapter 13, "Interfaces").<br>
Each property has a name and a type (which can't be void). It isn't possible to overload <br>properties (that is, have two properties with the same name if their types are different). <br>
<hr>
<A name=258></a><b>240 </b><br>
<b>Part II  Designing Types</b><br>
When you define a property, you typically specify both a get and a set method. However, <br>you can leave out the set method to define a read-only property or leave out the get  <br>method to define a write-only property.<br>
It's also quite common for the property's get/set methods to manipulate a private field  <br>defined within the type. This field is commonly referred to as the <i>backing field</i>. The get  <br>and set methods don't have to access a backing field, however. For example, the  <br>System.Threading.Thread type offers a Priority property that communicates directly <br>with the operating system; the Thread object doesn't maintain a field for a thread's priority. <br>Another example of properties without backing fields are those read-only properties calculat-<br>ed at runtime--for example, the length of a zero-terminated array or the area of a rectangle <br>when you have its height and width.<br>
When you define a property, depending on its definition, the compiler will emit either two or <br>three of the following items into the resulting managed assembly:<br>
  A method representing the property's get accessor method. This is emitted only if you <br>
define a get accessor method for the property.<br>
  A method representing the property's set accessor method. This is emitted only if you <br>
define a set accessor method for the property.<br>
  A property definition in the managed assembly's metadata. This is always emitted.<br>
Refer back to the Employee type shown earlier. As the compiler compiles this type, it comes <br>across the Name and Age properties. Because both properties have get and set accessor <br>methods, the compiler emits four method definitions into the Employee type. It's as though <br>the original source were written as follows:<br>
public sealed class Employee {  <br>   private String m_Name;  <br>   private Int32  m_Age;  <br> <br>   public String get_Name(){   <br>      return m_Name;    <br>   }  <br>   public void   set_Name(String value) {  <br>      m_Name = value; // The argument 'value' always identifies the new value.  <br>   }  <br> <br>   public Int32 get_Age() {  <br>      return m_Age;  <br>   }  <br> <br>   public void  set_Age(Int32 value) {  <br>      if (value &lt; 0)      // The 'value' always identifies the new value.  <br>         throw new ArgumentOutOfRangeException(&quot;value&quot;, value.ToString(),  <br>           &quot;The value must be greater than or equal to 0&quot;);  <br>      m_Age = value;  <br>   }  <br>}<br>
<hr>
<A name=259></a><b> </b><br>
<b>Chapter 10  Properties </b><br>
<b>241</b><br>
The compiler automatically generates names for these methods by prepending get_ or set_ <br>to the property name specified by the developer.<br>
C# has built-in support for properties. When the C# compiler sees code that's trying to get <br>or set a property, the compiler actually emits a call to one of these methods. If you're using a <br>programming language that doesn't directly support properties, you can stil  access properties <br>by calling the desired accessor method. The effect is exactly the same; it's just that the source <br>code doesn't look as pretty.<br>
In addition to emitting the accessor methods, compilers also emit a property definition entry <br>into the managed assembly's metadata for each property defined in the source code. This <br>entry contains some flags and the type of the property, and it refers to the get and set  <br>accessor methods. This information exists simply to draw an association between the abstract <br>concept of a "property" and its accessor methods. Compilers and other tools can use this <br>metadata, which can be obtained by using the System.Reflection.PropertyInfo class. <br>The CLR doesn't use this metadata information and requires only the accessor methods at <br>runtime.<br>
<b>Automatically Implemented Properties</b><br>
If you are creating a property to simply encapsulate a backing field, then C# offers a simpli-<br>fied syntax known as <i>automatically implemented properties</i> (AIPs), as shown here for the Name <br>property:<br>
public sealed class Employee {  <br>   // This property is an automatically implemented property <br>   public String Name { get; set; }  <br> <br>   private Int32  m_Age;  <br> <br> <br>   public Int32 Age {  <br>      get { return(m_Age); }  <br>      set {  <br>         if (value &lt; 0)    // The 'value' keyword always identifies the new value. <br>            throw new ArgumentOutOfRangeException(&quot;value&quot;,  value.ToString(),  <br>               &quot;The value must be greater than or equal to 0&quot;);  <br>         m_Age = value;  <br>      }  <br>   }  <br>}<br>
When you declare a property and do not provide an implementation for the get/set meth-<br>ods, then the C# compiler will automatically declare for you a private field. In this example, <br>the field will be of type String, the type of the property. And, the compiler will automatically <br>implement the get_Name and set_Name methods for you to return the value in the field and <br>to set the field's value, respectively.<br>
<hr>
<A name=260></a><b>242 </b><br>
<b>Part II  Designing Types</b><br>
You might wonder what the value of doing this is, as opposed to just declaring a public <br>String field called Name. Well, there is a big difference. Using the AIP syntax means that you <br>have created a property. Any code that accesses this property is actually calling get and set <br>methods. If you decide later to implement the get and/or set method yourself instead of <br>accepting the compiler's default implementation, then any code that accesses the property <br>will not have to be recompiled. However, if you declared Name as a field and then you later <br>change it to a property, then all code that accessed the field will have to be recompiled so <br>that it now accesses the property methods.<br>
  Personally, I do not like the compiler's AIP feature, so I usually avoid it for the follow-<br>
ing reason: The syntax for a field declaration can include initialization so that you are <br>declaring and initializing the field in one line of code. However, there is no convenient <br>syntax to set an AIP to an initial value. Therefore, you must explicitly initialize each AIP <br>in each constructor method.<br>
  The runtime serialization engines persist the name of the field in a serialized stream. <br>
The name of the backing field for an AIP is determined by the compiler, and it could <br>actually change the name of this backing field every time you recompile your code, <br>negating the ability to deserialize instances of any types that contain an AIP. Do not use <br>the AIP feature with any type you intend to serialize or deserialize.<br>
  When debugging, you cannot put a breakpoint on an AIP get or set method, so you <br>
cannot easily detect when an application is getting or setting this property. You can <br>set breakpoints on manually implemented properties, which can be quite handy when <br>tracking down bugs.<br>
You should also know that when you use AIPs, the property must be readable and writable; <br>that is, the compiler must produce both get and set methods. This makes sense because a <br>write-only field is not useful without the ability to read its value; likewise, a read-only field <br>would always have its default value. In addition, since you do not know the name of the  <br>compiler-generated backing field, your code must always access the property by using the <br>property name. And, if you decide you want to explicitly implement one of the accessor <br>methods, then you must explicitly implement both accessor methods and you are not using <br>the AIP feature anymore. For a single property, the AIP feature is an all-or-nothing deal.<br>
<b>Defining Properties Intelligently</b><br>
Personally, I don't like properties and I wish that they were not supported in the Microsoft <br>.NET Framework and its programming languages. The reason is that properties look like <br>fields, but they are methods. This has been known to cause a phenomenal amount of confu-<br>sion. When a programmer sees code that appears to be accessing a field, there are many  <br>assumptions that the programmer makes that may not be true for a property. For example,<br>
  A property may be read-only or write-only; field access is always readable and writable. <br>
If you define a property, it is best to offer both get and set accessor methods.<br>
<hr>
<A name=261></a><b> </b><br>
<b>Chapter 10  Properties </b><br>
<b>243</b><br>
  A property method may throw an exception; field access never throws an exception.<br>
  A property cannot be passed as an out or ref parameter to a method; a field can. For <br>
example, the following code will not compile:<br>
using System;  <br> <br>public sealed class SomeType {  <br>   private static String Name {   <br>      get { return null; }   <br>      set {}  <br>   }  <br> <br>   static void MethodWithOutParam(out String n) { n = null; }  <br> <br>   public static void Main() {  <br>      // For the line of code below, the C# compiler emits the following:  <br>      // error CS0206: A property or indexer may not   <br>      // be passed as an out or ref parameter  <br>      MethodWithOutParam(out Name);  <br>   }  <br>}<br>
  A property method can take a long time to execute; field access always completes <br>
immediately. A common reason to use properties is to perform thread synchroni-<br>zation, which can stop the thread forever, and therefore, a property should not be <br>used if thread synchronization is required. In that situation, a method is preferred. <br>Also, if your class can be accessed remotely (for example, your class is derived from <br>System.MarshalByRefObject), calling the property method will be very slow, and <br>therefore, a method is preferred to a property. In my opinion, classes derived from <br>MarshalByRefObject should never use properties.<br>
  If called multiple times in a row, a property method may return a different value each <br>
time; a field returns the same value each time. The System.DateTime class has a read-<br>only Now property that returns the current date and time. Each time you query this <br>property, it will return a different value. This is a mistake, and Microsoft wishes that <br>they could fix the class by making Now a method instead of a property. Environment's <br>TickCount property is another example of this mistake.<br>
  A property method may cause observable side effects; field access never does. In other <br>
words, a user of a type should be able to set various properties defined by a type in <br>any order he or she chooses without noticing any different behavior in the type.<br>
  A property method may require additional memory or return a reference to something <br>
that is not actually part of the object's state, so modifying the returned object has no <br>effect on the original object; querying a field always returns a reference to an object <br>that is guaranteed to be part of the original object's state. Working with a property <br>that returns a copy can be very confusing to developers, and this characteristic is fre-<br>quently not documented.<br>
<hr>
<A name=262></a><hr>
<A name=263></a><hr>
<A name=264></a><b>246 </b><br>
<b>Part II  Designing Types</b><br>
As a small side note, C# also lets you omit the parentheses before the open brace if you want <br>to call a parameterless constructor. The line below produces the same IL as the line above:<br>
String s = new Employee { Name = "Jeff", Age = 45 }.ToString().ToUpper();<br>
If a property's type implements the IEnumerable or IEnumerable&lt;T&gt; interface, then the <br>property is considered to be a collection, and initializing a collection is an additive operation  <br>as opposed to a replacement operation. For example, suppose I have the following class <br>definition:<br>
public sealed class Classroom { <br>   private List&lt;String&gt; m_students = new List&lt;String&gt;(); <br>   public List&lt;String&gt; Students { get { return m_students; } } <br> <br>   public Classroom() {} <br>}<br>
I can now have code that constructs a Classroom object and initializes the Students collec-<br>tion as follows:<br>
public static void M() { <br>   Classroom classroom = new Classroom {  <br>      Students = { &quot;Jeff&quot;, &quot;Kristin&quot;, &quot;Aidan&quot;, &quot;Grant&quot; }  <br>   }; <br> <br>   // Show the 4 students in the classroom <br>   foreach (var student in classroom.Students) <br>      Console.WriteLine(student); <br>}<br>
When compiling this code, the compiler sees that the Students property is of type <br>List&lt;String&gt; and that this type implements the IEnumerable&lt;String&gt; interface. Now, the <br>compiler assumes that the List&lt;String&gt; type offers a method called Add (because most <br>collection classes actually offer an Add method that adds items to the collection). The compiler <br>then generates code to call the collection's Add method. So, the code shown above is  <br>converted by the compiler into this:<br>
public static void M() { <br>   Classroom classroom = new Classroom(); <br>   classroom.Students.Add(&quot;Jeff&quot;); <br>   classroom.Students.Add(&quot;Kristin&quot;); <br>   classroom.Students.Add(&quot;Aidan&quot;); <br>   classroom.Students.Add(&quot;Grant&quot;); <br> <br>   // Show the 4 students in the classroom <br>   foreach (var student in classroom.Students) <br>      Console.WriteLine(student); <br>}<br>
If the property's type implements IEnumerable or IEnumerable&lt;T&gt; but the type doesn't <br>offer an Add method, then the compiler does not let you use the collection initialize syntax to <br>add items to the collection; instead, the compiler issues something like the following  <br>
<hr>
<A name=265></a><b> </b><br>
<b>Chapter 10  Properties </b><br>
<b>247</b><br>
message: &quot;error CS0117: 'System.Collections.Generic.IEnumerable&lt;string&gt;' does <br>not contain a definition for 'Add'.&quot;<br>
Some collection's Add methods take multiple arguments. For example, Dictionary's Add <br>method:<br>
public void Add(TKey key, TValue value);<br>
You can pass multiple arguments to an Add method by using nested braces in a collection <br>initializer, as follows:<br>
var table = new Dictionary&lt;String, Int32&gt; {  <br>   { &quot;Jeffrey&quot;, 1 }, { &quot;Kristin&quot;, 2 }, { &quot;Aidan&quot;, 3 }, { &quot;Grant&quot;, 4 } <br>};<br>
The line above is identical to:<br>
var table = new Dictionary&lt;String, Int32&gt;(); <br>table.Add(&quot;Jeffrey&quot;, 1); <br>table.Add(&quot;Kristin&quot;, 2); <br>table.Add(&quot;Aidan&quot;, 3); <br>table.Add(&quot;Grant&quot;, 4);<br>
<b>Anonymous Types</b><br>
C#'s anonymous type feature allows you to automatically declare an immutable tuple type <br>using a very simple and succinct syntax. A <i>tuple type</i>1 is a type that contains a collection of <br>properties that are usually related to each other in some way. In the top line of the code <br>below, I am defining a class with two properties (Name of type String, and Year of type <br>Int32), constructing an instance of this type, and setting its Name property to &quot;Jeff&quot; and its <br>Year property to 1964.<br>
// Define a type, construct an instance of it, &amp; initialize its properties <br>var o1 = new { Name = &quot;Jeff&quot;, Year = 1964 }; <br> <br>// Display the properties on the console: <br>Console.WriteLine(&quot;Name={0}, Year={1}&quot;, o1.Name, o1.Year);// Displays: Name=Jeff, Year=1964<br>
This top line of code creates an anonymous type because I did not specify a type name after <br>the new keyword, so the compiler will create a type name for me automatically and not tell <br>me what it is (which is why it is called an anonymous type). The line of code uses the object <br>initializer syntax discussed in the previous section to declare the properties and also to  <br>initialize these properties. Also, since I (the developer) do not know the name of the type at <br>compile time, I do not know what type to declare the variable o1 as. However, this is not a <br>problem, as I can use C#'s implicitly typed local variable feature (var), as discussed in  <br>
1  The term originated as an abstraction of the sequence: single, double, triple, quadruple, quintuple, <i>n</i>-tuple.<br>
<hr>
<A name=266></a><b>248 </b><br>
<b>Part II  Designing Types</b><br>
Chapter 9, "Parameters," to have the compiler infer the type from the expression on the right <br>of the assignment operator (=).<br>
Now, let's focus on what the compiler is actually doing. When you write a line of code like <br>this:<br>
var o = new { property1 = expression1, ..., propertyN = expressionN };<br>
the compiler infers the type of each expression, creates private fields of these inferred types, <br>creates public read-only properties for each of the fields, and creates a constructor that  <br>accepts all these expressions. The constructor's code initializes the private read-only fields <br>from the expression results passed in to it. In addition, the compiler overrides Object's <br>Equals,<b> </b>GetHashCode,<b> </b>and ToString methods and generates code inside all these methods. <br>In effect, the class that the compiler generates looks like this:<br>
[CompilerGenerated] <br>internal sealed class &lt;&gt;f__AnonymousType0&lt;...&gt;: Object { <br>   private readonly t1 f1; <br>   public  t1 p1 { get { return f1; } } <br> <br>   ... <br> <br>   private readonly tn fn; <br>   public  tn pn { get { return fn; } } <br> <br>   public &lt;&gt;f__AnonymousType0&lt;...&gt;(t1 a1, ..., tn an) {  <br>      f1 = a1; ...; fn = an; // Set all fields <br>   } <br> <br>   public override Boolean Equals(Object value) { <br>      // Return false if any fields don't match; else true <br>   } <br> <br>   public override Int32 GetHashCode() { <br>      // Returns a hash code generated from each fields' hash code <br>   } <br> <br>   public override String ToString() { <br>      // Return comma-separated set of property name = value pairs <br>   } <br>}<br>
The compiler generates Equals and GetHashCode methods so that instances of the anony-<br>mous type can be placed in a hash table collection. The properties are readonly as opposed <br>to read/write to help prevent the object's hashcode from changing. Changing the hashcode <br>for an object used as a key in a hashtable can prevent the object from being found. The com-<br>piler generates the ToString method to help with debugging. In the Visual Studio debugger, <br>you can place the mouse cursor over a variable that refers to an instance of an anonymous <br>type, and Visual Studio will invoke the ToString method and show the resulting string in a <br>datatip window. By the way, Visual Studio's IntelliSense will suggest the property names as <br>you write code in the editor--a very nice feature.<br>
<hr>
<A name=267></a><b> </b><br>
<b>Chapter 10  Properties </b><br>
<b>249</b><br>
The compiler supports two additional syntaxes for declaring a property inside an anonymous <br>type where it can infer the property names and types from variables:<br>
String Name = &quot;Grant&quot;; <br>DateTime dt = DateTime.Now; <br> <br>// Anonymous type with two properties <br>//  1. String Name property set to Grant <br>//  2. Int32 Year property set to the year inside the dt <br>var o2 = new { Name, dt.Year };<br>
In this example, the compiler determines that the first property should be called Name.<b> </b>Since <br>Name is the name of a local variable, the compiler sets the type of the property to be the <br>same type as the local variable: String. For the second property, the compiler uses the name <br>of the field/property: Year. Year is an Int32 property of the DateTime class and therefore <br>the Year property in the anonymous type will also be an Int32. Now, when the compiler <br>constructs an instance of this anonymous type, it will set the instance's Name property to <br>the same value that is in the Name local variable so the Name property will refer to the same <br>&quot;Grant&quot; string. The compiler will set the instance's Year property to the same value that is <br>returned from dt's Year property.<br>
The compiler is very intelligent about defining anonymous types. If the compiler sees that <br>you are defining multiple anonymous types in your source code that have the identical  <br>structure, the compiler will create just one definition for the anonymous type and create  <br>multiple instances of that type. By "same structure," I mean that the anonymous types have <br>the same type and name for each property and that these properties are specified in the <br>same order. In the code examples above, the type of variable o1 and the type of variable o2 <br>will be the same type because the two lines of code are defining an anonymous type with a  <br>Name/String property and a Year/Int32 property, and Name comes before Year.<br>
Since the two variables are of the same type, we get to do some cool things, such as check-<br>ing if the two objects contain equal values and assigning a reference to one object into the <br>other's variable, as follows:<br>
// One type allows equality and assignment operations. <br>Console.WriteLine(&quot;Objects are equal: &quot; + o1.Equals(o2)); <br>o1 = o2;  // Assignment<br>
Also, because of this type identity, we can create an implicitly typed array (discussed in the <br>"Initializing Array Elements" section in Chapter 16, "Arrays") of anonymous types:<br>
// This works because all of the objects are of the same anonymous type <br>var people = new[] { <br>   o1,  // From earlier in this section <br>   new { Name = &quot;Kristin&quot;, Year = 1970 }, <br>   new { Name = &quot;Aidan&quot;, Year = 2003 }, <br>   new { Name = &quot;Grant&quot;, Year = 2008 } <br>}; <br> <br>
<hr>
<A name=268></a><b>250 </b><br>
<b>Part II  Designing Types</b><br>
// This shows how to walk through the array of anonymous types (var is required) <br>foreach (var person in people) <br>   Console.WriteLine(&quot;Person={0}, Year={1}&quot;, person.Name, person.Year);<br>
Anonymous types are most commonly used with the Language Integrated Query (LINQ) <br>technology, where you perform a query that results in a collection of objects that are all of <br>the same anonymous type. Then, you process the objects in the resulting collection. All this <br>takes place in the same method. Here is an example that returns all the files in my document <br>directory that have been modified within the past seven days:<br>
String myDocuments = Environment.GetFolderPath(Environment.SpecialFolder.MyDocuments); <br>var query =  <br>         from pathname in Directory.GetFiles(myDocuments) <br>         let LastWriteTime = File.GetLastWriteTime(pathname) <br>         where LastWriteTime &gt; (DateTime.Now - TimeSpan.FromDays(7)) <br>         orderby LastWriteTime <br>         select new { Path = pathname, LastWriteTime };// Set of anonymous type objects <br> <br>foreach (var file in query)  <br>   Console.WriteLine(&quot;LastWriteTime={0}, Path={1}&quot;, file.LastWriteTime, file.Path);<br>
Instances of anonymous types are not supposed to leak outside of a method. A method  <br>cannot be prototyped as accepting a parameter of an anonymous type because there is no <br>way to specify the anonymous type. Similarly, a method cannot indicate that it returns a  <br>reference to an anonymous type. While it is possible to treat an instance of an anonymous <br>type as an Object (since all anonymous types are derived from Object), there is no way to <br>cast a variable of type Object back into an anonymous type because you don't know the <br>name of the anonymous type at compile time. If you want to pass a tuple around, then you <br>should consider using the System.Tuple type discussed in the next section.<br>
<b>The </b>System.Tuple<b> Type<br></b>In the System namespace, Microsoft has defined several generic Tuple types (all derived <br>from Object) that differ by arity (the number of generic parameters). Here is what the  <br>simplest and most complex ones essentially look like:<br>
// This is the simplest: <br>[Serializable] <br>public class Tuple&lt;T1&gt; { <br>   private T1 m_Item1; <br>   public Tuple(T1 item1) { m_Item1 = item1; } <br>   public T1 Item1 { get { return m_Item1; } } <br>} <br> <br> <br>// This is the most complex: <br>[Serializable] <br>public class Tuple&lt;T1, T2, T3, T4, T5, T6, T7, TRest&gt; { <br>   private T1 m_Item1; private T2 m_Item2; private T3 m_Item3; private T4 m_Item4; <br>   private T5 m_Item5; private T6 m_Item6; private T7 m_Item7; private TRestm_Rest; <br> <br>
<hr>
<A name=269></a><b> </b><br>
<b>Chapter 10  Properties </b><br>
<b>251</b><br>
   public Tuple(T1 item1, T2 item2, T3 item3, T4 item4, T5 item5, T6 item6, T7 item7,  <br>      TRest t) { <br>      m_Item1 = item1; m_Item2 = item2; m_Item3 = item3; m_Item4 = item4; <br>      m_Item5 = item5; m_Item6 = item6; m_Item7 = item7; m_Rest = rest; <br>   } <br> <br>   public T1 Item1 { get { return m_Item1; } } <br>   public T2 Item2 { get { return m_Item2; } } <br>   public T3 Item3 { get { return m_Item3; } } <br>   public T4 Item4 { get { return m_Item4; } } <br>   public T5 Item5 { get { return m_Item5; } } <br>   public T6 Item6 { get { return m_Item6; } } <br>   public T7 Item7 { get { return m_Item7; } } <br>   public TRest Rest { get { return m_Rest; } } <br>}<br>
Like anonymous types, once a Tuple is created, it is immutable (all properties are read-only). <br>I don't show it here, but the Tuple classes also offer CompareTo,<b> </b>Equals,<b> </b>GetHashCode, and <br>ToString methods, as well as a Size property. In addition, all the Tuple types implement <br>the IStructuralEquatable,<b> </b>IStructuralComparable, and IComparable interfaces so <br>that you can compare two Tuple objects with each other to see how their fields compare <br>with each other. Refer to the SDK documentation to learn more about these methods and <br>interfaces.<br>
Here is an example of a method that uses a Tuple type to return two pieces of information <br>back to a caller:<br>
// Returns minimum in Item1 &amp; maximum in Item2 <br>private static Tuple&lt;Int32, Int32&gt;MinMax(Int32 a, Int32 b) { <br>   return new Tuple&lt;Int32, Int32&gt;(Math.Min(a, b), Math.Max(a, b)); <br>} <br> <br>// This shows how to call the method and how to use the returned Tuple <br>private static void TupleTypes() { <br>   varminmax = MinMax(6, 2); <br>   Console.WriteLine(&quot;Min={0}, Max={1}&quot;, minmax.Item1, minmax.Item2); // Min=2, Max=6 <br>}<br>
Of course, it is very important that the producer and consumer of the Tuple have a clear <br>understanding of what is being returned in the Item# properties. With anonymous types, <br>the properties are given actual names based on the source code that defines the anonymous <br>type. With Tuple types, the properties are assigned their Item# names by Microsoft and you <br>cannot change this at all. Unfortunately, these names have no real meaning or significance, <br>so it is up to the producer and consumer to assign meanings to them. This also reduces code <br>readability and maintainability so you should add comments to your code explaining what <br>the producer/consumer understanding is.<br>
The compiler can only infer generic types when cal ing a generic method, not when you are <br>cal ing a constructor. For this reason, the System namespace also includes a non-generic, static <br>Tuple class containing a bunch of static Create methods which can infer generic types from <br>
<hr>
<A name=270></a><IMG src="CLRviaCsharp-270_1.jpg"><br>
<b>252 </b><br>
<b>Part II  Designing Types</b><br>
arguments. This class acts as a factory for creating Tuple objects, and it exists simply to simplify <br>your code. Here is a rewrite of the MinMax method shown earlier using the static Tuple class:<br>
// Returns minimum in Item1 &amp; maximum in Item2 <br>private static Tuple&lt;Int32, Int32&gt;MinMax(Int32 a, Int32 b) { <br>   return Tuple.Create(Math.Min(a, b), Math.Max(a, b)); <br>
// Simpler syntax <br>
}<br>
If you want to create a Tuple with more than eight elements in it, then you would pass  <br>another Tuple for the Rest parameter as follows:<br>
var t = Tuple.Create(0, 1, 2, 3, 4, 5, 6, Tuple.Create(7, 8)); <br>Console.WriteLine(&quot;{0}, {1}, {2}, {3}, {4}, {5}, {6}, {7}, {8}&quot;, <br>   t.Item1, t.Item2, t.Item3, t.Item4, t.Item5, t.Item6, t.Item7,  <br>   t.Rest.Item1.Item1, t.Rest.Item1.Item2);<br>
<b>Note  </b>In addition to anonymous types and the Tuple types, you might want to take a look  <br>at the System.Dynamic.ExpandoObject class (defined in the System.Core.dll assembly).  <br>When you use this class with C#'s dynamic type (discussed in Chapter 5, "Primitive, Reference, <br>and Value Types"), you have another way of grouping a set of properties (key/value pairs)  <br>together. The result is not compile-time type-safe, but the syntax looks nice (although you get <br>no IntelliSense support), and you can pass ExpandoObject objects between C# and dynamic <br>languages like Python. Here's some sample code that uses an ExpandoObject:<br>
dynamic e = new System.Dynamic.ExpandoObject(); <br>e.x = 6; <br>
// Add an Int32 'x' property whose value is 6 <br>
e.y = &quot;Jeff&quot;; // Add a String 'y' property whose value is &quot;Jeff&quot; <br>e.z = null;  // Add an Object 'z' property whose value is null <br> <br>// See all the properties and their values: <br>foreach (var v in (IDictionary&lt;String, Object&gt;)e) <br>   Console.WriteLine(&quot;Key={0}, V={1}&quot;, v.Key, v.Value); <br> <br> <br>// Remove the 'x' property and its value <br>var d = (IDictionary&lt;String, Object&gt;)e; <br>d.Remove(&quot;x&quot;);<br>
<b>Parameterful Properties</b><br>
In the previous section, the get accessor methods for the properties accepted no parameters. <br>For this reason, I called these properties <i>parameterless properties</i>. These properties are easy <br>to understand because they have the feel of accessing a field. In addition to these field-like <br>properties, programming languages also support what I call <i>parameterful properties</i>, whose <br>get accessor methods accept one or more parameters and whose set accessor methods <br>accept two or more parameters. Different programming languages expose parameterful <br>properties in different ways. Also, languages use different terms to refer to parameterful <br>properties: C# calls them <i>indexers</i> and Visual Basic calls them <i>default properties</i>. In this section, <br>I'll focus on how C# exposes its indexers by using parameterful properties.<br>
<hr>
<A name=271></a><b> </b><br>
<b>Chapter 10  Properties </b><br>
<b>253</b><br>
In C#, parameterful properties (indexers) are exposed using an array-like syntax. In other <br>words, you can think of an indexer as a way for the C# developer to overload the [] operator. <br>Here's an example of a BitArray class that allows array-like syntax to index into the set of <br>bits maintained by an instance of the class:<br>
using System;  <br> <br>public sealed class BitArray {  <br>   // Private array of bytes that hold the bits  <br>   private Byte[] m_byteArray;  <br>   private Int32  m_numBits;  <br> <br>   // Constructor that allocates the byte array and sets all bits to 0  <br>   public BitArray(Int32 numBits) {  <br>      // Validate arguments first.  <br>      if (numBits &lt;= 0)  <br>         throw new ArgumentOutOfRangeException(&quot;numBits must be &gt; 0&quot;);  <br> <br>      // Save the number of bits.  <br>      m_numBits = numBits;  <br> <br>      // Allocate the bytes for the bit array.  <br>      m_byteArray = new Byte[(numBits + 7) / 8];  <br>   }  <br> <br>   // This is the indexer (parameterful property).  <br>   public Boolean this[Int32 bitPos] {  <br> <br>      // This is the indexer's get accessor method.  <br>      get {  <br>         // Validate arguments first  <br>         if ((bitPos &lt; 0) || (bitPos &gt;= m_numBits))  <br>            throw new ArgumentOutOfRangeException(&quot;bitPos&quot;);  <br> <br>         // Return the state of the indexed bit.  <br>         return (m_byteArray[bitPos / 8] &amp; (1 &lt;&lt; (bitPos % 8))) != 0;  <br>      }  <br> <br>      // This is the indexer's set accessor method.  <br>      set {  <br>         if ((bitPos &lt; 0) || (bitPos &gt;= m_numBits))  <br>            throw new ArgumentOutOfRangeException(&quot;bitPos&quot;, bitPos.ToString());  <br>         if (value) {  <br>            // Turn the indexed bit on.  <br>            m_byteArray[bitPos / 8] = (Byte)  <br>               (m_byteArray[bitPos / 8] | (1 &lt;&lt; (bitPos % 8)));  <br>         } else {  <br>            // Turn the indexed bit off.  <br>            m_byteArray[bitPos / 8] = (Byte)  <br>               (m_byteArray[bitPos / 8] &amp; ~(1 &lt;&lt; (bitPos % 8)));  <br>         }  <br>      }  <br>   }  <br>}<br>
<hr>
<A name=272></a><b>254 </b><br>
<b>Part II  Designing Types</b><br>
Using the BitArray class's indexer is incredibly simple:<br>
// Allocate a BitArray that can hold 14 bits.  <br>BitArray ba = new BitArray(14);  <br> <br>// Turn all the even-numbered bits on by calling the set accessor.  <br>for (Int32 x = 0; x &lt; 14; x++) {  <br>   ba[x] = (x % 2 == 0);  <br>}  <br> <br>// Show the state of all the bits by calling the get accessor.  <br>for (Int32 x = 0; x &lt; 14; x++) {  <br>   Console.WriteLine(&quot;Bit &quot; + x + &quot; is &quot; + (ba[x] ? &quot;On&quot; : &quot;Off&quot;));  <br>}<br>
In the BitArray example, the indexer takes one Int32 parameter, bitPos. All indexers must <br>have at least one parameter, but they can have more. These parameters (as well as the return <br>type) can be of any data type (except void). An example of an indexer that has more than <br>one parameter can be found in the System.Drawing.Imaging.ColorMatrix class, which <br>ships in the System.Drawing.dll assembly.<br>
It's quite common to create an indexer to look up values in an associative array. In fact, the <br>System.Collections.Generic.Dictionary type offers an indexer that takes a key and <br>returns the value associated with the key. Unlike parameterless properties, a type can offer <br>multiple, overloaded indexers as long as their signatures differ.<br>
Like a parameterless property's set accessor method, an indexer's set accessor method also <br>contains a hidden parameter, called value in C#. This parameter indicates the new value  <br>desired for the "indexed element."<br>
The CLR doesn't differentiate parameterless properties and parameterful properties; to the <br>CLR, each is simply a pair of methods and a piece of metadata defined within a type. As  <br>mentioned earlier, different programming languages require different syntax to create and <br>use parameterful properties. The fact that C# requires this[...] as the syntax for express-<br>ing an indexer was purely a choice made by the C# team. What this choice means is that C# <br>allows indexers to be defined only on instances of objects. C# doesn't offer syntax allowing <br>a developer to define a static indexer property, although the CLR does support static param-<br>eterful properties.<br>
Because the CLR treats parameterful properties just as it does parameterless properties, the <br>compiler will emit either two or three of the following items into the resulting managed <br>assembly:<br>
  A method representing the parameterful property's get accessor method. This is emit-<br>
ted only if you define a get accessor method for the property.<br>
  A method representing the parameterful property's set accessor method. This is emit-<br>
ted only if you define a set accessor method for the property.<br>
<hr>
<A name=273></a><b> </b><br>
<b>Chapter 10  Properties </b><br>
<b>255</b><br>
  A property definition in the managed assembly's metadata, which is always emitted. <br>
There's no special parameterful property metadata definition table because, to the CLR, <br>parameterful properties are just properties.<br>
For the BitArray class shown earlier, the compiler compiles the indexer as though the original <br>source code were written as follows:<br>
public sealed class BitArray {  <br>     <br>   // This is the indexer's get accessor method.  <br>   public Boolean get_Item(Int32 bitPos) { /* ... */ }  <br> <br>   // This is the indexer's set accessor method.  <br>   public void    set_Item(Int32 bitPos, Boolean value)  { /* ... */ }  <br>}<br>
The compiler automatically generates names for these methods by prepending get_ and <br>set_ to the <i>indexer name</i>. Because the C# syntax for an indexer doesn't allow the developer <br>to specify an <i>indexer name</i>, the C# compiler team had to choose a default name to use for <br>the accessor methods; they chose Item.  Therefore, the method names emitted by the  <br>compiler are get_Item and set_Item.<br>
When examining the .NET Framework Reference documentation, you can tell if a type  <br>offers an indexer by looking for a property named Item. For example, the  <br>System.Collections.Generic.List type offers a public instance property named Item;<b> <br></b>this property is List's indexer.<br>
When you program in C#, you never see the name of Item, so you don't normally care  <br>that the compiler has chosen this name for you. However, if you're designing an indexer  <br>for a type that code written in other programming languages will be accessing, you might <br>want to change the default name, Item,<b> </b>given to your indexer's get and set accessor  <br>methods. C# allows you to rename these methods by applying the  <br>System.Runtime.CompilerServices.IndexerNameAttribute custom attribute to the  <br>indexer. The following code demonstrates how to do this:<br>
using System;  <br>using System.Runtime.CompilerServices;  <br> <br>public sealed class BitArray {  <br>     <br>   [IndexerName(&quot;Bit&quot;)]  <br>   public Boolean this[Int32 bitPos] {  <br>      // At least one accessor method is defined here  <br>   }  <br>}<br>
Now the compiler will emit methods called get_Bit and set_Bit instead of get_Item and <br>set_Item.<b> </b>When compiling, the C# compiler sees the IndexerName attribute, and this tells <br>
<hr>
<A name=274></a><b>256 </b><br>
<b>Part II  Designing Types</b><br>
the compiler how to name the methods and the property metadata; the attribute itself is not <br>emitted into the assembly's metadata.2<br>
Here's some Visual Basic code that demonstrates how to access this C# indexer:<br>
' Construct an instance of the BitArray type.  <br>Dim ba as New BitArray(10)  <br>     <br>' Visual Basic uses () instead of [] to specify array elements.  <br>Console.WriteLine(ba(2))       ' Displays True or False  <br> <br>' Visual Basic also allows you to access the indexer by its name.  <br>Console.WriteLine(ba.Bit(2))   ' Displays same as previous line<br>
In C#, a single type can define multiple indexers as long as the indexers all take different <br>parameter sets. In other programming languages, the IndexerName attribute allows you to <br>define multiple indexers with the same signature because each can have a different name. <br>The reason C# won't allow you to do this is because its syntax doesn't refer to the indexer by <br>name; the compiler wouldn't know which indexer you were referring to. Attempting to com-<br>pile the following C# source code causes the compiler to generate the following message: <br>&quot;error C0111: Type 'SomeType' already defines a member called 'this' with <br>the same parameter types.&quot;<br>
using System;  <br>using System.Runtime.CompilerServices;  <br> <br>public sealed class SomeType {  <br> <br>   // Define a get_Item accessor method.  <br>   public Int32 this[Boolean b] {  <br>      get { return 0; }      <br>   }  <br> <br>   // Define a get_Jeff accessor method.  <br>   [IndexerName(&quot;Jeff&quot;)]  <br>   public String this[Boolean b] {  <br>      get { return null; }  <br>   }  <br>}<br>
You can clearly see that C# thinks of indexers as a way to overload the [] operator, and <br>this operator can't be used to disambiguate parameterful properties with different method <br>names and identical parameter sets.<br>
By the way, the System.String type is an example of a type that changed the name of its in-<br>dexer. The name of String's indexer is Chars instead of Item.<b> </b>This read-only property al ows <br>you to get an individual character within a string. For programming languages that don't use <br>[] operator syntax to access this property, Chars was decided to be a more meaningful name.<br>
2  For this reason, the IndexerNameAttribute class is not part of the ECMA standardization of the CLI and the C#  <br>
language.<br>
<hr>
<A name=275></a><hr>
<A name=276></a><b>258 </b><br>
<b>Part II  Designing Types</b><br>
call at runtime at the expense of making the compiled method's code bigger. Because prop-<br>erty accessor methods typically contain very little code, inlining them can make the native <br>code smaller and can make it execute faster.<br>
Note that the JIT compiler does not inline property methods when debugging code because <br>inlined code is harder to debug. This means that the performance of accessing a property <br>can be fast in a release build and slow in a debug build. Field access is fast in both debug and <br>release builds.<br>
<b>Property Accessor Accessibility</b><br>
Occasionally, when designing a type, it is desired to have one accessibility for a get accessor <br>method and a different accessibility for a set accessor method. The most common scenario <br>is to have a public get accessor and a protected set accessor:<br>
public class SomeType {  <br>   private String m_name; <br>   public String Name {   <br>      get { return m_name; }   <br>      protected set {m_name = value; }  <br>   }  <br>}<br>
As you can see from the code above, the Name property is itself declared as a public prop-<br>erty, and this means that the get accessor method wil  be public and therefore cal able by all <br>code. However, notice that the set accessor is declared as protected and will be callable only <br>from code defined within SomeType or from code in a class that is derived from SomeType.<br>
When defining a property with accessor methods that have different accessibilities, C#  <br>syntax requires that the property itself must be declared with the least-restrictive accessibility <br>and that more restrictive accessibility be applied to just one of the accessor methods. In the <br>example above, the property is public, and the set accessor is protected (more restrictive <br>than public).<br>
<b>Generic Property Accessor Methods</b><br>
Since properties are really just methods, and because C# and the CLR allow methods to be <br>generic, sometimes people want to define properties that introduce their own generic type <br>parameters (as opposed to using the enclosing type's generic type parameter). However, <br>C# does not allow this. The main reason why properties cannot introduce their own generic <br>type parameters is because they don't make sense conceptually. A property is supposed to <br>represent a characteristic of an object that can be queried or set. Introducing a generic type <br>parameter would mean that the behavior of the querying/setting could be changed, but <br>conceptually, a property is not supposed to have behavior. If you want your object to expose <br>some behavior--generic or not--define a method, not a property.<br>
<hr>
<A name=277></a>Chapter 11<br><b>Events</b><br>
<b>In this chapter:<br>Designing a Type That Exposes an Event  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260<br>How the Compiler Implements an Event  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 266<br>Designing a Type That Listens for an Event  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269<br>Explicitly Implementing an Event. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271</b><br>
In this chapter, I'll talk about the last kind of member a type can define: events. A type that <br>defines an event member allows the type (or instances of the type) to notify other objects <br>that something special has happened. For example, the Button class offers an event called <br>Click. When a Button object is clicked, one or more objects in an application may want to <br>receive notification about this event in order to perform some action. Events are type mem-<br>bers that allow this interaction. Specifically, defining an event member means that a type is <br>offering the following capabilities:<br>
  A method can register its interest in the event.<br>
  A method can unregister its interest in the event.<br>
  Registered methods will be notified when the event occurs.<br>
Types can offer this functionality when defining an event because they maintain a list of the <br>registered methods. When the event occurs, the type notifies all of the registered methods in <br>the collection.<br>
The common language runtime's (CLR's) event model is based on <i>delegates</i>. A delegate is a <br>type-safe way to invoke a callback method. Cal back methods are the means by which objects <br>receive the notifications they subscribed to. In this chapter, I'll be using delegates, but I won't <br>fully explain all their details until Chapter 17, "Delegates."<br>
To help you fully understand the way events work within the CLR, I'll start with a scenario in <br>which events are useful. Suppose you want to design an e-mail application. When an e-mail <br>message arrives, the user might like the message to be forwarded to a fax machine or a pager. <br>In architecting this application, let's say that you'll first design a type, called MailManager, <br>that receives the incoming e-mail messages. MailManager will expose an event called <br>NewMail. Other types (such as Fax and Pager) may register interest in this event. When <br>MailManager receives a new e-mail message, it will raise the event, causing the message to <br>be distributed to each of the registered objects. Each object can process the message in any <br>way it desires.<br>
<b> </b><br>
<b> </b><br>
<b>259</b><br>
<hr>
<A name=278></a><b>260 </b><br>
<b>Part II  Designing Types</b><br>
When the application initializes, let's instantiate just one MailManager instance--the applica-<br>tion can then instantiate any number of Fax and Pager types. Figure 11-1 shows how the  <br>application initializes and what happens when a new e-mail message arrives.<br>
Fax #1<br>
Pager #1<br>
<b>4</b><br>
<b>1</b><br>
MailManager<br>
<b>2</b><br>
<b>3</b><br>
1.  A method in the Fax object registers interest with the MailManager's event.<br>2.  A method in the Pager object registers interest with the MailManager's event.<br>3.  A new mail message arrives at MailManager.<br>4.  The MailManager object fires the notification off to all the registered <br> <br>
methods, which process the mail message as desired<br>
<b>FIGURE 11-1  </b>Architecting an application to use events<br>
Here's how the application illustrated in Figure 11-1 works: The application initializes by  <br>constructing an instance of MailManager. MailManager offers a NewMail event. When the <br>Fax and Pager objects are constructed, they register an instance method with MailManager's <br>NewMail event so that MailManager knows to notify the Fax and Pager objects when new <br>e-mail messages arrive. Now, when MailManager receives a new e-mail message (sometime <br>in the future), it will raise the NewMail event, giving all of the registered methods an oppor-<br>tunity to process the new message in any way they want.<br>
<b>Designing a Type That Exposes an Event</b><br>
There are many steps a developer must take in order to define a type that exposes one <br>or more event members. In this section, I'll walk through each of the necessary steps. The <br>MailManager sample application (which can be downloaded from <i>http://wintellect.com</i>) <br>shows all of the source code for the MailManager type, the Fax type, and the Pager type. <br>You'll notice that the Pager type is practically identical to the Fax type.<br>
<hr>
<A name=279></a><IMG src="CLRviaCsharp-279_1.jpg"><br>
<b> </b><br>
<b>Chapter 11  Events </b><br>
<b>261</b><br>
<b>Step #1: Define a type that will hold any additional </b><br>
<b>information that should be sent to receivers of the event </b><br>
<b>notification</b><br>
When an event is raised, the object raising the event may want to pass some additional  <br>information to the objects receiving the event notification. This additional information  <br>needs to be encapsulated into its own class, which typically contains a bunch of private fields <br>along with some read-only public properties to expose these fields. By convention, classes <br>that hold event information to be passed to the event handler should be derived from <br>System.EventArgs, and the name of the class should be suffixed with EventArgs. In this <br>example, the NewMailEventArgs class has fields identifying who sent the message (m_from), <br>who is receiving the message (m_to), and the subject of the message (m_subject).<br>
// Step #1: Define a type that will hold any additional information that   <br>// should be sent to receivers of the event notification    <br>internal class NewMailEventArgs : EventArgs {  <br> <br>   private readonly String m_from, m_to, m_subject;  <br> <br>   public NewMailEventArgs(String from, String to, String subject) {  <br>      m_from = from; m_to = to; m_subject = subject;  <br>   }  <br>        <br>   public String From    { get { return m_from;    } }  <br>   public String To      { get { return m_to;      } }  <br>   public String Subject { get { return m_subject; } }  <br>}<br>
<b>Note  </b>The EventArgs class is defined in the Microsoft .NET Framework Class Library (FCL) and is <br>implemented like this:<br>
[ComVisible(true), Serializable]  <br>public class EventArgs {  <br>   public static readonly EventArgs Empty = new EventArgs();  <br>   public EventArgs() {  }  <br>}<br>
As you can see, this type is nothing to write home about. It simply serves as a base type from <br>which other types can derive. Many events don't have any additional information to pass on. <br>For example, when a Button notifies its registered receivers that it has been clicked, just invok-<br>ing the callback method is enough information. When you're defining an event that doesn't <br>have any additional data to pass on, just use EventArgs.Empty rather than constructing a new <br>EventArgs object.<br>
<hr>
<A name=280></a><IMG src="CLRviaCsharp-280_1.jpg"><br>
<b>262 </b><br>
<b>Part II  Designing Types</b><br>
<b>Step #2: Define the event member</b><br>
An event member is defined using the C# keyword event. Each event member is given ac-<br>cessibility (which is almost always public so that other code can access the event member), <br>a type of delegate indicating the prototype of the method(s) that will be called, and a name <br>(which can be any valid identifier). Here is what the event member in our MailManager class <br>looks like:<br>
internal class MailManager {  <br> <br>   // Step #2: Define the event member   <br>   public event EventHandler&lt;NewMailEventArgs&gt; NewMail;   <br>   ...  <br>}<br>
NewMail is the name of this event. The type of the event member is <br>EventHandler&lt;NewMailEventArgs&gt;, which means that all receivers of the event  <br>notification must supply a callback method whose prototype matches that of the <br>EventHandler&lt;NewMailEventArgs&gt; delegate type. Since the generic System.EventHandler <br>delegate is defined as follows:<br>
public delegate void EventHandler&lt;TEventArgs&gt;(Object sender, TEventArgs e) <br>   where TEventArgs: EventArgs;<br>
the method prototypes must look like this:<br>
void MethodName(Object sender, NewMailEventArgs e);<br>
<b>Note  </b>A lot of people wonder why the event pattern requires the sender parameter to always <br>be of type Object. After all, since the MailManager will be the only type raising an event with a <br>NewMailEventArgs object, it makes more sense for the callback method to be prototyped like <br>this:<br>
void MethodName(MailManager sender, NewMailEventArgs e);<br>
The pattern requires the sender parameter to be of type Object mostly because of inheritance. <br>What if MailManager were used as a base class for SmtpMailManager? In this case, the callback  <br>method should have the sender parameter prototyped as SmtpMailManager instead of <br>MailManager, but this can't happen because SmtpMailManager just inherited the NewMail <br>event. So the code that was expecting SmtpMailManager to raise the event must still have to <br>cast the sender argument to SmtpMailManager. In other words, the cast is still required, so the <br>sender parameter might as well be typed as Object.<br>
The next reason for typing the sender parameter as Object is just flexibility. It allows the del-<br>egate to be used by multiple types that offer an event that passes a NewMailEventArgs object. <br>For example, a PopMailManager class could use the delegate even if this class were not derived <br>from MailManager.<br>
<hr>
<A name=281></a><b> </b><br>
<b>Chapter 11  Events </b><br>
<b>263</b><br>
The event pattern also requires that the delegate definition and the callback method name the <br>EventArgs-derived parameter e. The only reason for this is to add additional consistency to the <br>pattern, making it easier for developers to learn and implement the pattern. Tools that spit out <br>source code (such as Microsoft Visual Studio) also know to call the parameter e.<br>
Finally, the event pattern requires all event handlers to have a return type of void. This is <br>necessary because raising an event might call several callback methods, and there is no way <br>to get the return values from all of them. Having a return type of void doesn't allow the <br>callbacks to return a value. Unfortunately, there are some event handlers in the FCL, such as <br>ResolveEventHandler, that did not follow Microsoft's own prescribed pattern because it  <br>returns an object of type Assembly.<br>
<b>Step #3: Define a method responsible for raising the event to </b><br>
<b>notify registered objects that the event has occurred</b><br>
By convention, the class should define a protected, virtual method that is called by code  <br>internally within the class and its derived classes when the event is to be raised. This method <br>takes one parameter, a NewMailEventArgs object, which includes the information passed <br>to the objects receiving the notification. The default implementation of this method simply <br>checks if any objects have registered interest in the event and, if so, the event will be raised, <br>thereby notifying the registered methods that the event has occurred. Here is what the <br>method in our MailManager class looks like:<br>
internal class MailManager {  <br>   ...  <br>   // Step #3: Define a method responsible for raising the event   <br>   // to notify registered objects that the event has occurred  <br>   // If this class is sealed, make this method private and nonvirtual  <br>   protected virtual void OnNewMail(NewMailEventArgs e) {  <br> <br>      // Copy a reference to the delegate field now into a temporary field for thread safety  <br>      EventHandler&lt;EventArgs&gt; temp =  <br>         Interlocked.CompareExchange(ref NewMail, null, null); <br> <br>      // If any methods registered interest with our event, notify them   <br>      if (temp != null) temp(this, e);  <br>   }  <br>   ...  <br>}<br>
<hr>
<A name=282></a><hr>
<A name=283></a><hr>
<A name=284></a><b>266 </b><br>
<b>Part II  Designing Types</b><br>
A class that uses MailManager as a base type is free to override the OnNewMail method. This <br>capability gives the derived class control over the raising of the event. The derived class can <br>handle the new e-mail message in any way it sees fit. Usually, a derived type calls the base <br>type's OnNewMail method so that the registered method(s) receive the notification. However, <br>the derived class might decide to disallow the event from being forwarded.<br>
<b>Step #4: Define a method that translates the input into the </b><br>
<b>desired event</b><br>
Your class must have some method that takes some input and translates it into the raising of <br>the event. In my MailManager example, the SimulateNewMail method is called to indicate <br>that a new e-mail message has arrived into MailManager:<br>
internal class MailManager {  <br> <br>   // Step #4: Define a method that translates the   <br>   // input into the desired event  <br>   public void SimulateNewMail(String from, String to, String subject) {  <br> <br>      // Construct an object to hold the information we wish  <br>      // to pass to the receivers of our notification  <br>      NewMailEventArgs e = new NewMailEventArgs(from, to, subject);  <br> <br>      // Call our virtual method notifying our object that the event  <br>      // occurred. If no type overrides this method, our object will  <br>      // notify all the objects that registered interest in the event  <br>      OnNewMail(e);  <br>   }     <br>}<br>
SimulateNewMail accepts information about the message and constructs a <br>NewMailEventArgs object, passing the message information to its constructor. <br>MailManager's own virtual OnNewMail method is then called to formally notify the <br>MailManager object of the new e-mail message. Usually, this causes the event to be raised, <br>notifying all of the registered methods. (As mentioned before, a class using MailManager as <br>a base class can override this behavior.)<br>
<b>How the Compiler Implements an Event</b><br>
Now that you know how to define a class that offers an event member, let's take a closer look <br>at what an event really is and how it works. In the MailManager class, we have a line of code <br>that defines the event member itself:<br>
public event EventHandler&lt;NewMailEventArgs&gt; NewMail;<br>
<hr>
<A name=285></a><b> </b><br>
<b>Chapter 11  Events </b><br>
<b>267</b><br>
When the C# compiler compiles the line above, it translates this single line of source code <br>into the following three constructs:<br>
// 1. A PRIVATE delegate field that is initialized to null   <br>private EventHandler&lt;NewMailEventArgs&gt; NewMail = null;  <br> <br>// 2. A PUBLIC add_Xxx method (where Xxx is the Event name)  <br>// Allows methods to register interest in the event.  <br>public void add_NewMail(EventHandler&lt;NewMailEventArgs&gt; value) {  <br>   // The loop and the call to CompareExchange is all just a fancy way  <br>   // of adding a delegate to the event in a thread-safe way <br>   EventHandler&lt;NewMailEventArgs&gt;prevHandler; <br>   EventHandler&lt;NewMailEventArgs&gt; newMail = this.NewMail; <br>   do { <br>      prevHandler = newMail; <br>      EventHandler&lt;NewMailEventArgs&gt;newHandler =  <br>         (EventHandler&lt;NewMailEventArgs&gt;) Delegate.Combine(prevHandler, value); <br>      newMail = Interlocked.CompareExchange&lt;EventHandler&lt;NewMailEventArgs&gt;&gt;( <br>         ref this.NewMail, newHandler, prevHandler); <br>   } while (newMail != prevHandler); <br>}  <br> <br>// 3. A PUBLIC remove_Xxx method (where Xxx is the Event name)  <br>// Allows methods to unregister interest in the event.  <br>public void remove_NewMail(EventHandler&lt;NewMailEventArgs&gt; value) {  <br>   // The loop and the call to CompareExchange is all just a fancy way  <br>   // of removing a delegate from the event in a thread-safe way <br>   EventHandler&lt;NewMailEventArgs&gt; prevHandler; <br>   EventHandler&lt;NewMailEventArgs&gt; newMail = this.NewMail; <br>   do { <br>      prevHandler = newMail; <br>      EventHandler&lt;NewMailEventArgs&gt; newHandler =  <br>         (EventHandler&lt;NewMailEventArgs&gt;) Delegate.Remove(prevHandler, value); <br>      newMail = Interlocked.CompareExchange&lt;EventHandler&lt;NewMailEventArgs&gt;&gt;( <br>         ref this.NewMail, newHandler, prevHandler); <br>   } while (newMail != prevHandler); <br>}<br>
The first construct is simply a field of the appropriate delegate type. This field is a reference  <br>to the head of a list of delegates that will be notified when this event occurs. This field is  <br>initialized to null, meaning that no listeners have registered interest in the event. When a  <br>method registers interest in the event, this field refers to an instance of the <br>EventHandler&lt;NewMailEventArgs&gt; delegate, which may refer to additional <br>EventHandler&lt;NewMailEventArgs&gt; delegates. When a listener registers interest in an event, <br>the listener is simply adding an instance of the delegate type to the list. Obviously, unregis-<br>tering means removing the delegate from the list.<br>
You'll notice that the delegate field, NewMail in this example, is always private even though <br>the original line of source code defines the event as public. The reason for making the  <br>delegate field private is to prevent code outside the defining class from manipulating it  <br>
<hr>
<A name=286></a><IMG src="CLRviaCsharp-286_1.jpg"><br>
<IMG src="CLRviaCsharp-286_2.jpg"><br>
<b>268 </b><br>
<b>Part II  Designing Types</b><br>
improperly. If the field were public, any code could alter the value in the field and poten-<br>tially wipe out all of the delegates that have registered interest in the event.<br>
The second construct the C# compiler generates is a method that allows other objects to <br>register their interest in the event. The C# compiler automatically names this function by <br>prepending add_ to the event's name (NewMail). The C# compiler automatically generates <br>the code that is inside this method. The code always calls System.Delegate's static Combine <br>method, which adds the instance of a delegate to the list of delegates and returns the new <br>head of the list, which gets saved back in the field.<br>
The third construct the C# compiler generates is a method that allows an object to unreg-<br>ister its interest in the event. Again, the C# compiler automatically names this function by <br>prepending remove_ to the event's name (NewMail). The code inside this method always calls <br>Delegate's static Remove method, which removes the instance of a delegate from the list of <br>delegates and returns the new head of the list, which gets saved back in the field.<br>
<b>Warning  </b>If you attempt to remove a method that was never added, then Delegate's Remove <br>method internally does nothing. That is, you get no exception or warning of any type; the event's <br>collection of methods remains unchanged.<br>
<b>Note  </b>The add and remove methods use a well-known pattern to update a value in a thread-safe <br>way. This pattern is discussed in the "The Interlocked Anything Pattern" section of Chapter 28."<br>
In this example, the add and remove methods are public. The reason they are public is  <br>that the original line of source code declared the event to be public. If the event had been <br>declared protected, the add and remove methods generated by the compiler would also <br>have been declared protected. So, when you define an event in a type, the accessibility of <br>the event determines what code can register and unregister interest in the event, but only <br>the type itself can ever access the delegate field directly. Event members can also be declared <br>as static or virtual, in which case the add and remove methods generated by the compiler <br>would be either static or virtual, respectively.<br>
In addition to emitting the aforementioned three constructs, compilers also emit an event <br>definition entry into the managed assembly's metadata. This entry contains some flags and <br>the underlying delegate type, and refers to the add and remove accessor methods. This  <br>information exists simply to draw an association between the abstract concept of an "event" <br>and its accessor methods. Compilers and other tools can use this metadata, and this informa-<br>tion can also be obtained by using the System.Reflection.EventInfo class. However, the <br>CLR itself doesn't use this metadata information and requires only the accessor methods at <br>runtime.<br>
<hr>
<A name=287></a><b> </b><br>
<b>Chapter 11  Events </b><br>
<b>269</b><br>
<b>Designing a Type That Listens for an Event</b><br>
The hard work is definitely behind you at this point. In this section, I'l  show you how to define <br>a type that uses an event provided by another type. Let's start off by examining the code for <br>the Fax type:<br>
internal sealed class Fax {  <br>   // Pass the MailManager object to the constructor  <br>   public Fax(MailManager mm) {  <br> <br>      // Construct an instance of the EventHandler&lt;NewMailEventArgs&gt;   <br>      // delegate that refers to our FaxMsg callback method.  <br>      // Register our callback with MailManager's NewMail event  <br>      mm.NewMail += FaxMsg;  <br>   }  <br> <br>   // This is the method the MailManager will call  <br>   // when a new e-mail message arrives  <br>   private void FaxMsg(Object sender, NewMailEventArgs e) {  <br> <br>      // 'sender' identifies the MailManager object in case   <br>      // we want to communicate back to it.  <br> <br>      // 'e' identifies the additional event information   <br>      // the MailManager wants to give us.  <br> <br>      // Normally, the code here would fax the e-mail message.  <br>      // This test implementation displays the info in the console  <br>      Console.WriteLine(&quot;Faxing mail message:&quot;);  <br>      Console.WriteLine(&quot;   From={0}, To={1}, Subject={2}&quot;,  <br>         e.From, e.To, e.Subject);  <br>   }  <br> <br>   // This method could be executed to have the Fax object unregister   <br>   // itself with the NewMail event so that it no longer receives  <br>   // notifications  <br>   public void Unregister(MailManager mm) {  <br> <br>      // Unregister with MailManager's NewMail event  <br>      mm.NewMail -= FaxMsg;  <br>   }  <br>}<br>
When the e-mail application initializes, it would first construct a MailManager object and <br>save the reference to this object in a variable. Then the application would construct a Fax ob-<br>ject, passing the reference to the MailManager object as a parameter. In the Fax constructor, <br>the Fax object registers its interest in MailManager's NewMail event using C#'s <b>+=</b> operator:<br>
mm.NewMail += FaxMsg;<br>
<hr>
<A name=288></a><b>270 </b><br>
<b>Part II  Designing Types</b><br>
Because the C# compiler has built-in support for events, the compiler translates the use of <br>the += operator into the following line of code to add the object's interest in the event:<br>
mm.add_NewMail(new EventHandler&lt;NewMailEventArgs&gt;(this.FaxMsg));<br>
As you can see, the C# compiler is generating code that will construct an <br>EventHandler&lt;NewMailEventArgs&gt; delegate object that wraps the Fax class's FaxMsg <br>method. Then, the C# compiler calls the MailManager's add_NewMail method, passing it the <br>new delegate. Of course, you can verify all of this by compiling the code and looking at the IL <br>with a tool such as ILDasm.exe.<br>
Even if you're using a programming language that doesn't directly support events, you can <br>still register a delegate with the event by calling the add accessor method explicitly. The ef-<br>fect is identical; the source code will just not look as pretty. It's the add method that registers <br>the delegate with the event by adding it to the event's list of delegates.<br>
When the MailManager object raises the event, the Fax object's FaxMsg method gets called. <br>The method is passed a reference to the MailManager object as the first parameter, sender. <br>Most of the time, this parameter is ignored, but it can be used if the Fax object wants to  <br>access members of the MailManager object in response to the event notification. The second <br>parameter is a reference to a NewMailEventArgs object. This object contains any additional <br>information the designer of MailManager and NewMailEventArgs thought would be useful <br>to the event receivers.<br>
From the NewMailEventArgs object, the FaxMsg method has easy access to the message's <br>sender, the message's recipient, and the message's subject. In a real Fax object, this informa-<br>tion would be faxed somewhere. In this example, the information is simply displayed in the <br>console window.<br>
When an object is no longer interested in receiving event notifications, it should unregister <br>its interest. For example, the Fax object would unregister its interest in the NewMail event <br>if the user no longer wanted his or her e-mail forwarded to a fax. As long as an object has <br>registered one of its methods with an event, the object can't be garbage collected. If your <br>type implements IDisposable's Dispose method, the implementation should cause it to <br>unregister interest in all events. (See Chapter 21, "Automatic Memory Management (Garbage <br>Collection)," for more information about IDisposable.)<br>
Code that demonstrates how to unregister for an event is shown in Fax's Unregister method. <br>This method is practically identical to the code shown in the Fax constructor. The only dif-<br>ference is that this code uses -= instead of +=. When the C# compiler sees code using the -= <br>operator to unregister a delegate with an event, the compiler emits a call to the event's re-<br>move method:<br>
mm.remove_NewMail(new EventHandler&lt;NewMailEventArgs&gt;(FaxMsg));<br>
<hr>
<A name=289></a><b> </b><br>
<b>Chapter 11  Events </b><br>
<b>271</b><br>
As with the += operator, even if you're using a programming language that doesn't directly <br>support events, you can still unregister a delegate with the event by calling the remove  <br>accessor method explicitly. The remove method unregisters the delegate from the event by <br>scanning the list for a delegate that wraps the same method as the one passed in. If a match <br>is found, the existing delegate is removed from the event's list of delegates. If a match isn't <br>found, no error occurs, and the list is unaltered.<br>
By the way, C# requires your code to use the += and -= operators to add and remove del-<br>egates from the list. If you try to call the add or remove method explicitly, the C# compiler <br>produces the CS0571 &quot;cannot explicitly call operator or accessor&quot; error message.<br>
<b>Explicitly Implementing an Event</b><br>
The System.Windows.Forms.Control type defines about 70 events. If the Control type <br>implemented the events by allowing the compiler to implicitly generate the add and remove <br>accessor methods and delegate fields, every Control object would have 70 delegate fields <br>in it just for the events! Since most programmers care about just a few events, an enor-<br>mous amount of memory would be wasted for each object created from a Control-derived <br>type. By the way, the ASP.NET System.Web.UI.Control and the Windows Presentation <br>Foundation (WPF) System.Windows.UIElement type also offer many events that most  <br>programmers do not use.<br>
In this section, I discuss how the C# compiler allows a class developer to explicitly implement <br>an event, allowing the developer to control how the add and remove methods manipulate <br>the callback delegates. I'm going to demonstrate how explicitly implementing an event can <br>be used to efficiently implement a class that offers many events. However, there are certainly <br>other scenarios where you might want to explicitly implement a type's event.<br>
To efficiently store event delegates, each object that exposes events will maintain a collection <br>(usually a dictionary) with some sort of event identifier as the key and a delegate list as the <br>value. When a new object is constructed, this collection is empty. When interest in an event is <br>registered, the event's identifier is looked up in the collection. If the event identifier is there, <br>the new delegate is combined with the list of delegates for this event. If the event identifier <br>isn't in the collection, the event identifier is added with the delegate.<br>
When the object needs to raise an event, the event identifier is looked up in the collection. If <br>the collection doesn't have an entry for the event identifier, nothing has registered interest in <br>the event and no delegates need to be called back. If the event identifier is in the collection, <br>the delegate list associated with the event identifier is invoked. Implementing this design  <br>pattern is the responsibility of the developer who is designing the type that defines the <br>events; the developer using the type has no idea how the events are implemented internally.<br>
<hr>
<A name=290></a><b>272 </b><br>
<b>Part II  Designing Types</b><br>
Here is an example of how you could accomplish this pattern. First, I implemented an <br>EventSet class that represents a collection of events and each event's delegate list as follows:<br>
using System; <br>using System.Collections.Generic; <br> <br>// This class exists to provide a bit more type safety and  <br>// code maintainability when using EventSet <br>public sealed class EventKey : Object { } <br> <br>public sealed class EventSet { <br>   // The private dictionary used to maintain EventKey -&gt; Delegate mappings <br>private readonly Dictionary&lt;EventKey, Delegate&gt; m_events = <br>   newDictionary&lt;EventKey, Delegate&gt;(); <br> <br>// Adds an EventKey -&gt; Delegate mapping if it doesn't exist or  <br>// combines a delegate to an existing EventKey <br>public void Add(EventKey eventKey, Delegate handler) { <br>   Monitor.Enter(m_events); <br>   Delegate d; <br>   m_events.TryGetValue(eventKey, out d); <br>   m_events[eventKey] = Delegate.Combine(d, handler); <br>   Monitor.Exit(m_events); <br>} <br> <br>// Removes a delegate from an EventKey (if it exists) and  <br>// removes the EventKey -&gt; Delegate mapping the last delegate is removed <br>public void Remove(EventKey eventKey, Delegate handler) { <br>   Monitor.Enter(m_events); <br>   // Call TryGetValue to ensure that an exception is not thrown if <br>   // attempting to remove a delegate from an EventKey not in the set <br>   Delegate d; <br>   if (m_events.TryGetValue(eventKey, out d)) { <br>      d = Delegate.Remove(d, handler); <br> <br>      // If a delegate remains, set the new head else remove the EventKey <br>      if (d != null) m_events[eventKey] = d; <br>      else m_events.Remove(eventKey); <br>   } <br>   Monitor.Exit(m_events); <br>} <br> <br>// Raises the event for the indicated EventKey <br>public void Raise(EventKey eventKey, Object sender, EventArgs e) { <br>   // Don't throw an exception if the EventKey is not in the set <br>   Delegate d; <br>   Monitor.Enter(m_events); <br>   m_events.TryGetValue(eventKey, out d); <br>   Monitor.Exit(m_events); <br> <br>   if (d != null) { <br>      // Because the dictionary can contain several different delegate types, <br>      // it is impossible to construct a type-safe call to the delegate at  <br>      // compile time. So, I call the System.Delegate type's DynamicInvoke  <br>      // method, passing it the callback method's parameters as an array of  <br>
<hr>
<A name=291></a><IMG src="CLRviaCsharp-291_1.jpg"><br>
<b> </b><br>
<b>Chapter 11  Events </b><br>
<b>273</b><br>
      // objects. Internally, DynamicInvoke will check the type safety of the  <br>      // parameters with the callback method being called and call the method. <br>      // If there is a type mismatch, then DynamicInvoke will throw an exception. <br>      d.DynamicInvoke(newObject[] { sender, e }); <br>      } <br>   }<br>
<b>Note  </b>The FCL defines a type, System.ComponentModel.EventHandlerList, which does <br>essentially the same thing as my EventSet class. The System.Windows.Forms.Control and <br>System.Web.UI.Control types use the EventHandlerList type internally to maintain their <br>sparse set of events. You're certainly welcome to use the FCL's EventHandlerList type if <br>you'd like. The difference between the EventHandlerList type and my EventSet type is that <br>EventHandlerList uses a linked list instead of a hash table. This means that accessing elements  <br>managed by the EventHandlerList is slower than using my EventSet. In addition, the <br>EventHandlerList doesn't offer any thread-safe way to access the events; you would have to <br>implement your own thread-safe wrapper around the EventHandlerList collection if you need <br>to do this. <br>
Now, I show a class that uses my EventSet class. This class has a field that refers to an <br>EventSet object, and each of this class's events is explicitly implemented so that each event's <br>add method stores the specified callback delegate in the EventSet object and each event's <br>remove method eliminates the specified callback delegate (if found):<br>
using System; <br> <br>// Define the EventArgs-derived type for this event. <br>public class FooEventArgs : EventArgs { } <br> <br>public class TypeWithLotsOfEvents { <br> <br>   // Define a private instance field that references a collection. <br>   // The collection manages a set of Event/Delegate pairs. <br>   // NOTE: The EventSet type is not part of the FCL, it is my own type. <br>   private readonly EventSet m_eventSet = newEventSet(); <br> <br>   // The protected property allows derived types access to the collection. <br>   protected EventSet EventSet { get { return m_eventSet; } } <br> <br>   #region Code to support the Foo event (repeat this pattern for additional events) <br>   // Define the members necessary for the Foo event. <br>   // 2a. Construct a static, read-only object to identify this event. <br>   // Each object has its own hash code for looking up this <br>   // event's delegate linked list in the object's collection. <br>   protected static readonly EventKey s_fooEventKey = newEventKey(); <br> <br>   // 2d. Define the event's accessor methods that add/remove the <br>   // delegate from the collection. <br>   public event EventHandler&lt;FooEventArgs&gt; Foo { <br>      add    { m_eventSet.Add(s_fooEventKey, value); } <br>      remove { m_eventSet.Remove(s_fooEventKey, value); } <br> <br>   } <br> <br>
<hr>
<A name=292></a><b>274 </b><br>
<b>Part II  Designing Types</b><br>
   // 2e. Define the protected, virtual On method for this event. <br>   protected virtual void OnFoo(FooEventArgs e) { <br>      m_eventSet.Raise(s_fooEventKey, this, e); <br>   } <br> <br>   // 2f. Define the method that translates input to this event. <br>   public void SimulateFoo() {OnFoo(newFooEventArgs());} <br>   #endregion <br>}<br>
Code that uses the TypeWithLotsOfEvents type can't tell whether the events have been <br>implemented implicitly by the compiler or explicitly by the developer. They just register the <br>events using normal syntax. Here is some code demonstrating this:<br>
public sealed class Program { <br>   public static void Main() { <br>      TypeWithLotsOfEvents twle = newTypeWithLotsOfEvents(); <br> <br>      // Add a callback here <br>      twle.Foo += HandleFooEvent; <br> <br>      // Prove that it worked <br>      twle.SimulateFoo(); <br>   } <br> <br>   private static void HandleFooEvent(object sender, FooEventArgs e) { <br>      Console.WriteLine(&quot;Handling Foo Event here...&quot;); <br>   } <br>}<br>
<hr>
<A name=293></a>Chapter 12<br><b>Generics</b><br>
<b>In this chapter:<br>Generics in the Framework Class Library. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 280<br>Wintellect's Power Collections Library  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281<br>Generics Infrastructure. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282<br>Generic Interfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289<br>Generic Delegates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290<br>Delegate and Interface Contravariant and Covariant  <br>   Generic Type Arguments  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291<br>Generic Methods. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 293<br>Generics and Other Members . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296<br>Verifiability and Constraints  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296</b><br>
Developers who are familiar with object-oriented programming know the benefits it offers. <br>One of the big benefits that make developers extremely productive is code reuse, which is <br>the ability to derive a class that inherits all of the capabilities of a base class. The derived class <br>can simply override virtual methods or add some new methods to customize the behavior of <br>the base class to meet the developer's needs. <i>Generics</i> is another mechanism offered by the <br>common language runtime (CLR) and programming languages that provides one more form <br>of code reuse: algorithm reuse.<br>
Basically, one developer defines an algorithm such as sorting, searching, swapping, compar-<br>ing, or converting. However, the developer defining the algorithm doesn't specify what data <br>type(s) the algorithm operates on; the algorithm can be generically applied to objects of <br>different types. Another developer can then use this existing algorithm as long as he or she <br>indicates the specific data type(s) the algorithm should operate on, for example, a sorting <br>algorithm that operates on Int32s, Strings, etc., or a comparing algorithm that operates on <br>DateTimes, Versions, etc.<br>
Most algorithms are encapsulated in a type, and the CLR allows the creation of generic  <br>reference types as well as generic value types, but it does not allow the creation of generic <br>enumerated types. In addition, the CLR allows the creation of generic interfaces and generic <br>delegates. Occasionally, a single method can encapsulate a useful algorithm, and therefore, <br>the CLR allows the creation of generic methods that are defined in a reference type, value <br>type, or interface.<br>
<b> </b><br>
<b> </b><br>
<b>275</b><br>
<hr>
<A name=294></a><IMG src="CLRviaCsharp-294_1.jpg"><br>
<b>276 </b><br>
<b>Part II  Designing Types</b><br>
Let's look at a quick example. The Framework Class Library (FCL) defines a generic list algorithm <br>that knows how to manage a set of objects; the data type of these objects is not specified <br>by the generic algorithm. Someone wanting to use the generic list algorithm can specify the <br>exact data type to use with it later.<br>
The FCL class that encapsulates the generic list algorithm is called List&lt;T&gt; (pronounced <i>List <br>of Tee</i>), and this class is defined in the System.Collections.Generic namespace. Here is <br>what this class definition looks like (the code is severely abbreviated):<br>
[Serializable]  <br>public class List&lt;T&gt; : IList&lt;T&gt;, ICollection&lt;T&gt;, IEnumerable&lt;T&gt;,  <br>   IList, ICollection, IEnumerable {  <br> <br>   public List();  <br>   public void Add(T item);  <br>   public Int32 BinarySearch(T item);  <br>   public void Clear();  <br>   public Boolean Contains(T item);  <br>   public Int32 IndexOf(T item);  <br>   public Boolean Remove(T item);  <br>   public void Sort();  <br>   public void Sort(IComparer&lt;T&gt; comparer);  <br>   public void Sort(Comparison&lt;T&gt; comparison);  <br>   public T[] ToArray();  <br> <br>   public Int32 Count { get; }  <br>   public T this[Int32 index] { get; set; }  <br>}<br>
The programmer who defined the generic List class indicates that it works with an unspeci-<br>fied data type by placing the &lt;T&gt; immediately after the class name. When defining a generic <br>type or method, any variables it specifies for types (such as T) are called <i>type parameters</i>. T <br>is a variable name that can be used in source code anywhere a data type can be used. For <br>example, in the List class definition, you see T being used for method parameters (the Add <br>method accepts a parameter of type T) and return values (the ToArray method returns a <br>single-dimension array of type T). Another example is the indexer method (called this in <br>C#). The indexer has a get accessor method that returns a value of type T and a set accessor <br>method that accepts a parameter of type T. Since the T variable can be used anywhere that <br>a data type can be specified, it is also possible to use T when defining local variables inside a <br>method or when defining fields inside a type.<br>
<b>Note  </b>Microsoft's design guidelines state that generic parameter variables should either be <br>called T or at least start with an uppercase T (as in TKey and TValue). The uppercase T stands for <br><i>type</i>, just as an uppercase I stands for <i>interface</i> (as in IComparable).<br>
<hr>
<A name=295></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>277</b><br>
Now that the generic List&lt;T&gt; type has been defined, other developers can use this generic <br>algorithm by specifying the exact data type they would like the algorithm to operate on. <br>When using a generic type or method, the specified data types are referred to as <i>type  <br>arguments</i>. For example, a developer might want to work with the List algorithm by  <br>specifying a DateTime type argument. Here is some code that shows this:<br>
private static void SomeMethod() {  <br>   // Construct a List that operates on DateTime objects  <br>   List&lt;DateTime&gt; dtList = new List&lt;DateTime&gt;();  <br> <br>   // Add a DateTime object to the list  <br>   dtList.Add(DateTime.Now);      // No boxing  <br> <br>   // Add another DateTime object to the list  <br>   dtList.Add(DateTime.MinValue); // No boxing  <br> <br>   // Attempt to add a String object to the list  <br>   dtList.Add(&quot;1/1/2004&quot;);        // Compile-time error  <br> <br>   // Extract a DateTime object out of the list  <br>   DateTime dt = dtList[0];       // No cast required  <br>}<br>
Generics provide the following big benefits to developers as exhibited by the code just <br>shown:<br>
<b>  Source code protection  </b>The developer using a generic algorithm doesn't need to <br>
have access to the algorithm's source code. With C++ templates or Java's generics, <br>however, the algorithm's source code must be available to the developer who is using <br>the algorithm.<br>
<b>  Type safety  </b>When a generic algorithm is used with a specific type, the compiler and <br>
the CLR understand this and ensure that only objects compatible with the specified <br>data type are used with the algorithm. Attempting to use an object of an incompatible <br>type will result in either a compiler error or a runtime exception being thrown. In the <br>example, attempting to pass a String object to the Add method results in the compiler <br>issuing an error.<br>
<b>  Cleaner code  </b>Since the compiler enforces type safety, fewer casts are required in your <br>
source code, meaning that your code is easier to write and maintain. In the last line of <br>SomeMethod, a developer doesn't need to use a (DateTime) cast to put the result of the <br>indexer (querying element at index 0) into the dt variable.<br>
<b>  Better performance  </b>Before generics, the way to define a generalized algorithm was <br>
to define all of its members to work with the Object data type. If you wanted to use <br>the algorithm with value type instances, the CLR had to box the value type instance <br>prior to calling the members of the algorithm. As discussed in Chapter 5, "Primitive, <br>Reference, and Value Types," boxing causes memory allocations on the managed heap, <br>which causes more frequent garbage collections, which, in turn, hurt an application's <br>
<hr>
<A name=296></a><b>278 </b><br>
<b>Part II  Designing Types</b><br>
performance. Since a generic algorithm can now be created to work with a specific val-<br>ue type, the instances of the value type can be passed by value, and the CLR no longer <br>has to do any boxing. In addition, since casts are not necessary (see the previous bullet), <br>the CLR doesn't have to check the type safety of the attempted cast, and this results in <br>faster code too.<br>
To drive home the performance benefits of generics, I wrote a program that tests the perfor-<br>mance of the generic List algorithm against the FCL's non-generic ArrayList algorithm. In <br>fact, I tested the performance of these two algorithms by using both value type objects and <br>reference type objects. Here is the program itself:<br>
using System;  <br>using System.Collections;  <br>using System.Collections.Generic;  <br>using System.Diagnostics;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      ValueTypePerfTest();  <br>      ReferenceTypePerfTest();  <br>   }  <br> <br>   private static void ValueTypePerfTest() {  <br>      const Int32 count = 10000000;  <br> <br>      using (new OperationTimer(&quot;List&lt;Int32&gt;&quot;)) {  <br>         List&lt;Int32&gt; l = new List&lt;Int32&gt;(count);  <br>         for (Int32 n = 0; n &lt; count; n++) {  <br>            l.Add(n);  <br>            Int32 x = l[n];  <br>         }  <br>         l = null;  // Make sure this gets GC'd  <br>      }  <br> <br>      using (new OperationTimer(&quot;ArrayList of Int32&quot;)) {  <br>         ArrayList a = new ArrayList();  <br>         for (Int32 n = 0; n &lt; count; n++) {  <br>            a.Add(n);  <br>            Int32 x = (Int32) a[n];  <br>         }  <br>         a = null;  // Make sure this gets GC'd  <br>      }  <br>   }  <br> <br>   private static void ReferenceTypePerfTest() {  <br>      const Int32 count = 10000000;  <br> <br>      using (new OperationTimer(&quot;List&lt;String&gt;&quot;)) {  <br>         List&lt;String&gt; l = new List&lt;String&gt;();  <br>         for (Int32 n = 0; n &lt; count; n++) {  <br>            l.Add(&quot;X&quot;);  <br>            String x = l[n];  <br>         }  <br>
<hr>
<A name=297></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>279</b><br>
         l = null;  // Make sure this gets GC'd  <br>      }  <br> <br>      using (new OperationTimer(&quot;ArrayList of String&quot;)) {  <br>         ArrayList a = new ArrayList();  <br>         for (Int32 n = 0; n &lt; count; n++) {  <br>            a.Add(&quot;X&quot;);  <br>            String x = (String) a[n];  <br>         }  <br>         a = null;  // Make sure this gets GC'd  <br>      }  <br>   }  <br>}  <br> <br>// This class is useful for doing operation performance timing  <br>internal sealed class OperationTimer : IDisposable {  <br>   private Int64  m_startTime;  <br>   private String m_text;  <br>   private Int32  m_collectionCount;  <br> <br>   public OperationTimer(String text) {  <br>      PrepareForOperation();  <br> <br>      m_text = text;  <br>      m_collectionCount = GC.CollectionCount(0);  <br>        <br>      // This should be the last statement in this   <br>      // method to keep timing as accurate as possible  <br>      m_startTime = Stopwatch.GetTimestamp();  <br>   }  <br> <br>   public void Dispose() {  <br>      Console.WriteLine(&quot;{0,6:###.00} seconds (GCs={1,3}) {2}&quot;,  <br>         (Stopwatch.GetTimestamp() - m_startTime) /   <br>            (Double) Stopwatch.Frequency,   <br>         GC.CollectionCount(0) - m_collectionCount, m_text);  <br>   }  <br> <br>   private static void PrepareForOperation() {  <br>      GC.Collect();  <br>      GC.WaitForPendingFinalizers();  <br>      GC.Collect();  <br>   }  <br>}<br>
When I compile and run a release build (with optimizations turned on) of this program on my <br>computer, I get the following output:<br>
   .10 seconds (GCs=  0) List&lt;Int32&gt; <br>  3.02 seconds (GCs= 45) ArrayList of Int32  <br>   .47 seconds (GCs=  6) List&lt;String&gt; <br>   .51 seconds (GCs=  6) ArrayList of String<br>
<hr>
<A name=298></a><IMG src="CLRviaCsharp-298_1.jpg"><br>
<b>280 </b><br>
<b>Part II  Designing Types</b><br>
The output here shows that using the generic List algorithm with the Int32 type is much <br>faster than using the non-generic ArrayList algorithm with Int32. In fact, the difference <br>is phenomenal: .1 second versus 3 seconds. That's 30 times faster! In addition, using a value <br>type (Int32) with ArrayList causes a lot of boxing operations to occur, which results in 45 <br>garbage collections. Meanwhile, the List algorithm required 0 garbage collections.<br>
The result of the test using reference types is not as momentous. Here we see that the times <br>and number of garbage collections are about the same. So it doesn't appear that the generic <br>List algorithm is of any benefit here. However, keep in mind that when using a generic al-<br>gorithm, you also get cleaner code and compile-time type safety. So while the performance <br>improvement is not huge, the other benefits you get when using a generic algorithm are <br>usually an improvement.<br>
<b>Note  </b>You do need to realize that the CLR generates native code for each method the first time <br>the method is called for a particular data type. This will increase an application's working set size, <br>which will hurt performance. I will talk about this more in the "Generics Infrastructure" section of <br>this chapter.<br>
<b>Generics in the Framework Class Library</b><br>
Certainly, the most obvious use of generics is with collection classes, and the FCL defines <br>several generic collection classes available for your use. Most of these classes can be found in <br>the System.Collections.Generic namespace and the System.Collections.ObjectModel <br>namespace. There are also thread-safe generic collection classes available in the  <br>System.Collections.Concurrent namespace. Microsoft recommends that programmers <br>use the generic collection classes and now discourages use of the non-generic collection <br>classes for several reasons. First, the non-generic collection classes are not generic, and so <br>you don't get the type safety, cleaner code, and better performance that you get when you <br>use generic collection classes. Second, the generic classes have a better object model than <br>the non-generic classes. For example, fewer methods are virtual, resulting in better per-<br>formance, and new members have been added to the generic collections to provide new <br>functionality.<br>
The collection classes implement many interfaces, and the objects that you place into the <br>collections can implement interfaces that the collection classes use for operations such as <br>sorting and searching. The FCL ships with many generic interface definitions so that the  <br>benefits of generics can be realized when working with interfaces as well. The commonly <br>used interfaces are contained in the System.Collections.Generic namespace.<br>
<hr>
<A name=299></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>281</b><br>
The new generic interfaces are not a replacement for the old non-generic interfaces; in many <br>scenarios, you will have to use both. The reason is backward compatibility. For example, <br>if the List&lt;T&gt; class implemented only the IList&lt;T&gt; interface, no code could consider a <br>List&lt;DateTime&gt; object an IList.<br>
I should also point out that the System.Array class, the base class of all array types, offers <br>many static generic methods, such as AsReadOnly, BinarySearch, ConvertAll, Exists, <br>Find, FindAll, FindIndex, FindLast, FindLastIndex, ForEach, IndexOf, LastIndexOf, <br>Resize, Sort, and TrueForAll. Here are examples showing what some of these methods <br>look like:<br>
public abstract class Array : ICloneable, IList, ICollection, IEnumerable, <br>   IStructuralComparable, IStructuralEquatable {  <br> <br>   public static void  Sort&lt;T&gt;(T[] array);  <br>   public static void  Sort&lt;T&gt;(T[] array, IComparer&lt;T&gt; comparer);  <br> <br>   public static Int32 BinarySearch&lt;T&gt;(T[] array, T value);  <br>   public static Int32 BinarySearch&lt;T&gt;(T[] array, T value,  <br>      IComparer&lt;T&gt; comparer);  <br>   ...  <br>}<br>
Here is code that demonstrates how to use some of these methods:<br>
public static void Main() {  <br>   // Create &amp; initialize a byte array  <br>   Byte[] byteArray = new Byte[] { 5, 1, 4, 2, 3 };  <br> <br>   // Call Byte[] sort algorithm  <br>   Array.Sort&lt;Byte&gt;(byteArray);  <br> <br>   // Call Byte[] binary search algorithm  <br>   Int32 i = Array.BinarySearch&lt;Byte&gt;(byteArray, 1);  <br>   Console.WriteLine(i);   // Displays &quot;0&quot;  <br>}<br>
<b>Wintellect's Power Collections Library</b><br>
At Microsoft's request, Wintellect has produced the Power Collections library to bring some <br>of the C++ Standard Template Library's collection classes to the CLR programmer. This library <br>is a set of collection classes that anyone can download and use free of charge. See  <br><i>http://Wintellect.com</i> for details. These collection classes are generic themselves and make <br>extensive use of generics. Table 12-1 shows a list of some of the collection classes you'll find <br>in the Power Collections library.<br>
<hr>
<A name=300></a><b>282 </b><br>
<b>Part II  Designing Types</b><br>
<b>TABLE 12-1  Generic Collection Classes from Wintellect's Power Collections Library</b><br>
<b>Collection Class</b><br>
<b>Description</b><br>
BigList&lt;T&gt;<br>
Collection of ordered T objects. Very efficient <br>when working with more than 100 items.<br>
Bag&lt;T&gt;<br>
Collection of unordered T objects. The collection <br>is hashed, and duplicates are allowed.<br>
OrderedBag&lt;T&gt;<br>
Collection of ordered T objects. Duplicates are <br>allowed.<br>
Set&lt;T&gt;<br>
Collection of unordered T items. Duplicates are <br>not allowed.<br>
OrderedSet&lt;T&gt;<br>
Collection of ordered T items. Duplicates are not <br>allowed.<br>
Deque&lt;T&gt;<br>
Double-ended queue. Similar to a list but more <br>efficient for adding/removing items at the begin-<br>ning than a list.<br>
OrderedDictionary&lt;TKey,TValue&gt;<br>
Dictionary in which keys are ordered, and each <br>can have one value.<br>
MultiDictionary&lt;TKey,TValue&gt;<br>
Dictionary in which a key can have multiple val-<br>ues. Keys are hashed, duplicates are allowed, and <br>items are unordered.<br>
OrderedMultiDictionary&lt;TKey,TValue&gt;<br>
Dictionary in which keys are ordered, and each <br>can have multiple values (also maintained in <br>sorted order). Duplicate keys are allowed.<br>
<b>Generics Infrastructure</b><br>
Generics were added to version 2.0 of the CLR, and it was a major task that required many <br>people working for quite some time. Specifically, to make generics work, Microsoft had to do <br>the following:<br>
  Create new Intermediate Language (IL) instructions that are aware of type arguments.<br>
  Modify the format of existing metadata tables so that type names and methods with <br>
generic parameters could be expressed.<br>
  Modify the various programming languages (C#, Microsoft Visual Basic .NET, etc.) to <br>
support the new syntax, allowing developers to define and reference generic types and <br>methods.<br>
  Modify the compilers to emit the new IL instructions and the modified metadata <br>
format.<br>
  Modify the just-in-time (JIT) compiler to process the new type-argument­aware IL  <br>
instructions that produce the correct native code.<br>
<hr>
<A name=301></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>283</b><br>
  Create new reflection members so that developers can query types and members to <br>
determine if they have generic parameters. Also, new reflection emit members had to <br>be defined so that developers could create generic type and method definitions at  <br>runtime.<br>
  Modify the debugger to show and manipulate generic types, members, fields, and local <br>
variables.<br>
  Modify the Microsoft Visual Studio IntelliSense feature to show specific member proto-<br>
types when using a generic type or a method with a specific data type.<br>
Now let's spend some time discussing how the CLR handles generics internally. This informa-<br>tion could impact how you architect and design a generic algorithm. It could also impact <br>your decision to use an existing generic algorithm or not.<br>
<b>Open and Closed Types</b><br>
In various chapters throughout this book, I have discussed how the CLR creates an internal <br>data structure for each and every type in use by an application. These data structures are <br>called <i>type objects</i>. Well, a type with generic type parameters is still considered a type, and <br>the CLR will create an internal type object for each of these. This applies to reference types <br>(classes), value types (structs), interface types, and delegate types. However, a type with <br>generic type parameters is called an <i>open type</i>, and the CLR does not allow any instance of <br>an open type to be constructed (similar to how the CLR prevents an instance of an interface <br>type from being constructed).<br>
When code references a generic type, it can specify a set of generic type arguments. If actual <br>data types are passed in for all of the type arguments, the type is called a <i>closed type</i>, and <br>the CLR does allow instances of a closed type to be constructed. However, it is possible for <br>code referencing a generic type to leave some generic type arguments unspecified. This  <br>creates a new open type object in the CLR, and instances of this type cannot be created. The <br>following code should make this clear:<br>
using System;  <br>using System.Collections.Generic;  <br> <br>// A partially specified open type  <br>internal sealed class DictionaryStringKey&lt;TValue&gt; :   <br>   Dictionary&lt;String, TValue&gt; {  <br>} <br> <br>public static class Program {  <br>   public static void Main() {  <br>      Object o = null;  <br> <br>      // Dictionary&lt;,&gt; is an open type having 2 type parameters  <br>      Type t = typeof(Dictionary&lt;,&gt;);  <br> <br>
<hr>
<A name=302></a><b>284 </b><br>
<b>Part II  Designing Types</b><br>
      // Try to create an instance of this type (fails)  <br>      o = CreateInstance(t);  <br>      Console.WriteLine();  <br> <br>      // DictionaryStringKey&lt;&gt; is an open type having 1 type parameter  <br>      t = typeof(DictionaryStringKey&lt;&gt;);  <br> <br>      // Try to create an instance of this type (fails)  <br>      o = CreateInstance(t);  <br>      Console.WriteLine();  <br> <br>      // DictionaryStringKey&lt;Guid&gt; is a closed type  <br>      t = typeof(DictionaryStringKey&lt;Guid&gt;);  <br> <br>      // Try to create an instance of this type (succeeds)  <br>      o = CreateInstance(t);  <br> <br>      // Prove it actually worked  <br>      Console.WriteLine(&quot;Object type=&quot; + o.GetType());  <br>   }  <br> <br>   private static Object CreateInstance(Type t) {  <br>      Object o = null;  <br>      try {  <br>         o = Activator.CreateInstance(t);  <br>         Console.Write(&quot;Created instance of {0}&quot;, t.ToString());  <br>      }  <br>      catch (ArgumentException e) {  <br>         Console.WriteLine(e.Message);  <br>      }  <br>      return o;  <br>   }  <br>} <br>
When I compile the code above and run it, I get the following output:<br>
Cannot create an instance of System.Collections.Generic.  <br>Dictionary`2[TKey,TValue] because Type.ContainsGenericParameters is true.  <br> <br>Cannot create an instance of DictionaryStringKey`1[TValue] because   <br>Type.ContainsGenericParameters is true.  <br> <br>Created instance of DictionaryStringKey`1[System.Guid]  <br>Object type=DictionaryStringKey`1[System.Guid]<br>
As you can see, Activator's CreateInstance method throws an ArgumentException when <br>you ask it to construct an instance of an open type. In fact, the exception's string message <br>indicates that the type still contains some generic parameters.<br>
In the output, you'll notice that the type names end with a backtick (`) followed by a number. <br>The number indicates the type's <i>arity</i>, which indicates the number of type parameters  <br>required by the type. For example, the Dictionary class has an arity of 2 since it requires <br>that types be specified for TKey and TValue. The DictionaryStringKey class has an arity of <br>1 since it requires just one type to be specified for TValue.<br>
<hr>
<A name=303></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>285</b><br>
I should also point out that the CLR allocates a type's static fields inside the type object (as <br>discussed in Chapter 4, "Type Fundamentals"). So each closed type has its own static fields. <br>In other words, if List&lt;T&gt; defined any static fields, these fields are not shared between a <br>List&lt;DateTime&gt; and a List&lt;String&gt;; each closed type object has its own static fields.  <br>Also, if a generic type defines a static constructor (discussed in Chapter 8, "Methods"), this <br>constructor will execute once per closed type. Sometimes people define a static constructor <br>on a generic type to ensure that the type arguments will meet certain criteria. For example, if <br>you wanted to define a generic type that can be used only with enumerated types, you could <br>do the following:<br>
internal sealed class GenericTypeThatRequiresAnEnum&lt;T&gt; {  <br>   static GenericTypeThatRequiresAnEnum() {  <br>      if (!typeof(T).IsEnum) {  <br>         throw new ArgumentException(&quot;T must be an enumerated type&quot;);  <br>      }  <br>   }  <br>}<br>
The CLR has a feature, called <i>constraints</i>, that offers a better way for you to define a generic <br>type indicating what type arguments are valid for it. I'l  discuss constraints later in this chapter. <br>Unfortunately, constraints do not support the ability to limit a type argument to enumerated <br>types only, which is why the previous example requires a static constructor to ensure that the <br>type is an enumerated type.<br>
<b>Generic Types and Inheritance</b><br>
A generic type is a type, and as such, it can be derived from any other type. When you use <br>a generic type and specify type arguments, you are defining a new type object in the CLR, <br>and the new type object is derived from whatever type the generic type was derived from. <br>In other words, since List&lt;T&gt; is derived from Object, List&lt;String&gt; and List&lt;Guid&gt; <br>are also derived from Object. Similarly, since DictionaryStringKey&lt;TValue&gt; is derived <br>from Dictionary&lt;String, TValue&gt;, DictionaryStringKey&lt;Guid&gt; is also derived from <br>Dictionary&lt;String, Guid&gt;. Understanding that specifying type arguments doesn't have <br>anything to do with inheritance hierarchies will help you to recognize what kind of casting <br>you can and can't do.<br>
For example, if a linked-list node class is defined like this:<br>
internal sealed class Node&lt;T&gt; {  <br>   public T m_data;  <br>   public Node&lt;T&gt; m_next;  <br>     <br>   public Node(T data) : this(data, null) {   <br>   }  <br> <br>   public Node(T data, Node&lt;T&gt; next) {  <br>      m_data = data; m_next = next;   <br>
<hr>
<A name=304></a><b>286 </b><br>
<b>Part II  Designing Types</b><br>
   }  <br> <br>   public override String ToString() {  <br>      return m_data.ToString() +   <br>         ((m_next != null) ? m_next.ToString() : String.Empty);  <br>   }  <br>}<br>
then I can write some code to build up a linked list that would look something like this:<br>
private static void SameDataLinkedList() {  <br>   Node&lt;Char&gt; head = new Node&lt;Char&gt;('C');  <br>   head = new Node&lt;Char&gt;('B', head);  <br>   head = new Node&lt;Char&gt;('A', head);  <br>   Console.WriteLine(head.ToString());  <br>}<br>
In the Node class just shown, the m_next field must refer to another node that has the same <br>kind of data type in its m_data field. This means that the linked list must contain nodes in <br>which all data items are of the same type (or derived type). For example, I can't use the Node <br>class to create a linked list in which one element contains a Char, another element contains  <br>a DateTime, and another element contains a String. Well, I could if I use Node&lt;Object&gt;  <br>everywhere, but then I would lose compile-time type safety, and value types would get <br>boxed.<br>
So a better way to go would be to define a non-generic Node base class and then define a <br>generic TypedNode class (using the Node class as a base class). Now, I can have a linked list in <br>which each node can be of a specific data type (not Object), get compile-time type safety <br>and avoid the boxing of value types. Here are the new class definitions:<br>
internal class Node {  <br>   protected Node m_next;  <br> <br>   public Node(Node next) {  <br>      m_next = next;  <br>   }  <br>}  <br> <br>internal sealed class TypedNode&lt;T&gt; : Node {  <br>   public T m_data;  <br> <br>   public TypedNode(T data) : this(data, null) {  <br>   }  <br> <br>   public TypedNode(T data, Node next) : base(next) {  <br>      m_data = data;  <br>   }  <br> <br>   public override String ToString() {  <br>      return m_data.ToString() +  <br>         ((m_next != null) ? m_next.ToString() : String.Empty);  <br>   }  <br>}<br>
<hr>
<A name=305></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>287</b><br>
I can now write code to create a linked list in which each node is a different data type. The <br>code could look something like this:<br>
private static void DifferentDataLinkedList() {  <br>   Node head = new TypedNode&lt;Char&gt;('.');  <br>   head = new TypedNode&lt;DateTime&gt;(DateTime.Now, head);  <br>   head = new TypedNode&lt;String&gt;(&quot;Today is &quot;, head);  <br>   Console.WriteLine(head.ToString());  <br>}<br>
<b>Generic Type Identity</b><br>
Sometimes generic syntax confuses developers. After all, there can be a lot of less-than (&lt;) <br>and greater-than (&gt;) signs sprinkled throughout your source code, and this hurts readability. <br>To improve syntax, some developers define a new non-generic class type that is derived from <br>a generic type and that specifies all of the type arguments. For example, to simplify code <br>like this:<br>
List&lt;DateTime&gt; dtl= new List&lt;DateTime&gt;();<br>
Some developers might first define a class like this:<br>
internal sealed class DateTimeList : List&lt;DateTime&gt; {  <br>   // No need to put any code in here!  <br>}<br>
Now, the code that creates a list can be rewritten more simply (without less-than and  <br>greater-than signs) like this:<br>
DateTimeList dtl = new DateTimeList();<br>
While this seems like a convenience, especially if you use the new type for parameters, local <br>variables, and fields, you should never define a new class explicitly for the purpose of making <br>your source code easier to read. The reason is because you lose type identity and equivalence, <br>as you can see in the following code:<br>
Boolean sameType = (typeof(List&lt;DateTime&gt;) == typeof(DateTimeList));<br>
When the code above runs, sameType will be initialized to false because you are comparing  <br>two different type objects. This also means that a method prototyped as accepting a <br>DateTimeList will not be able to have a List&lt;DateTime&gt; passed to it. However, a method <br>prototyped as accepting a List&lt;DateTime&gt; can have a DateTimeList passed to it since <br>DateTimeList is derived from List&lt;DateTime&gt;. Programmers may become easily confused <br>by all of this.<br>
<hr>
<A name=306></a><b>288 </b><br>
<b>Part II  Designing Types</b><br>
Fortunately, C# does offer a way to use simplified syntax to refer to a generic closed type <br>while not affecting type equivalence at all; you can use the good old using directive at the <br>top of your source code file. Here is an example:<br>
using DateTimeList = System.Collections.Generic.List&lt;System.DateTime&gt;;<br>
Here, the using directive is really just defining a symbol called DateTimeList. As the  <br>code compiles, the compiler substitutes all occurrences of DateTimeList with  <br>System.Collections.Generic.List&lt;System.DateTime&gt;. This just allows developers to  <br>use a simplified syntax without affecting the actual meaning of the code, and therefore,  <br>type identity and equivalence are maintained. So now, when the following line executes, <br>sameType will be initialized to true.<br>
Boolean sameType = (typeof(List&lt;DateTime&gt;) == typeof(DateTimeList));<br>
As another convenience, you can use C#'s implicitly typed local variable feature, where the <br>compiler infers the type of a method's local variable from the type of the expression you are <br>assigning to it:<br>
using System; <br>using System.Collections.Generic; <br>... <br>internal sealed class SomeType { <br>   private static void SomeMethod () { <br>
      // Compiler infers that DateTimeList is of type <br>      // System.Collections.Generic.List&lt;System.DateTime&gt; <br>      var dtl = List&lt;DateTime&gt;(); <br>      ... <br>   }<br>
}<br>
<b>Code Explosion</b><br>
When a method that uses generic type parameters is JIT-compiled, the CLR takes the meth-<br>od's IL, substitutes the specified type arguments, and then creates native code that is specific <br>to that method operating on the specified data types. This is exactly what you want and is <br>one of the main features of generics. However, there is a downside to this: the CLR keeps <br>generating native code for every method/type combination. This is referred to as <i>code  <br>explosion</i>. This can end up increasing the application's working set substantially, thereby  <br>hurting performance.<br>
Fortunately, the CLR has some optimizations built into it to reduce code explosion. First, if a <br>method is called for a particular type argument, and later, the method is called again using <br>the same type argument, the CLR will compile the code for this method/type combination <br>just once. So if one assembly uses List&lt;DateTime&gt;, and a completely different assembly <br>
<hr>
<A name=307></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>289</b><br>
(loaded in the same AppDomain) also uses List&lt;DateTime&gt;, the CLR will compile the  <br>methods for List&lt;DateTime&gt; just once. This reduces code explosion substantially.<br>
The CLR has another optimization: the CLR considers all reference type arguments to be <br>identical, and so again, the code can be shared. For example, the code compiled by the CLR <br>for List&lt;String&gt;'s methods can be used for List&lt;Stream&gt;'s methods, since String and <br>Stream are both reference types. In fact, for any reference type, the same code will be used. <br>The CLR can perform this optimization because all reference type arguments or variables are <br>really just pointers (all 32 bits on a 32-bit Windows system and 64 bits on a 64-bit Windows <br>system) to objects on the heap, and object pointers are all manipulated in the same way.<br>
But if any type argument is a value type, the CLR must produce native code specifically for <br>that value type. The reason is because value types can vary in size. And even if two value <br>types are the same size (such as Int32 and UInt32, which are both 32 bits), the CLR still can't <br>share the code because different native CPU instructions can be used to manipulate these <br>values.<br>
<b>Generic Interfaces</b><br>
Obviously, the ability to define generic reference and value types was the main feature of <br>generics. However, it was critical for the CLR to also allow generic interfaces. Without generic <br>interfaces, any time you tried to manipulate a value type by using a non-generic interface <br>(such as IComparable), boxing and a loss of compile-time type safety would happen again. <br>This would severely limit the usefulness of generic types. And so the CLR does support generic <br>interfaces. A reference or value type can implement a generic interface by specifying type <br>arguments, or a type can implement a generic interface by leaving the type arguments  <br>unspecified. Let's look at some examples.<br>
Here is the definition of a generic interface that ships as part of the FCL (in the  <br>System.Collections.Generic namespace):<br>
public interface IEnumerator&lt;T&gt; : IDisposable, IEnumerator {  <br>   T Current { get; }  <br>}<br>
Here is an example of a type that implements this generic interface and that specifies type <br>arguments. Notice that a Triangle object can enumerate a set of Point objects. Also note <br>that the Current property is of the Point data type:<br>
internal sealed class Triangle : IEnumerator&lt;Point&gt; {  <br>   private Point[] m_vertices;  <br> <br>   // IEnumerator&lt;Point&gt;'s Current property is of type Point  <br>   public Point Current { get { ... } }  <br> <br>   ... <br>}<br>
<hr>
<A name=308></a><IMG src="CLRviaCsharp-308_1.jpg"><br>
<b>290 </b><br>
<b>Part II  Designing Types</b><br>
Now let's look at an example of a type that implements the same generic interface but with <br>the type arguments left unspecified:<br>
internal sealed class ArrayEnumerator&lt;T&gt; : IEnumerator&lt;T&gt; {  <br>   private T[] m_array;  <br> <br>   // IEnumerator&lt;T&gt;'s Current property is of type T  <br>   public T Current { get { ... } }  <br> <br>   ... <br>}<br>
Notice that an ArrayEnumerator object can enumerate a set of T objects (where T is  <br>unspecified allowing code using the generic ArrayEnumerator type to specify a type for T <br>later). Also note that the Current property is now of the unspecified data type T. Much more <br>information about generic interfaces is presented in Chapter 13, "Interfaces."<br>
<b>Generic Delegates</b><br>
The CLR supports generic delegates to ensure that any type of object can be passed to a  <br>callback method in a type-safe way. Furthermore, generic delegates allow a value type  <br>instance to be passed to a callback method without any boxing. As discussed in Chapter 17, <br>"Delegates," a delegate is really just a class definition with four methods: a constructor, an <br>Invoke method, a BeginInvoke method, and an EndInvoke method. When you define a <br>delegate type that specifies type parameters, the compiler defines the delegate class's meth-<br>ods, and the type parameters are applied to any methods having parameters/return values of <br>the specified type parameter.<br>
For example, if you define a generic delegate like this:<br>
public delegate TReturn CallMe&lt;TReturn, TKey, TValue&gt;(TKey key, TValue value);<br>
The compiler turns that into a class that logically looks like this:<br>
public sealed class CallMe&lt;TReturn, TKey, TValue&gt; : MulticastDelegate {  <br>   public CallMe(Object object, IntPtr method);  <br>   public virtual TReturn Invoke(TKey key, TValue value);  <br>   public virtual IAsyncResult BeginInvoke(TKey key, TValue value,  <br>      AsyncCallback callback, Object object);  <br>   public virtual TReturn EndInvoke(IAsyncResult result);  <br>}<br>
<b>Note  </b>It is recommended that you use the generic Action and Func delegates that come  <br>predefined in the Framework Class Library (FCL) wherever possible. I describe these delegate <br>types in the "Enough with the Delegate Definitions Already (Generic Delegates)" section of <br>Chapter 17, "Delegates."<br>
<hr>
<A name=309></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>291</b><br>
<b>Delegate and Interface Contravariant and Covariant </b><br>
<b>Generic Type Arguments</b><br>
Each of a delegate's generic type parameters can be marked as covariant or contravariant. <br>This feature allows you to cast a variable of a generic delegate type to the <i>same delegate <br>type</i> where the generic parameter types differ. A generic type parameter can be any one of <br>the following:<br>
<b>  Invariant  </b>Meaning that that generic type parameter cannot be changed. I have <br>
shown only invariant generic type parameters so far in this chapter.<br>
<b>  Contravariant  </b>Meaning that the generic type parameter can change from a class to a <br>
class derived from it. In C#, you indicate contravariant generic type parameters with the <br>in keyword. Contravariant generic type parameters can appear only in input positions <br>such as a method's argument.<br>
<b>  Covariant  </b>Meaning that the generic type argument can change from a class to one of <br>
its base classes. In C#, you indicate covariant generic type parameters with the out key-<br>word. Covariant generic type parameters can appear only in output positions such as a <br>method's return type.<br>
For example, let's say that the following delegate type definition exists (which, by the way, it <br>does):<br>
public delegate TResult Func&lt;in T, out TResult&gt;(T arg);<br>
Here, the generic type parameter T is marked with the in keyword, making it contravariant;  <br>and the generic type parameter TResult is marked with the out keyword, making it covariant.<br>
So now, if I have a variable declared as follows:<br>
Func&lt;Object, ArgumentException&gt; fn1 = null;<br>
I can cast it to another Func type, where the generic type parameters are different:<br>
Func&lt;String, Exception&gt;fn2 = fn1;// No explicit cast is required here <br>Exception e = fn2(&quot;&quot;);<br>
What this is saying is that fn1 refers to a function that accepts an Object and returns an <br>ArgumentException. The fn2 variable wants to refer to a method that takes a String and <br>returns an Exception. Since you can pass a String to a method that wants an Object  <br>(because String is derived from Object), and since you can take the result of a method that <br>returns an ArgumentException and treat it as an Exception (because Exception is a base <br>class of ArgumentException), the code above compiles and is known at compile time to  <br>preserve type safety.<br>
<hr>
<A name=310></a><IMG src="CLRviaCsharp-310_1.jpg"><br>
<b>292 </b><br>
<b>Part II  Designing Types</b><br>
<b>Note  </b>Variance applies only if the compiler can verify that a reference conversion exists between <br>types. In other words, variance is not possible for value types because boxing would be required. <br>In my opinion, this restriction is what makes these variance features not that useful. For example, <br>if I have the following method:<br>
voidProcessCollection(IEnumerable&lt;Object&gt; collection) { ... }<br>
I can't call it passing in a reference to a List&lt;DateTime&gt; object since a reference conversion <br>doesn't exist between the DateTime value type and Object even though DateTime is derived <br>from Object. You solve this problem by declaring ProcessCollection as follows:<br>
void ProcessCollection&lt;T&gt;(IEnumerable&lt;T&gt; collection) { ... }<br>
Plus, the big benefit of ProcessCollection(IEnumerable&lt;Object&gt; collection) is that there <br>is only one version of the JITted code. However, with ProcessCollection&lt;T&gt;(IEnumerable&lt;T&gt; <br>collection), there is also only one version of the JITted code shared by all Ts that are reference <br>types. You do get other versions of JITted code for Ts that are value types, but now you can at <br>least call the method passing it a collection of value types.<br>
Also, variance is not allowed on a generic type parameter if an argument of that type is passed <br>to a method using the out or ref keyword. For example, the line of code below causes the com-<br>piler to generate the following error message: &quot;Invalid variance: The type parameter <br>'T' must be invariantly valid on 'SomeDelegate&lt;T&gt;.Invoke(ref T)'. 'T' is <br>contravariant.&quot;<br>
delegate void SomeDelegate&lt;in T&gt;(ref T t);<br>
When using delegates that take generic arguments and return values, it is recommended to <br>always specify the in and out keywords for contravariance and covariance whenever possible, <br>as doing this has no ill effects and enables your delegate to be used in more scenarios.<br>
Like delegates, an interface with generic type parameters can have its type parameters be <br>contravariant or covariant. Here is an example of an interface with a contravariant generic <br>type parameter:<br>
public interface IEnumerator&lt;out T&gt; : IEnumerator { <br>   Boolean MoveNext(); <br>   T Current { get; } <br>}<br>
Since T is contravariant, it is possible to have the following code compile and run successfully:<br>
// This method accepts an IEnumerable of any reference type <br>Int32 Count(IEnumerable&lt;Object&gt; collection) { ... } <br> <br>... <br>// The call below passes an IEnumerable&lt;String&gt; to Count <br>Int32 c = Count(new[] { &quot;Grant&quot; });<br>
<hr>
<A name=311></a><IMG src="CLRviaCsharp-311_1.jpg"><br>
<b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>293</b><br>
<b>Important  </b>Sometimes developers ask why they must explicitly put in or out on generic type <br>parameters. They think the compiler should be able to examine the delegate or interface declara-<br>tion and automatically detect what generic type parameters can be contravariant and covariant. <br>While it is true that the compiler could detect this automatically, the C# team believes that you <br>are declaring a contract and that you should be explicit about what you want to allow. For example, <br>it would be bad if the compiler determined that a generic type parameter could be contravariant <br>and then, in the future, you added a member to an interface that had the type parameter used <br>in an output position. The next time you compile, the compiler would determine that the type <br>parameter should be invariant, but all code sites that reference the other members might now <br>produce errors if they had used the fact that the type parameter had been contravariant.<br>
For this reason, the compiler team forces you to be explicit when declaring a generic type  <br>parameter. Then, if you attempt to use this type parameter in a context that doesn't match how <br>you declared it, the compiler issues an error letting you know that you are attempting to break <br>the contract. If you then decide to break the contract by adding in or out on generic type  <br>parameters, you should expect to have to modify some of the code sites that were using the  <br>old contract.<br>
<b>Generic Methods</b><br>
When you define a generic class, struct, or interface, any methods defined in these types can <br>refer to a type parameter specified by the type. A type parameter can be used as a method's  <br>parameter, a method's return value, or as a local variable defined inside the method. However, <br>the CLR also supports the ability for a method to specify its very own type parameters. And <br>these type parameters can also be used for parameters, return values, or local variables. Here <br>is a somewhat contrived example of a type that defines a type parameter and a method that <br>has its very own type parameter:<br>
internal sealed class GenericType&lt;T&gt; {  <br>   private T m_value;  <br> <br>   public GenericType(T value) { m_value = value; }  <br> <br>   public TOutput Converter&lt;TOutput&gt;() {  <br>      TOutput result = (TOutput) Convert.ChangeType(m_value, typeof(TOutput));  <br>      return result;  <br>   }  <br>}<br>
In this example, you can see that the GenericType class defines its own type parameter <br>(T), and the Converter method defines its own type parameter (TOutput). This allows a <br>GenericType to be constructed to work with any type. The Converter method can convert <br>the object referred to by the m_value field to various types depending on what type argument <br>is passed to it when called. The ability to have type parameters and method parameters  <br>allows for phenomenal flexibility.<br>
<hr>
<A name=312></a><b>294 </b><br>
<b>Part II  Designing Types</b><br>
A reasonably good example of a generic method is the Swap method:<br>
private static void Swap&lt;T&gt;(ref T o1, ref T o2) {  <br>   T temp = o1;  <br>   o1 = o2;  <br>   o2 = temp;  <br>}<br>
Code can now call Swap like this:<br>
private static void CallingSwap() {  <br>   Int32 n1 = 1, n2 = 2;  <br>   Console.WriteLine(&quot;n1={0}, n2={1}&quot;, n1, n2);  <br>   Swap&lt;Int32&gt;(ref n1, ref n2);  <br>   Console.WriteLine(&quot;n1={0}, n2={1}&quot;, n1, n2);  <br> <br>   String s1 = &quot;Aidan&quot;, s2 = &quot;Grant&quot;;  <br>   Console.WriteLine(&quot;s1={0}, s2={1}&quot;, s1, s2);  <br>   Swap&lt;String&gt;(ref s1, ref s2);  <br>   Console.WriteLine(&quot;s1={0}, s2={1}&quot;, s1, s2);  <br>}<br>
Using generic types with methods that take out and ref parameters can be particularly  <br>interesting because the variable you pass as an out/ref argument must be the same type  <br>as the method's parameter to avoid a potential type safety exploit. This issue related to  <br>out/ref parameters is discussed toward the end of the "Passing Parameters by Reference to <br>a Method" section in Chapter 9, "Parameters." In fact, the Interlocked class's Exchange and <br>CompareExchange methods offer generic overloads for precisely this reason1:<br>
public static class Interlocked {  <br>   public static T Exchange&lt;T&gt;(ref T location1, T value) where T: class;  <br>   public static T CompareExchange&lt;T&gt;(  <br>      ref T location1, T value, T comparand) where T: class;  <br>}<br>
<b>Generic Methods and Type Inference<br></b>For many developers, the C# generic syntax can be confusing with all of its less-than and <br>greater-than signs. To help improve code creation, readability, and maintainability, the C# <br>compiler offers <i>type inference</i> when calling a generic method. Type inference means that the <br>compiler attempts to determine (or infer) the type to use automatically when calling a generic <br>method. Here is some code that demonstrates type inference:<br>
private static void CallingSwapUsingInference() {  <br>   Int32 n1 = 1, n2 = 2;  <br>   Swap(ref n1, ref n2);// Calls Swap&lt;Int32&gt; <br> <br>   String s1 = &quot;Aidan&quot;;  <br>   Object s2 = &quot;Grant&quot;;  <br>   Swap(ref s1, ref s2);// Error, type can't be inferred  <br>}<br>
1  The where clause will be explained in the "Verifiability and Constraints" section later in this chapter.<br>
<hr>
<A name=313></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>295</b><br>
In this code, notice that the calls to Swap do not specify type arguments in less-than/greater-<br>than signs. In the first call to Swap, the C# compiler was able to infer that n1 and n2 are <br>Int32s, and therefore, it should call Swap by using an Int32 type argument.<br>
When performing type inference, C# uses the variable's data type, not the actual type of the <br>object referred to by the variable. So in the second call to Swap, C# sees that s1 is a String <br>and s2 is an Object (even though it happens to refer to a String). Since s1 and s2 are  <br>variables of different data types, the compiler can't accurately infer the type to use for Swap's <br>type argument, and it issues the following message: &quot;error CS0411: The type arguments <br>for method 'Program.Swap&lt;T&gt;(ref T, ref T)' cannot be inferred from the  <br>usage. Try specifying the type arguments explicitly.&quot;<br>
A type can define multiple methods with one of its methods taking a specific data type and <br>another taking a generic type parameter, as in the following example:<br>
private static void Display(String s) {  <br>   Console.WriteLine(s);  <br>}  <br> <br>private static void Display&lt;T&gt;(T o) {  <br>   Display(o.ToString());  // Calls Display(String)  <br>}<br>
Here are some ways to call the Display method:<br>
Display(&quot;Jeff&quot;);           // Calls Display(String)  <br>Display(123);              // Calls Display&lt;T&gt;(T)  <br>Display&lt;String&gt;(&quot;Aidan&quot;);  // Calls Display&lt;T&gt;(T)<br>
In the first call, the compiler could actually call either the Display method that takes a <br>String or the generic Display method (replacing T with String). However, the C# compiler <br>always prefers a more explicit match over a generic match, and therefore, it generates a call <br>to the non-generic Display method that takes a String. For the second call, the compiler <br>can't call the non-generic Display method that takes a String, so it must call the generic <br>Display method. By the way, it is fortunate that the compiler always prefers the more  <br>explicit match; if the compiler had preferred the generic method, because the generic <br>Display method calls Display again (but with a String returned by ToString), there  <br>would have been infinite recursion.<br>
The third call to Display specifies a generic type argument, String. This tells the compiler <br>not to try to infer type arguments but instead to use the type arguments that I explicitly <br>specified. In this case, the compiler also assumes that I must really want to call the generic <br>Display method, so the generic Display will be called. Internally, the generic Display <br>method will call ToString on the passed-in string, which results in a string that is then <br>passed to the non-generic Display method.<br>
<hr>
<A name=314></a><b>296 </b><br>
<b>Part II  Designing Types</b><br>
<b>Generics and Other Members</b><br>
In C#, properties, indexers, events, operator methods, constructors, and finalizers cannot <br>themselves have type parameters. However, they can be defined within a generic type, and <br>the code in these members can use the type's type parameters.<br>
C# doesn't allow these members to specify their own generic type parameters because <br>Microsoft's C# team believes that developers would rarely have a need to use these members <br>as generic. Furthermore, the cost of adding generic support to these members would be <br>quite high in terms of designing adequate syntax into the language. For example, when you <br>use a <b>+</b> operator in code, the compiler could call an operator overload method. There is no <br>way to indicate any type arguments in your code along with the <b>+</b> operator.<br>
<b>Verifiability and Constraints</b><br>
When compiling generic code, the C# compiler analyzes it and ensures that the code will <br>work for any type that exists today or that may be defined in the future. Let's look at the  <br>following method:<br>
private static Boolean MethodTakingAnyType&lt;T&gt;(T o) {  <br>   T temp = o;  <br>   Console.WriteLine(o.ToString());  <br>   Boolean b = temp.Equals(o);  <br>   return b;  <br>}<br>
This method declares a temporary variable (temp) of type T, and then the method performs <br>a couple of variable assignments and a few method calls. This method works for any type. If <br>T is a reference type, it works. If T is a value or enumeration type, it works. If T is an interface <br>or delegate type, it works. This method works for all types that exist today or that will be <br>defined tomorrow because every type supports assignment and calls to methods defined by <br>Object (such as ToString and Equals).<br>
Now look at the following method:<br>
private static T Min&lt;T&gt;(T o1, T o2) {  <br>   if (o1.CompareTo(o2) &lt; 0) return o1;  <br>   return o2;  <br>}<br>
The Min method attempts to use the o1 variable to call the CompareTo method. But there are <br>lots of types that do not offer a CompareTo method, and therefore, the C# compiler can't <br>compile this code and guarantee that this method would work for all types. If you attempt <br>to compile the above code, the compiler issues the following message: &quot;error CS0117: 'T' <br>does not contain a definition for 'CompareTo'.&quot;<br>
<hr>
<A name=315></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>297</b><br>
So it would seem that when using generics, you can declare variables of a generic type, per-<br>form some variable assignments, call methods defined by Object, and that's about it! This <br>makes generics practically useless. Fortunately, compilers and the CLR support a mechanism <br>called <i>constraints</i> that you can take advantage of to make generics useful again.<br>
A constraint is a way to limit the number of types that can be specified for a generic argu-<br>ment. Limiting the number of types allows you to do more with those types. Here is a new <br>version of the Min method that specifies a constraint (in bold):<br>
public static T Min&lt;T&gt;(T o1, T o2) where T : IComparable&lt;T&gt; {  <br>   if (o1.CompareTo(o2) &lt; 0) return o1;  <br>   return o2;  <br>}<br>
The C# where token tells the compiler that any type specified for T must implement the  <br>generic IComparable interface of the same type (T). Because of this constraint, the compiler <br>now allows the method to call the CompareTo method since this method is defined by the <br>IComparable&lt;T&gt; interface.<br>
Now, when code references a generic type or method, the compiler is responsible for ensur-<br>ing that a type argument that meets the constraints is specified. For example, the following  <br>code causes the compiler to issue the following message: &quot;error CS0311: The type  <br>'object' cannot be used as type parameter 'T' in the generic type or method <br>'SomeType.Min&lt;T&gt;(T, T)'. There is no implicit reference conversion from  <br>'object' to 'System.IComparable&lt;object&gt;'.&quot;<br>
private static void CallMin() {  <br>   Object o1 = &quot;Jeff&quot;, o2 = &quot;Richter&quot;;  <br>   Object oMin = Min&lt;Object&gt;(o1, o2);  // Error CS0311 <br>}<br>
The compiler issues the error because System.Object doesn't implement the <br>IComparable&lt;Object&gt; interface. In fact, System.Object doesn't implement any interfaces  <br>at all.<br>
Now that you have a sense of what constraints are and how they work, we'll start to look <br>a little deeper into them. Constraints can be applied to a generic type's type parameters <br>as well as to a generic method's type parameters (as shown in the Min method). The CLR <br>doesn't allow overloading based on type parameter names or constraints; you can overload <br>types or methods based only on arity. The following examples show what I mean:<br>
// It is OK to define the following types:  <br>internal sealed class AType {}  <br>internal sealed class AType&lt;T&gt; {}  <br>internal sealed class AType&lt;T1, T2&gt; {}  <br> <br>// Error: conflicts with AType&lt;T&gt; that has no constraints  <br>internal sealed class AType&lt;T&gt; where T : IComparable&lt;T&gt; {}  <br> <br>
<hr>
<A name=316></a><b>298 </b><br>
<b>Part II  Designing Types</b><br>
// Error: conflicts with AType&lt;T1, T2&gt; <br>internal sealed class AType&lt;T3, T4&gt; {}  <br> <br>internal sealed class AnotherType {  <br>   // It is OK to define the following methods:  <br>   private static void M() {}  <br>   private static void M&lt;T&gt;() {}  <br>   private static void M&lt;T1, T2&gt;() {}  <br> <br>   // Error: conflicts with M&lt;T&gt; that has no constraints  <br>   private static void M&lt;T&gt;() where T : IComparable&lt;T&gt; {}  <br> <br>   // Error: conflicts with M&lt;T1, T2&gt; <br>   private static void M&lt;T3, T4&gt;() {}  <br>}<br>
When overriding a virtual generic method, the overriding method must specify the same <br>number of type parameters, and these type parameters will inherit the constraints specified <br>on them by the base class's method. In fact, the overriding method is not allowed to specify <br>any constraints on its type parameters at all. However, it can change the names of the type <br>parameters. Similarly, when implementing an interface method, the method must specify the <br>same number of type parameters as the interface method, and these type parameters will <br>inherit the constraints specified on them by the interface's method. Here is an example that <br>demonstrates this rule by using virtual methods:<br>
internal class Base {  <br>   public virtual void M&lt;T1, T2&gt;()   <br>      where T1 : struct  <br>      where T2 : class {  <br>   }  <br>}  <br> <br>internal sealed class Derived : Base {  <br>   public override void M&lt;T3, T4&gt;()   <br>      where T3 : EventArgs  // Error  <br>      where T4 : class      // Error  <br>      { }  <br>}<br>
Attempting to compile the code above causes the compiler to issue the following message: <br>&quot;error CS0460: Constraints for override and explicit interface implementa-<br>tion methods are inherited from the base method so cannot be specified  <br>directly.&quot; If we remove the two where lines from the Derived class's M&lt;T3, T4&gt; method, <br>the code will compile just fine. Notice that you can change the names of the type parameters <br>(as in the example: from T1 to T3 and T2 to T4); however, you cannot change (or even specify) <br>constraints.<br>
Now let's talk about the different kinds of constraints the compiler/CLR allows you to apply  <br>to a type parameter. A type parameter can be constrained using a <i>primary constraint</i>, a  <br><i>secondary constraint</i>, and/or a <i>constructor constraint</i>. I'll talk about these three kinds of  <br>constraints in the next three sections.<br>
<hr>
<A name=317></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>299</b><br>
<b>Primary Constraints</b><br>
A type parameter can specify zero primary constraints or one primary constraint. A primary <br>constraint can be a reference type that identifies a class that is not sealed. You cannot  <br>specify one of the following special reference types: System.Object, System.Array, <br>System.Delegate, System.MulticastDelegate, System.ValueType, System.Enum, or <br>System.Void.<br>
When specifying a reference type constraint, you are promising the compiler that a specified <br>type argument will either be of the same type or of a type derived from the constraint type. <br>For example, see the following generic class:<br>
internal sealed class PrimaryConstraintOfStream&lt;T&gt; where T : Stream {  <br>   public void M(T stream) {  <br>      stream.Close();// OK  <br>   }  <br>}<br>
In this class definition, the type parameter T has a primary constraint of Stream (defined  <br>in the System.IO namespace). This tells the compiler that code using <br>PrimaryConstraintOfStream must specify a type argument of Stream or a type derived <br>from Stream (such as FileStream). If a type parameter doesn't specify a primary constraint, <br>System.Object is assumed. However, the C# compiler issues an error message (&quot;error <br>CS0702: Constraint cannot be special class 'object' &quot;) if you explicitly specify <br>System.Object in your source code.<br>
There are two special primary constraints: class and struct. The class constraint promises <br>the compiler that a specified type argument will be a reference type. Any class type, interface <br>type, delegate type, or array type satisfies this constraint. For example, see the following  <br>generic class:<br>
internal sealed class PrimaryConstraintOfClass&lt;T&gt; where T : class {  <br>   public void M() {  <br>      T temp = null;// Allowed because T must be a reference type  <br>   }  <br>}<br>
In this example, setting temp to null is legal because T is known to be a reference type, <br>and all reference type variables can be set to null. If T were unconstrained, the code above <br>would not compile because T could be a value type, and value type variables cannot be set <br>to null.<br>
The struct constraint promises the compiler that a specified type argument will be a value <br>type. Any value type, including enumerations, satisfies this constraint. However, the  <br>compiler and the CLR treat any System.Nullable&lt;T&gt; value type as a special type, and  <br>nullable types do not satisfy this constraint. The reason is because the Nullable&lt;T&gt; type <br>constrains its type parameter to struct, and the CLR wants to prohibit a recursive type such <br>
<hr>
<A name=318></a><b>300 </b><br>
<b>Part II  Designing Types</b><br>
as Nullable&lt;Nullable&lt;T&gt;&gt;. Nullable types are discussed in Chapter 19, "Nullable Value <br>Types."<br>
Here is an example class that constrains its type parameter by using the struct constraint:<br>
internal sealed class PrimaryConstraintOfStruct&lt;T&gt; where T : struct {  <br>   public static T Factory() {  <br>      // Allowed because all value types implicitly   <br>      // have a public, parameterless constructor  <br>      return new T();  <br>   }  <br>}<br>
In this example, newing up a T is legal because T is known to be a value type, and all value <br>types implicitly have a public, parameterless constructor. If T were unconstrained, constrained <br>to a reference type, or constrained to class, the above code would not compile because <br>some reference types do not have public, parameterless constructors.<br>
<b>Secondary Constraints</b><br>
A type parameter can specify zero or more secondary constraints where a secondary  <br>constraint represents an interface type. When specifying an interface type constraint, you  <br>are promising the compiler that a specified type argument will be a type that implements the <br>interface. And since you can specify multiple interface constraints, the type argument must <br>specify a type that implements all of the interface constraints (and all of the primary con-<br>straints too, if specified). Chapter 13 discusses interface constraints in detail.<br>
There is another kind of secondary constraint called a <i>type parameter constraint</i> (sometimes <br>referred to as a<i> naked type constraint</i>). This kind of constraint is used much less often than <br>an interface constraint. It allows a generic type or method to indicate that there must be a <br>relationship between specified type arguments. A type parameter can have zero or more <br>type constraints applied to it. Here is a generic method that demonstrates the use of a type <br>parameter constraint:<br>
private static List&lt;TBase&gt; ConvertIList&lt;T, TBase&gt;(IList&lt;T&gt; list)   <br>   where T : TBase {  <br>   List&lt;TBase&gt; baseList = new List&lt;TBase&gt;(list.Count);  <br>   for (Int32 index = 0; index &lt; list.Count; index++) {  <br>      baseList.Add(list[index]);  <br>   }  <br>   return baseList;  <br>}<br>
The ConvertIList method specifies two type parameters in which the T parameter is con-<br>strained by the TBase type parameter. This means that whatever type argument is specified <br>for T, the type argument must be compatible with whatever type argument is specified for <br>TBase. Here is a method showing some legal and illegal calls to ConvertIList:<br>
<hr>
<A name=319></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>301</b><br>
private static void CallingConvertIList() {  <br>   // Construct and initialize a List&lt;String&gt; (which implements IList&lt;String&gt;)  <br>   IList&lt;String&gt; ls = new List&lt;String&gt;();  <br>   ls.Add(&quot;A String&quot;);  <br> <br>   // Convert the IList&lt;String&gt; to an IList&lt;Object&gt; <br>   IList&lt;Object&gt; lo = ConvertIList&lt;String, Object&gt;(ls);  <br> <br>   // Convert the IList&lt;String&gt; to an IList&lt;IComparable&gt; <br>   IList&lt;IComparable&gt; lc = ConvertIList&lt;String, IComparable&gt;(ls);  <br> <br>   // Convert the IList&lt;String&gt; to an IList&lt;IComparable&lt;String&gt;&gt; <br>   IList&lt;IComparable&lt;String&gt;&gt; lcs =   <br>      ConvertIList&lt;String, IComparable&lt;String&gt;&gt;(ls);  <br> <br>   // Convert the IList&lt;String&gt; to an IList&lt;String&gt; <br>   IList&lt;String&gt; ls2 = ConvertIList&lt;String, String&gt;(ls);  <br> <br>   // Convert the IList&lt;String&gt; to an IList&lt;Exception&gt; <br>   IList&lt;Exception&gt; le = ConvertIList&lt;String, Exception&gt;(ls);// Error  <br>}<br>
In the first call to ConvertIList, the compiler ensures that String is compatible with <br>Object. Since String is derived from Object, the first call adheres to the type parameter <br>constraint. In the second call to ConvertIList, the compiler ensures that String is compat-<br>ible with IComparable. Since String implements the IComparable interface, the second call <br>adheres to the type parameter constraint. In the third call to ConvertIList, the compiler <br>ensures that String is compatible with IComparable&lt;String&gt;. Since String implements <br>the IComparable&lt;String&gt; interface, the third call adheres to the type parameter constraint. <br>In the fourth call to ConvertIList, the compiler knows that String is compatible with itself. <br>In the fifth call to ConvertIList, the compiler ensures that String is compatible with <br>Exception. Since String is not compatible with Exception, the fifth call doesn't adhere  <br>to the type parameter constraint, and the compiler issues the following message: &quot;error  <br>CS0311: The type 'string' cannot be used as type parameter 'T' in the  <br>generic type or method 'Program.ConvertIList&lt;T,TBase&gt;(System.Collections.<br>Generic.IList&lt;T&gt;)'. There is no implicit reference conversion from 'string' <br>to 'System.Exception'.&quot;<br>
<b>Constructor Constraints</b><br>
A type parameter can specify zero constructor constraints or one constructor constraint. <br>When specifying a constructor constraint, you are promising the compiler that a specified <br>type argument will be a non-abstract type that implements a public, parameterless construc-<br>tor. Note that the C# compiler considers it an error to specify a constructor constraint with <br>the struct constraint because it is redundant; all value types implicitly offer a public, param-<br>eterless constructor. Here is an example class that constrains its type parameter by using the <br>constructor constraint:<br>
<hr>
<A name=320></a><b>302 </b><br>
<b>Part II  Designing Types</b><br>
internal sealed class ConstructorConstraint&lt;T&gt; where T : new() {  <br>   public static T Factory() {  <br>      // Allowed because all value types implicitly   <br>      // have a public, parameterless constructor and because  <br>      // the constraint requires that any specified reference   <br>      // type also have a public, parameterless constructor  <br>      return new T();  <br>   }  <br>}<br>
In this example, newing up a T is legal because T is known to be a type that has a public,  <br>parameterless constructor. This is certainly true of all value types, and the constructor  <br>constraint requires that it be true of any reference type specified as a type argument.<br>
Sometimes, developers would like to declare a type parameter by using a constructor  <br>constraint whereby the constructor takes various parameters itself. As of now, the CLR (and <br>therefore the C# compiler) supports only parameterless constructors. Microsoft feels that this <br>will be good enough for almost all scenarios, and I agree.<br>
<b>Other Verifiability Issues</b><br>
In the remainder of this section, I'd like to point out a few other code constructs that have <br>unexpected behavior when used with generics due to verifiability issues and how constraints <br>can be used to make the code verifiable again.<br>
<b>Casting a Generic Type Variable<br></b>Casting a generic type variable to another type is illegal unless you are casting to a type <br>compatible with a constraint:<br>
private static void CastingAGenericTypeVariable1&lt;T&gt;(T obj) {  <br>   Int32  x = (Int32) obj;   // Error  <br>   String s = (String) obj;  // Error  <br>}<br>
The compiler issues an error on both lines above because T could be any type, and there is <br>no guarantee that the casts will succeed. You can modify this code to get it to compile by <br>casting to Object first:<br>
private static void CastingAGenericTypeVariable2&lt;T&gt;(T obj) {  <br>   Int32  x = (Int32) (Object) obj;   // No error  <br>   String s = (String) (Object) obj;  // No error  <br>}<br>
While this code will now compile, it is still possible for the CLR to throw an <br>InvalidCastException at runtime .<br>
<hr>
<A name=321></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>303</b><br>
If you are trying to cast to a reference type, you can also use the C# as operator. Here is <br>code modified to use the as operator with String (since Int32 is a value type):<br>
private static void CastingAGenericTypeVariable3&lt;T&gt;(T obj) {  <br>   String s = obj as String;  // No error  <br>} <br>
<b>Setting a Generic Type Variable to a Default Value<br></b>Setting a generic type variable to null is illegal unless the generic type is constrained to a <br>reference type.<br>
private static void SettingAGenericTypeVariableToNull&lt;T&gt;() {  <br>   T temp = null;    // CS0403 ­ Cannot convert null to type parameter 'T' because it could <br>                     // be a non-nullable value type. Consider using 'default(T)' instead <br>}<br>
Since T is unconstrained, it could be a value type, and setting a variable of a value type to <br>null is not possible. If T were constrained to a reference type, setting temp to null would <br>compile and run just fine.<br>
Microsoft's C# team felt that it would be useful to give developers the ability to set a variable <br>to a default value. So the C# compiler allows you to use the default keyword to accomplish <br>this:<br>
private static void SettingAGenericTypeVariableToDefaultValue&lt;T&gt;() {  <br>   T temp = default(T);  // OK  <br>}<br>
The use of the default keyword above tells the C# compiler and the CLR's JIT compiler to <br>produce code to set temp to null if T is a reference type and to set temp to all-bits-zero if T <br>is a value type.<br>
<b>Comparing a Generic Type Variable with </b>null<br>Comparing a generic type variable to null by using the == or != operator is legal regardless <br>of whether the generic type is constrained:<br>
private static void ComparingAGenericTypeVariableWithNull&lt;T&gt;(T obj) {  <br>   if (obj == null) { /* Never executes for a value type */ }  <br>}<br>
Since T is unconstrained, it could be a reference type or a value type. If T is a value type, obj <br>can never be null. Normally, you'd expect the C# compiler to issue an error because of this. <br>However, the C# compiler does not issue an error; instead, it compiles the code just fine. <br>When this method is called using a type argument that is a value type, the JIT compiler sees <br>that the if statement can never be true, and the JIT compiler will not emit the native code <br>for the if test or the code in the braces. If I had used the != operator, the JIT compiler would <br>
<hr>
<A name=322></a><b>304 </b><br>
<b>Part II  Designing Types</b><br>
not emit the code for the if test (since it is always true), and it will emit the code inside the <br>if's braces.<br>
By the way, if T had been constrained to a struct, the C# compiler would issue an error  <br>because you shouldn't be writing code that compares a value type variable with null since <br>the result is always the same.<br>
<b>Comparing Two Generic Type Variables with Each Other<br></b>Comparing two variables of the same generic type is illegal if the generic type parameter is <br>not known to be a reference type:<br>
private static void ComparingTwoGenericTypeVariables&lt;T&gt;(T o1, T o2) {  <br>   if (o1 == o2) { }  // Error  <br>}<br>
In this example, T is unconstrained, and whereas it is legal to compare two reference type <br>variables with one another, it is not legal to compare two value type variables with one  <br>another unless the value type overloads the == operator. If T were constrained to class, this <br>code would compile, and the == operator would return true if the variables referred to the <br>same object, checking for exact identity. Note that if T were constrained to a reference type <br>that overloaded the operator == method, the compiler would emit calls to this method <br>when it sees the == operator. Obviously, this whole discussion applies to uses of the != op-<br>erator too.<br>
When you write code to compare the primitive value types--Byte, Int32, Single, Decimal, <br>etc.--the C# compiler knows how to emit the right code. However, for non-primitive <br>value types, the C# compiler doesn't know how to emit the code to do comparisons. So if <br>ComparingTwoGenericTypeVariables method's T were constrained to struct, the compiler  <br>would issue an error. And you're not allowed to constrain a type parameter to a specific value <br>type because it is implicitly sealed, and therefore no types exist that are derived from the <br>value type. Allowing this would make the generic method constrained to a specific type, and <br>the C# compiler doesn't allow this because it is more efficient to just make a non-generic <br>method.<br>
<b>Using Generic Type Variables as Operands<br></b>Finally, it should be noted that there are a lot of issues about using operators with generic <br>type operands. In Chapter 5, I talked about C# and how it handles its primitive types: Byte, <br>Int16, Int32, Int64, Decimal, and so on. In particular, I mentioned that C# knows how to <br>interpret operators (such as +, -, *, and /) when applied to the primitive types. Well, these <br>operators can't be applied to variables of a generic type because the compiler doesn't know <br>the type at compile time. This means that you can't use any of these operators with variables <br>of a generic type. So it is impossible to write a mathematical algorithm that works on an  <br>arbitrary numeric data type. Here is an example of a generic method that I'd like to write:<br>
<hr>
<A name=323></a><b> </b><br>
<b>Chapter 12  Generics </b><br>
<b>305</b><br>
private static T Sum&lt;T&gt;(T num) where T : struct {  <br>   T sum = default(T) ;  <br>   for (T n = default(T) ; n &lt; num ; n++)  <br>      sum += n;  <br>   return sum;  <br>}<br>
I've done everything possible to try to get this method to compile. I've constrained T to <br>struct, and I'm using default(T) to initialize sum and n to 0. But when I compile this code, I <br>get the following three errors:<br>
  error CS0019: Operator '&lt;' cannot be applied to operands of type 'T' <br>
and 'T'<br>
  error CS0023: Operator '++' cannot be applied to operand of type 'T'<br>
  error CS0019: Operator '+=' cannot be applied to operands of type 'T' <br>
and 'T'<br>
This is a severe limitation on the CLR's generic support, and many developers (especially in <br>the scientific, financial, and mathematical world) are very disappointed by this limitation. <br>Many people have tried to come up with techniques to work around this limitation by using <br>reflection (see Chapter 23, "Assembly Loading and Reflection"), operator overloading, and so <br>on. But all of these cause a severe performance penalty or hurt readability of the code sub-<br>stantially. Hopefully, this is an area that Microsoft will address in a future version of the CLR <br>and the compilers.<br>
<hr>
<A name=324></a><hr>
<A name=325></a>Chapter 13<br><b>Interfaces</b><br>
<b>In this chapter:<br>Class and Interface Inheritance. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308<br>Defining an Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308<br>Inheriting an Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310<br>More About Calling Interface Methods  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312<br>Implicit and Explicit Interface Method Implementations (What's Happening  <br>   Behind the Scenes). . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314<br>Generic Interfaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315<br>Generics and Interface Constraints  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 318<br>Implementing Multiple Interfaces That Have the Same Method Name and  <br>   Signature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319<br>Improving Compile-Time Type Safety with Explicit Interface Method  <br>   Implementations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 320<br>Be Careful with Explicit Interface Method Implementations. . . . . . . . . . . . . . . . 322<br>Design: Base Class or Interface? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325</b><br>
Many programmers are familiar with the concept of multiple inheritance: the ability to define <br>a class that is derived from two or more base classes. For example, imagine a class named <br>TransmitData, whose function is to transmit data, and another class named ReceiveData, <br>whose function is to receive data. Now imagine that you want to create a class named <br>SocketPort, whose function is to transmit and receive data. In order to accomplish this, you <br>would want to derive SocketPort from both TransmitData and ReceiveData.<br>
Some programming languages allow multiple inheritance, making it possible for the <br>SocketPort class to be derived from the two base classes, TransmitData and ReceiveData. <br>However, the common language runtime (CLR)--and therefore all managed programming <br>languages--does not support multiple inheritance. Rather than not offer any kind of multiple <br>inheritance at all, the CLR does offer scaled-down multiple inheritance via <i>interfaces</i>. This <br>chapter will discuss how to define and use interfaces as well as provide some guidelines to <br>help you determine when to use an interface rather than a base class.<br>
<b> </b><br>
<b> </b><br>
<b>307</b><br>
<hr>
<A name=326></a><b>308 </b><br>
<b>Part II  Designing Types</b><br>
<b>Class and Interface Inheritance</b><br>
In the Microsoft .NET Framework, there is a class called System.Object that defines four <br>public instance methods: ToString,<b> </b>Equals,<b> </b>GetHashCode, and GetType. This class is the <br>root or ultimate base class of all other classes--all classes will inherit Object's four instance <br>methods. This also means that code written to operate on an instance of the Object class <br>can actually perform operations on an instance of any class.<br>
Since someone at Microsoft has implemented Object's methods, any class derived from <br>Object is actually inheriting the following:<br>
<b>  The method signatures  </b>This allows code to think that it is operating on an instance of <br>
the Object class, when in fact, it could be operating on an instance of some other class.<br>
<b>  The implementation of these methods  </b>This allows the developer defining a class  <br>
derived from Object not to be required to implement Object's methods manually.<br>
In the CLR, a class is always derived from one and only one class (that must ultimately be <br>derived from Object). This base class provides a set of method signatures and implementa-<br>tions for these methods. And a cool thing about defining a new class is that it can become <br>the base class for another class defined in the future by some other developer--all of the <br>method signatures and their implementations will be inherited by the new derived class.<br>
The CLR also allows developers to define an <i>interface</i>, which is really just a way to give a <br>name to a set of method signatures. These methods do not come with any implementation <br>at all. A class inherits an interface by specifying the interface's name, and the class must  <br>explicitly provide implementations of the interface's methods before the CLR will consider the <br>type definition to be valid. Of course, implementing interface methods can be tedious, which <br>is why I referred to interface inheritance as a scaled-down mechanism to achieve multiple  <br>inheritance. The C# compiler and the CLR actually allow a class to inherit several interfaces, <br>and of course, the class must provide implementations for all of the inherited interface <br>methods.<br>
One of the great features of class inheritance is that it allows instances of a derived type to <br>be substituted in all contexts that expect instances of a base type. Similarly, interface inheri-<br>tance allows instances of a type that implements the interface to be substituted in all con-<br>texts that expect instances of the named interface type. We will now look at how to define <br>interfaces to make our discussion more concrete.<br>
<b>Defining an Interface</b><br>
As mentioned in the previous section, an interface is a named set of method signatures. Note <br>that interfaces can also define events, parameterless properties, and parameterful properties <br>(indexers in C#) because all of these are just syntax shorthands that map to methods anyway, <br>
<hr>
<A name=327></a><b> </b><br>
<b>Chapter 13  Interfaces </b><br>
<b>309</b><br>
as shown in previous chapters. However, an interface cannot define any constructor methods. <br>In addition, an interface is not allowed to define any instance fields.<br>
Although the CLR does allow an interface to define static methods, static fields, constants, <br>and static constructors, a Common Language Infrastructure (CLI)­compliant interface must <br>not have any of these static members because some programming languages aren't able <br>to define or access them. In fact, C# prevents an interface from defining any of these static <br>members.<br>
In C#, you use the interface keyword to define an interface, giving it a name and its set <br>of instance method signatures. Here are the definitions of a few interfaces defined in the <br>Framework Class Library (FCL):<br>
public interface IDisposable {  <br>   void Dispose();  <br>}  <br> <br>public interface IEnumerable {   <br>   IEnumerator GetEnumerator();  <br>}  <br> <br>public interface IEnumerable&lt;out T&gt; : IEnumerable {  <br>   new IEnumerator&lt;T&gt; GetEnumerator();  <br>}  <br> <br>public interface ICollection&lt;T&gt; : IEnumerable&lt;T&gt;, IEnumerable {  <br>   void    Add(T item);  <br>   void    Clear();  <br>   Boolean Contains(T item);  <br>   void    CopyTo(T[] array, Int32 arrayIndex);  <br>   Boolean Remove(T item);  <br>   Int32   Count      { get; } // Read-only property  <br>   Boolean IsReadOnly { get; } // Read-only property  <br>}<br>
To the CLR, an interface definition is just like a type definition. That is, the CLR will define <br>an internal data structure for the interface type object, and reflection can be used to query <br>features of the interface type. Like types, an interface can be defined at file scope or defined <br>nested within another type. When defining the interface type, you can specify whatever vis-<br>ibility/accessibility (public,<b> </b>protected,<b> </b>internal, etc.) you desire.<br>
By convention, interface type names are prefixed with an uppercase I, making it easy to <br>spot an interface type in source code. The CLR does support generic interfaces (as you can <br>see from some of the previous examples) as well as generic methods in an interface. I will <br>discuss some of the many features offered by generic interfaces later in this chapter and in <br>Chapter 12, "Generics," in which I cover generics more broadly.<br>
An interface definition can "inherit" other interfaces. However, I use the word <i>inherit</i> here <br>rather loosely because interface inheritance doesn't work exactly as does class inheritance.  <br>I prefer to think of interface inheritance as including the contract of other interfaces. <br>
<hr>
<A name=328></a><b>310 </b><br>
<b>Part II  Designing Types</b><br>
For example, the ICollection&lt;T&gt; interface definition includes the contracts of the <br>IEnumerable&lt;T&gt; and IEnumerable interfaces. This means that:<br>
  Any class that inherits the ICollection&lt;T&gt; interface must implement al  of the methods <br>
defined by the ICollection&lt;T&gt;, IEnumerable&lt;T&gt;, and IEnumerable interfaces.<br>
  Any code that expects an object whose type implements the ICollection&lt;T&gt; interface <br>
can assume that the object's type also implements the methods of the IEnumerable&lt;T&gt; <br>and IEnumerable interfaces.<br>
<b>Inheriting an Interface</b><br>
In this section, I'll show how to define a type that implements an interface, and then I'll show <br>how to create an instance of this type and use the object to call the interface's methods. C# <br>actually makes this pretty simple, but what happens behind the scenes is a bit more compli-<br>cated. I'll explain what is happening behind the scenes later in this chapter.<br>
The System.IComparable&lt;T&gt; interface is defined (in MSCorLib.dll) as follows:<br>
public interface IComparable&lt;in T&gt; {  <br>   Int32 CompareTo(T other);  <br>}<br>
The following code shows how to define a type that implements this interface and also shows <br>code that compares two Point objects:<br>
using System;  <br> <br> <br>// Point is derived from System.Object and implements IComparable&lt;T&gt; for Point.  <br>public sealed class Point : IComparable&lt;Point&gt; {  <br>   private Int32 m_x, m_y;  <br> <br>   public Point(Int32 x, Int32 y) {  <br>      m_x = x;  <br>      m_y = y;  <br>   }  <br> <br>   // This method implements IComparable&lt;T&gt;.CompareTo() for Point  <br>   public Int32 CompareTo(Point other) {  <br>      return Math.Sign(Math.Sqrt(m_x * m_x + m_y * m_y)  <br>         - Math.Sqrt(other.m_x * other.m_x + other.m_y * other.m_y));  <br>   }  <br> <br>   public override String ToString() {  <br>      return String.Format(&quot;({0}, {1})&quot;, m_x, m_y);  <br>   }  <br>}  <br> <br> <br>
<hr>
<A name=329></a><b> </b><br>
<b>Chapter 13  Interfaces </b><br>
<b>311</b><br>
public static class Program {  <br>   public static void Main() {  <br>      Point[] points = new Point[] {  <br>         new Point(3, 3),  <br>         new Point(1, 2),  <br>      };  <br> <br>      // Here is a call to Point's IComparable&lt;T&gt; CompareTo method  <br>      if (points[0].CompareTo(points[1]) &gt; 0) {  <br>         Point tempPoint = points[0];  <br>         points[0] = points[1];  <br>         points[1] = tempPoint;  <br>      }  <br>      Console.WriteLine(&quot;Points from closest to (0, 0) to farthest:&quot;);  <br>      foreach (Point p in points)  <br>         Console.WriteLine(p);  <br>   }  <br>}<br>
The C# compiler requires that a method that implements an interface be marked as public. <br>The CLR requires that interface methods be marked as virtual. If you do not explicitly mark <br>the method as virtual in your source code, the compiler marks the method as virtual and <br>sealed; this prevents a derived class from overriding the interface method. If you explicitly <br>mark the method as virtual, the compiler marks the method as virtual (and leaves it unsealed); <br>this allows a derived class to override the interface method.<br>
If an interface method is sealed, a derived class cannot override the method. However, a  <br>derived class can re-inherit the same interface and can provide its own implementation for <br>the interface's methods. When calling an interface's method on an object, the implementation <br>associated with the object's type is called. Here is an example that demonstrates this:<br>
using System;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      /************************* First Example *************************/  <br>      Base b = new Base();  <br>        <br>      // Calls Dispose by using b's type: &quot;Base's Dispose&quot;  <br>      b.Dispose();  <br>        <br>      // Calls Dispose by using b's object's type: &quot;Base's Dispose&quot;  <br>      ((IDisposable)b).Dispose();  <br> <br> <br>      /************************* Second Example ************************/  <br>      Derived d = new Derived();  <br> <br>      // Calls Dispose by using d's type: &quot;Derived's Dispose&quot;  <br>      d.Dispose();  <br> <br>      // Calls Dispose by using d's object's type: &quot;Derived's Dispose&quot;  <br>
<hr>
<A name=330></a><b>312 </b><br>
<b>Part II  Designing Types</b><br>
      ((IDisposable)d).Dispose();  <br> <br> <br>      /************************* Third Example *************************/  <br>      b = new Derived();  <br> <br>      // Calls Dispose by using b's type: &quot;Base's Dispose&quot;  <br>      b.Dispose();  <br> <br>      // Calls Dispose by using b's object's type: &quot;Derived's Dispose&quot;  <br>      ((IDisposable)b).Dispose();  <br>   }  <br>}  <br> <br>// This class is derived from Object and it implements IDisposable  <br>internal class Base : IDisposable {  <br>   // This method is implicitly sealed and cannot be overridden  <br>   public void Dispose() {  <br>      Console.WriteLine(&quot;Base's Dispose&quot;);  <br>   }  <br>}  <br> <br>// This class is derived from Base and it re-implements IDisposable  <br>internal class Derived : Base, IDisposable {  <br>   // This method cannot override Base's Dispose. 'new' is used to indicate   <br>   // that this method re-implements IDisposable's Dispose method  <br>   new public void Dispose() {  <br>      Console.WriteLine(&quot;Derived's Dispose&quot;);  <br> <br>      // NOTE: The next line shows how to call a base class's implementation (if desired)  <br>      // base.Dispose();  <br>   }  <br>}<br>
<b>More About Calling Interface Methods</b><br>
The FCL's System.String type inherits System.Object's method signatures and their imple-<br>mentations. In addition, the String type also implements several interfaces: IComparable, <br>ICloneable, IConvertible, IEnumerable, IComparable&lt;String&gt;, IEnumerable&lt;Char&gt;, <br>and IEquatable&lt;String&gt;. This means that the String type isn't required to implement (or <br>override) the methods its Object base type offers. However, the String type must implement <br>the methods declared in all of the interfaces.<br>
The CLR allows you to define field, parameter, or local variables that are of an interface type. <br>Using a variable of an interface type allows you to call methods defined by that interface. In <br>addition, the CLR will allow you to call methods defined by Object because all classes inherit <br>Object's methods. The following code demonstrates this:<br>
<hr>
<A name=331></a><IMG src="CLRviaCsharp-331_1.jpg"><br>
<b> </b><br>
<b>Chapter 13  Interfaces </b><br>
<b>313</b><br>
// The s variable refers to a String object.  <br>String s = &quot;Jeffrey&quot;;  <br>// Using s, I can call any method defined in  <br>// String, Object, IComparable, ICloneable, IConvertible, IEnumerable, etc.  <br> <br>// The cloneable variable refers to the same String object  <br>ICloneable cloneable = s;  <br>// Using cloneable, I can call any method declared by the  <br>// ICloneable interface (or any method defined by Object) only.  <br> <br>// The comparable variable refers to the same String object  <br>IComparable comparable = s;  <br>// Using comparable, I can call any method declared by the  <br>// IComparable interface (or any method defined by Object) only.  <br> <br>// The enumerable variable refers to the same String object  <br>// At run time, you can cast a variable from one interface to another as  <br>// long as the object's type implements both interfaces.  <br>IEnumerable enumerable = (IEnumerable) comparable;   <br>// Using enumerable, I can call any method declared by the  <br>// IEnumerable interface (or any method defined by Object) only.<br>
In this code, all of the variables refer to the same "Jeffrey" String object that is in the man-<br>aged heap, and therefore, any method that I call while using any of these variables affects <br>the one "Jeffrey" String object. However, the type of the variable indicates the action that I <br>can perform on the object. The s variable is of type String, and therefore, I can use s to call <br>any members defined by the String type (such as the Length property). I can also use the <br>variable s to call any methods inherited from Object (such as GetType).<br>
The cloneable variable is of the ICloneable interface type, and therefore, using the  <br>cloneable variable, I can call the Clone method defined by this interface. In addition, I can <br>call any method defined by Object (such as GetType) because the CLR knows that all types <br>derive from Object. However, using the cloneable variable, I cannot call public methods <br>defined by String itself or any methods defined by any other interface that String imple-<br>ments. Similarly, using the comparable variable, I can call CompareTo or any method defined <br>by Object, but no other methods are callable using this variable.<br>
<b>Important  </b>Like a reference type, a value type can implement zero or more interfaces. However, <br>when you cast an instance of a value type to an interface type, the value type instance must be <br>boxed. This is because an interface variable is a reference that must point to an object on the <br>heap so that the CLR can examine the object's type object pointer to determine the exact type of <br>the object. Then, when calling an interface method with a boxed value type, the CLR will follow <br>the object's type object pointer to find the type object's method table in order to call the proper <br>method.<br>
<hr>
<A name=332></a><b>314 </b><br>
<b>Part II  Designing Types</b><br>
<b>Implicit and Explicit Interface Method Implementations </b><br>
<b>(What's Happening Behind the Scenes)</b><br>
When a type is loaded into the CLR, a method table is created and initialized for the type (as <br>discussed in Chapter 1, "The CLR's Execution Model"). This method table contains one entry <br>for every new method introduced by the type as well as entries for any virtual methods in-<br>herited by the type. Inherited virtual methods include methods defined by the base types <br>in the inheritance hierarchy as well as any methods defined by the interface types. So if you <br>have a simple type defined like this:<br>
internal sealed class SimpleType : IDisposable {  <br>   public void Dispose() { Console.WriteLine(&quot;Dispose&quot;); }  <br>}<br>
the type's method table contains entries for the following:<br>
  All the virtual instance methods defined by Object, the implicitly inherited base class.<br>
  All the interface methods defined by IDisposable, the inherited interface. In this  <br>
example, there is only one method, Dispose, since the IDisposable interface defines <br>just one method.<br>
  The new method, Dispose, introduced by SimpleType.<br>
To make things simple for the programmer, the C# compiler assumes that the Dispose <br>method introduced by SimpleType is the implementation for IDisposable's Dispose <br>method. The C# compiler makes this assumption because the method is public, and the sig-<br>natures of the interface method and the newly introduced method are identical. That is, the <br>methods have the same parameter and return types. By the way, if the new Dispose method <br>were marked as virtual, the C# compiler would still consider this method to be a match for <br>the interface method.<br>
When the C# compiler matches a new method to an interface method, it emits metadata  <br>indicating that both entries in SimpleType's method table should refer to the same  <br>implementation. To help make this clearer, here is some code that demonstrates how to <br>call the class's public Dispose method as well as how to call the class's implementation of <br>IDisposable's Dispose method:<br>
public sealed class Program {  <br>   public static void Main() {  <br>      SimpleType st = new SimpleType();  <br> <br>      // This calls the public Dispose method implementation  <br>      st.Dispose();  <br> <br>      // This calls IDisposable's Dispose method implementation  <br>      IDisposable d = st;  <br>      d.Dispose();  <br>   }  <br>}<br>
<hr>
<A name=333></a><b> </b><br>
<b>Chapter 13  Interfaces </b><br>
<b>315</b><br>
In the first call to Dispose, the Dispose method defined by SimpleType is called. Then I <br>define a variable, d, which is of the IDisposable interface type. I initialize the d variable to <br>refer to the SimpleType object. Now when I call d.Dispose(), I am calling the IDisposable <br>interface's Dispose method. Since C# requires the public Dispose method to also be the <br>implementation for IDisposable's Dispose method, the same code will execute, and, in this <br>example, you can't see any observable difference. The output is as follows:<br>
Dispose  <br>Dispose<br>
Now, let me rewrite the SimpleType from above so that you can see an observable <br>difference:<br>
internal sealed class SimpleType : IDisposable {  <br>   public void Dispose() { Console.WriteLine(&quot;public Dispose&quot;); }  <br>   void IDisposable.Dispose() { Console.WriteLine(&quot;IDisposable Dispose&quot;); }  <br>}<br>
Without changing the Main method shown earlier, if we just recompile and rerun the pro-<br>gram, the output will be this:<br>
public Dispose  <br>IDisposable Dispose<br>
In C#, when you prefix the name of a method with the name of the interface that defines <br>the method (IDisposable.Dispose as in this example), you are creating an <i>explicit interface <br>method implementation</i> (EIMI). Note that when you define an explicit interface method in C#, <br>you are not allowed to specify any accessibility (such as public or private). However, when <br>the compiler generates the metadata for the method, its accessibility is set to private, pre-<br>venting any code using an instance of the class from simply calling the interface method. The <br>only way to call the interface method is through a variable of the interface's type.<br>
Also note that an EIMI method cannot be marked as virtual and therefore cannot be over-<br>ridden. This is because the EIMI method is not really part of the type's object model; it's a <br>way of attaching an interface (set of behaviors or methods) onto a type without making the <br>behaviors/methods obvious. If all of this seems a bit kludgy to you, you <i>are</i> understanding it <br>correctly--this is all a bit kludgy. Later in this chapter, I'll show some valid reasons for using <br>EIMIs.<br>
<b>Generic Interfaces</b><br>
C#'s and the CLR's support of generic interfaces offers many great features for developers. In <br>this section, I'd like to discuss the benefits offered when using generic interfaces.<br>
First, generic interfaces offer great compile-time type safety. Some interfaces (such as the <br>non-generic IComparable interface) define methods that have Object parameters or return <br>
<hr>
<A name=334></a><IMG src="CLRviaCsharp-334_1.jpg"><br>
<b>316 </b><br>
<b>Part II  Designing Types</b><br>
types. When code calls these interface methods, a reference to an instance of any type can <br>be passed. But this is usually not desired. The following code demonstrates:<br>
private void SomeMethod1() {  <br>   Int32 x = 1, y = 2;  <br>   IComparable c = x;  <br> <br>   // CompareTo expects an Object; passing y (an Int32) is OK  <br>   c.CompareTo(y);     // y is boxed here  <br> <br>   // CompareTo expects an Object; passing &quot;2&quot; (a String) compiles  <br>   // but an ArgumentException is thrown at runtime  <br>   c.CompareTo(&quot;2&quot;);  <br>}<br>
Obviously, it is preferable to have the interface method strongly typed, and this is why the <br>FCL includes a generic IComparable&lt;in T&gt; interface. Here is the new version of the code <br>revised by using the generic interface:<br>
private void SomeMethod2() {  <br>   Int32 x = 1, y = 2;  <br>   IComparable&lt;Int32&gt; c = x;  <br> <br>   // CompareTo expects an Int32; passing y (an Int32) is OK  <br>   c.CompareTo(y);     // y is not boxed here  <br> <br>   // CompareTo expects an Int32; passing &quot;2&quot; (a String) results  <br>   // in a compiler error indicating that String cannot be cast to an Int32  <br>   c.CompareTo(&quot;2&quot;);   // Error <br>}<br>
The second benefit of generic interfaces is that much less boxing will occur when working  <br>with value types. Notice in SomeMethod1 that the non-generic IComparable interface's <br>CompareTo method expects an Object; passing y (an Int32 value type) causes the value <br>in y to be boxed. However, in SomeMethod2, the generic IComparable&lt;in T&gt; interface's <br>CompareTo method expects an Int32;<b> </b>passing y causes it to be passed by value, and no  <br>boxing is necessary.<br>
<b>Note  </b>The FCL defines non-generic and generic versions of the IComparable, ICollection, <br>IList, and IDictionary interfaces, as well as some others. If you are defining a type, and <br>you want to implement any of these interfaces, you should typically implement the generic  <br>versions of these interfaces. The non-generic versions are in the FCL for backward compatibility <br>to work with code written before the .NET Framework supported generics. The non-generic ver-<br>sions also provide users a way of manipulating the data in a more general, less type-safe fashion.<br>
Some of the generic interfaces inherit the non-generic versions, so your class will have to imple-<br>ment both the generic and non-generic versions of the interfaces. For example, the generic <br>IEnumerable&lt;out T&gt; interface inherits the non-generic IEnumerable interface. So if your class <br>implements IEnumerable&lt;out T&gt;, your class must also implement IEnumerable.<br>
<hr>
<A name=335></a><b> </b><br>
<b>Chapter 13  Interfaces </b><br>
<b>317</b><br>
Sometimes when integrating with other code, you may have to implement a non-generic  <br>interface because a generic version of the interface simply doesn't exist. In this case, if any of  <br>the interface's methods take or return Object, you will lose compile-time type safety, and you <br>will get boxing with value types. You can alleviate this situation to some extent by using a  <br>technique I describe in the "Improving Compile-Time Type Safety with Explicit Interface Method <br>Implementations" section near the end of this chapter.<br>
The third benefit of generic interfaces is that a class can implement the same interface  <br>multiple times as long as different type parameters are used. The following code shows an <br>example of how useful this could be:<br>
using System;  <br> <br>// This class implements the generic IComparable&lt;T&gt; interface twice  <br>public sealed class Number: IComparable&lt;Int32&gt;, IComparable&lt;String&gt; {  <br>   private Int32 m_val = 5;  <br> <br>   // This method implements IComparable&lt;Int32&gt;'s CompareTo  <br>   public Int32 CompareTo(Int32 n) {   <br>      return m_val.CompareTo(n);   <br>   }  <br> <br>   // This method implements IComparable&lt;String&gt;'s CompareTo  <br>   public Int32 CompareTo(String s) {   <br>      return m_val.CompareTo(Int32.Parse(s));   <br>   }  <br>}  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      Number n = new Number();  <br> <br>      // Here, I compare the value in n with an Int32 (5)  <br>      IComparable&lt;Int32&gt; cInt32 = n;  <br>      Int32 result = cInt32.CompareTo(5);  <br> <br>      // Here, I compare the value in n with a String (&quot;5&quot;)  <br>      IComparable&lt;String&gt; cString = n;  <br>      result = cString.CompareTo(&quot;5&quot;);  <br>   }  <br>}<br>
An interface's generic type parameters can also be marked as contravariant and covariant, <br>which allows even more flexibility for using generic interfaces. For more about contravariance <br>and covariance, see the "Delegate and Interface Contravariant and Covariant Generic Type <br>Arguments" section in Chapter 12.<br>
<hr>
<A name=336></a><b>318 </b><br>
<b>Part II  Designing Types</b><br>
<b>Generics and Interface Constraints</b><br>
In the previous section, I discussed the benefits of using generic interfaces. In this section, I'll <br>discuss the benefits of constraining generic type parameters to interfaces.<br>
The first benefit is that you can constrain a single generic type parameter to multiple inter-<br>faces. When you do this, the type of parameter you are passing in must implement <i>all</i> of the <br>interface constraints. Here is an example:<br>
public static class SomeType {  <br>   private static void Test() {  <br>      Int32 x = 5;  <br>      Guid g = new Guid();  <br> <br>      // This call to M compiles fine because   <br>      // Int32 implements IComparable AND IConvertible  <br>      M(x);  <br> <br>      // This call to M causes a compiler error because   <br>      // Guid implements IComparable but it does not implement IConvertible  <br>      M(g);  <br>   }  <br> <br>   // M's type parameter, T, is constrained to work only with types that  <br>   // implement both the IComparable AND IConvertible interfaces  <br>   private static Int32 M&lt;T&gt;(T t) where T : IComparable, IConvertible {  <br>      ...  <br>   }  <br>}<br>
This is actually quite cool! When you define a method's parameters, each parameter's type <br>indicates that the argument passed must be of the parameter's type or be derived from it. If <br>the parameter type is an interface, this indicates that the argument can be of any class type <br>as long as the class implements the interface. Using multiple interface constraints actually lets <br>the method indicate that the passed argument must implement multiple interfaces.<br>
In fact, if we constrained T to a class and two interfaces, we are saying that the type of  <br>argument passed must be of the specified base class (or derived from it), and it must also <br>implement the two interfaces. This flexibility allows the method to really dictate what callers <br>can pass, and compiler errors will be generated if callers do not meet these constraints.<br>
The second benefit of interface constraints is reduced boxing when passing instances of <br>value types. In the previous code fragment, the M method was passed x (an instance of an <br>Int32, which is a value type). No boxing will occur when x is passed to M. If code inside M <br>does call t.CompareTo(...), still no boxing occurs to make the call (boxing may still happen <br>for arguments passed to CompareTo).<br>
On the other hand, if M had been declared like this:<br>
<hr>
<A name=337></a><b> </b><br>
<b>Chapter 13  Interfaces </b><br>
<b>319</b><br>
private static Int32 M(IComparable t) {  <br>   ...  <br>}<br>
then in order to pass x to M, x would have to be boxed.<br>
For interface constraints, the C# compiler emits certain Intermediate Language (IL) instruc-<br>tions that result in calling the interface method on the value type directly without boxing <br>it. Aside from using interface constraints, there is no other way to get the C# compiler to <br>emit these IL instructions, and therefore, calling an interface method on a value type always <br>causes boxing.<br>
<b>Implementing Multiple Interfaces That Have the Same </b><br>
<b>Method Name and Signature</b><br>
Occasionally, you might find yourself defining a type that implements multiple interfaces that <br>define methods with the same name and signature. For example, imagine that there are two <br>interfaces defined as follows:<br>
public interface IWindow {  <br>   Object GetMenu();  <br>}  <br> <br>public interface IRestaurant {  <br>   Object GetMenu();  <br>}<br>
Let's say that you want to define a type that implements both of these interfaces. You'd have <br>to implement the type's members by using explicit interface method implementations as <br>follows:<br>
// This type is derived from System.Object and   <br>// implements the IWindow and IRestaurant interfaces.  <br>public sealed class MarioPizzeria : IWindow, IRestaurant {  <br> <br>   // This is the implementation for IWindow's GetMenu method.  <br>   Object IWindow.GetMenu() { ... }  <br> <br>   // This is the implementation for IRestaurant's GetMenu method.  <br>   Object IRestaurant.GetMenu() { ... }  <br> <br>   // This (optional method) is a GetMenu method that has nothing   <br>   // to do with an interface.  <br>   public Object GetMenu() { ... }  <br>}<br>
Because this type must implement multiple and separate GetMenu methods, you need to <br>tell the C# compiler which GetMenu method contains the implementation for a particular <br>interface.<br>
<hr>
<A name=338></a><b>320 </b><br>
<b>Part II  Designing Types</b><br>
Code that uses a MarioPizzeria object must cast to the specific interface to call the desired <br>method. The following code demonstrates:<br>
MarioPizzeria mp = new MarioPizzeria();  <br> <br>// This line calls MarioPizzeria's public GetMenu method  <br>mp.GetMenu();  <br> <br>// These lines call MarioPizzeria's IWindow.GetMenu method  <br>IWindow window = mp;  <br>window.GetMenu();  <br> <br>// These lines call MarioPizzeria's IRestaurant.GetMenu method  <br>IRestaurant restaurant = mp;  <br>restaurant.GetMenu();<br>
<b>Improving Compile-Time Type Safety with Explicit </b><br>
<b>Interface Method Implementations</b><br>
Interfaces are great because they define a standard way for types to communicate with each <br>other. Earlier, I talked about generic interfaces and how they improve compile-time type <br>safety and reduce boxing. Unfortunately, there may be times when you need to implement a <br>non-generic interface because a generic version doesn't exist. If any of the interface's  <br>method(s) accept parameters of type System.Object or return a value whose type is <br>System.Object, you will lose compile-time type safety, and you will get boxing. In this  <br>section, I'll show you how you can use EIMI to improve this situation somewhat.<br>
Look at the very common IComparable interface:<br>
public interface IComparable {  <br>   Int32 CompareTo(Object other);  <br>}<br>
This interface defines one method that accepts a parameter of type System.Object. If I  <br>define my own type that implements this interface, the type definition might look like this:<br>
internal struct SomeValueType : IComparable {  <br>   private Int32 m_x;  <br>   public SomeValueType(Int32 x) { m_x = x; }  <br>   public Int32 CompareTo(Object other) {  <br>      return(m_x - ((SomeValueType) other).m_x);  <br>   }  <br>}<br>
Using SomeValueType, I can now write the following code:<br>
<hr>
<A name=339></a><b> </b><br>
<b>Chapter 13  Interfaces </b><br>
<b>321</b><br>
public static void Main() {  <br>   SomeValueType v = new SomeValueType(0);  <br>   Object o = new Object();  <br>   Int32 n = v.CompareTo(v); // Undesired boxing  <br>   n = v.CompareTo(o);       // InvalidCastException  <br>}<br>
There are two characteristics of this code that are not ideal:<br>
<b>  Undesired boxing  </b>When v is passed as an argument to the CompareTo method, it <br>
must be boxed because CompareTo expects an Object.<br>
<b>  The lack of type safety  </b>This code compiles, but an InvalidCastException is thrown <br>
inside the CompareTo method when it attempts to cast o to SomeValueType.<br>
Both of these issues can be fixed by using EIMIs. Here's a modified version of SomeValueType <br>that has an EIMI added to it:<br>
internal struct SomeValueType : IComparable {  <br>   private Int32 m_x;  <br>   public SomeValueType(Int32 x) { m_x = x; }  <br> <br>   public Int32 CompareTo(SomeValueType other) {  <br>      return(m_x - other.m_x);  <br>   }  <br> <br>   // NOTE: No public/private used on the next line  <br>   Int32 IComparable.CompareTo(Object other) {  <br>      return CompareTo((SomeValueType) other);  <br>   }  <br>}<br>
Notice several changes in this new version. First, it now has two CompareTo methods. <br>The first CompareTo method no longer takes an Object as a parameter; it now takes a <br>SomeValueType instead. Because this parameter has changed, the code that casts other to <br>SomeValueType is no longer necessary and has been removed. Second, changing the first <br>CompareTo method to make it type-safe means that SomeValueType no longer adheres to <br>the contract placed on it by implementing the IComparable interface. So SomeValueType <br>must implement a CompareTo method that satisfies the IComparable contract. This is the job <br>of the second IComparable.CompareTo method, which is an EIMI.<br>
Having made these two changes means that we now get compile-time type safety and no <br>boxing:<br>
public static void Main() {  <br>   SomeValueType v = new SomeValueType(0);  <br>   Object o = new Object();  <br>   Int32  n = v.CompareTo(v); // No boxing  <br>   n = v.CompareTo(o);        // compile-time error   <br>}<br>
<hr>
<A name=340></a><b>322 </b><br>
<b>Part II  Designing Types</b><br>
If, however, we define a variable of the interface type, we will lose compile-time type safety <br>and experience undesired boxing again:<br>
public static void Main() {  <br>   SomeValueType v = new SomeValueType(0);  <br>   IComparable c = v;         // Boxing!  <br> <br>   Object o = new Object();  <br>   Int32  n = c.CompareTo(v); // Undesired boxing  <br>   n = c.CompareTo(o);        // InvalidCastException  <br>}<br>
In fact, as mentioned earlier in this chapter, when casting a value type instance to an inter-<br>face type, the CLR must box the value type instance. Because of this fact, two boxings will <br>occur in the previous Main method.<br>
EIMIs are frequently used when implementing interfaces such as IConvertible, <br>ICollection, IList, and IDictionary. They let you create type-safe versions of these  <br>interfaces' methods, and they enable you to reduce boxing operations for value types.<br>
<b>Be Careful with Explicit Interface Method </b><br>
<b>Implementations</b><br>
It is critically important for you to understand some ramifications that exist when using <br>EIMIs. And because of these ramifications, you should try to avoid EIMIs as much as possible. <br>Fortunately, generic interfaces help you avoid EIMIs quite a bit. But there may still be times <br>when you will need to use them (such as implementing two interface methods with the same <br>name and signature). Here are the big problems with EIMIs:<br>
  There is no documentation explaining how a type specifically implements an EIMI <br>
method, and there is no Microsoft Visual Studio IntelliSense support.<br>
  Value type instances are boxed when cast to an interface.<br>
  An EIMI cannot be called by a derived type.<br>
Let's take a closer look at these problems.<br>
When examining the methods for a type in the .NET Framework reference documentation, <br>explicit interface method implementations are listed, but no type-specific help exists; you <br>can just read the general help about the interface methods. For example, the documentation <br>for the Int32 type shows that it implements all of IConvertible interface's methods. This is <br>good because developers know that these methods exist; however, this has been very con-<br>fusing to developers because you can't call an IConvertible method on an Int32 directly. <br>For example, the following method won't compile:<br>
<hr>
<A name=341></a><b> </b><br>
<b>Chapter 13  Interfaces </b><br>
<b>323</b><br>
public static void Main() {  <br>   Int32 x = 5;  <br>   Single s = x.ToSingle(null); // Trying to call an IConvertible method  <br>}<br>
When compiling this method, the C# compiler produces the following message:  <br>&quot;messagepil17: 'int' does not contain a definition for 'ToSingle'.&quot; This error <br>message confuses the developer because it's clearly stating that the Int32 type doesn't  <br>define a ToSingle method when, in fact, it does.<br>
To call ToSingle on an Int32, you must first cast the Int32 to an IConvertible, as shown <br>in the following method:<br>
public static void Main() {  <br>   Int32 x = 5;  <br>   Single s = ((IConvertible) x).ToSingle(null);  <br>}<br>
Requiring this cast isn't obvious at all, and many developers won't figure this out on their <br>own. But an even more troublesome problem exists: casting the Int32 value type to an <br>IConvertible also boxes the value type, wasting memory and hurting performance. This is <br>the second of the big problems I mentioned at the beginning of this section.<br>
The third and perhaps the biggest problem with EIMIs is that they cannot be called by a  <br>derived class. Here is an example:<br>
internal class Base : IComparable {  <br> <br>   // Explicit Interface Method Implementation  <br>   Int32 IComparable.CompareTo(Object o) {  <br>      Console.WriteLine(&quot;Base's CompareTo&quot;);  <br>      return 0;   <br>   }  <br>}  <br> <br>internal sealed class Derived : Base, IComparable {  <br> <br>   // A public method that is also the interface implementation  <br>   public Int32 CompareTo(Object o) {  <br>      Console.WriteLine(&quot;Derived's CompareTo&quot;);  <br> <br>      // This attempt to call the base class's EIMI causes a compiler error:  <br>      // error CS0117: 'Base' does not contain a definition for 'CompareTo'  <br>      base.CompareTo(o);  <br>      return 0;   <br>   }  <br>}<br>
In Derived's CompareTo method, I try to call base.CompareTo, but this causes the C# com-<br>piler to issue an error. The problem is that the Base class doesn't offer a public or protected <br>CompareTo method that can be called; it offers a CompareTo method that can be called only <br>
<hr>
<A name=342></a><b>324 </b><br>
<b>Part II  Designing Types</b><br>
by using a variable that is of the IComparable type. I could modify Derived's CompareTo <br>method so that it looks like this:<br>
// A public method that is also the interface implementation  <br>public Int32 CompareTo(Object o) {  <br>   Console.WriteLine(&quot;Derived's CompareTo&quot;);  <br> <br>   // This attempt to call the base class's EIMI causes infinite recursion  <br>   IComparable c = this;  <br>   c.CompareTo(o);  <br> <br>   return 0;   <br>}<br>
In this version, I am casting this to an IComparable variable, c. And then, I use c to call <br>CompareTo.<b> </b>However, the Derived's public CompareTo method serves as the implementation <br>for Derived's IComparableCompareTo method, and therefore, infinite recursion occurs. This <br>could be fixed by declaring the Derived class without the IComparable interface, like this:<br>
internal sealed class Derived : Base /*, IComparable */ { ... }<br>
Now the previous CompareTo method will call the CompareTo method in Base. But sometimes <br>you cannot simply remove the interface from the type because you want the derived type <br>to implement an interface method. The best way to fix this is for the base class to provide a <br>virtual method in addition to the interface method that it has chosen to implement explicitly. <br>Then the Derived class can override the virtual method. Here is the correct way to define the <br>Base and Derived classes:<br>
internal class Base : IComparable {  <br> <br>   // Explicit Interface Method Implementation  <br>   Int32 IComparable.CompareTo(Object o) {  <br>      Console.WriteLine(&quot;Base's IComparable CompareTo&quot;);  <br>      return CompareTo(o);   // This now calls the virtual method  <br>   }  <br> <br>   // Virtual method for derived classes (this method could have any name)  <br>   public virtual Int32 CompareTo(Object o) {  <br>      Console.WriteLine(&quot;Base's virtual CompareTo&quot;);  <br>      return 0;  <br>   }  <br>}  <br> <br>internal sealed class Derived : Base, IComparable {  <br> <br>   // A public method that is also the interface implementation  <br>   public override Int32 CompareTo(Object o) {  <br>      Console.WriteLine(&quot;Derived's CompareTo&quot;);  <br> <br>      // Now, we can call Base's virtual method  <br>      return base.CompareTo(o);  <br>   }  <br>}<br>
<hr>
<A name=343></a><b> </b><br>
<b>Chapter 13  Interfaces </b><br>
<b>325</b><br>
Note that I have defined the virtual method above as a public method, but in some cases, you <br>will prefer to make the method protected instead. It is fine to make this method protected <br>instead of public, but that will necessitate other minor changes. This discussion clearly shows <br>you that EIMIs should be used with great care. When many developers first learn about EIMIs, <br>they think that they're cool and they start using them whenever possible. Don't do this! EIMIs <br>are useful in some circumstances, but you should avoid them whenever possible because <br>they make using a type much more difficult.<br>
<b>Design: Base Class or Interface?</b><br>
I often hear the question, "Should I design a base type or an interface?" The answer isn't  <br>always clear-cut. Here are some guidelines that might help you:<br>
<b>  IS-A vs. CAN-DO relationship  </b>A type can inherit only one implementation. If the  <br>
derived type can't claim an IS-A relationship with the base type, don't use a base type; <br>use an interface. Interfaces imply a CAN-DO relationship. If the CAN-DO functionality  <br>appears to belong with various object types, use an interface. For example, a type <br>can convert instances of itself to another type (IConvertible), a type can serialize an <br>instance of itself (ISerializable), etc. Note that value types must be derived from <br>System.ValueType, and therefore, they cannot be derived from an arbitrary base class. <br>In this case, you must use a CAN-DO relationship and define an interface.<br>
<b>  Ease of use  </b>It's generally easier for you as a developer to define a new type derived <br>
from a base type than to implement all of the methods of an interface. The base type <br>can provide a lot of functionality, so the derived type probably needs only relatively <br>small modifications to its behavior. If you supply an interface, the new type must  <br>implement all of the members.<br>
<b>  Consistent implementation  </b>No matter how well an interface contract is documented, <br>
it's very unlikely that everyone will implement the contract 100 percent correctly. In <br>fact, COM suffers from this very problem, which is why some COM objects work cor-<br>rectly only with Microsoft Office Word or with Windows Internet Explorer. By providing <br>a base type with a good default implementation, you start off using a type that works <br>and is well tested; you can then modify parts that need modification.<br>
<b>  Versioning  </b>If you add a method to the base type, the derived type inherits the new <br>
method, you start off using a type that works, and the user's source code doesn't even <br>have to be recompiled. Adding a new member to an interface forces the inheritor of <br>the interface to change its source code and recompile.<br>
In the FCL, the classes related to streaming data use an implementation inheritance design. <br>The System.IO.Stream class is the abstract base class. It provides a bunch of methods, such <br>as Read and Write. Other classes--System.IO.FileStream, System.IO.MemoryStream, <br>and System.Net.Sockets.NetworkStream--are derived from Stream. Microsoft chose an <br>
<hr>
<A name=344></a><b>326 </b><br>
<b>Part II  Designing Types</b><br>
IS-A relationship between each of these three classes and the Stream class because it made <br>implementing the concrete classes easier. For example, the derived classes need to implement <br>only synchronous I/O operations; they inherit the ability to perform asynchronous I/O opera-<br>tions from the Stream base class.<br>
Admittedly, choosing to use inheritance for the stream classes isn't entirely clear-cut; the <br>Stream base class actually provides very little implementation. However, if you consider the <br>Microsoft Windows Forms control classes, in which Button, CheckBox, ListBox, and all of <br>the other controls are derived from System.Windows.Forms.Control, it's easy to imagine <br>all of the code that Control implements, which the various control classes simply inherit to <br>function correctly.<br>
By contrast, Microsoft designed the FCL collections to be interface based. The  <br>System.Collections.Generic namespace defines several collection-related interfaces: <br>IEnumerable&lt;out T&gt;, ICollection&lt;T&gt;, IList&lt;T&gt;,<b> </b>and IDictionary&lt;TKey, TValue&gt;. <br>Then Microsoft provided a number of classes, such as List&lt;T&gt;, Dictionary&lt;TKey, TValue&gt;, <br>Queue&lt;T&gt;, Stack&lt;T&gt;, and so on, that implement combinations of these interfaces. Here the <br>designers chose a CAN-DO relationship between the classes and the interfaces because the <br>implementations of these various collection classes are radically different from one another. <br>In other words, there isn't a lot of sharable code between a List&lt;T&gt;, a Dictionary&lt;TKey, <br>TValue&gt;, and a Queue&lt;T&gt;.<br>
The operations these collection classes offer are, nevertheless, pretty consistent. For example,  <br>they all maintain a set of elements that can be enumerated, and they all allow adding and <br>removing of elements. If you have a reference to an object whose type implements the <br>IList&lt;T&gt; interface, you can write code to insert elements, remove elements, and search for <br>an element without having to know exactly what type of collection you're working with. This <br>is a very powerful mechanism.<br>
Finally, it should be pointed out that you can actually do both: define an interface <i>and</i> <br>provide a base class that implements the interface. For example, the FCL defines the <br>IComparer&lt;in T&gt; interface, and any type can choose to implement this interface. In  <br>addition, the FCL provides an abstract base class, Comparer&lt;T&gt;, which implements this  <br>interface and provides a default implementation for the non-generic IComparable's Compare <br>method. Having both an interface definition and a base class offers great flexibility because <br>developers can now choose whichever they prefer.<br>
<hr>
<A name=345></a>Chapter 14<br><b>Chars, Strings, and Working with Text</b><br>
<b>In this chapter:<br>Characters. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327<br>The </b>System.String<b> Type. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330<br>Constructing a String Efficiently. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 346<br>Obtaining a String Representation of an Object: </b>ToString<b>  . . . . . . . . . . . . . . . . 350<br>Parsing a String to Obtain an Object: </b>Parse<b>  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359<br>Encodings: Converting Between Characters and Bytes  . . . . . . . . . . . . . . . . . . . . 361<br>Secure Strings  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369</b><br>
In this chapter, I'll explain the mechanics of working with individual characters and strings in <br>the Microsoft .NET Framework. I'll start by talking about the System.Char structure and the <br>various ways that you can manipulate a character. Then I'll go over the more useful  <br>System.String class, which allows you to work with immutable strings. (Once created, <br>strings can't be modified in any way.) After examining strings, I'll show you how to perform  <br>various operations efficiently to build a string dynamically via the System.Text.StringBuilder <br>class. With the string basics out of the way, I'll then describe how to format objects into <br>strings and how to efficiently persist or transmit strings by using various encodings. Finally, <br>I'll discuss the System.Security.SecureString class, which can be used to protect sensitive <br>string data such as passwords and credit card information.<br>
<b>Characters</b><br>
In the .NET Framework, characters are always represented in 16-bit Unicode code values, <br>easing the development of global applications. A character is represented with an instance <br>of the System.Char structure (a value type). The System.Char type is pretty simple. It offers <br>two public read-only constant fields: MinValue, defined as '\0', and MaxValue, defined as <br>'\uffff'.<br>
Given an instance of a Char, you can call the static GetUnicodeCategory method, which re-<br>turns a value of the System.Globalization.UnicodeCategory enumerated type. This value <br>indicates whether the character is a control character, a currency symbol, a lowercase letter, <br>an uppercase letter, a punctuation character, a math symbol, or another character (as defined <br>by the Unicode standard).<br>
<b> </b><br>
<b> </b><br>
<b>327</b><br>
<hr>
<A name=346></a><b>328 </b><br>
<b>Part III  Essential Types</b><br>
To ease developing, the Char type also offers several static methods, such as IsDigit, <br>IsLetter, IsWhiteSpace, IsUpper, IsLower, IsPunctuation, IsLetterOrDigit, <br>IsControl, IsNumber, IsSeparator, IsSurrogate,<b> </b>IsLowSurrogate, IsHighSurrogate, <br>and IsSymbol. Most of these methods call GetUnicodeCategory internally and simply return <br>true or false accordingly. Note that all of these methods take either a single character for a <br>parameter or a String and the index of a character within the String as parameters.<br>
In addition, you can convert a single character to its lowercase or uppercase equivalent in a <br>culture-agnostic way by calling the static ToLowerInvariant or ToUpperInvariant method. <br>Alternatively, the ToLower and ToUpper methods convert the character by using the culture  <br>information associated with the calling thread (which the methods obtain internally by <br>querying the static CurrentCulture property of the System.Threading.Thread class). <br>You can also specify a particular culture by passing an instance of the CultureInfo class to <br>these methods. ToLower and ToUpper require culture information because letter casing is <br>a culture-dependent operation. For example, Turkish considers the uppercase of U+0069 <br>(LATIN LOWERCASE LETTER I) to be U+0130 (LATIN UPPERCASE LETTER I WITH DOT ABOVE), <br>whereas other cultures consider the result to be U+0049 (LATIN CAPITAL LETTER I).<br>
Besides these static methods, the Char type also offers a few instance methods of its own. <br>The Equals method returns true if two Char instances represent the same 16-bit Unicode <br>code point. The CompareTo methods (defined by the IComparable/IComparable&lt;Char&gt; in-<br>terfaces) return a comparison of two Char instances; this comparison is not culture-sensitive. <br>The ConvertFromUtf32 method produces a string consisting of two UTF-16 characters from <br>a single UTF-32 character. The ConvertToUtf32 produces a UTF-16 character from a low/<br>high surrogate pair or from a string. The ToString method returns a String consisting of a <br>single character. The opposite of ToString is Parse/TryParse, which takes a single-character <br>String and returns its UTF-16 code point.<br>
The last method, GetNumericValue, returns the numeric equivalent of a character. I demon-<br>strate this method in the following code:<br>
using System;  <br> <br>public static class Program {   <br>   public static void Main() {   <br>      Double d;                           // '\u0033' is the &quot;digit 3&quot;  <br>      d = Char.GetNumericValue('\u0033'); // '3' would work too  <br>      Console.WriteLine(d.ToString());    // Displays &quot;3&quot;  <br> <br>      // '\u00bc' is the &quot;vulgar fraction one quarter ('¼')&quot;  <br>      d = Char.GetNumericValue('\u00bc');  <br>      Console.WriteLine(d.ToString());    // Displays &quot;0.25&quot;  <br> <br>      // 'A' is the &quot;Latin capital letter A&quot;  <br>      d = Char.GetNumericValue('A');  <br>      Console.WriteLine(d.ToString());    // Displays &quot;-1&quot;  <br>   }  <br>}<br>
<hr>
<A name=347></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>329</b><br>
Finally, three techniques allow you to convert between various numeric types to Char  <br>instances and vice versa. The techniques are listed here in order of preference:<br>
<b>  Casting  </b>The easiest way to convert a Char to a numeric value such as an Int32 is  <br>
simply by casting. Of the three techniques, this is the most efficient because the  <br>compiler emits Intermediate Language (IL) instructions to perform the conversion, and <br>no methods have to be called. In addition, some languages (such as C#) allow you to <br>indicate whether the conversion should be performed using checked or unchecked <br>code (discussed in Chapter 5, "Primitive, Reference, and Value Types").<br>
<b>  Use the </b>Convert<b> type  </b>The System.Convert type offers several static methods that <br>
are capable of converting a Char to a numeric type and vice versa. All of these methods <br>perform the conversion as a checked operation, causing an OverflowException to <br>be thrown if the conversion results in the loss of data.<br>
<b>  Use the </b>IConvertible<b> interface  </b>The Char type and all of the numeric types in the <br>
.NET Framework Class Library (FCL) implement the IConvertible interface. This inter-<br>face defines methods such as ToUInt16 and ToChar. This technique is the least efficient <br>of the three because calling an interface method on a value type requires that the <br>instance be boxed--Char and all of the numeric types are value types. The methods <br>of IConvertible throw a System.InvalidCastException if the type can't be con-<br>verted (such as converting a Char to a Boolean) or if the conversion results in a loss of <br>data. Note that many types (including the FCL's Char and numeric types) implement <br>IConvertible's methods as explicit interface member implementations (described in <br>Chapter 13, "Interfaces"). This means that you must explicitly cast the instance to an <br>IConvertible before you can call any of the interface's methods. All of the methods <br>of IConvertible except GetTypeCode accept a reference to an object that implements <br>the IFormatProvider interface. This parameter is useful if for some reason the conver-<br>sion needs to take culture information into account. For most conversions, you can pass <br>null for this parameter because it would be ignored anyway.<br>
The following code demonstrates how to use these three techniques:<br>
using System;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      Char  c;  <br>      Int32 n;  <br> <br>      // Convert number &lt;-&gt; character using C# casting  <br>      c = (Char) 65;  <br>      Console.WriteLine(c);                  // Displays &quot;A&quot;  <br> <br>      n = (Int32) c;  <br>      Console.WriteLine(n);                  // Displays &quot;65&quot;  <br> <br>
<hr>
<A name=348></a><b>330 </b><br>
<b>Part III  Essential Types</b><br>
      c = unchecked((Char) (65536 + 65));  <br>      Console.WriteLine(c);                  // Displays &quot;A&quot;  <br> <br> <br> <br>      // Convert number &lt;-&gt; character using Convert  <br>      c = Convert.ToChar(65);  <br>      Console.WriteLine(c);                  // Displays &quot;A&quot;  <br> <br>      n = Convert.ToInt32(c);  <br>      Console.WriteLine(n);                  // Displays &quot;65&quot;   <br> <br> <br>      // This demonstrates Convert's range checking  <br>      try {  <br>         c = Convert.ToChar(70000);          // Too big for 16 bits  <br>         Console.WriteLine(c);               // Doesn't execute  <br>      }  <br>      catch (OverflowException) {  <br>         Console.WriteLine(&quot;Can't convert 70000 to a Char.&quot;);  <br>      }  <br> <br> <br>      // Convert number &lt;-&gt; character using IConvertible  <br>      c = ((IConvertible) 65).ToChar(null);  <br>      Console.WriteLine(c);                  // Displays &quot;A&quot;  <br> <br>      n = ((IConvertible) c).ToInt32(null);  <br>      Console.WriteLine(n);                  // Displays &quot;65&quot;  <br>   }  <br>}<br>
<b>The </b>System.String<b> Type</b><br>
One of the most used types in any application is System.String. A String represents an <br>immutable ordered set of characters. The String type is derived immediately from Object, <br>making it a reference type, and therefore, String objects (its array of characters) always <br>live in the heap, never on a thread's stack. The String type also implements several inter-<br>faces (IComparable/IComparable&lt;String&gt;, ICloneable, IConvertible, IEnumerable/<br>IEnumerable&lt;Char&gt;, and IEquatable&lt;String&gt;).<br>
<b>Constructing Strings</b><br>
Many programming languages (including C#) consider String to be a primitive type--that is, <br>the compiler lets you express literal strings directly in your source code. The compiler places <br>these literal strings in the module's metadata, and they are then loaded and referenced at <br>runtime.<br>
<hr>
<A name=349></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>331</b><br>
In C#, you can't use the new operator to construct a String object from a literal string:<br>
using System;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      String s = new String(&quot;Hi there.&quot;);  // &lt;-- Error  <br>      Console.WriteLine(s);  <br>   }  <br>}<br>
Instead, you must use the following simplified syntax:<br>
using System;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      String s = &quot;Hi there.&quot;;  <br>      Console.WriteLine(s);  <br>   }  <br>}<br>
If you compile this code and examine its IL (using ILDasm.exe), you'd see the following:<br>
.method public hidebysig static void  Main() cil managed  <br>{  <br>  .entrypoint  <br>  // Code size       13 (0xd)  <br>  .maxstack  1  <br>  .locals init (string V_0)  <br>  IL_0000:  ldstr      &quot;Hi there.&quot;  <br>  IL_0005:  stloc.0  <br>  IL_0006:  ldloc.0  <br>  IL_0007:  call       void [mscorlib]System.Console::WriteLine(string)  <br>  IL_000c:  ret  <br>} // end of method Program::Main<br>
The newobj IL instruction constructs a new instance of an object. However, no newobj  <br>instruction appears in the IL code example. Instead, you see the special ldstr (load string) IL <br>instruction, which constructs a String object by using a literal string obtained from metadata. <br>This shows you that the common language runtime (CLR) does, in fact, have a special way of <br>constructing literal String objects.<br>
If you are using unsafe code, you can construct a String object from a Char* or SByte*. To <br>accomplish this, you would use C#'s new operator and cal  one of the constructors provided by <br>the String type that takes Char* or SByte* parameters. These constructors create a String <br>object, initializing the string from an array of Char instances or signed bytes. The other con-<br>structors don't have any pointer parameters and can be called using safe (verifiable) code <br>written in any managed programming language.<br>
<hr>
<A name=350></a><IMG src="CLRviaCsharp-350_1.jpg"><br>
<b>332 </b><br>
<b>Part III  Essential Types</b><br>
C# offers some special syntax to help you enter literal strings into the source code. For special <br>characters such as new lines, carriage returns, and backspaces, C# uses the escape mechanism <br>familiar to C/C++ developers:<br>
// String containing carriage-return and newline characters  <br>String s = &quot;Hi\r\nthere.&quot;;<br>
<b>Important  </b>Although the preceding example hard-codes carriage-return and newline characters <br>into the string, I don't recommend this practice. Instead, the System.Environment type defines <br>a read-only NewLine property that returns a string consisting of these characters when your  <br>application is running on Microsoft Windows. However, the NewLine property is platform  <br>sensitive, and it returns the appropriate string required to obtain a newline by the underlying <br>platform. So, for example, if the Common Language Infrastructure (CLI) is ported to a UNIX  <br>system, the NewLine property would return a string consisting of just a single character \n. <br>Here's the proper way to define the previous string so that it works correctly on any platform:<br>
String s = &quot;Hi&quot; + Environment.NewLine + &quot;there.&quot;;<br>
You can concatenate several strings to form a single string by using C#'s + operator as <br>follows:<br>
// Three literal strings concatenated to form a single literal string  <br>String s = &quot;Hi&quot; + &quot; &quot; + &quot;there.&quot;;<br>
In this code, because all of the strings are literal strings, the C# compiler concatenates them <br>at compile time and ends up placing just one string--&quot;Hi there.&quot;--in the module's meta-<br>data. Using the + operator on nonliteral strings causes the concatenation to be performed <br>at runtime. To concatenate several strings together at runtime, avoid using the + operator <br>because it creates multiple string objects on the garbage-collected heap. Instead, use the <br>System.Text.StringBuilder type (which I'll explain later in this chapter).<br>
Finally, C# also offers a special way to declare a string in which all characters between quotes <br>are considered part of the string. These special declarations are called <i>verbatim strings </i>and are <br>typically used when specifying the path of a file or directory or when working with regular  <br>expressions. Here is some code showing how to declare the same string with and without  <br>using the verbatim string character (@).<br>
// Specifying the pathname of an application   <br>String file = &quot;C:\\Windows\\System32\\Notepad.exe&quot;;  <br> <br>// Specifying the pathname of an application by using a verbatim string  <br>String file = @&quot;C:\Windows\System32\Notepad.exe&quot;;<br>
<hr>
<A name=351></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>333</b><br>
You could use either one of the preceding code lines in a program because they produce <br>identical strings in the assembly's metadata. However, the @ symbol before the string on the <br>second line tells the compiler that the string is a verbatim string. In effect, this tells the  <br>compiler to treat backslash characters as backslash characters instead of escape characters, <br>making the path much more readable in your source code.<br>
Now that you've seen how to construct a string, let's talk about some of the operations you <br>can perform on String objects.<br>
<b>Strings Are Immutable</b><br>
The most important thing to know about a String object is that it is immutable. That <br>is, once created, a string can never get longer, get shorter, or have any of its characters <br>changed. Having immutable strings offers several benefits. First, it allows you to perform  <br>operations on a string without actually changing the string:<br>
if (s.ToUpperInvariant().Substring(10, 21).EndsWith(&quot;EXE&quot;)) {  <br>  ...  <br>}<br>
Here, ToUpperInvariant returns a new string; it doesn't modify the characters of the string <br>s. Substring operates on the string returned by ToUpperInvariant and also returns a <br>new string, which is then examined by EndsWith. The two temporary strings created by <br>ToUpperInvariant and Substring are not referenced for long by the application code, and <br>the garbage collector will reclaim their memory at the next collection. If you perform a lot of <br>string manipulations, you end up creating a lot of String objects on the heap, which causes <br>more frequent garbage collections, thus hurting your application's performance. To perform <br>a lot of string manipulations efficiently, use the StringBuilder class.<br>
Having immutable strings also means that there are no thread synchronization issues when <br>manipulating or accessing a string. In addition, it's possible for the CLR to share multiple <br>identical String contents through a single String object. This can reduce the number of <br>strings in the system--thereby conserving memory usage--and it is what string interning <br>(discussed later in the chapter) is all about.<br>
For performance reasons, the String type is tightly integrated with the CLR. Specifically, the <br>CLR knows the exact layout of the fields defined within the String type, and the CLR accesses <br>these fields directly. This performance and direct access come at a small development cost: <br>the String class is sealed, which means that you cannot use it as a base class for your own <br>type. If you were able to define your own type, using String as a base type, you could add <br>your own fields, which would break the CLR's assumptions. In addition, you could break some <br>assumptions that the CLR team has made about String objects being immutable.<br>
<hr>
<A name=352></a><b>334 </b><br>
<b>Part III  Essential Types</b><br>
<b>Comparing Strings</b><br>
Comparing is probably the most common operation performed on strings. There are two <br>reasons to compare two strings with each other. We compare two strings to determine <br>equality or to sort them (usually for presentation to a user).<br>
In determining string equality or when comparing strings for sorting, it is highly recommend-<br>ed that you call one of these methods (defined by the String class):<br>
Boolean Equals(String value, StringComparison comparisonType)  <br>static Boolean Equals(String a, String b, StringComparison comparisonType)  <br> <br>static Int32 Compare(String strA, String strB, StringComparison comparisonType)  <br>static Int32 Compare(string strA, string strB, Boolean ignoreCase, CultureInfo culture)  <br>static Int32 Compare(String strA, String strB, CultureInfo culture, CompareOptions options) <br>static Int32 Compare(String strA, Int32 indexA, String strB, Int32 indexB, Int32 length, <br>   StringComparison comparisonType)  <br>static Int32 Compare(String strA, Int32 indexA, String strB, Int32 indexB, Int32 length, <br>   CultureInfo culture, CompareOptions options) <br>static Int32 Compare(String strA, Int32 indexA, String strB, Int32 indexB, Int32 length, <br>   Boolean ignoreCase, CultureInfo culture)  <br> <br>Boolean StartsWith(String value, StringComparison comparisonType)  <br>Boolean StartsWith(String value,   <br>   Boolean ignoreCase, CultureInfo culture)  <br> <br>Boolean EndsWith(String value, StringComparison comparisonType)  <br>Boolean EndsWith(String value, Boolean ignoreCase, CultureInfo culture)<br>
When sorting, you should always perform case-sensitive comparisons. The reason is that if <br>two strings differing only by case are considered to be equal, they could be ordered differ-<br>ently each time you sort them; this would confuse the user.<br>
The comparisonType argument (in most of the methods shown above) is one of the values <br>defined by the StringComparison enumerated type, which is defined as follows:<br>
public enum StringComparison {  <br>   CurrentCulture = 0,  <br>   CurrentCultureIgnoreCase = 1,  <br>   InvariantCulture = 2,  <br>   InvariantCultureIgnoreCase = 3,  <br>   Ordinal = 4,  <br>   OrdinalIgnoreCase = 5  <br>}<br>
The CompareOptions argument (in two of the methods above) is one of the values defined <br>by the CompareOptions enumerator type:<br>
<hr>
<A name=353></a><IMG src="CLRviaCsharp-353_1.jpg"><br>
<IMG src="CLRviaCsharp-353_2.jpg"><br>
<b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>335</b><br>
[Flags] <br>public enum CompareOptions { <br>   None = 0, <br>   IgnoreCase = 1, <br>   IgnoreNonSpace = 2, <br>   IgnoreSymbols  = 4, <br>   IgnoreKanaType = 8, <br>   IgnoreWidth = 0x00000010, <br>   Ordinal = 0x40000000, <br>   OrdinalIgnoreCase = 0x10000000, <br>   StringSort = 0x20000000 <br>}<br>
Methods that accept a CompareOptions argument also force you to explicitly pass in a  <br>culture. When passing in the Ordinal or OrdinalIgnoreCase flag, these Compare methods <br>ignore the specified culture.<br>
Many programs use strings for internal programmatic purposes such as path names, file <br>names, URLs, registry keys and values, environment variables, reflection, Extensible Markup <br>Language (XML) tags, XML attributes, and so on. Often, these strings are not shown to a user <br>and are used only within the program. When comparing programmatic strings, you should <br>always use StringComparison.Ordinal or StringComparison.OrdinalIgnoreCase. This is <br>the fastest way to perform a comparison that is not to be affected in any linguistic way  <br>because culture information is not taken into account when performing the comparison.<br>
On the other hand, when you want to compare strings in a linguistically correct manner <br>(usually for display to an end user), you should use StringComparison.CurrentCulture or <br>StringComparison.CurrentCultureIgnoreCase.<br>
<b>Important  </b>For the most part, StringComparison.InvariantCulture and <br>StringComparison.InvariantCultureIgnoreCase should not be used. Although these <br>values cause the comparison to be linguistically correct, using them to compare programmatic <br>strings takes longer than performing an ordinal comparison. Furthermore, the invariant culture is <br>culture agnostic, which makes it an incorrect choice when working with strings that you want to <br>show to an end user.<br>
<b>Important  </b>If you want to change the case of a string's characters before performing an ordi-<br>nal comparison, you should use String's ToUpperInvariant or ToLowerInvariant method. <br>When normalizing strings, it is highly recommended that you use ToUpperInvariant instead of <br>ToLowerInvariant because Microsoft has optimized the code for performing uppercase com-<br>parisons. In fact, the FCL internally normalizes strings to uppercase prior to performing case-<br>insensitive comparisons. We use ToUpperInvariant and ToLowerInvariant methods because <br>the String class does not offer ToUpperOrdinal and ToLowerOrdinal methods. We do not <br>use the ToUpper and ToLower methods because these are culture sensitive.<br>
<hr>
<A name=354></a><IMG src="CLRviaCsharp-354_1.jpg"><br>
<b>336 </b><br>
<b>Part III  Essential Types</b><br>
Sometimes, when you compare strings in a linguistically correct manner, you want to specify <br>a specific culture rather than use a culture that is associated with the calling thread. In this <br>case, you can use the overloads of the StartsWith, EndsWith, and Compare methods shown <br>earlier, all of which take Boolean and CultureInfo arguments.<br>
<b>Important  </b>The String type defines several overloads of the Equals, StartsWith, EndsWith, <br>and Compare methods in addition to the versions shown earlier. Microsoft recommends that <br>these other versions (not shown in this book) be avoided. Furthermore, String's other compari-<br>son methods--CompareTo (required by the IComparable interface), CompareOrdinal, and <br>the == and != operators--should also be avoided. The reason for avoiding these methods and <br>operators is because the caller does not explicitly indicate how the string comparison should <br>be performed, and you cannot determine from the name of the method what the default com-<br>parison will be. For example, by default, CompareTo performs a culture-sensitive comparison, <br>whereas Equals performs an ordinal comparison. Your code will be easier to read and maintain <br>if you always indicate explicitly how you want to perform your string comparisons.<br>
Now, let's talk about how to perform linguistically correct comparisons. The .NET Framework <br>uses the System.Globalization.CultureInfo type to represent a language/country pair <br>(as described by the RFC 1766 standard). For example, "en-US" identifies English as written <br>in the United States, "en-AU" identifies English as written in Australia, and "de-DE" identifies <br>German as written in Germany. In the CLR, every thread has two properties associated with it. <br>Each of these properties refers to a CultureInfo object. The two properties are:<br>
<b>  </b>CurrentUICulture<b>  </b>This property is used to obtain resources that are shown to an <br>
end user. It is most useful for GUI or Web Forms applications because it indicates the <br>language that should be used when displaying UI elements such as labels and buttons. <br>By default, when you create a thread, this thread property is set to a CultureInfo  <br>object, which identifies the language of the Windows version the application is running  <br>on using the Win32 GetUserDefaultUILanguage function. If you're running a <br>Multilingual User Interface (MUI) version of Windows, you can set this via the "Regional <br>and Language Options" Control Panel Settings dialog box. On a non-MUI version of <br>Windows, the language is determined by the localized version of the OS installed (or <br>the installed language pack) and the language is not changeable.<br>
<b>  </b>CurrentCulture<b>  </b>This property is used for everything that CurrentUICulture isn't <br>
used for, including number and date formatting, string casing, and string comparing.  <br>When formatting, both the language and country parts of the CultureInfo <br>object are used. By default, when you create a thread, this thread property is <br>set to a CultureInfo object, whose value is determined by calling the Win32 <br>GetUserDefaultLCID method, whose value is set in the "Regional and Language" <br>Control Panel applet. <br>
<hr>
<A name=355></a><IMG src="CLRviaCsharp-355_1.jpg"><br>
<b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>337</b><br>
On many computers, a thread's CurrentUICulture and CurrentCulture properties will <br>be set to the same CultureInfo object, which means that they both use the same language/<br>country information. However, they can be set differently. For example: an application running <br>in the United States could use Spanish for all of its menu items and other GUI elements while <br>properly displaying all of the currency and date formatting for the United States. To do this, <br>the thread's CurrentUICulture property should be set to a CultureInfo object initialized <br>with a language of "es" (for Spanish), while the thread's CurrentCulture property should be <br>set to a CultureInfo object initialized with a language/country pair of "en-US."<br>
Internally, a CultureInfo object has a field that refers to a System.Globalization.<br>CompareInfo object, which encapsulates the culture's character-sorting table information as <br>defined by the Unicode standard. The following code demonstrates the difference between <br>performing an ordinal comparison and a culturally aware string comparison:<br>
using System;  <br>using System.Globalization;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      String s1 = &quot;Strasse&quot;;  <br>      String s2 = &quot;Straße&quot;;  <br>      Boolean eq;  <br> <br>      // CompareOrdinal returns nonzero.  <br>      eq = String.Compare(s1, s2, StringComparison.Ordinal) == 0;  <br>      Console.WriteLine(&quot;Ordinal  comparison: '{0}' {2} '{1}'&quot;, s1, s2,  <br>         eq ? &quot;==&quot; : &quot;!=&quot;);  <br> <br>      // Compare Strings appropriately for people   <br>      // who speak German (de) in Germany (DE)  <br>      CultureInfo ci = new CultureInfo(&quot;de-DE&quot;);  <br> <br>      // Compare returns zero.  <br>      eq = String.Compare(s1, s2, true, ci) == 0;  <br>      Console.WriteLine(&quot;Cultural comparison: '{0}' {2} '{1}'&quot;, s1, s2,  <br>         eq ? &quot;==&quot; : &quot;!=&quot;);  <br>   }  <br>}<br>
Building and running this code produces the following output:<br>
Ordinal  comparison: 'Strasse' != 'Straße'  <br>Cultural comparison: 'Strasse' == 'Straße'<br>
<b>Note  </b>When the Compare method is not performing an ordinal comparison, it performs <i>character <br>expansions</i>. A character expansion is when a character is expanded to multiple characters  <br>regardless of culture. In the above case, the German <i>Eszet</i> character `ß' is always expanded to  <br>`ss.' Similarly, the `Æ' ligature character is always expanded to `AE.' So in the code example, the <br>second call to Compare will always return 0 regardless of which culture I actually pass in to it.<br>
<hr>
<A name=356></a><b>338 </b><br>
<b>Part III  Essential Types</b><br>
In some rare circumstances, you may need to have even more control when comparing <br>strings for equality or for sorting. This could be necessary when comparing strings consisting <br>of Japanese characters. This additional control can be accessed via the CultureInfo object's <br>CompareInfo property. As mentioned earlier, a CompareInfo object encapsulates a culture's <br>character comparison tables, and there is just one CompareInfo object per culture.<br>
When you call String's Compare method, if the caller specifies a culture, the specified culture  <br>is used, or if no culture is specified, the value in the calling thread's CurrentCulture property <br>is used. Internally, the Compare method obtains the reference to the CompareInfo object for <br>the appropriate culture and calls the Compare method of the CompareInfo object, passing <br>along the appropriate options (such as case insensitivity). Natural y, you could call the Compare <br>method of a specific CompareInfo object yourself if you need the additional control.<br>
The Compare method of the CompareInfo type takes as a parameter a value from the <br>CompareOptions enumerated type (as shown earlier). You can OR these bit flags together to <br>gain significantly greater control when performing string comparisons. For a complete  <br>description of these symbols, consult the .NET Framework documentation.<br>
The following code demonstrates how important culture is to sorting strings and shows  <br>various ways of performing string comparisons:<br>
using System;  <br>using System.Text;  <br>using System.Windows.Forms;  <br>using System.Globalization;  <br>using System.Threading;  <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      String output = String.Empty;  <br>      String[] symbol = new String[] { &quot;&lt;&quot;, &quot;=&quot;, &quot;&gt;&quot; };  <br>      Int32 x;  <br>      CultureInfo ci;  <br> <br>      // The code below demonstrates how strings compare   <br>      // differently for different cultures.  <br>      String s1 = &quot;coté&quot;;  <br>      String s2 = &quot;côte&quot;;  <br> <br>      // Sorting strings for French in France.  <br>      ci = new CultureInfo(&quot;fr-FR&quot;);  <br>      x = Math.Sign(ci.CompareInfo.Compare(s1, s2));  <br>      output += String.Format(&quot;{0} Compare: {1} {3} {2}&quot;,  <br>         ci.Name, s1, s2, symbol[x + 1]);  <br>      output += Environment.NewLine;  <br> <br>      // Sorting strings for Japanese in Japan.  <br>      ci = new CultureInfo(&quot;ja-JP&quot;);  <br>      x = Math.Sign(ci.CompareInfo.Compare(s1, s2));  <br>      output += String.Format(&quot;{0} Compare: {1} {3} {2}&quot;,  <br>         ci.Name, s1, s2, symbol[x + 1]);  <br>      output += Environment.NewLine;  <br> <br>
<hr>
<A name=357></a><IMG src="CLRviaCsharp-357_1.jpg"><br>
<b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>339</b><br>
      // Sorting strings for the thread's culture  <br>      ci = Thread.CurrentThread.CurrentCulture;  <br>      x = Math.Sign(ci.CompareInfo.Compare(s1, s2));  <br>      output += String.Format(&quot;{0} Compare: {1} {3} {2}&quot;,  <br>         ci.Name, s1, s2, symbol[x + 1]);  <br>      output += Environment.NewLine + Environment.NewLine;  <br> <br>      // The code below demonstrates how to use CompareInfo.Compare's  <br>      // advanced options with 2 Japanese strings. One string represents  <br>      // the word &quot;shinkansen&quot; (the name for the Japanese high-speed   <br>      // train) in hiragana (one subtype of Japanese writing), and the   <br>      // other represents the same word in katakana (another subtype of   <br>      // Japanese writing).  <br>      s1 = &quot;<br>
&quot;;  // (&quot;\u3057\u3093\u304B\u3093\u305b\u3093&quot;) <br>
      s2 = &quot;<br>
&quot;;  // (&quot;\u30b7\u30f3\u30ab\u30f3\u30bb\u30f3&quot;) <br>
 <br>      // Here is the result of a default comparison  <br>      ci = new CultureInfo(&quot;ja-JP&quot;);  <br>      x = Math.Sign(String.Compare(s1, s2, true, ci));  <br>      output += String.Format(&quot;Simple {0} Compare: {1} {3} {2}&quot;,  <br>         ci.Name, s1, s2, symbol[x + 1]);  <br>      output += Environment.NewLine;  <br> <br>      // Here is the result of a comparison that ignores   <br>      // kana type (a type of Japanese writing)  <br>      CompareInfo compareInfo = CompareInfo.GetCompareInfo(&quot;ja-JP&quot;);  <br>      x = Math.Sign(compareInfo.Compare(s1, s2, CompareOptions.IgnoreKanaType));  <br>      output += String.Format(&quot;Advanced {0} Compare: {1} {3} {2}&quot;,  <br>         ci.Name, s1, s2, symbol[x + 1]);  <br> <br>      MessageBox.Show(output, &quot;Comparing Strings For Sorting&quot;);  <br>   }  <br>}<br>
<b>Note  </b>This source code file can't be saved in ANSI or the Japanese characters will be lost. To save <br>this file in Microsoft Visual Studio, go to the Save File As dialog box, click the down arrow that is <br>part of the Save button and select Save With Encoding. I selected "Unicode (UTF-8 with signature) <br>­ Codepage 65001". Microsoft's C# compiler can successfully parse source code files using this <br>code page.<br>
Building and running this code produces the output shown in Figure 14-1.<br>
<b>FIGURE 14-1  </b>String sorting results<br>
<hr>
<A name=358></a><b>340 </b><br>
<b>Part III  Essential Types</b><br>
In addition to Compare, the CompareInfo class offers the IndexOf, LastIndexOf, IsPrefix, <br>and IsSuffix methods. Because all of these methods offer overloads that take a <br>CompareOptions enumeration value as a parameter, they give you more control than the <br>Compare, IndexOf, LastIndexOf, StartsWith, and EndsWith methods defined by the <br>String class. Also, you should be aware that the FCL includes a System.StringComparer <br>class that you can also use for performing string comparisons. This class is useful when you <br>want to perform the same kind of comparison repeatedly for many different strings.<br>
<b>String Interning</b><br>
As I said in the preceding section, checking strings for equality is a common operation for <br>many applications--this task can hurt performance significantly. When performing an  <br>ordinal equality check, the CLR quickly tests to see if both strings have the same number of <br>characters. If they don't, the strings are definitely not equal; if they do, the strings might be <br>equal, and the CLR must then compare each individual character to determine for sure. When <br>performing a culturally aware comparison, the CLR must always compare all of the individual <br>characters because strings of different lengths might be considered equal.<br>
In addition, if you have several instances of the same string duplicated in memory, you're <br>wasting memory because strings are immutable. You'll use memory much more efficiently <br>if there is just one instance of the string in memory and all variables needing to refer to the <br>string can just point to the single string object.<br>
If your application frequently compares strings for equality using case-sensitive, ordinal com-<br>parisons, or if you expect to have many string objects with the same value, you can enhance <br>performance substantially if you take advantage of the <i>string interning</i> mechanism in the <br>CLR. When the CLR initializes, it creates an internal hash table in which the keys are strings <br>and the values are references to String objects in the managed heap. Initially, the table is <br>empty (of course). The String class offers two methods that allow you to access this internal <br>hash table:<br>
public static String Intern(String str);  <br>public static String IsInterned(String str);<br>
The first method, Intern, takes a String, obtains a hash code for it, and checks the internal <br>hash table for a match. If an identical string already exists, a reference to the already existing <br>String object is returned. If an identical string doesn't exist, a copy of the string is made, the <br>copy is added to the internal hash table, and a reference to this copy is returned. If the ap-<br>plication no longer holds a reference to the original String object, the garbage collector is <br>able to free the memory of that string. Note that the garbage collector can't free the strings <br>that the internal hash table refers to because the hash table holds the reference to those <br>String objects. String objects referred to by the internal hash table can't be freed until the <br>AppDomain is unloaded or the process terminates.<br>
<hr>
<A name=359></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>341</b><br>
As does the Intern method, the IsInterned method takes a String and looks it up in <br>the internal hash table. If a matching string is in the hash table, IsInterned returns a ref-<br>erence to the interned string object. If a matching string isn't in the hash table, however, <br>IsInterned returns null; it doesn't add the string to the hash table.<br>
By default, when an assembly is loaded, the CLR interns all of the literal strings  <br>described in the assembly's metadata. Microsoft learned that this hurts performance  <br>significantly due to the additional hash table lookups, so it is now possible to turn  <br>this "feature" off. If an assembly is marked with a  <br>System.Runtime.CompilerServices.CompilationRelaxationsAttribute specifying the <br>System.Runtime.CompilerServices.CompilationRelaxations.NoStringInterning <br>flag value, the CLR <i>may</i>, according to the ECMA specification, choose not to intern all of the <br>strings defined in that assembly's metadata. Note that, in an attempt to improve your  <br>application's performance, the C# compiler always specifies this attribute/flag whenever  <br>you compile an assembly.<br>
Even if an assembly has this attribute/flag specified, the CLR may choose to intern the strings, <br>but you should not count on this. In fact, you really should never write code that relies on <br>strings being interned unless you have written code that explicitly calls the String's Intern <br>method yourself. The following code demonstrates string interning:<br>
String s1 = &quot;Hello&quot;;  <br>String s2 = &quot;Hello&quot;;  <br>Console.WriteLine(Object.ReferenceEquals(s1, s2));   // Should be 'False'  <br> <br>s1 = String.Intern(s1);  <br>s2 = String.Intern(s2);  <br>Console.WriteLine(Object.ReferenceEquals(s1, s2));   // 'True'<br>
In the first call to the ReferenceEquals method, s1 refers to a &quot;Hello&quot; string object in the <br>heap, and s2 refers to a different &quot;Hello&quot; string object in the heap. Since the references are <br>different, False should be displayed. However, if you run this on version 4.0 of the CLR, you'll <br>see that True is displayed. The reason is because this version of the CLR chooses to ignore <br>the attribute/flag emitted by the C# compiler, and the CLR interns the literal &quot;Hello&quot; string <br>when the assembly is loaded into the AppDomain. This means that s1 and s2 refer to the <br>single &quot;Hello&quot; string in the heap. However, as mentioned previously, you should never write <br>code that relies on this behavior because a future version of the CLR might honor the  <br>attribute/flag and not intern the &quot;Hello&quot; string. In fact, version 4.0 of the CLR does honor <br>the attribute/flag when this assembly's code has been compiled using the NGen.exe utility.<br>
Before the second call to the ReferenceEquals method, the &quot;Hello&quot; string has been  <br>explicitly interned, and s1 now refers to an interned &quot;Hello&quot;. Then by calling Intern again, <br>s2 is set to refer to the same &quot;Hello&quot; string as s1. Now, when ReferenceEquals is called <br>the second time, we are guaranteed to get a result of True regardless of whether the assem-<br>bly was compiled with the attribute/flag.<br>
<hr>
<A name=360></a><b>342 </b><br>
<b>Part III  Essential Types</b><br>
So now, let's look at an example to see how you can use string interning to improve per-<br>formance and reduce memory usage. The NumTimesWordAppearsEquals method below <br>takes two arguments: a word and an array of strings in which each array element refers to a <br>single word. This method then determines how many times the specified word appears in the <br>wordlist and returns this count:<br>
private static Int32 NumTimesWordAppearsEquals(String word, String[] wordlist) {  <br>   Int32 count = 0;  <br>   for (Int32 wordnum = 0; wordnum &lt; wordlist.Length; wordnum++) {  <br>      if (word.Equals(wordlist[wordnum], StringComparison.Ordinal))  <br>         count++;  <br>   }  <br>   return count;  <br>}<br>
As you can see, this method calls String's Equals method, which internally compares the <br>strings' individual characters and checks to ensure that all characters match. This comparison <br>can be slow. In addition, the wordlist array might have multiple entries that refer to multiple <br>String objects containing the same set of characters. This means that multiple identical <br>strings might exist in the heap and are surviving ongoing garbage collections.<br>
Now, let's look at a version of this method that was written to take advantage of string <br>interning:<br>
private static Int32 NumTimesWordAppearsIntern(String word, String[] wordlist) {  <br>   // This method assumes that all entries in wordlist refer to interned strings.  <br>   word = String.Intern(word);  <br>   Int32 count = 0;  <br>   for (Int32 wordnum = 0; wordnum &lt; wordlist.Length; wordnum++) {  <br>      if (Object.ReferenceEquals(word, wordlist[wordnum]))  <br>         count++;  <br>   }  <br>   return count;  <br>}<br>
This method interns the word and assumes that the wordlist contains references to interned <br>strings. First, this version might be saving memory if a word appears in the wordlist multiple <br>times because, in this version, wordlist would now contain multiple references to the same <br>single String object in the heap. Second, this version will be faster because determining if <br>the specified word is in the array is simply a matter of comparing pointers.<br>
Although the NumTimesWordAppearsIntern method is faster than the <br>NumTimesWordAppearsEquals method, the overall performance of the application might be <br>slower when using the NumTimesWordAppearsIntern method because of the time it takes <br>to intern all of the strings when they were added to the wordlist array (code not shown). <br>The NumTimesWordAppearsIntern method will really show its performance and memory <br>improvement if the application needs to call the method multiple times using the same <br>wordlist. The point of this discussion is to make it clear that string interning is useful, but it <br>
<hr>
<A name=361></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>343</b><br>
should be used with care and caution. In fact, this is why the C# compiler indicates that it <br>doesn't want string interning to be enabled.<br>
<b>String Pooling</b><br>
When compiling source code, your compiler must process each literal string and emit the <br>string into the managed module's metadata. If the same literal string appears several times <br>in your source code, emitting all of these strings into the metadata will bloat the size of the <br>resulting file.<br>
To remove this bloat, many compilers (include the C# compiler) write the literal string into <br>the module's metadata only once. All code that references the string will be modified to refer <br>to the one string in the metadata. This ability of a compiler to merge multiple occurrences of <br>a single string into a single instance can reduce the size of a module substantially. This  <br>process is nothing new--C/C++ compilers have been doing it for years. (Microsoft's  <br>C/C++ compiler calls this <i>string pooling</i>.) Even so, string pooling is another way to improve <br>the performance of strings and just one more piece of knowledge that you should have in <br>your repertoire.<br>
<b>Examining a String's Characters and Text Elements</b><br>
Although comparing strings is useful for sorting them or for detecting equality, sometimes  <br>you need just to examine the characters within a string. The String type offers several  <br>properties and methods to help you do this, including Length, Chars (an indexer in C#), <br>GetEnumerator, ToCharArray, Contains, IndexOf, LastIndexOf, IndexOfAny, and <br>LastIndexOfAny.<br>
In reality, a System.Char represents a single 16-bit Unicode code value that doesn't  <br>necessarily equate to an abstract Unicode character. For example, some abstract Unicode <br>characters are a combination of two code values. When combined, the U+0625 (the Arabic <br>letter <i>Alef</i> with <i>Hamza</i> below) and U+0650 (the Arabic <i>Kasra</i>) characters form a single  <br>abstract character or <i>text element</i>.<br>
In addition, some Unicode text elements require more than a 16-bit value to represent them. <br>These text elements are represented using two 16-bit code values. The first code value is <br>called the high surrogate, and the second code value is called the low surrogate. High surro-<br>gates have a value between U+D800 and U+DBFF, and low surrogates have a value between <br>U+DC00 and U+DFFF. The use of surrogates allows Unicode to express more than a million <br>different characters.<br>
Surrogates are rarely used in the United States and Europe but are more commonly  <br>used in East Asia. To properly work with text elements, you should use the  <br>System.Globalization.StringInfo type. The easiest way to use this type is to construct <br>
<hr>
<A name=362></a><b>344 </b><br>
<b>Part III  Essential Types</b><br>
an instance of it, passing its constructor a string. Then you can see how many text elements <br>are in the string by querying the StringInfo's LengthInTextElements property. You can <br>then call StringInfo's SubstringByTextElements method to extract the text element or <br>the number of consecutive text elements that you desire.<br>
In addition, the StringInfo class offers a static GetTextElementEnumerator method, which <br>acquires a System.Globalization.TextElementEnumerator object that allows you to  <br>enumerate through all of the abstract Unicode characters contained in the string. Finally, you <br>could call StringInfo's static ParseCombiningCharacters method to obtain an array of <br>Int32<b> </b>values. The length of the array indicates how many text elements are contained in the <br>string. Each element of the array identifies an index into the string where the first code value <br>for a new text element can be found.<br>
The following code demonstrates the various ways of using the StringInfo class to manipu-<br>late a string's text elements:<br>
using System;  <br>using System.Text;  <br>using System.Globalization;  <br>using System.Windows.Forms;  <br> <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      // The string below contains combining characters  <br>      String s = &quot;a\u0304\u0308bc\u0327&quot;;  <br>      SubstringByTextElements(s);  <br>      EnumTextElements(s);  <br>      EnumTextElementIndexes(s);  <br>   }  <br> <br>   private static void SubstringByTextElements(String s) {  <br>      String output = String.Empty;  <br> <br>      StringInfo si = new StringInfo(s);  <br>      for (Int32 element = 0; element &lt; si.LengthInTextElements; element++) {  <br>         output += String.Format(  <br>            &quot;Text element {0} is '{1}'{2}&quot;,  <br>            element, si.SubstringByTextElements(element, 1),  <br>            Environment.NewLine);  <br>      }  <br>      MessageBox.Show(output, &quot;Result of SubstringByTextElements&quot;);  <br>   }  <br> <br>   private static void EnumTextElements(String s) {  <br>      String output = String.Empty;  <br> <br>      TextElementEnumerator charEnum =   <br>         StringInfo.GetTextElementEnumerator(s);  <br>      while (charEnum.MoveNext()) {  <br>         output += String.Format(  <br>            &quot;Character at index {0} is '{1}'{2}&quot;,  <br>
<hr>
<A name=363></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>345</b><br>
            charEnum.ElementIndex, charEnum.GetTextElement(),  <br>            Environment.NewLine);  <br>      }  <br>      MessageBox.Show(output, &quot;Result of GetTextElementEnumerator&quot;);  <br>   }  <br> <br>   private static void EnumTextElementIndexes(String s) {  <br>      String output = String.Empty;  <br> <br>      Int32[] textElemIndex = StringInfo.ParseCombiningCharacters(s);  <br>      for (Int32 i = 0; i &lt; textElemIndex.Length; i++) {  <br>         output += String.Format(  <br>            &quot;Character {0} starts at index {1}{2}&quot;,   <br>            i, textElemIndex[i], Environment.NewLine);  <br>      }  <br>      MessageBox.Show(output, &quot;Result of ParseCombiningCharacters&quot;);  <br>   }  <br>}<br>
Building and running this code produces the message boxes shown in Figures 14-2, 14-3, and <br>14-4.<br>
<b>FIGURE 14-2  </b>Result of SubstringByTextElements<br>
<b>FIGURE 14-3  </b>Result of GetTextElementEnumerator<br>
<b>FIGURE 14-4  </b>Result of ParseCombiningCharacters<br>
<hr>
<A name=364></a><b>346 </b><br>
<b>Part III  Essential Types</b><br>
<b>Other String Operations</b><br>
The String type also offers methods that allow you to copy a string or parts of it. Table 14-1 <br>summarizes these methods.<br>
<b>TABLE 14-1  Methods for Copying Strings</b><br>
<b>Member</b><br>
<b>Method Type</b><br>
<b>Description</b><br>
Clone<br>
Instance<br>
Returns a reference to the same object (this). This is OK because <br>String objects are immutable. This method implements String's <br>ICloneable interface.<br>
Copy<br>
Static<br>
Returns a new duplicate string of the specified string. This method <br>is rarely used and exists to help applications that treat strings as  <br>tokens. Normally, strings with the same set of characters are  <br>interned to a single string. This method creates a new string object <br>so that the references (pointers) are different even though the <br>strings contain the same characters.<br>
CopyTo<br>
Instance<br>
Copies a portion of the string's characters to an array of characters.<br>
Substring<br>
Instance<br>
Returns a new string that represents a portion of the original <br>string.<br>
ToString<br>
Instance<br>
Returns a reference to the same object (this).<br>
In addition to these methods, String offers many static and instance methods that manipu-<br>late a string, such as Insert, Remove, PadLeft, Replace, Split, Join, ToLower, ToUpper, <br>Trim, Concat, Format, and so on. Again, the important thing to remember about all of these <br>methods is that they return new string objects; because strings are immutable, once they're <br>created, they can't be modified (using safe code).<br>
<b>Constructing a String Efficiently</b><br>
Because the String type represents an immutable string, the FCL provides another type, <br>System.Text.StringBuilder, which allows you to perform dynamic operations efficiently <br>with strings and characters to create a String. Think of StringBuilder as a fancy constructor <br>to create a String that can be used with the rest of the framework. In general, you should <br>design methods that take String parameters, not StringBuilder parameters.<br>
Logically, a StringBuilder object contains a field that refers to an array of Char structures. <br>StringBuilder's members allow you to manipulate this character array, effectively shrinking <br>the string or changing the characters in the string. If you grow the string past the allocated <br>array of characters, the StringBuilder automatically allocates a new, larger array, copies the <br>characters, and starts using the new array. The previous array is garbage collected.<br>
When finished using the StringBuilder object to construct your string, "convert" the <br>StringBuilder's character array into a String simply by calling the StringBuilder's <br>
<hr>
<A name=365></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>347</b><br>
ToString method. This creates a new String object in the heap that contains the string that <br>was in the StringBuilder at the time you called ToString. At this point, you can continue <br>to manipulate the string inside the StringBuilder, and later you can call ToString again to <br>convert it into another String object.<br>
<b>Constructing a </b>StringBuilder<b> Object<br></b>Unlike with the String class, the CLR has no special information about the StringBuilder <br>class. In addition, most languages (including C#) don't consider the StringBuilder class <br>to be a primitive type. You construct a StringBuilder object as you would any other non-<br>primitive type:<br>
StringBuilder sb = new StringBuilder();<br>
The StringBuilder type offers many constructors. The job of each constructor is to allocate <br>and initialize the state maintained by each StringBuilder object:<br>
<b>  Maximum capacity  </b>An Int32 value that specifies the maximum number of characters <br>
that can be placed in the string. The default is Int32.MaxValue (approximately 2 bil ion). <br>It's unusual to change this value. However, you might specify a smaller maximum  <br>capacity to ensure that you never create a string over a certain length. Once  <br>constructed, a StringBuilder's maximum capacity value can't be changed.<br>
<b>  Capacity  </b>An Int32 value indicating the size of the character array being maintained <br>
by the StringBuilder. The default is 16. If you have some idea of how many charac-<br>ters you'll place in the StringBuilder, you should use this number to set the capacity <br>when constructing the StringBuilder object. <br>
When appending characters to the character array, the StringBuilder detects if the <br>array is trying to grow beyond the array's capacity. If it is, the StringBuilder automati-<br>cally doubles the capacity field, allocates a new array (the size of the new capacity), and <br>copies the characters from the original array into the new array. The original array will <br>be garbage collected in the future. Dynamical y growing the array hurts performance; <br>avoid this by setting a good initial capacity.<br>
<b>  Character array  </b>An array of Char structures that maintains the set of characters in the <br>
"string." The number of characters is always less than or equal to the capacity and maxi-<br>mum capacity values. You can use the StringBuilder's Length property to obtain the <br>number of characters used in the array. The Length is always less than or equal to the <br>StringBuilder's capacity value. When constructing a StringBuilder, you can pass <br>a String to initialize the character array. If you don't specify a string, the array initially <br>contains no characters--that is, the Length property returns 0.<br>
<hr>
<A name=366></a><b>348 </b><br>
<b>Part III  Essential Types</b><br>
StringBuilder <b>Members</b><br>
Unlike a String, a StringBuilder represents a mutable string. This means that most of <br>StringBuilder's members change the contents in the array of characters and don't cause <br>new objects to be allocated on the managed heap. A StringBuilder allocates a new object <br>on only two occasions:<br>
  You dynamically build a string whose length is longer than the capacity you've set.<br>
  You call StringBuilder's ToString method.<br>
Table 14-2 summarizes StringBuilder's members.<br>
<b>TABLE 14-2  </b>StringBuilder<b> Members</b><br>
<b>Member</b><br>
<b>Member Type</b><br>
<b>Description</b><br>
MaxCapacity<br>
Read-only property<br>
Returns the largest number of characters that can be <br>placed in the string.<br>
Capacity<br>
Read/write property<br>
Gets or sets the size of the character array. Trying <br>to set the capacity smaller than the string's <br>length or bigger than MaxCapacity throws an <br>ArgumentOutOfRangeException.<br>
EnsureCapacity<br>
Method<br>
Guarantees that the character array is at least the <br>size specified. If the value passed is larger than the <br>StringBuilder's current capacity, the current capacity <br>increases. If the current capacity is already larger than <br>the value passed to this property, no change occurs.<br>
Length<br>
Read/write property<br>
Gets or sets the number of characters in the "string." <br>This will likely be smaller than the character array's <br>current capacity. Setting this property to 0 resets the <br>StringBuilder's contents to an empty string.<br>
ToString<br>
Method<br>
The parameterless version of this method returns a <br>String representing the StringBuilder's character <br>array. <br>
Chars<br>
Read/write indexer <br>
Gets or sets the character at the specified index into <br>
property<br>
the character array. In C#, this is an indexer (parame-<br>terful property) that you access using array syntax ([]).<br>
Clear<br>
Method<br>
Clears the contents of the StringBuilder object, the <br>same as setting its Length property to 0.<br>
Append<br>
Method<br>
Appends a single object to the end of the character <br>array, growing the array if necessary. The object is  <br>converted to a string by using the general format and <br>the culture associated with the calling thread.<br>
Insert<br>
Method<br>
Inserts a single object into the character array, growing  <br>the array if necessary. The object is converted to a <br>string by using the general format and the culture  <br>associated with the calling thread.<br>
<hr>
<A name=367></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>349</b><br>
<b>Member</b><br>
<b>Member Type</b><br>
<b>Description</b><br>
AppendFormat<br>
Method<br>
Appends the specified objects to the end of the  <br>character array, growing the array if necessary. The  <br>objects are converted to strings by using the format-<br>ting and culture information provided by the caller. <br>AppendFormat is one of the most common methods <br>used with StringBuilder objects.<br>
AppendLine<br>
Method<br>
Appends a blank line or a string with a blank line to the <br>end of the character array, increasing the capacity of <br>the array if necessary.<br>
Replace<br>
Method<br>
Replaces one character with another or one string with <br>another from within the character array.<br>
Remove<br>
Method<br>
Removes a range of characters from the character array.<br>
Equals<br>
Method<br>
Returns true only if both StringBuilder objects <br>have the same maximum capacity, capacity, and  <br>characters in the array.<br>
CopyTo<br>
Method<br>
Copies a subset of the StringBuilder's characters to <br>a Char array.<br>
One important thing to note about StringBuilder's methods is that most of them return a <br>reference to the same StringBuilder object. This allows a convenient syntax to chain several <br>operations together:<br>
StringBuilder sb = new StringBuilder();  <br>String s = sb.AppendFormat(&quot;{0} {1}&quot;, &quot;Jeffrey&quot;, &quot;Richter&quot;).  <br>   Replace(' ', '-').Remove(4, 3).ToString();  <br>Console.WriteLine(s);  // &quot;Jeff-Richter&quot;<br>
You'll notice that the String and StringBuilder classes don't have full method parity;  <br>that is, String has ToLower, ToUpper, EndsWith, PadLeft, PadRight, Trim, and so on. <br>The StringBuilder class doesn't offer any of these methods. On the other hand, the <br>StringBuilder class offers a richer Replace method that allows you to replace characters <br>or strings in a portion of the string (not the whole string). It's unfortunate that there isn't <br>complete parity between these two classes because now you must convert between String <br>and StringBuilder to accomplish certain tasks. For example, to build up a string, convert all <br>characters to uppercase, and then insert a string requires code like this:<br>
// Construct a StringBuilder to perform string manipulations.  <br>StringBuilder sb = new StringBuilder();  <br> <br>// Perform some string manipulations by using the StringBuilder.  <br>sb.AppendFormat(&quot;{0} {1}&quot;, &quot;Jeffrey&quot;, &quot;Richter&quot;).Replace(&quot; &quot;, &quot;-&quot;);  <br> <br>// Convert the StringBuilder to a String in   <br>// order to uppercase all the characters.  <br>String s = sb.ToString().ToUpper();  <br> <br>
<hr>
<A name=368></a><b>350 </b><br>
<b>Part III  Essential Types</b><br>
// Clear the StringBuilder (allocates a new Char array).  <br>sb.Length = 0;  <br> <br>// Load the uppercase String into the StringBuilder,   <br>// and perform more manipulations.  <br>sb.Append(s).Insert(8, &quot;Marc-&quot;);  <br> <br>// Convert the StringBuilder back to a String.   <br>s = sb.ToString();  <br> <br>// Display the String to the user.  <br>Console.WriteLine(s);  // &quot;JEFFREY-Marc-RICHTER&quot;<br>
It's inconvenient and inefficient to have to write this code just because StringBuilder <br>doesn't offer all of the operations that String does. In the future, I hope that Microsoft will <br>add more string operation methods to StringBuilder to make it a more complete class.<br>
<b>Obtaining a String Representation of an Object: </b>ToString<br>
You frequently need to obtain a string representation of an object. Usually, this is necessary <br>when you want to display a numeric type (such as Byte, Int32, and Single) or a DateTime <br>object to the user. Because the .NET Framework is an object-oriented platform, every type is <br>responsible for providing code that converts an instance's value to a string equivalent. When <br>designing how types should accomplish this, the designers of the FCL devised a pattern that <br>would be used consistently throughout. In this section, I'll describe this pattern.<br>
You can obtain a string representation for any object by calling the ToString method. A <br>public, virtual, parameterless ToString method is defined by System.Object and is therefore <br>callable using an instance of any type. Semantically, ToString returns a string representing <br>the object's current value, and this string should be formatted for the calling thread's current <br>culture; that is, the string representation of a number should use the proper decimal separator, <br>digit-grouping symbol, and other elements associated with the culture assigned to the cal ing <br>thread.<br>
System.Object's implementation of ToString simply returns the full name of the object's <br>type. This value isn't particularly useful, but it is a reasonable default for the many types <br>that can't offer a sensible string. For example, what should a string representation of a <br>FileStream or a Hashtable object look like?<br>
All types that want to offer a reasonable way to obtain a string representing the current value <br>of the object should override the ToString method. All base types built into the FCL (Byte, <br>Int32, UInt64, Double, and so on) override their ToString method and return a culturally <br>aware string. In the Visual Studio debugger, a datatip is displayed when the mouse is placed <br>over a particular variable. The text shown in the datatip is obtained by calling the object's <br>ToString method. So, when you define a class, you should always override the ToString <br>method so that you get good debugging support.<br>
<hr>
<A name=369></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>351</b><br>
<b>Specific Formats and Cultures</b><br>
The parameterless ToString method has two problems. First, the caller has no control over <br>the formatting of the string. For example, an application might want to format a number <br>into a currency string, decimal string, percent string, or hexadecimal string. Second, the caller <br>can't easily choose to format a string by using a specific culture. This second problem is more <br>troublesome for server-side application code than for client-side code. On rare occasions, an <br>application needs to format a string by using a culture other than the culture associated with <br>the calling thread. To have more control over string formatting, you need a version of the <br>ToString method that allows you to specify precise formatting and culture information.<br>
Types that offer the caller a choice in formatting and culture implement the System.<br>IFormattable interface:<br>
public interface IFormattable {  <br>   String ToString(String format, IFormatProvider formatProvider);  <br>}<br>
In the FCL, all of the base types (Byte, SByte, Int16/UInt16, Int32/UInt32, Int64/UInt64, <br>Single, Double, Decimal, and DateTime) implement this interface. In addition, some other <br>types, such as Guid, implement it. Finally, every enumerated type definition will automatically <br>implement the IFormattable interface so that a meaningful string symbol from an instance <br>of the enumerated type can be obtained.<br>
IFormattable's ToString method takes two parameters. The first, format, is a string that <br>tells the method how the object should be formatted. ToString's second parameter,  <br>formatProvider, is an instance of a type that implements the System.IFormatProvider <br>interface. This type supplies specific culture information to the ToString method. I'll discuss <br>how shortly.<br>
The type implementing the IFormattable interface's ToString method determines which <br>format strings it's going to recognize. If you pass a format string that the type doesn't recog-<br>nize, the type is supposed to throw a System.FormatException.<br>
Many of the types Microsoft has defined in the FCL recognize several formats. For example, <br>the DateTime type supports "d" for short date, "D" for long date, "g" for general, "M" for <br>month/day, "s" for sortable, "T" for long time, "u" for universal time in ISO 8601 format, "U" <br>for universal time in full date format, "Y" for year/month, and others. All enumerated types <br>support "G" for general, "F" for flags, "D" decimal, and "X" for hexadecimal. I'll cover format-<br>ting enumerated types in more detail in Chapter 15, "Enumerated Types and Bit Flags."<br>
Also, all of the built-in numeric types support "C" for currency, "D" for decimal, "E" for  <br>exponential (scientific) notation, "F" for fixed-point, "G" for general, "N" for number, "P" for <br>percent, "R" for round-trip, and "X" for hexadecimal. In fact, the numeric types also support  <br>picture format strings just in case the simple format strings don't offer you exactly what <br>
<hr>
<A name=370></a><b>352 </b><br>
<b>Part III  Essential Types</b><br>
you're looking for. Picture format strings contain special characters that tell the type's <br>ToString method exactly how many digits to show, exactly where to place a decimal separa-<br>tor, exactly how many digits to place after the decimal separator, and so on. For complete <br>information about format strings, see "Formatting Types" in the .NET Framework SDK.<br>
For most types, calling ToString and passing null for the format string is identical to calling <br>ToString and passing "G" for the format string. In other words, objects format themselves <br>using the "General format" by default. When implementing a type, choose a format that you <br>think will be the most commonly used format; this format is the "General format." By the way, <br>the ToString method that takes no parameters assumes that the caller wants the "General <br>format."<br>
So now that format strings are out of the way, let's turn to culture information. By default, <br>strings are formatted using the culture information associated with the calling thread. The <br>parameterless ToString method certainly does this, and so does IFormattable's ToString <br>if you pass null for the formatProvider parameter.<br>
Culture-sensitive information applies when you're formatting numbers (including currency, <br>integers, floating point, percentages, dates, and times). The Guid type has a ToString  <br>method that returns only a string representing its value. There's no need to consider a culture <br>when generating the Guid's string because GUIDs are used for programmatic purposes only.<br>
When formatting a number, the ToString method sees what you've passed for the  <br>formatProvider parameter. If null is passed, ToString determines the culture  <br>associated with the calling thread by reading the  <br>System.Threading.Thread.CurrentThread.CurrentCulture property. This property  <br>returns an instance of the System.Globalization.CultureInfo type.<br>
Using this object, ToString reads its NumberFormat or DateTimeFormat property,  <br>depending on whether a number or date/time is being formatted. These properties return <br>an instance of System.Globalization.NumberFormatInfo or System.Globalization.<br>DateTimeFormatInfo, respectively. The NumberFormatInfo type defines a bunch of <br>properties, such as CurrencyDecimalSeparator, CurrencySymbol, NegativeSign, <br>NumberGroupSeparator, and PercentSymbol. Likewise, the DateTimeFormatInfo type <br>defines an assortment of properties, such as Calendar, DateSeparator, DayNames, <br>LongDatePattern, ShortTimePattern, and TimeSeparator. ToString reads these proper-<br>ties when constructing and formatting a string.<br>
When calling IFormattable's ToString method, instead of passing null, you can pass a  <br>reference to an object whose type implements the IFormatProvider interface:<br>
public interface IFormatProvider {  <br>   Object GetFormat(Type formatType);  <br>}<br>
<hr>
<A name=371></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>353</b><br>
Here's the basic idea behind the IFormatProvider interface: when a type implements this <br>interface, it is saying that an instance of the type is able to provide culture-specific format-<br>ting information and that the culture information associated with the calling thread should <br>be ignored.<br>
The System.Globalization.CultureInfo type is one of the very few types defined in the <br>FCL that implements the IFormatProvider interface. If you want to format a string for, say, <br>Vietnam, you'd construct a CultureInfo object and pass that object in as ToString's  <br>formatProvider parameter. The following code obtains a string representation of a Decimal <br>numeric value formatted as currency appropriate for Vietnam:<br>
Decimal price = 123.54M;  <br>String s = price.ToString(&quot;C&quot;, new CultureInfo(&quot;vi-VN&quot;));  <br>MessageBox.Show(s);<br>
If you build and run this code, the message box shown in Figure 14-5 appears.<br>
<b>FIGURE 14-5  </b>Numeric value formatted correctly to represent Vietnamese currency<br>
Internally, Decimal's ToString method sees that the formatProvider argument is not null <br>and calls the object's GetFormat method as follows:<br>
NumberFormatInfo nfi = (NumberFormatInfo)   <br>   formatProvider.GetFormat(typeof(NumberFormatInfo));<br>
This is how ToString requests the appropriate number-formatting information from the <br>(CultureInfo) object. Number types (such as Decimal) request only number-formatting  <br>information. But other types (such as DateTime) could call GetFormat like this:<br>
DateTimeFormatInfo dtfi = (DateTimeFormatInfo)   <br>   formatProvider.GetFormat(typeof(DateTimeFormatInfo));<br>
Actually, because GetFormat's parameter can identify any type, the method is flexible <br>enough to allow any type of format information to be requested. The types in the .NET <br>Framework call GetFormat, requesting only number or date/time information; in the future, <br>other kinds of formatting information could be requested.<br>
<hr>
<A name=372></a><b>354 </b><br>
<b>Part III  Essential Types</b><br>
By the way, if you want to obtain a string for an object that isn't formatted for any particular <br>culture, you should call System.Globalization.CultureInfo's static InvariantCulture <br>property and pass the object returned as ToString's formatProvider parameter:<br>
Decimal price = 123.54M;  <br>String s = price.ToString(&quot;C&quot;, CultureInfo.InvariantCulture);  <br>MessageBox.Show(s);<br>
If you build and run this code, the message box shown in Figure 14-6 appears. Notice the <br>first character in the resulting string:  . This is the international sign for currency (U+00A4).<br>
<b>FIGURE 14-6  </b>Numeric value formatted to represent a culture-neutral currency<br>
Normally, you wouldn't display a string formatted by using the invariant culture to a user. <br>Typically, you'd just save this string in a data file so that it could be parsed later.<br>
In the FCL, just three types implement the IFormatProvider interface. The first is <br>CultureInfo, which I've already explained. The other two are NumberFormatInfo and <br>DateTimeFormatInfo. When GetFormat is called on a NumberFormatInfo object, the  <br>method checks if the type being requested is a NumberFormatInfo. If it is, this is returned; <br>if it's not, null is returned. Similarly, calling GetFormat on a DateTimeFormatInfo object <br>returns this if a DateTimeFormatInfo is requested and null if it's not. These two types im-<br>plement this interface simply as a programming convenience. When trying to obtain a string <br>representation of an object, the caller commonly specifies a format and uses the  <br>culture associated with the calling thread. For this reason, you often call ToString, passing  <br>a string for the format parameter and null for the formatProvider parameter. To make <br>calling ToString easier for you, many types offer several overloads of the ToString method. <br>For example, the Decimal type offers four different ToString methods:<br>
// This version calls ToString(null, null).  <br>// Meaning: General numeric format, thread's culture information  <br>public override String ToString();  <br> <br>// This version is where the actual implementation of ToString goes.  <br>// This version implements IFormattable's ToString method.  <br>// Meaning: Caller-specified format and culture information  <br>public String ToString(String format, IFormatProvider formatProvider);  <br> <br>
<hr>
<A name=373></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>355</b><br>
// This version simply calls ToString(format, null).  <br>// Meaning: Caller-specified format, thread's culture information  <br>public String ToString(String format);  <br> <br>// This version simply calls ToString(null, formatProvider).  <br>// This version implements IConvertible's ToString method.  <br>// Meaning: General format, caller-specified culture information  <br>public String ToString(IFormatProvider formatProvider);<br>
<b>Formatting Multiple Objects into a Single String</b><br>
So far, I've explained how an individual type formats its own objects. At times, however, you <br>want to construct strings consisting of many formatted objects. For example, the following <br>string has a date, a person's name, and an age:<br>
String s = String.Format(&quot;On {0}, {1} is {2} years old.&quot;,   <br>   new DateTime(2010, 4, 22, 14, 35, 5), &quot;Aidan&quot;, 7);  <br>Console.WriteLine(s);<br>
If you build and run this code where "en-US" is the thread's current culture, you'll see the  <br>following line of output:<br>
On 4/22/2010 2:35:05 PM, Aidan is 7 years old.<br>
String's static Format method takes a format string that identifies replaceable parameters <br>using numbers in braces. The format string used in this example tells the Format method to <br>replace {0} with the first parameter after the format string (the date/time), replace {1} with <br>the second parameter after the format string ("Aidan"), and replace {2} with the third  <br>parameter after the format string (7).<br>
Internally, the Format method calls each object's ToString method to obtain a string repre-<br>sentation for the object. Then the returned strings are all appended and the complete, final <br>string is returned. This is all fine and good, but it means that all of the objects are formatted <br>by using their general format and the calling thread's culture information.<br>
You can have more control when formatting an object if you specify format information <br>within braces. For example, the following code is identical to the previous example except <br>that I've added formatting information to replaceable parameters 0 and 2:<br>
String s = String.Format(&quot;On {0:D}, {1} is {2:E} years old.&quot;,  <br>   new DateTime(2010, 4, 22, 14, 35, 5), &quot;Aidan&quot;, 7);  <br>Console.WriteLine(s);<br>
If you build and run this code where "en-US" is the thread's current culture, you'll see the  <br>following line of output:<br>
On Thursday, April 22, 2010, Aidan is 7.000000E+000 years old.<br>
<hr>
<A name=374></a><b>356 </b><br>
<b>Part III  Essential Types</b><br>
When the Format method parses the format string, it sees that replaceable parameter 0 <br>should have its IFormattable interface's ToString method called passing &quot;D&quot; and null <br>for its two parameters. Likewise, Format calls replaceable parameter 2's IFormattable <br>ToString method, passing &quot;E&quot; and null. If the type doesn't implement the IFormattable <br>interface, Format calls its parameterless ToString method inherited from Object (and pos-<br>sibly overridden), and the default format is appended into the resulting string.<br>
The String class offers several overloads of the static Format method. One version takes <br>an object that implements the IFormatProvider interface so that you can format all of the <br>replaceable parameters by using caller-specified culture information. Obviously, Format calls <br>each object's IFormattableToString method, passing it whatever IFormatProvider object <br>was passed to Format.<br>
If you're using StringBuilder instead of String to construct a string, you can call <br>StringBuilder's AppendFormat method. This method works exactly as String's Format <br>method except that it formats a string and appends to the StringBuilder's character array.  <br>As does String's Format, AppendFormat takes a format string, and there's a version that <br>takes an IFormatProvider.<br>
System.Console offers Write and WriteLine methods that also take format strings <br>and replaceable parameters. However, there are no overloads of Console's Write and <br>WriteLine methods that allow you to pass an IFormatProvider. If you want to format a <br>string for a specific culture, you have to call String's Format method, first passing the de-<br>sired IFormatProvider object and then passing the resulting string to Console's Write or <br>WriteLine method. This shouldn't be a big deal because, as I said earlier, it's rare for client-<br>side code to format a string by using a culture other than the one associated with the calling <br>thread.<br>
<b>Providing Your Own Custom Formatter</b><br>
By now it should be clear that the formatting capabilities in the .NET Framework were de-<br>signed to offer you a great deal of flexibility and control. However, we're not quite finished. <br>It's possible for you to define a method that StringBuilder's AppendFormat method will <br>call whenever any object is being formatted into a string. In other words, instead of calling <br>ToString for each object, AppendFormat can call a function you define, allowing you to  <br>format any or all of the objects in any way you want. What I'm about to describe also works <br>with String's Format method.<br>
Let me explain this mechanism by way of an example. Let's say that you're formatting HTML <br>text that a user will view in an Internet browser. You want all Int32 values to appear in bold. <br>To accomplish this, every time an Int32 value is formatted into a String, you want to  <br>surround the string with HTML bold tags: &lt;B&gt; and &lt;/B&gt;. The following code demonstrates <br>how easy it is to do this:<br>
<hr>
<A name=375></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>357</b><br>
using System;  <br>using System.Text;  <br>using System.Threading;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      StringBuilder sb = new StringBuilder();  <br>      sb.AppendFormat(new BoldInt32s(), &quot;{0} {1} {2:M}&quot;, &quot;Jeff&quot;, 123, DateTime.Now);  <br>      Console.WriteLine(sb);  <br>   }  <br>}  <br> <br>internal sealed class BoldInt32s : IFormatProvider, ICustomFormatter {  <br>   public Object GetFormat(Type formatType) {  <br>      if (formatType == typeof(ICustomFormatter)) return this;  <br>      return Thread.CurrentThread.CurrentCulture.GetFormat(formatType);  <br>   }  <br> <br>   public String Format(String format, Object arg, IFormatProvider formatProvider) {  <br>      String s;  <br> <br>      IFormattable formattable = arg as IFormattable;  <br> <br>      if (formattable == null) s = arg.ToString();  <br>      else s = formattable.ToString(format, formatProvider);  <br> <br>      if (arg.GetType() == typeof(Int32))  <br>         return &quot;&lt;B&gt;&quot; + s + &quot;&lt;/B&gt;&quot;;  <br>      return s;  <br>   }  <br>}<br>
When you compile and run this code where "en-US" is the thread's current culture, it displays <br>the following output (your date may be different, of course):<br>
Jeff &lt;B&gt;123&lt;/B&gt; January 23<br>
In Main, I'm constructing an empty StringBuilder and then appending a formatted string <br>into it. When I call AppendFormat, the first parameter is an instance of the BoldInt32s class. <br>This class implements the IFormatProvider interface that I discussed earlier. In addition, this <br>class implements the ICustomFormatter interface:<br>
public interface ICustomFormatter {  <br>   String Format(String format, Object arg,   <br>      IFormatProvider formatProvider);  <br>}<br>
This interface's Format method is called whenever StringBuilder's AppendFormat needs to <br>obtain a string for an object. You can do some pretty clever things inside this method that <br>give you a great deal of control over string formatting. Let's look inside the AppendFormat <br>method to see exactly how it works. The following pseudocode shows how AppendFormat <br>works:<br>
<hr>
<A name=376></a><b>358 </b><br>
<b>Part III  Essential Types</b><br>
public StringBuilder AppendFormat(IFormatProvider formatProvider,   <br>   String format, params Object[] args) {  <br> <br>   // If an IFormatProvider was passed, find out  <br>   // whether it offers an ICustomFormatter object.  <br>   ICustomFormatter cf = null;  <br> <br>   if (formatProvider != null)  <br>      cf = (ICustomFormatter)   <br>         formatProvider.GetFormat(typeof(ICustomFormatter));  <br> <br>   // Keep appending literal characters (not shown in this pseudocode)  <br>   // and replaceable parameters to the StringBuilder's character array.  <br>   Boolean MoreReplaceableArgumentsToAppend = true;  <br>   while (MoreReplaceableArgumentsToAppend) {  <br>      // argFormat refers to the replaceable format string obtained  <br>      // from the format parameter  <br>      String argFormat = /* ... */;  <br> <br>      // argObj refers to the corresponding element   <br>      // from the args array parameter  <br>      Object argObj = /* ... */;  <br> <br>      // argStr will refer to the formatted string to be appended  <br>      // to the final, resulting string  <br>      String argStr = null;  <br> <br>      // If a custom formatter is available, let it format the argument.  <br>      if (cf != null)   <br>         argStr = cf.Format(argFormat, argObj, formatProvider);  <br> <br>      // If there is no custom formatter or if it didn't format  <br>      // the argument, try something else.  <br>      if (argStr == null) {  <br>         // Does the argument's type support rich formatting?  <br>         IFormattable formattable = argObj as IFormattable;  <br>         if (formattable != null) {  <br>            // Yes; pass the format string and provider to  <br>            // the type's IFormattable ToString method.  <br>            argStr = formattable.ToString(argFormat, formatProvider);  <br>         } else {  <br>            // No; get the default format by using  <br>            // the thread's culture information.  <br>            if (argObj != null) argStr = argObj.ToString();  <br>            else argStr = String.Empty;  <br>         }  <br>      }  <br>      // Append argStr's characters to the character array field member.  <br>      /* ... */  <br> <br>      // Check if any remaining parameters to format  <br>      MoreReplaceableArgumentsToAppend = /* ... */;  <br>   }  <br>   return this;  <br>}<br>
<hr>
<A name=377></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>359</b><br>
When Main calls AppendFormat, AppendFormat calls my format provider's GetFormat <br>method, passing it the ICustomFormatter type. The GetFormat method defined in my <br>BoldInt32s type sees that the ICustomFormatter is being requested and returns a reference <br>to itself because it implements this interface. If my GetFormat method is called and is passed <br>any other type, I call the GetFormat method of the CultureInfo object associated with the <br>calling thread.<br>
Whenever AppendFormat needs to format a replaceable parameter, it calls <br>ICustomFormatter's Format method. In my example, AppendFormat calls the Format  <br>method defined by my BoldInt32s type. In my Format method, I check whether the object  <br>being formatted supports rich formatting via the IFormattable interface. If the object <br>doesn't, I then call the simple, parameterless ToString method (inherited from Object) to <br>format the object. If the object does support IFormattable, I then call the rich ToString <br>method, passing it the format string and the format provider.<br>
Now that I have the formatted string, I check whether the corresponding object is an Int32 <br>type, and if it is, I wrap the formatted string in &lt;B&gt; and &lt;/B&gt; HTML tags and return the new <br>string. If the object is not an Int32, I simply return the formatted string without any further <br>processing.<br>
<b>Parsing a String to Obtain an Object: </b>Parse<br>
In the preceding section, I explained how to take an object and obtain a string representation <br>of that object. In this section, I'll talk about the opposite: how to take a string and obtain an <br>object representation of it. Obtaining an object from a string isn't a very common operation, <br>but it does occasionally come in handy. Microsoft felt it necessary to formalize a mechanism <br>by which strings can be parsed into objects.<br>
Any type that can parse a string offers a public, static method called Parse. This method <br>takes a String and returns an instance of the type; in a way, Parse acts as a factory. In the <br>FCL, a Parse method exists on all of the numeric types as well as for DateTime, TimeSpan, <br>and a few other types (such as the SQL data types).<br>
Let's look at how to parse a string into a number type. Almost all of the numeric types <br>(Byte, SByte, Int16/UInt16, Int32/UInt32, Int64/UInt64, Single, Double, Decimal, and <br>BigInteger) offer at least one Parse method. Here I'll show you just the Parse method  <br>defined by the Int32 type. (The Parse methods for the other numeric types work similarly to <br>Int32's Parse method.)<br>
public static Int32 Parse(String s, NumberStyles style,   <br>   IFormatProvider provider);<br>
Just from looking at the prototype, you should be able to guess exactly how this method <br>works. The String parameter, s, identifies a string representation of a number you want <br>
<hr>
<A name=378></a><b>360 </b><br>
<b>Part III  Essential Types</b><br>
parsed into an Int32 object. The System.Globalization.NumberStyles parameter, style, <br>is a set of bit flags that identify characters that Parse should expect to find in the string. And <br>the IFormatProvider parameter, provider, identifies an object that the Parse method can <br>use to obtain culture-specific information, as discussed earlier in this chapter.<br>
For example, the following code causes Parse to throw a System.FormatException because <br>the string being parsed contains a leading space:<br>
Int32 x = Int32.Parse(&quot; 123&quot;, NumberStyles.None, null);<br>
To allow Parse to skip over the leading space, change the style parameter as follows:<br>
Int32 x = Int32.Parse(&quot; 123&quot;, NumberStyles.AllowLeadingWhite, null);<br>
See the .NET Framework SDK documentation for a complete description of the bit symbols <br>and common combinations that the NumberStyles enumerated type defines.<br>
Here's a code fragment showing how to parse a hexadecimal number:<br>
Int32 x = Int32.Parse(&quot;1A&quot;, NumberStyles.HexNumber, null);  <br>Console.WriteLine(x);  // Displays &quot;26&quot;<br>
This Parse method accepts three parameters. For convenience, many types offer additional <br>overloads of Parse so you don't have to pass as many arguments. For example, Int32 offers <br>four overloads of the Parse method:<br>
// Passes NumberStyles.Integer for style   <br>// and thread's culture's provider information.  <br>public static Int32 Parse(String s);  <br> <br>// Passes thread's culture's provider information.  <br>public static Int32 Parse(String s, NumberStyles style);  <br> <br>// Passes NumberStyles.Integer for the style parameter.  <br>public static Int32 Parse(String s, IFormatProvider provider);  <br> <br>// This is the method I've been talking about in this section.  <br>public static Int32 Parse(String s, NumberStyles style,   <br>   IFormatProvider provider);<br>
The DateTime type also offers a Parse method:<br>
public static DateTime Parse(String s,   <br>   IFormatProvider provider, DateTimeStyles styles);<br>
This method works just as the Parse method defined on the number types except  <br>that DateTime's Parse method takes a set of bit flags defined by the  <br>System.Globalization.DateTimeStyles enumerated type instead of the NumberStyles <br>enumerated type. See the .NET Framework SDK documentation for a complete description  <br>of the bit symbols and common combinations the DateTimeStyles type defines.<br>
<hr>
<A name=379></a><IMG src="CLRviaCsharp-379_1.jpg"><br>
<b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>361</b><br>
For convenience, the DateTime type offers three overloads of the Parse method:<br>
// Passes thread's culture's provider information   <br>// and DateTimeStyles.None for the style  <br>public static DateTime Parse(String s);  <br> <br>// Passes DateTimeStyles.None for the style  <br>public static DateTime Parse(String s, IFormatProvider provider);  <br> <br>// This is the method I've been talking about in this section.  <br>public static DateTime Parse(String s,   <br>   IFormatProvider provider, DateTimeStyles styles);<br>
Parsing dates and times is complex. Many developers have found the Parse method of the <br>DateTime type too forgiving in that it sometimes parses strings that don't contain dates or <br>times. For this reason, the DateTime type also offers a ParseExact method that accepts a <br>picture format string that indicates exactly how the date/time string should be formatted <br>and how it should be parsed. For more information about picture format strings, see the <br>DateTimeFormatInfo class in the .NET Framework SDK.<br>
<b>Note  </b>Some developers have reported the following back to Microsoft: when their application <br>calls Parse frequently, and Parse throws exceptions repeatedly (due to invalid user input),  <br>performance of the application suffers. For these performance-sensitive uses of Parse, Microsoft <br>added TryParse methods to all of the numeric data types, DateTime, DateTimeOffset, <br>TimeSpan, and even IPAddress. This is what one of the two Int32's two TryParse method <br>overloads looks like:<br>
public static Boolean TryParse(String s, NumberStyles style,   <br>   IFormatProvider provider, out Int32 result);<br>
As you can see, this method returns true or false indicating whether the specified string can <br>be parsed into an Int32. If the method returns true, the variable passed by reference to the  <br>result parameter will contain the parsed numeric value. The TryXxx pattern is discussed in <br>Chapter 20, &quot;Exceptions and State Management.&quot;<br>
<b>Encodings: Converting Between Characters and Bytes</b><br>
In Win32, programmers all too frequently have to write code to convert Unicode characters <br>and strings to Multi-Byte Character Set (MBCS) characters and strings. I've certainly written <br>my share of this code, and it's very tedious to write and error-prone to use. In the CLR, all <br>characters are represented as 16-bit Unicode code values and all strings are composed of  <br>16-bit Unicode code values. This makes working with characters and strings easy at runtime.<br>
At times, however, you want to save strings to a file or transmit them over a network. If the <br>strings consist mostly of characters readable by English-speaking people, saving or transmit-<br>ting a set of 16-bit values isn't very efficient because half of the bytes written would contain <br>zeros. Instead, it would be more efficient to <i>encode </i>the 16-bit values into a compressed array <br>of bytes and then <i>decode </i>the array of bytes back into an array of 16-bit values.<br>
<hr>
<A name=380></a><b>362 </b><br>
<b>Part III  Essential Types</b><br>
Encodings also allow a managed application to interact with strings created by non-Unicode <br>systems. For example, if you want to produce a file readable by an application running on a <br>Japanese version of Microsoft Windows 95, you have to save the Unicode text by using the <br>Shift-JIS (code page 932) encoding. Likewise, you'd use Shift-JIS encoding to read a text file <br>produced on a Japanese Windows 95 system into the CLR.<br>
Encoding is typically done when you want to send a string to a file or network stream by  <br>using the System.IO.BinaryWriter or System.IO.StreamWriter type. Decoding is  <br>typically done when you want to read a string from a file or network stream by using the  <br>System.IO.BinaryReader or System.IO.StreamReader type. If you don't explicitly <br>select an encoding, all of these types default to using UTF-8. (UTF stands for Unicode <br>Transformation Format.) However, at times, you might want to explicitly encode or decode a <br>string. Even if you don't want to explicitly do this, this section will give you more insight into <br>the reading and writing of strings from and to streams.<br>
Fortunately, the FCL offers some types to make character encoding and decoding easy. The <br>two most frequently used encodings are UTF-16 and UTF-8.<br>
  UTF-16 encodes each 16-bit character as 2 bytes. It doesn't affect the characters at <br>
all, and no compression occurs--its performance is excellent. UTF-16 encoding is also <br>referred to as Unicode encoding. Also note that UTF-16 can be used to convert from <br>little-endian to big-endian and vice versa.<br>
  UTF-8 encodes some characters as 1 byte, some characters as 2 bytes, some characters <br>
as 3 bytes, and some characters as 4 bytes. Characters with a value below 0x0080 are <br>compressed to 1 byte, which works very well for characters used in the United States. <br>Characters between 0x0080 and 0x07FF are converted to 2 bytes, which works well  <br>for European and Middle Eastern languages. Characters of 0x0800 and above are  <br>converted to 3 bytes, which works well for East Asian languages. Finally, surrogate pairs <br>are written out as 4 bytes. UTF-8 is an extremely popular encoding, but it's less efficient <br>than UTF-16 if you encode many characters with values of 0x0800 or above.<br>
Although the UTF-16 and UTF-8 encodings are by far the most common, the FCL also sup-<br>ports some encodings that are used less frequently:<br>
  UTF-32 encodes all characters as 4 bytes. This encoding is useful when you want to <br>
write a simple algorithm to traverse characters and you don't want to have to deal with <br>characters taking a variable number of bytes. For example, with UTF-32, you do not <br>need to think about surrogates because every character is 4 bytes. Obviously, UTF-32 <br>is not an efficient encoding in terms of memory usage and is therefore rarely used for <br>saving or transmitting strings to a file or network. This encoding is typically used inside <br>the program itself. Also note that UTF-32 can be used to convert from little-endian to <br>big-endian and vice versa.<br>
<hr>
<A name=381></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>363</b><br>
  UTF-7 encoding is typically used with older systems that work with characters that can <br>
be expressed using 7-bit values. You should avoid this encoding because it usually ends <br>up expanding the data rather than compressing it. The Unicode Consortium has depre-<br>cated this encoding.<br>
  ASCII encodes the 16-bit characters into ASCII characters; that is, any 16-bit character <br>
with a value of less than 0x0080 is converted to a single byte. Any character with a val-<br>ue greater than 0x007F can't be converted, so that character's value is lost. For strings <br>consisting of characters in the ASCII range (0x00 to 0x7F), this encoding compresses the <br>data in half and is very fast (because the high byte is just cut off). This encoding isn't <br>appropriate if you have characters outside of the ASCII range because the character's <br>values will be lost.<br>
Finally, the FCL also allows you to encode 16-bit characters to an arbitrary code page. As with <br>the ASCII encoding, encoding to a code page is dangerous because any character whose <br>value can't be expressed in the specified code page is lost. You should always use UTF-16 or <br>UTF-8 encoding unless you must work with some legacy files or applications that already use <br>one of the other encodings.<br>
When you need to encode or decode a set of characters, you should obtain an instance of <br>a class derived from System.Text.Encoding. Encoding is an abstract base class that offers <br>several static readonly properties, each of which returns an instance of an Encoding-derived <br>class.<br>
Here's an example that encodes and decodes characters by using UTF-8:<br>
using System;  <br>using System.Text;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      // This is the string we're going to encode.  <br>      String s = &quot;Hi there.&quot;;  <br> <br>      // Obtain an Encoding-derived object that knows how   <br>      // to encode/decode using UTF8  <br>      Encoding encodingUTF8 = Encoding.UTF8;  <br> <br>      // Encode a string into an array of bytes.  <br>      Byte[] encodedBytes = encodingUTF8.GetBytes(s);  <br> <br>      // Show the encoded byte values.  <br>      Console.WriteLine(&quot;Encoded bytes: &quot; +  <br>         BitConverter.ToString(encodedBytes));  <br> <br>      // Decode the byte array back to a string.  <br>      String decodedString = encodingUTF8.GetString(encodedBytes);  <br> <br>      // Show the decoded string.  <br>      Console.WriteLine(&quot;Decoded string: &quot; + decodedString);  <br>   }  <br>}<br>
<hr>
<A name=382></a><b>364 </b><br>
<b>Part III  Essential Types</b><br>
This code yields the following output:<br>
Encoded bytes: 48-69-20-74-68-65-72-65-2E  <br>Decoded string: Hi there.<br>
In addition to the UTF8 static property, the Encoding class also offers the following static <br>properties: Unicode, BigEndianUnicode, UTF32, UTF7, ASCII, and Default. The Default <br>property returns an object that is able to encode/decode using the user's code page as <br>specified by the Language for Non-Unicode Programs option of the Regional And Language <br>dialog box in Control Panel. (See the GetACP Win32 function for more information.) However, <br>using the Default property is discouraged because your application's behavior would be <br>machine-setting dependent, so if you change the system's default code page or if your  <br>application runs on another machine, your application will behave differently.<br>
In addition to these properties, Encoding also offers a static GetEncoding method that allows <br>you to specify a code page (by integer or by string) and returns an object that can encode/<br>decode using the specified code page. You can call GetEncoding, passing &quot;Shift-JIS&quot; or <br>932, for example.<br>
When you first request an encoding object, the Encoding class's property or GetEncoding <br>method constructs a single object for the requested encoding and returns this object. If an <br>already-requested encoding object is requested in the future, the encoding class simply  <br>returns the object it previously constructed; it doesn't construct a new object for each  <br>request. This efficiency reduces the number of objects in the system and reduces pressure in <br>the garbage-collected heap.<br>
Instead of calling one of Encoding's static properties or its GetEncoding method, you could <br>also construct an instance of one of the following classes: System.Text.UnicodeEncoding, <br>System.Text.UTF8Encoding, System.Text.UTF32Encoding, System.Text.UTF7Encoding, <br>or System.Text.ASCIIEncoding. However, keep in mind that constructing any of these <br>classes creates new objects in the managed heap, which hurts performance.<br>
Four of these classes, UnicodeEncoding, UTF8Encoding, UTF32Encoding, and UTF7Encoding, <br>offer multiple constructors, providing you with more control over the  <br>encoding and preamble. (Preamble is sometimes referred to as a <i>byte order mark</i> or <i>BOM.</i>) <br>The first three aforementioned classes also offer constructors that let you tell the class to <br>throw exceptions when decoding an invalid byte sequence; you should use these construc-<br>tors when you want your application to be secure and resistant to invalid incoming data.<br>
You might want to explicitly construct instances of these encoding types when working  <br>with a BinaryWriter or a StreamWriter. The ASCIIEncoding class has only a single  <br>constructor and therefore doesn't offer any more control over the encoding. If you need an <br>ASCIIEncoding object, always obtain it by querying Encoding's ASCII property; this returns <br>a reference to a single ASCIIEncoding object. If you construct ASCIIEncoding objects your-<br>self, you are creating more objects on the heap, which hurts your application's performance.<br>
<hr>
<A name=383></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>365</b><br>
Once you have an Encoding-derived object, you can convert a string or an array of characters <br>to an array of bytes by calling the GetBytes method. (Several overloads of this method exist.) <br>To convert an array of bytes to an array of characters, call the GetChars method or the more <br>useful GetString method. (Several overloads exist for both of these methods.) The preceding <br>code demonstrated calls to the GetBytes and GetString methods.<br>
All Encoding-derived types offer a GetByteCount method that obtains the number of bytes <br>necessary to encode a set of characters without actually encoding. Although GetByteCount <br>isn't especially useful, you can use this method to allocate an array of bytes. There's also a <br>GetCharCount method that returns the number of characters that would be decoded with-<br>out actually decoding them. These methods are useful if you're trying to save memory and <br>reuse an array.<br>
The GetByteCount/GetCharCount methods aren't that fast because they must analyze the <br>array of characters/bytes in order to return an accurate result. If you prefer speed to an exact <br>result, you can call the GetMaxByteCount or GetMaxCharCount method instead. Both meth-<br>ods take an integer specifying the number of characters or number of bytes and return a <br>worst-case value.<br>
Each Encoding-derived object offers a set of public read-only properties that you can query <br>to obtain detailed information about the encoding. See the .NET Framework SDK documen-<br>tation for a description of these properties.<br>
To illustrate most of the properties and their meanings, I wrote the following program that <br>displays the property values for several different encodings:<br>
using System;  <br>using System.Text;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      foreach (EncodingInfo ei in Encoding.GetEncodings()) {  <br>         Encoding e = ei.GetEncoding();  <br>         Console.WriteLine(&quot;{1}{0}&quot; +  <br>            &quot;\tCodePage={2}, WindowsCodePage={3}{0}&quot; +  <br>            &quot;\tWebName={4}, HeaderName={5}, BodyName={6}{0}&quot; +  <br>            &quot;\tIsBrowserDisplay={7}, IsBrowserSave={8}{0}&quot; +  <br>            &quot;\tIsMailNewsDisplay={9}, IsMailNewsSave={10}{0}&quot;,  <br> <br>            Environment.NewLine,  <br>            e.EncodingName, e.CodePage, e.WindowsCodePage,  <br>            e.WebName, e.HeaderName, e.BodyName,  <br>            e.IsBrowserDisplay, e.IsBrowserSave,  <br>            e.IsMailNewsDisplay, e.IsMailNewsSave);  <br>      }  <br>   }  <br>}<br>
<hr>
<A name=384></a><b>366 </b><br>
<b>Part III  Essential Types</b><br>
Running this program yields the following output (abridged to conserve paper):<br>
IBM EBCDIC (US-Canada)  <br>        CodePage=37, WindowsCodePage=1252  <br>        WebName=IBM037, HeaderName=IBM037, BodyName=IBM037  <br>        IsBrowserDisplay=False, IsBrowserSave=False  <br>        IsMailNewsDisplay=False, IsMailNewsSave=False  <br> <br>OEM United States  <br>        CodePage=437, WindowsCodePage=1252  <br>        WebName=IBM437, HeaderName=IBM437, BodyName=IBM437  <br>        IsBrowserDisplay=False, IsBrowserSave=False  <br>        IsMailNewsDisplay=False, IsMailNewsSave=False  <br> <br>IBM EBCDIC (International)  <br>        CodePage=500, WindowsCodePage=1252  <br>        WebName=IBM500, HeaderName=IBM500, BodyName=IBM500  <br>        IsBrowserDisplay=False, IsBrowserSave=False  <br>        IsMailNewsDisplay=False, IsMailNewsSave=False  <br> <br>Arabic (ASMO 708)  <br>        CodePage=708, WindowsCodePage=1256  <br>        WebName=ASMO-708, HeaderName=ASMO-708, BodyName=ASMO-708  <br>        IsBrowserDisplay=True, IsBrowserSave=True  <br>        IsMailNewsDisplay=False, IsMailNewsSave=False  <br> <br>Unicode  <br>        CodePage=1200, WindowsCodePage=1200  <br>        WebName=utf-16, HeaderName=utf-16, BodyName=utf-16  <br>        IsBrowserDisplay=False, IsBrowserSave=True  <br>        IsMailNewsDisplay=False, IsMailNewsSave=False  <br> <br>Unicode (Big-Endian)  <br>        CodePage=1201, WindowsCodePage=1200  <br>        WebName=unicodeFFFE, HeaderName=unicodeFFFE, BodyName=unicodeFFFE  <br>        IsBrowserDisplay=False, IsBrowserSave=False  <br>        IsMailNewsDisplay=False, IsMailNewsSave=False  <br> <br>Western European (DOS)  <br>        CodePage=850, WindowsCodePage=1252  <br>        WebName=ibm850, HeaderName=ibm850, BodyName=ibm850  <br>        IsBrowserDisplay=False, IsBrowserSave=False  <br>        IsMailNewsDisplay=False, IsMailNewsSave=False  <br> <br>Unicode (UTF-8)   <br>        CodePage=65001, WindowsCodePage=1200  <br>        WebName=utf-8, HeaderName=utf-8, BodyName=utf-8  <br>        IsBrowserDisplay=True, IsBrowserSave=True  <br>        IsMailNewsDisplay=True, IsMailNewsSave=True<br>
Table 14-3 covers the most commonly used methods offered by all Encoding-derived <br>classes.<br>
<hr>
<A name=385></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>367</b><br>
<b>TABLE 14-3  Methods of the </b>Encoding<b>-Derived Classes</b><br>
<b>Method</b><br>
<b>Description</b><br>
GetPreamble<br>
Returns an array of bytes indicating what should be written to a stream  <br>before writing any encoded bytes. Frequently, these bytes are referred to  <br>as BOM bytes. When you start reading from a stream, the BOM bytes  <br>automatically help detect the encoding that was used when the stream <br>was written so that the correct decoder can be used. For some Encoding-<br>derived classes, this method returns an array of 0 bytes--that is, no preamble <br>bytes. A UTF8Encoding object can be explicitly constructed so that this <br>method returns a 3-byte array of 0xEF, 0xBB, 0xBF. A UnicodeEncoding <br>object can be explicitly constructed so that this method returns a 2-byte  <br>array of 0xFE, 0xFF for big-endian encoding or a 2-byte array of 0xFF, 0xFE <br>for little-endian encoding. The default is little-endian.<br>
Convert<br>
Converts an array of bytes specified in a source encoding to an array of <br>bytes specified by a destination encoding. Internally, this static method calls <br>the source encoding object's GetChars method and passes the result to the <br>destination encoding object's GetBytes method. The resulting byte array is <br>returned to the caller.<br>
Equals<br>
Returns true if two Encoding-derived objects represent the same code <br>page and preamble setting.<br>
GetHashCode<br>
Returns the encoding object's code page.<br>
<b>Encoding and Decoding Streams of Characters and Bytes<br></b>Imagine that you're reading a UTF-16 encoded string via a System.Net.Sockets.<br>NetworkStream object. The bytes will very likely stream in as chunks of data. In other words, <br>you might first read 5 bytes from the stream, followed by 7 bytes. In UTF-16, each character  <br>consists of 2 bytes. So calling Encoding's GetString method passing the first array of 5 bytes <br>will return a string consisting of just two characters. If you later call GetString, passing in the <br>next 7 bytes that come in from the stream, GetString will return a string consisting of three <br>characters, and all of the code points will have the wrong values!<br>
This data corruption problem occurs because none of the Encoding-derived classes maintains <br>any state in between calls to their methods. If you'l  be encoding or decoding characters/bytes <br>in chunks, you must do some additional work to maintain state between calls, preventing any <br>loss of data.<br>
To decode chunks of bytes, you should obtain a reference to an Encoding-derived  <br>object (as described in the previous section) and call its GetDecoder method. This  <br>method returns a reference to a newly constructed object whose type is derived from the <br>System.Text.Decoder class. Like the Encoding class, the Decoder class is an abstract base <br>class. If you look in the .NET Framework SDK documentation, you won't find any classes  <br>that represent concrete implementations of the Decoder class. However, the FCL does  <br>define a bunch of Decoder-derived classes. These classes are all internal to the FCL, but  <br>
<hr>
<A name=386></a><b>368 </b><br>
<b>Part III  Essential Types</b><br>
the GetDecoder method can construct instances of these classes and return them to your <br>application code.<br>
All Decoder-derived classes offer two important methods: GetChars and GetCharCount. <br>Obviously, these methods are used for decoding an array of bytes and work similarly to <br>Encoding's GetChars and GetCharCount methods, discussed earlier. When you call one of <br>these methods, it decodes the byte array as much as possible. If the byte array doesn't  <br>contain enough bytes to complete a character, the leftover bytes are saved inside the  <br>decoder object. The next time you call one of these methods, the decoder object uses the <br>leftover bytes plus the new byte array passed to it--this ensures that the chunks of data are <br>decoded properly. Decoder objects are very useful when reading bytes from a stream.<br>
An Encoding-derived type can be used for stateless encoding and decoding. However, <br>a Decoder-derived type can be used only for decoding. If you want to encode strings in <br>chunks, call GetEncoder instead of calling the Encoding object's GetDecoder method. <br>GetEncoder returns a newly constructed object whose type is derived from the abstract base <br>class System.Text.Encoder. Again, the .NET Framework SDK documentation doesn't contain <br>any classes representing concrete implementations of the Encoder class. However, the FCL <br>does define some Encoder-derived classes. As with the Decoder-derived classes, these classes <br>are all internal to the FCL, but the GetEncoder method can construct instances of these <br>classes and return them to your application code.<br>
All Encoder-derived classes offer two important methods: GetBytes and GetByteCount. On <br>each call, the Encoder-derived object maintains any leftover state information so that you <br>can encode data in chunks.<br>
<b>Base-64 String Encoding and Decoding</b><br>
As of this writing, the UTF-16 and UTF-8 encodings are becoming quite popular. It is also quite <br>popular to encode a sequence of bytes to a base-64 string. The FCL does offer methods to <br>do base-64 encoding and decoding, and you might expect that this would be accomplished <br>via an Encoding-derived type. However, for some reason, base-64 encoding and decoding is <br>done using some static methods offered by the System.Convert type.<br>
To encode a base-64 string as an array of bytes, you call Convert's static FromBase64String <br>or FromBase64CharArray method. Likewise, to decode an array of bytes as a base-64 string, <br>you call Convert's static ToBase64String or ToBase64CharArray method. The following <br>code demonstrates how to use some of these methods:<br>
using System;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      // Get a set of 10 randomly generated bytes  <br>      Byte[] bytes = new Byte[10];  <br>
<hr>
<A name=387></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>369</b><br>
      new Random().NextBytes(bytes);  <br> <br>      // Display the bytes  <br>      Console.WriteLine(BitConverter.ToString(bytes));  <br> <br>      // Decode the bytes into a base-64 string and show the string  <br>      String s = Convert.ToBase64String(bytes);  <br>      Console.WriteLine(s);  <br> <br>      // Encode the base-64 string back to bytes and show the bytes  <br>      bytes = Convert.FromBase64String(s);  <br>      Console.WriteLine(BitConverter.ToString(bytes));  <br>   }  <br>}<br>
Compiling this code and running the executable file produces the following output (your <br>output might vary from mine because of the randomly generated bytes):<br>
3B-B9-27-40-59-35-86-54-5F-F1  <br>O7knQFk1hlRf8Q==  <br>3B-B9-27-40-59-35-86-54-5F-F1<br>
<b>Secure Strings</b><br>
Often, String objects are used to contain sensitive data such as a user's password or credit-<br>card information. Unfortunately, String objects contain an array of characters in memory, <br>and if some unsafe or unmanaged code is allowed to execute, the unsafe/unmanaged code <br>could snoop around the process's address space, locate the string containing the sensitive <br>information, and use this data in an unauthorized way. Even if the String object is used <br>for just a short time and then garbage collected, the CLR might not immediately reuse the <br>String object's memory (especially if the String object was in an older generation), leaving <br>the String's characters in the process's memory, where the information could be compro-<br>mised. In addition, since strings are immutable, as you manipulate them, the old copies linger <br>in memory and you end up with different versions of the string scattered all over memory.<br>
Some governmental departments have stringent security requirements that require very spe-<br>cific security guarantees. To meet these requirements, Microsoft added a more secure string <br>class to the FCL: System.Security.SecureString. When you construct a SecureString <br>object, it internally allocates a block of unmanaged memory that contains an array of charac-<br>ters. Unmanaged memory is used so that the garbage collector isn't aware of it.<br>
These string's characters are encrypted, protecting the sensitive information from any  <br>malicious unsafe/unmanaged code. You can append, insert, remove, or set a character in the <br>secure string by using any of these methods: AppendChar, InsertAt, RemoveAt, and SetAt. <br>Whenever you call any of these methods, internally, the method decrypts the characters, <br>performs the operation in place, and then re-encrypts the characters. This means that the <br>characters are in an unencrypted state for a very short period of time. This also means that <br>
<hr>
<A name=388></a><b>370 </b><br>
<b>Part III  Essential Types</b><br>
the performance of each operation is less than stellar, so you should perform as few of these <br>operations as possible.<br>
The SecureString class implements the IDisposable interface to provide an easy way to <br>deterministically destroy the string's secured contents. When your application no longer <br>needs the sensitive string information, you simply call SecureString's Dispose method. <br>Internally, Dispose zeroes out the contents of the memory buffer to make sure that the sen-<br>sitive information is not accessible to malicious code, and then the buffer is freed. Internally, a <br>SecureString object has a field to a SafeBuffer-derived object, which maintains the actual <br>string. Since the SafeBuffer class is ultimately derived from CriticalFinalizerObject, <br>discussed in Chapter 21, "Automatic Memory Management (Garbage Collection)," the string's <br>characters are guaranteed to be zeroed out and have its buffer freed when it is garbage <br>collected. Unlike a String object, when a SecureString object is collected, the encrypted <br>string's characters will no longer be in memory.<br>
Now that you know how to create and modify a SecureString object, let's talk about how <br>to use one. Unfortunately, the most recent FCL has limited support for the SecureString <br>class. In other words, there are only a few methods that accept a SecureString argument. In <br>version 4 of the .NET Framework, you can pass a SecureString as a password when<br>
  Working with a cryptographic service provider (CSP). See the  <br>
System.Security.Cryptography.CspParameters class.<br>
  Creating, importing, or exporting an X.509 certificate. See the  <br>
System.Security.Cryptography.X509Certificates.X509Certificate and <br>System.Security.Cryptography.X509Certificates.X509Certificate2 classes.<br>
  Starting a new process under a specific user account. See the  <br>
System.Diagnostics.Process and System.Diagnostics.ProcessStartInfo <br>classes.<br>
  Constructing an event log session. See the  <br>
System.Diagnostics.Eventing.Reader.EventLogSession class.<br>
  Using the System.Windows.Controls.PasswordBox control. See this class's <br>
SecurePassword property.<br>
Finally, you can create your own methods that can accept a SecureString object parameter. <br>Inside your method, you must have the SecureString object create an unmanaged memory <br>buffer that contains the decrypted characters before your method uses the buffer. To keep <br>the window of opportunity for malicious code to access the sensitive data as smal  as pos-<br>sible, your code should require access to the decrypted string for as short a period of time <br>as possible. When finished using the string, your code should zero the buffer and free it as <br>soon as possible. Also, never put the contents of a SecureString into a String: if you do, <br>the String lives unencrypted in the heap and will not have its characters zeroed out until the <br>memory is reused after a garbage collection. The SecureString class does not override the <br>
<hr>
<A name=389></a><b> </b><br>
<b>Chapter 14  Chars, Strings, and Working with Text </b><br>
<b>371</b><br>
ToString method specifically to avoid exposing the sensitive data (which converting it to a <br>String would do).<br>
Here is some sample code demonstrating how to initialize and use a SecureString (when <br>compiling this, you'll need to specify the /unsafe switch to the C# compiler):<br>
using System;  <br>using System.Security;  <br>using System.Runtime.InteropServices;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      using (SecureString ss = new SecureString()) {  <br>         Console.Write(&quot;Please enter password: &quot;);  <br>         while (true) {  <br>            ConsoleKeyInfo cki = Console.ReadKey(true);  <br>            if (cki.Key == ConsoleKey.Enter) break;  <br> <br>            // Append password characters into the SecureString  <br>            ss.AppendChar(cki.KeyChar);  <br>            Console.Write(&quot;*&quot;);  <br>         }  <br>         Console.WriteLine();  <br> <br>         // Password entered, display it for demonstration purposes  <br>         DisplaySecureString(ss);  <br>      }  <br>      // After 'using', the SecureString is Disposed; no sensitive data in memory  <br>   }  <br> <br>   // This method is unsafe because it accesses unmanaged memory  <br>   private unsafe static void DisplaySecureString(SecureString ss) {  <br>      Char* pc = null;  <br>      try {  <br>         // Decrypt the SecureString into an unmanaged memory buffer  <br>         pc = (Char*) Marshal.SecureStringToCoTaskMemUnicode(ss);  <br> <br>         // Access the unmanaged memory buffer that   <br>         // contains the decrypted SecureString  <br>         for (Int32 index = 0; pc[index] != 0; index++)  <br>            Console.Write(pc[index]);  <br>      }  <br>      finally {  <br>         // Make sure we zero and free the unmanaged memory buffer that contains  <br>         // the decrypted SecureString characters  <br>         if (pc != null)  <br>            Marshal.ZeroFreeCoTaskMemUnicode((IntPtr) pc);  <br>      }  <br>   }  <br>}<br>
The System.Runtime.InteropServices.Marshal class offers five methods that you can <br>call to decrypt a SecureString's characters into an unmanaged memory buffer. All of these <br>methods are static, all accept a SecureString argument, and all return an IntPtr. Each of <br>
<hr>
<A name=390></a><b>372 </b><br>
<b>Part III  Essential Types</b><br>
these methods has a corresponding method that you must call in order to zero the internal <br>buffer and free it. Table 14-4 shows the System.Runtime.InteropServices.Marshal class's <br>methods to decrypt a SecureString into a memory buffer and the corresponding method <br>to zero and free the buffer.<br>
<b>TABLE 14-4  Methods of the </b>Marshal<b> Class for Working with Secure Strings</b><br>
<b>Method to Decrypt </b>SecureString<b> to Buffer</b><br>
<b>Method to Zero and Free Buffer</b><br>
SecureStringToBSTR<br>
ZeroFreeBSTR<br>
SecureStringToCoTaskMemAnsi<br>
ZeroFreeCoTaskMemAnsi<br>
SecureStringToCoTaskMemUnicode<br>
ZeroFreeCoTaskMemUnicode<br>
SecureStringToGlobalAllocAnsi<br>
ZeroFreeGlobalAllocAnsi<br>
SecureStringToGlobalAllocUnicode<br>
ZeroFreeGlobalAllocUnicode<br>
<hr>
<A name=391></a>Chapter 15<br><b>Enumerated Types and Bit Flags</b><br>
<b>In this chapter:<br>Enumerated Types. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373<br>Bit Flags. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 379<br>Adding Methods to Enumerated Types. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383</b><br>
In this chapter, I'll discuss enumerated types and bit flags. Since Microsoft Windows and <br>many programming languages have used these constructs for so many years, I'm sure that <br>many of you are already familiar with how to use enumerated types and bit flags. However, <br>the common language runtime (CLR) and the Framework Class Library (FCL) work together to <br>make enumerated types and bit flags real object-oriented types that offer cool new features <br>that I suspect most developers aren't familiar with. It's amazing to me how these new features, <br>which are the focus of this chapter, make developing application code so much easier.<br>
<b>Enumerated Types</b><br>
An <i>enumerated type</i> is a type that defines a set of symbolic name and value pairs. For  <br>example, the Color type shown here defines a set of symbols, with each symbol identifying  <br>a single color:<br>
internal enum Color {  <br>   White,       // Assigned a value of 0  <br>   Red,         // Assigned a value of 1  <br>   Green,       // Assigned a value of 2  <br>   Blue,        // Assigned a value of 3  <br>   Orange       // Assigned a value of 4  <br>}<br>
Of course, programmers can always write a program using 0 to represent white, 1 to repre-<br>sent red, and so on. However, programmers shouldn't hard-code numbers into their code <br>and should use an enumerated type instead, for at least two reasons:<br>
  Enumerated types make the program much easier to write, read, and maintain. With <br>
enumerated types, the symbolic name is used throughout the code, and the program-<br>mer doesn't have to mentally map the meaning of each hard-coded value (for example, <br>white is 0 or vice versa). Also, should a symbol's numeric value change, the code can <br>simply be recompiled without requiring any changes to the source code. In addition, <br>documentation tools and other utilities, such as a debugger, can show meaningful sym-<br>bolic names to the programmer.<br>
<b> </b><br>
<b> </b><br>
<b>373</b><br>
<hr>
<A name=392></a><b>374 </b><br>
<b>Part III  Essential Types</b><br>
  Enumerated types are strongly typed. For example, the compiler will report an error if <br>
I attempt to pass Color.Orange as a value to a method requiring a Fruit enumerated <br>type as a parameter.<br>
In the Microsoft .NET Framework, enumerated types are more than just symbols that the <br>compiler cares about. Enumerated types are treated as first-class citizens in the type system, <br>which allows for very powerful operations that simply can't be done with enumerated types <br>in other environments (such as in unmanaged C++, for example).<br>
Every enumerated type is derived directly from System.Enum, which is derived from  <br>System.ValueType, which in turn is derived from System.Object. So enumerated types are <br>value types (described in Chapter 5, "Primitive, Reference, and Value Types") and can be  <br>represented in unboxed and boxed forms. However, unlike other value types, an enumerated  <br>type can't define any methods, properties, or events. However, you can use C#'s <i>extension  <br>methods</i> feature to simulate adding methods to an enumerated type. See the "Adding <br>Methods to Enumerated Types" section at the end of this chapter for an example of this.<br>
When an enumerated type is compiled, the C# compiler turns each symbol into a constant <br>field of the type. For example, the compiler treats the Color enumeration shown earlier <br>as if you had written code similar to the following:<br>
internal struct Color : System.Enum {  <br>   // Below are public constants defining Color's symbols and values  <br>   public const Color White  = (Color) 0;  <br>   public const Color Red    = (Color) 1;  <br>   public const Color Green  = (Color) 2;  <br>   public const Color Blue   = (Color) 3;  <br>   public const Color Orange = (Color) 4;  <br> <br>   // Below is a public instance field containing a Color variable's value  <br>   // You cannot write code that references this instance field directly  <br>   public Int32 value__;  <br>}<br>
The C# compiler won't actually compile this code because it forbids you from defining a type <br>derived from the special System.Enum type. However, this pseudo-type definition shows you <br>what's happening internally. Basically, an enumerated type is just a structure with a bunch <br>of constant fields defined in it and one instance field. The constant fields are emitted to the <br>assembly's metadata and can be accessed via reflection. This means that you can get all of <br>the symbols and their values associated with an enumerated type at runtime. It also means <br>that you can convert a string symbol into its equivalent numeric value. These operations are <br>made available to you by the System.Enum base type, which offers several static and instance <br>methods that can be performed on an instance of an enumerated type, saving you the trouble <br>of having to use reflection. I'll discuss some of these operations next.<br>
<hr>
<A name=393></a><IMG src="CLRviaCsharp-393_1.jpg"><br>
<b> </b><br>
<b>Chapter 15  Enumerated Types and Bit Flags </b><br>
<b>375</b><br>
<b>Important  </b>Symbols defined by an enumerated type are constant values. So when a compiler <br>sees code that references an enumerated type's symbol, the compiler substitutes the symbol's <br>numeric value at compile time, and this code no longer references the enumerated type that <br>defined the symbol. This means that the assembly that defines the enumerated type may not be <br>required at runtime; it was required only when compiling. If you have code that references the <br>enumerated type--rather than just having references to symbols defined by the type--the  <br>assembly containing the enumerated type's definition will be required at runtime. Some version-<br>ing issues arise because enumerated type symbols are constants instead of read-only values. I <br>explained these issues in the "Constants" section of Chapter 7, "Constants and Fields."<br>
For example, the System.Enum type has a static method called GetUnderlyingType, and the <br>System.Type type has an instance method called GetEnumUnderlyingType:<br>
public static Type GetUnderlyingType(Type enumType);       // Defined in System.Enum <br>public        Type GetEnumUnderlyingType();                // Defined in System.Type<br>
These methods return the core type used to hold an enumerated type's value. Every enumer-<br>ated type has an underlying type, which can be a byte, sbyte, short, ushort, int (the most <br>common type and what C# chooses by default), uint, long, or ulong. Of course, these C# <br>primitive types correspond to FCL types. However, to make the implementation of the com-<br>piler itself simpler, the C# compiler requires you to specify a primitive type name here; using <br>an FCL type name (such as Int32) generates the following message: &quot;error CS1008: Type <br>byte, sbyte, short, ushort, int, uint, long, or ulong expected.&quot; The following <br>code shows how to declare an enumerated type with an underlying type of byte  <br>(System.Byte):<br>
internal enum Color : byte {  <br>   White,  <br>   Red,  <br>   Green,  <br>   Blue,  <br>   Orange  <br>}<br>
With the Color enumerated type defined in this way, the following code shows what <br>GetUnderlyingType will return:<br>
// The following line displays &quot;System.Byte&quot;.  <br>Console.WriteLine(Enum.GetUnderlyingType(typeof(Color)));<br>
The C# compiler treats enumerated types as primitive types. As such, you can use many of <br>the familiar operators (==, !=, &lt;, &gt;, &lt;=, &gt;=, +, -, ^, &amp;, |, ~, ++, and --) to manipulate enumer-<br>ated type instances. All of these operators actually work on the value__ instance field inside <br>each enumerated type instance. Furthermore, the C# compiler allows you to explicitly cast <br>instances of an enumerated type to a different enumerated type. You can also explicitly cast <br>an enumerated type instance to a numeric type.<br>
<hr>
<A name=394></a><IMG src="CLRviaCsharp-394_1.jpg"><br>
<IMG src="CLRviaCsharp-394_2.jpg"><br>
<b>376 </b><br>
<b>Part III  Essential Types</b><br>
Given an instance of an enumerated type, it's possible to map that value to one of several <br>string representations by calling the ToString method inherited from System.Enum:<br>
Color c = Color.Blue;  <br>Console.WriteLine(c);               // &quot;Blue&quot; (General format)  <br>Console.WriteLine(c.ToString());    // &quot;Blue&quot; (General format)  <br>Console.WriteLine(c.ToString(&quot;G&quot;)); // &quot;Blue&quot; (General format)  <br>Console.WriteLine(c.ToString(&quot;D&quot;)); // &quot;3&quot;    (Decimal format)  <br>Console.WriteLine(c.ToString(&quot;X&quot;)); // &quot;03&quot;   (Hex format)<br>
<b>Note  </b>When using hex formatting, ToString always outputs uppercase letters. In addition, the <br>number of digits outputted depends on the enum's underlying type: 2 digits for byte/sbyte, 4 <br>digits for short/ushort, 8 digits for int/uint, and 16 digits for long/ulong. Leading zeros are <br>outputted if necessary.<br>
In addition to the ToString method, the System.Enum type offers a static Format method <br>that you can call to format an enumerated type's value:<br>
public static String Format(Type enumType, Object value, String format);<br>
Generally, I prefer to call the ToString method because it requires less code and it's easier <br>to call. But using Format has one advantage over ToString: Format lets you pass a numeric <br>value for the value parameter; you don't have to have an instance of the enumerated type. <br>For example, the following code will display "Blue":<br>
// The following line displays &quot;Blue&quot;.  <br>Console.WriteLine(Enum.Format(typeof(Color), 3, &quot;G&quot;));<br>
<b>Note  </b>It's possible to declare an enumerated type that has multiple symbols, all with the same <br>numeric value. When converting a numeric value to a symbol by using general formatting, <br>Enum's methods return one of the symbols. However, there's no guarantee of which symbol name <br>is returned. Also, if no symbol is defined for the numeric value you're looking up, a string  <br>containing the numeric value is returned.<br>
It's also possible to call System.Enum's static GetValues method or System.Type's instance <br>GetEnumValues method to obtain an array that contains one element for each symbolic <br>name in an enumerated type; each element contains the symbolic name's numeric value:<br>
public static Array GetValues(Type enumType);      // Defined in System.Enum <br>public        Array GetEnumValues();               // Defined in System.Type<br>
Using this method along with the ToString method, you can display all of an enumerated <br>type's symbolic and numeric values, like so:<br>
Color[] colors = (Color[]) Enum.GetValues(typeof(Color));  <br>Console.WriteLine(&quot;Number of symbols defined: &quot; + colors.Length);  <br>
<hr>
<A name=395></a><b> </b><br>
<b>Chapter 15  Enumerated Types and Bit Flags </b><br>
<b>377</b><br>
Console.WriteLine(&quot;Value\tSymbol\n-----\t------&quot;);  <br>foreach (Color c in colors) {  <br>   // Display each symbol in Decimal and General format.  <br>   Console.WriteLine(&quot;{0,5:D}\t{0:G}&quot;, c);  <br>}<br>
The previous code produces the following output:<br>
Number of symbols defined: 5  <br>Value   Symbol  <br>-----   ------  <br>    0   White  <br>    1   Red  <br>    2   Green  <br>    3   Blue  <br>    4   Orange<br>
This discussion shows some of the cool operations that can be performed on enumerated <br>types. I suspect that the ToString method with the general format will be used quite fre-<br>quently to show symbolic names in a program's user interface elements (list boxes, combo <br>boxes, and the like), as long as the strings don't need to be localized (since enumerated types <br>offer no support for localization). In addition to the GetValues method, the System.Enum <br>type and the System.Type type also offer the following methods that return an enumerated <br>type's symbols:<br>
// Returns a String representation for the numeric value  <br>public static String GetName(Type enumType, Object value); // Defined in System.Enum <br>public        String GetEnumName(Object value);            // Defined in System.Type <br> <br> <br>// Returns an array of Strings: one per symbol defined in the enum  <br>public static String[] GetNames(Type enumType);            // Defined in System.Enum <br>public        String[] GetEnumNames();                     // Defined in System.Type<br>
I've discussed a lot of methods that you can use to look up an enumerated type's symbol. <br>But you also need a method that can look up a symbol's equivalent value, an operation that <br>could be used to convert a symbol that a user enters into a text box, for example. Converting <br>a symbol to an instance of an enumerated type is easily accomplished by using one of Enum's <br>static Parse and TryParse methods:<br>
public static Object Parse(Type enumType, String value);  <br>public static Object Parse(Type enumType, String value, Boolean ignoreCase); <br>public static Boolean TryParse&lt;TEnum&gt;(String value, out TEnum result) where TEnum: struct; <br>public static Boolean TryParse&lt;TEnum&gt;(String value, Boolean ignoreCase, out TEnum result) <br>   where TEnum : struct;<br>
Here's some code demonstrating how to use this method:<br>
// Because Orange is defined as 4, 'c' is initialized to 4.  <br>Color c = (Color) Enum.Parse(typeof(Color), &quot;orange&quot;, true);  <br> <br>
<hr>
<A name=396></a><b>378 </b><br>
<b>Part III  Essential Types</b><br>
// Because Brown isn't defined, an ArgumentException is thrown.  <br>c = (Color) Enum.Parse(typeof(Color), &quot;Brown&quot;, false);  <br> <br>// Creates an instance of the Color enum with a value of 1  <br>Enum.TryParse&lt;Color&gt;(&quot;1&quot;, false, out c); <br> <br>// Creates an instance of the Color enum with a value of 23  <br>Enum.TryParse&lt;Color&gt;(&quot;23&quot;, false, out c);<br>
Finally, using Enum's static IsDefined method and Type's IsEnumDefined method,<br>
public static Boolean IsDefined(Type enumType, Object value);     // Defined in System.Enum <br>public        Boolean IsEnumDefined(Object value);                // Defined in System.Type<br>
you can determine whether a numeric value is legal for an enumerated type:<br>
// Displays &quot;True&quot; because Color defines Red as 1  <br>Console.WriteLine(Enum.IsDefined(typeof(Color),  1));  <br> <br>// Displays &quot;True&quot; because Color defines White as 0  <br>Console.WriteLine(Enum.IsDefined(typeof(Color), &quot;White&quot;));  <br> <br>// Displays &quot;False&quot; because a case-sensitive check is performed   <br>Console.WriteLine(Enum.IsDefined(typeof(Color), &quot;white&quot;));  <br> <br>// Displays &quot;False&quot; because Color doesn't have a symbol of value 10  <br>Console.WriteLine(Enum.IsDefined(typeof(Color),  10));<br>
The IsDefined method is frequently used for parameter validation. Here's an example:<br>
public void SetColor(Color c) {  <br>   if (!Enum.IsDefined(typeof(Color), c)) {  <br>      throw(new ArgumentOutOfRangeException(&quot;c&quot;, c, &quot;Invalid Color value.&quot;));  <br>   }  <br>   // Set color to White, Red, Green, Blue, or Orange  <br>   ...  <br>}<br>
The parameter validation is useful because someone could call SetColor like this:<br>
SetColor((Color) 547);<br>
Because no symbol has a corresponding value of 547, the SetColor method will throw an <br>ArgumentOutOfRangeException exception, indicating which parameter is invalid and why.<br>
<hr>
<A name=397></a><IMG src="CLRviaCsharp-397_1.jpg"><br>
<b> </b><br>
<b>Chapter 15  Enumerated Types and Bit Flags </b><br>
<b>379</b><br>
<b>Important  </b>The IsDefined method is very convenient, but you must use it with caution. First, <br>IsDefined always does a case-sensitive search, and there is no way to get it to perform a case-<br>insensitive search. Second, IsDefined is pretty slow because it uses reflection internally; if you <br>wrote code to manually check each possible value, your application's performance would most <br>certainly be better. Third, you should really use IsDefined only if the enum type itself is defined <br>in the same assembly that is calling IsDefined. Here's why: Let's say the Color enum is defined <br>in one assembly and the SetColor method is defined in another assembly. The SetColor meth-<br>od calls IsDefined, and if the color is White, Red, Green, Blue, or Orange, SetColor performs <br>its work. However, if the Color enum changes in the future to include Purple, SetColor will <br>now allow Purple, which it never expected before, and the method might execute with unpre-<br>dictable results.<br>
Finally, the System.Enum type offers a set of static ToObject methods that convert an  <br>instance of a Byte, SByte, Int16, UInt16, Int32, UInt32, Int64, or UInt64 to an instance  <br>of an enumerated type.<br>
Enumerated types are always used in conjunction with some other type. Typically, they're <br>used for the type's method parameters or return type, properties, and fields. A common <br>question that arises is whether to define the enumerated type nested within the type that <br>requires it or to define the enumerated type at the same level as the type that requires it. If <br>you examine the FCL, you'll see that an enumerated type is usually defined at the same level <br>as the class that requires it. The reason is simply to make the developer's life a little easier by <br>reducing the amount of typing required. So you should define your enumerated type at the <br>same level unless you're concerned about name conflicts.<br>
<b>Bit Flags</b><br>
Programmers frequently work with sets of bit flags. When you call the System.IO.File type's <br>GetAttributes method, it returns an instance of a FileAttributes type. A FileAttributes <br>type is an instance of an Int32-based enumerated type, in which each bit reflects a single  <br>attribute of the file. The FileAttributes type is defined in the FCL as follows:<br>
[Flags, Serializable]  <br>public enum FileAttributes {  <br>   ReadOnly          = 0x0001,  <br>   Hidden            = 0x0002,  <br>   System            = 0x0004,  <br>   Directory         = 0x0010,  <br>   Archive           = 0x0020,  <br>   Device            = 0x0040,  <br>   Normal            = 0x0080,  <br>   Temporary         = 0x0100,  <br>   SparseFile        = 0x0200,  <br>   ReparsePoint      = 0x0400,  <br>   Compressed        = 0x0800,  <br>   Offline           = 0x1000,  <br>   NotContentIndexed = 0x2000,  <br>   Encrypted         = 0x4000  <br>}<br>
<hr>
<A name=398></a><IMG src="CLRviaCsharp-398_1.jpg"><br>
<b>380 </b><br>
<b>Part III  Essential Types</b><br>
To determine whether a file is hidden, you would execute code like this:<br>
String file = Assembly.GetEntryAssembly().Location; <br>FileAttributes attributes = File.GetAttributes(file);  <br>Console.WriteLine(&quot;Is {0} hidden? {1}&quot;, file, (attributes &amp; FileAttributes.Hidden) != 0);<br>
<b>Note  </b>The Enum class defines a HasFlag method defined as follows:<br>
public Boolean HasFlag(Enum flag);<br>
Using this method, you could rewrite the call to Console.WriteLine like this:<br>
Console.WriteLine(&quot;Is {0} hidden? {1}&quot;, file,  <br>   attributes.HasFlag(FileAttributes.Hidden));<br>
However, I recommend that you avoid the HasFlag method for this reason: Since it takes a  <br>parameter of type Enum, any value you pass to it must be boxed, requiring a memory allocation.<br>
And here's code demonstrating how to change a file's attributes to read-only and hidden:<br>
File.SetAttributes(file, FileAttributes.ReadOnly | FileAttributes.Hidden);<br>
As the FileAttributes type shows, it's common to use enumerated types to express the <br>set of bit flags that can be combined. However, although enumerated types and bit flags are <br>similar, they don't have exactly the same semantics. For example, enumerated types repre-<br>sent single numeric values, and bit flags represent a set of bits, some of which are on, and <br>some of which are off.<br>
When defining an enumerated type that is to be used to identify bit flags, you should, of <br>course, explicitly assign a numeric value to each symbol. Usually, each symbol will have an <br>individual bit turned on. It is also common to see a symbol called None defined with a  <br>value of 0, and you can also define symbols that represent commonly used combinations  <br>(see the ReadWrite symbol below). It's also highly recommended that you apply the  <br>System.FlagsAttribute custom attribute type to the enumerated type, as shown here:<br>
[Flags]    // The C# compiler allows either &quot;Flags&quot; or &quot;FlagsAttribute&quot;.  <br>internal enum Actions {  <br>   None      = 0  <br>   Read      = 0x0001,  <br>   Write     = 0x0002,  <br>   ReadWrite = Actions.Read | Actions.Write,  <br>   Delete    = 0x0004,  <br>   Query     = 0x0008,  <br>   Sync      = 0x0010   <br>}<br>
<hr>
<A name=399></a><b> </b><br>
<b>Chapter 15  Enumerated Types and Bit Flags </b><br>
<b>381</b><br>
Because Actions is an enumerated type, you can use all of the methods described in the <br>previous section when working with bit-flag enumerated types. However, it would be nice if <br>some of those functions behaved a little differently. For example, let's say you had the  <br>following code:<br>
Actions actions = Actions.Read | Actions.Delete; // 0x0005  <br>Console.WriteLine(actions.ToString());           // &quot;Read, Delete&quot;<br>
When ToString is called, it attempts to translate the numeric value into its symbolic equiva-<br>lent. The numeric value is 0x0005, which has no symbolic equivalent. However, the ToString <br>method detects the existence of the [Flags] attribute on the Actions type, and ToString <br>now treats the numeric value not as a single value but as a set of bit flags. Because the <br>0x0001 and 0x0004 bits are set, ToString generates the following string: "Read, Delete". If <br>you remove the [Flags] attribute from the Actions type, ToString would return "5."<br>
I discussed the ToString method in the previous section, and I showed that it offered three <br>ways to format the output: "G" (general), "D" (decimal), and "X" (hex). When you're formatting <br>an instance of an enumerated type by using the general format, the type is first checked to <br>see if the [Flags] attribute is applied to it. If this attribute is not applied, a symbol matching <br>the numeric value is looked up and returned. If the [Flags] attribute is applied, ToString <br>works like this:<br>
<b> </b><br>
<b>1.  </b>The set of numeric values defined by the enumerated type is obtained, and the  <br>
numbers are sorted in descending order.<br>
<b> </b><br>
<b>2.  </b>Each numeric value is bitwise-ANDed with the value in the enum instance, and if <br>
the result equals the numeric value, the string associated with the numeric value is ap-<br>pended to the output string, and the bits are considered accounted for and are turned <br>off. This step is repeated until all numeric values have been checked or until the enum <br>instance has all of its bits turned off.<br>
<b> </b><br>
<b>3.  </b>If, after all the numeric values have been checked, the enum instance is still not 0, the <br>
enum instance has some bits turned on that do not correspond to any defined symbols. <br>In this case, ToString returns the original number in the enum instance as a string.<br>
<b> </b><br>
<b>4.  </b>If the enum instance's original value wasn't 0, the string with the comma-separated set <br>
of symbols is returned.<br>
<b> </b><br>
<b>5.  </b>If the enum instance's original value was 0 and if the enumerated type has a symbol <br>
defined with a corresponding value of 0, the symbol is returned.<br>
<b> </b><br>
<b>6.  </b>If we reach this step, "0" is returned.<br>
<hr>
<A name=400></a><b>382 </b><br>
<b>Part III  Essential Types</b><br>
If you prefer, you could define the Actions type without the [Flags] attribute and still get <br>the correct string by using the "F" format:<br>
// [Flags]    // Commented out now  <br>internal enum Actions {  <br>   None      = 0  <br>   Read      = 0x0001,  <br>   Write     = 0x0002,  <br>   ReadWrite = Actions.Read | Actions.Write,  <br>   Delete    = 0x0004,  <br>   Query     = 0x0008,  <br>   Sync      = 0x0010   <br>}  <br> <br>Actions actions = Actions.Read | Actions.Delete; // 0x0005  <br>Console.WriteLine(actions.ToString(&quot;F&quot;));        // &quot;Read, Delete&quot;<br>
If the numeric value has a bit that cannot be mapped to a symbol, the returned string will <br>contain just a decimal number indicating the original numeric value; no symbols will appear <br>in the string.<br>
Note that the symbols you define in your enumerated type don't have to be pure powers of <br>2. For example, the Actions type could define a symbol called All with a value of 0x001F. If <br>an instance of the Actions type has a value of 0x001F, formatting the instance will produce a <br>string that contains "All." The other symbol strings won't appear.<br>
So far, I've discussed how to convert numeric values into a string of flags. It's also possible <br>to convert a string of comma-delimited symbols into a numeric value by calling Enum's static <br>Parse and TryParse method. Here's some code demonstrating how to use this method:<br>
// Because Query is defined as 8, 'a' is initialized to 8.  <br>Actions a = (Actions) Enum.Parse(typeof(Actions), &quot;Query&quot;, true);  <br>Console.WriteLine(a.ToString());  // &quot;Query&quot;  <br> <br>// Because Query and Read are defined, 'a' is initialized to 9.  <br>Enum.TryParse&lt;Actions&gt;(&quot;Query, Read&quot;, false, out a); <br>Console.WriteLine(a.ToString());  // &quot;Read, Query&quot;  <br> <br>// Creates an instance of the Actions enum with a value of 28  <br>a = (Actions) Enum.Parse(typeof(Actions), &quot;28&quot;, false);  <br>Console.WriteLine(a.ToString());  // &quot;Delete, Query, Sync&quot;<br>
When Parse and TryParse are called, the following actions are performed internally:<br>
<b> </b><br>
<b>1.  </b>It removes all whitespace characters from the start and end of the string.<br>
<b> </b><br>
<b>2.  </b>If the first character of the string is a digit, plus sign (+), or minus sign (-), the string is <br>
assumed to be a number, and an enum instance is returned whose numeric value is <br>equal to the string converted to its numeric equivalent.<br>
<hr>
<A name=401></a><b> </b><br>
<b>Chapter 15  Enumerated Types and Bit Flags </b><br>
<b>383</b><br>
<b> </b><br>
<b>3.  </b>The passed string is split into a set of tokens (separated by commas), and all white <br>
space is trimmed away from each token.<br>
<b> </b><br>
<b>4.  </b>Each token string is looked up in the enum type's defined symbols. If the symbol is not <br>
found, Parse throws a System.ArgumentException and TryParse returns false. If <br>the symbol is found, bitwise-OR its numeric value into a running result, and then look <br>up the next token.<br>
<b> </b><br>
<b>5.  </b>If all tokens have been sought and found, return the running result.<br>
You should never use the IsDefined method with bit flag­enumerated types. It won't work <br>for two reasons:<br>
  If you pass a string to IsDefined, it doesn't split the string into separate tokens to look <br>
up; it will attempt to look up the string as through it were one big symbol with commas <br>in it. Since you can't define an enum with a symbol that has commas in it, the symbol <br>will never be found.<br>
  If you pass a numeric value to IsDefined, it checks if the enumerated type defines a <br>
single symbol whose numeric value matches the passed-in number. Since this is unlikely <br>for bit flags, IsDefined will usually return false.<br>
<b>Adding Methods to Enumerated Types</b><br>
Earlier in this chapter, I mentioned that you cannot define a method as part of an enumerat-<br>ed type. And, for many years, this has saddened me because there are many occasions when <br>I would love to have been able to supply some methods to my enumerated type. Fortunately, <br>I can now use C#'s relatively new extension method feature (discussed in Chapter 8, <br>"Methods") to simulate adding methods to an enumerated type.<br>
If I want to add some methods to the FileAttributes enumerated type, I can define a static <br>class with extension methods as follows:<br>
internal static class FileAttributesExtensionMethods { <br>   public static Boolean IsSet(this FileAttributes flags, FileAttributes flagToTest) { <br>      if (flagToTest == 0) <br>         throw new ArgumentOutOfRangeException(&quot;flagToTest&quot;, &quot;Value must not be 0&quot;); <br>      return (flags &amp; flagToTest) == flagToTest; <br>   } <br> <br>   public static Boolean IsClear(this FileAttributes flags, FileAttributes flagToTest) { <br>      if (flagToTest == 0) <br>         throw new ArgumentOutOfRangeException(&quot;flagToTest&quot;, &quot;Value must not be 0&quot;); <br>      return !IsSet(flags, flagToTest); <br>   } <br> <br>   public static Boolean AnyFlagsSet(this FileAttributes flags, FileAttributes testFlags) { <br>      return ((flags &amp; testFlags) != 0); <br>   } <br> <br>
<hr>
<A name=402></a><b>384 </b><br>
<b>Part III  Essential Types</b><br>
   public static FileAttributes Set(this FileAttributes flags, FileAttributes setFlags) { <br>      return flags | setFlags; <br>   } <br> <br>   public static FileAttributes Clear(this FileAttributes flags,  <br>      FileAttributes clearFlags) { <br>      return flags &amp; ~clearFlags; <br>   } <br> <br>   public static void ForEach(this FileAttributes flags,  <br>      Action&lt;FileAttributes&gt; processFlag) { <br>      if (processFlag == null) throw new ArgumentNullException(&quot;processFlag&quot;); <br>      for (UInt32 bit = 1; bit != 0; bit &lt;&lt;= 1) { <br>         UInt32 temp = ((UInt32)flags) &amp; bit; <br>         if (temp != 0) processFlag((FileAttributes)temp); <br>      } <br>   } <br>}<br>
And here is some code that demonstrates calling some of these methods. As you can see, the <br>code looks as if I'm calling methods on the enumerated type:<br>
FileAttributes fa = FileAttributes.System; <br>fa = fa.Set(FileAttributes.ReadOnly); <br>fa = fa.Clear(FileAttributes.System); <br>fa.ForEach(f =&gt; Console.WriteLine(f));<br>
<hr>
<A name=403></a>Chapter 16<br><b>Arrays</b><br>
<b>In this chapter:<br>Initializing Array Elements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 388<br>Casting Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390<br>All Arrays Are Implicitly Derived from </b>System.Array<b>  . . . . . . . . . . . . . . . . . . . . . 392<br>All Arrays Implicitly Implement </b>IEnumerable<b>, </b>ICollection<b>, and </b>IList<b> . . . . . 393<br>Passing and Returning Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 394<br>Creating Non-Zero­Lower Bound Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395<br>Array Access Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396<br>Unsafe Array Access and Fixed-Size Array  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 401</b><br>
Arrays are mechanisms that allow you to treat several items as a single collection. The <br>Microsoft .NET common language runtime (CLR) supports single-dimensional arrays, multi-<br>dimensional arrays, and jagged arrays (that is, arrays of arrays). All array types are implicitly <br>derived from the System.Array abstract class, which itself is derived from System.Object. <br>This means that arrays are always reference types that are allocated on the managed heap <br>and that your application's variable or field contains a reference to the array and not the  <br>elements of the array itself. The following code makes this clearer:<br>
Int32[] myIntegers;          // Declares a reference to an array  <br>myIntegers = new Int32[100]; // Creates an array of 100 Int32s<br>
On the first line, myIntegers is a variable that's capable of pointing to a single-dimensional <br>array of Int32s. Initially, myIntegers will be set to null because I haven't allocated an  <br>array. The second line of code allocates an array of 100 Int32 values; all of the Int32s are <br>initialized to 0. Since arrays are reference types, the memory block required to hold the 100 <br>unboxed Int32s is allocated on the managed heap. Actually, in addition to the array's ele-<br>ments, the memory block occupied by an array object also contains a type object pointer, a <br>sync block index, and some additional overhead members as well. The address of this array's <br>memory block is returned and saved in the variable myIntegers.<br>
You can also create arrays of reference types:<br>
Control[] myControls;         // Declares a reference to an array  <br>myControls = new Control[50]; // Creates an array of 50 Control references<br>
On the first line, myControls is a variable capable of pointing to a single-dimensional array <br>of Control references. Initially, myControls will be set to null because I haven't allocated <br>
<b> </b><br>
<b> </b><br>
<b>385</b><br>
<hr>
<A name=404></a><b>386 </b><br>
<b>Part III  Essential Types</b><br>
an array. The second line allocates an array of 50 Control references; all of these references <br>are initialized to null. Because Control is a reference type, creating the array creates only a <br>bunch of references; the actual objects aren't created at this time. The address of this memory <br>block is returned and saved in the variable myControls.<br>
Figure 16-1 shows how arrays of value types and arrays of reference types look in the  <br>managed heap.<br>
99<br>
Int32<br>
98<br>
Int32<br>
97<br>
Button<br>
Int32<br>
Control<br>
49<br>
96<br>
Int32<br>
ComboBox<br>
Control<br>
48<br>
Control<br>
47<br>
DataGrid<br>
Control<br>
46<br>
3<br>
Int32<br>
Control<br>
3<br>
2<br>
TextBox<br>
Int32<br>
Control<br>
2<br>
1<br>
Int32<br>
Button<br>
Control<br>
1<br>
0<br>
Int32<br>
Control<br>
0<br>
myIntegers<br>
Overhead<br>
Overhead<br>
myControls<br>
<b>FIGURE 16-1  </b>Arrays of value and reference types in the managed heap<br>
In the figure, the Controls array shows the result after the following lines have executed:<br>
myControls[1]  = new Button();  <br>myControls[2]  = new TextBox();  <br>myControls[3]  = myControls[2];  // Two elements refer to the same object.  <br>myControls[46] = new DataGrid();  <br>myControls[48] = new ComboBox();  <br>myControls[49] = new Button();<br>
Common Language Specification (CLS) compliance requires all arrays to be zero-based. This <br>allows a method written in C# to create an array and pass the array's reference to code writ-<br>ten in another language, such as Microsoft Visual Basic .NET. In addition, because zero-based <br>arrays are, by far, the most common arrays, Microsoft has spent a lot of time optimizing their <br>performance. However, the CLR does support non-zero­based arrays even though their use <br>is discouraged. For those of you who don't care about a slight performance penalty or cross-<br>language portability, I'll demonstrate how to create and use non-zero­based arrays later in <br>this chapter.<br>
Notice in Figure 16-1 that each array has some additional overhead information associated <br>with it. This information contains the rank of the array (number of dimensions), the lower <br>bounds for each dimension of the array (almost always 0), and the length of each dimension. <br>
<hr>
<A name=405></a><IMG src="CLRviaCsharp-405_1.jpg"><br>
<b> </b><br>
<b>Chapter 16  Arrays </b><br>
<b>387</b><br>
The overhead also contains the array's element type. I'll mention the methods that allow you <br>to query this overhead information later in this chapter.<br>
So far, I've shown examples demonstrating how to create single-dimensional arrays. When <br>possible, you should stick with single-dimensional, zero-based arrays, sometimes referred <br>to as <i>SZ arrays</i>, or <i>vectors</i>. Vectors give the best performance because you can use specific <br>Intermediate Language (IL) instructions--such as newarr, ldelem, ldelema, ldlen, and <br>stelem--to manipulate them. However, if you prefer to work with multi-dimensional arrays, <br>you can. Here are some examples of multi-dimensional arrays:<br>
// Create a two-dimensional array of Doubles.  <br>Double[,] myDoubles = new Double[10, 20];  <br> <br>// Create a three-dimensional array of String references.  <br>String[,,] myStrings = new String[5, 3, 10];<br>
The CLR also supports jagged arrays, which are arrays of arrays. Zero-based, single- <br>dimensional jagged arrays have the same performance as normal vectors. However, accessing <br>the elements of a jagged array means that two or more array accesses must occur. Here are <br>some examples of how to create an array of polygons with each polygon consisting of an  <br>array of Point instances:<br>
// Create a single-dimensional array of Point arrays.  <br>Point[][] myPolygons = new Point[3][];  <br> <br>// myPolygons[0] refers to an array of 10 Point instances.  <br>myPolygons[0] = new Point[10];   <br> <br>// myPolygons[1] refers to an array of 20 Point instances.  <br>myPolygons[1] = new Point[20];  <br> <br>// myPolygons[2] refers to an array of 30 Point instances.  <br>myPolygons[2] = new Point[30];  <br> <br>// Display the Points in the first polygon.  <br>for (Int32 x = 0; x &lt; myPolygons[0].Length; x++)   <br>   Console.WriteLine(myPolygons[0][x]);<br>
<b>Note  </b>The CLR verifies that an index into an array is valid. In other words, you can't create an  <br>array with 100 elements in it (numbered 0 through 99) and then try to access the element at <br>index ­5 or 100. Doing so will cause a System.IndexOutOfRangeException to be thrown. <br>Allowing access to memory outside the range of an array would be a breach of type safety and  <br>a potential security hole, and the CLR doesn't allow verifiable code to do this. Usually, the per-<br>formance degradation associated with index checking is insubstantial because the just-in-time <br>(JIT) compiler normally checks array bounds once before a loop executes instead of at each loop <br>iteration. However, if you're still concerned about the performance hit of the CLR's index checks, <br>you can use unsafe code in C# to access the array. The "Array Access Performance" section later <br>in this chapter demonstrates how to do this.<br>
<hr>
<A name=406></a><b>388 </b><br>
<b>Part III  Essential Types</b><br>
<b>Initializing Array Elements</b><br>
In the previous section, I showed how to create an array object and then I showed how to <br>initialize the elements of the array. C# offers syntax that allows you to do these two opera-<br>tions in one statement. For example:<br>
String[] names = new String[] { &quot;Aidan&quot;, &quot;Grant&quot; };<br>
The comma-separated set of tokens contained within the braces is cal ed an <i>array initializer</i>. <br>Each token can be an arbitrarily complex expression or, in the case of a multi-dimensional array, <br>a nested array initializer. In the example above, I used just two simple String expressions.<br>
If you are declaring a local variable in a method to refer to the initialized array, then you can <br>use C#'s implicitly typed local variable (var) feature to simplify the code a little:<br>
// Using C#'s implicitly typed local variable feature: <br>var names = new String[] { &quot;Aidan&quot;, &quot;Grant&quot; };<br>
Here, the compiler is inferring that the names local variable should be of the String[] type <br>since that is the type of the expression on the right of the assignment operator (=).<br>
You can use C#'s implicitly typed array feature to have the compiler infer the type of the  <br>array's elements. Notice the line below has no type specified between new and []:<br>
// Using C#'s implicitly typed local variable and implicitly typed array features: <br>var names = new[] { &quot;Aidan&quot;, &quot;Grant&quot;, null };<br>
In the line above, the compiler examines the types of the expressions being used inside the <br>array to initialize the array's elements, and the compiler chooses the closest base class that <br>all the elements have in common to determine the type of the array. In this example, the <br>compiler sees two Strings and null. Since null is implicitly castable to any reference type <br>(including String), the compiler infers that it should be creating and initializing an array of <br>String references.<br>
If you had this code,<br>
// Using C#'s implicitly typed local variable &amp; implicitly typed array features: (error) <br>var names = new[] { &quot;Aidan&quot;, &quot;Grant&quot;, 123 };<br>
the compiler would issue the message &quot;error CS0826: No best type found for  <br>implicitly-typed array.&quot; This is because the base type in common between the two <br>Strings and the Int32 is Object, which would mean that the compiler would have to create <br>an array of Object references and then box the 123 and have the last array element refer to <br>a boxed Int32 with a value of 123. The C# compiler team thinks that boxing array elements <br>is too heavy-handed for the compiler to do for you implicitly, and that is why the compiler <br>issues the error.<br>
<hr>
<A name=407></a><b> </b><br>
<b>Chapter 16  Arrays </b><br>
<b>389</b><br>
As an added syntactical bonus when initializing an array, you can write the following:<br>
String[] names = { &quot;Aidan&quot;, &quot;Grant&quot; };<br>
Notice that on the right of the assignment operator (=), only the array initializer expression is <br>given with no new, no type, and no []s. This syntax is nice, but unfortunately, the C#  <br>compiler does not allow you to use implicitly typed local variables with this syntax:<br>
// This is a local variable now (error) <br>var names = { &quot;Aidan&quot;, &quot;Grant&quot; };<br>
If you try to compile the line of code above, the compiler issues two messages: &quot;error <br>CS0820: Cannot initialize an implicitly-typed local variable with an array <br>initializer&quot; and &quot;error CS0622: Can only use array initializer expressions to <br>assign to array types. Try using a new expression instead.&quot; While the compiler <br>could make this work, the C# team thought that the compiler would be doing too much for <br>you here. It would be inferring the type of the array, new'ing the array, initializing the array, <br>and inferring the type of the local variable, too.<br>
The last thing I'd like to show you is how to use implicitly typed arrays with anonymous types <br>and implicitly typed local variables. Anonymous types and how type identity applies to them <br>are discussed in Chapter 10, "Properties." Examine the code below:<br>
// Using C#'s implicitly typed local, implicitly typed array, and anonymous type features: <br>var kids = new[] {new { Name=&quot;Aidan&quot; }, new { Name=&quot;Grant&quot; }}; <br> <br>// Sample usage (with another implicitly typed local variable): <br>foreach (var kid in kids) <br>   Console.WriteLine(kid.Name);<br>
In this example, I am using an array initializer that has two expressions for the array elements. <br>Each expression represents an anonymous type (since no type name is specified after the new <br>operator). Since the two anonymous types have the identical structure (one field called Name <br>of type String), the compiler knows that these two objects are of the exact same type. Now, <br>I use C#'s implicitly typed array feature (no type specified between the new and the []s) so <br>that the compiler will infer the type of the array itself, construct this array object, and initialize <br>its references to the two instances of the one anonymous type.1 Final y, a reference to this  <br>array object is assigned to the kids local variable, the type of which is inferred by the com-<br>piler due to C#'s implicitly typed local variable feature.<br>
I show the foreach loop as an example of how to use this array that was just created and ini-<br>tialized with the two anonymous type objects. I have to use an implicitly typed local variable <br>(kid) for the loop, too. When I run this code, I get the following output:<br>
Aidan <br>Grant<br>
1  If you think these sentences are fun to read, you can only imagine how fun they were to write in the first place!<br>
<hr>
<A name=408></a><b>390 </b><br>
<b>Part III  Essential Types</b><br>
<b>Casting Arrays</b><br>
For arrays with reference type elements, the CLR allows you to implicitly cast the source  <br>array's element type to a target type. For the cast to succeed, both array types must have the <br>same number of dimensions, and an implicit or explicit conversion from the source element <br>type to the target element type must exist. The CLR doesn't allow the casting of arrays with <br>value type elements to any other type. (However, by using the Array.Copy method, you can <br>create a new array and populate its elements in order to obtain the desired effect.) The  <br>following code demonstrates how array casting works:<br>
// Create a two-dimensional FileStream array.  <br>FileStream[,] fs2dim = new FileStream[5, 10];  <br> <br>// Implicit cast to a two-dimensional Object array  <br>Object[,] o2dim = fs2dim;  <br> <br>// Can't cast from two-dimensional array to one-dimensional array  <br>// Compiler error CS0030: Cannot convert type 'object[*,*]' to   <br>// 'System.IO.Stream[]'  <br>Stream[] s1dim = (Stream[]) o2dim;  <br> <br>// Explicit cast to two-dimensional Stream array  <br>Stream[,] s2dim = (Stream[,]) o2dim;  <br> <br>// Explicit cast to two-dimensional String array   <br>// Compiles but throws InvalidCastException at runtime <br>String[,] st2dim = (String[,]) o2dim;  <br> <br>// Create a one-dimensional Int32 array (value types).  <br>Int32[] i1dim = new Int32[5];  <br> <br>// Can't cast from array of value types to anything else  <br>// Compiler error CS0030: Cannot convert type 'int[]' to 'object[]'  <br>Object[] o1dim = (Object[]) i1dim;  <br> <br>// Create a new array, then use Array.Copy to coerce each element in the   <br>// source array to the desired type in the destination array.  <br>// The following code creates an array of references to boxed Int32s.  <br>Object[] ob1dim = new Object[i1dim.Length];  <br>Array.Copy(i1dim, ob1dim, i1dim.Length);<br>
The Array.Copy method is not just a method that copies elements from one array to  <br>another. The Copy method handles overlapping regions of memory correctly, as does C's <br>memmove function. C's memcpy function, on the other hand, doesn't handle overlapping  <br>regions correctly. The Copy method can also convert each array element as it is copied if  <br>conversion is required. The Copy method is capable of performing the following conversions:<br>
  Boxing value type elements to reference type elements, such as copying an Int32[] to <br>
an Object[].<br>
<hr>
<A name=409></a><b> </b><br>
<b>Chapter 16  Arrays </b><br>
<b>391</b><br>
  Unboxing reference type elements to value type elements, such as copying an <br>
Object[] to an Int32[].<br>
  Widening CLR primitive value types, such as copying elements from an Int32[] to a <br>
Double[].<br>
  Downcasting elements when copying between array types that can't be proven to be <br>
compatible based on the array's type, such as when casting from an Object[] to an <br>IFormattable[]. If every object in the Object[] implements IFormattable[], Copy <br>will succeed.<br>
Here's another example showing the usefulness of Copy:<br>
// Define a value type that implements an interface.  <br>internal struct MyValueType : IComparable {   <br>   public Int32 CompareTo(Object obj) {  <br>      ...   <br>   }  <br>}  <br> <br> <br>public static class Program {  <br>   public static void Main() {  <br>      // Create an array of 100 value types.  <br>      MyValueType[] src = new MyValueType[100];  <br> <br>      // Create an array of IComparable references.  <br>      IComparable[] dest = new IComparable[src.Length];  <br> <br>      // Initialize an array of IComparable elements to refer to boxed   <br>      // versions of elements in the source array.  <br>      Array.Copy(src, dest, src.Length);  <br>   }  <br>}<br>
As you might imagine, the Framework Class Library (FCL) takes advantage of Array's Copy <br>method quite frequently.<br>
In some situations, it is useful to cast an array from one type to another. This kind of func-<br>tionality is called <i>array covariance</i>. When you take advantage of array covariance, you should <br>be aware of an associated performance penalty. Let's say you have the following code:<br>
String[] sa = new String[100];  <br>Object[] oa = sa;  // oa refers to an array of String elements  <br>oa[5] = &quot;Jeff&quot;;    // Perf hit: CLR checks oa's element type for String; OK  <br>oa[3] = 5;         // Perf hit: CLR checks oa's element type for Int32; throws  <br>                   // ArrayTypeMismatchException<br>
In the code above, the oa variable is typed as an Object[]; however, it really refers to a <br>String[]. The compiler will allow you to write code that attempts to put a 5 into an  <br>array element because 5 is an Int32, which is derived from Object. Of course, the CLR must <br>
<hr>
<A name=410></a><IMG src="CLRviaCsharp-410_1.jpg"><br>
<b>392 </b><br>
<b>Part III  Essential Types</b><br>
ensure type safety, and when assigning to an array element, the CLR must ensure that the  <br>assignment is legal. So the CLR must check at runtime whether the array contains Int32  <br>elements. In this case, it doesn't, and the assignment cannot be allowed; the CLR will throw <br>an ArrayTypeMismatchException.<br>
<b>Note  </b>If you just need to make a copy of some array elements to another array, System.Buffer's <br>BlockCopy method executes faster than Array's Copy method. However, Buffer's BlockCopy <br>supports only primitive types; it does not offer the same casting abilities as Array's Copy method. <br>The Int32 parameters are expressed as byte offsets within the array, not as element indexes. <br>BlockCopy is really designed for copying data that is bitwise-compatible from one array type <br>to another blittable array type, such as copying a Byte[] containing Unicode characters (in the <br>proper byte order) to a Char[]. This method allows programmers to partially make up for the <br>lack of the ability to treat an array as a block of memory of any type.<br>
If you need to reliably copy a set of array elements from one array to another array, you should  <br>use System.Array's ConstrainedCopy method. This method guarantees that the copy operation <br>will either complete or throw an exception without destroying any data within the destination  <br>array. This allows ConstrainedCopy to be used in a constrained execution region (CER). In order <br>to offer this guarantee, ConstrainedCopy requires that the source array's element type be the <br>same as or derived from the destination array's element type. In addition, it will not perform any <br>boxing, unboxing, or downcasting.<br>
<b>All Arrays Are Implicitly Derived from </b>System.Array<br>
When you declare an array variable like this,<br>
FileStream[] fsArray;<br>
then the CLR automatically creates a FileStream[] type for the AppDomain. This type will <br>be implicitly derived from the System.Array type, and therefore, all of the instance methods <br>and properties defined on the System.Array type will be inherited by the FileStream[] <br>type, allowing these methods and properties to be called using the fsArray variable. This <br>makes working with arrays extremely convenient because there are many helpful instance <br>methods and properties defined by System.Array, such as Clone, CopyTo, GetLength, <br>GetLongLength, GetLowerBound, GetUpperBound, Length, Rank, and others.<br>
The System.Array type also exposes a large number of extremely useful static methods <br>that operate on arrays. These methods all take a reference to an array as a parameter. Some <br>of the useful static methods are AsReadOnly, BinarySearch, Clear, ConstrainedCopy, <br>ConvertAll, Copy, Exists, Find, FindAll, FindIndex, FindLast, FindLastIndex, ForEach, <br>IndexOf, LastIndexOf, Resize, Reverse, Sort, and TrueForAll. There are many overloads  <br>for each of these methods. In fact, many of the methods provide generic overloads for <br>compile-time type safety as well as good performance. I encourage you to examine the SDK <br>documentation to get an understanding of how useful and powerful these methods are.<br>
<hr>
<A name=411></a><b> </b><br>
<b>Chapter 16  Arrays </b><br>
<b>393</b><br>
<b>All Arrays Implicitly Implement </b>IEnumerable<b>, <br></b>ICollection<b>, and </b>IList<br>
There are many methods that operate on various collection objects because the methods are <br>declared with parameters such as IEnumerable, ICollection, and IList. It is possible to <br>pass arrays to these methods because System.Array also implements these three interfaces. <br>System.Array implements these non-generic interfaces because they treat all elements as <br>System.Object. However, it would be nice to have System.Array implement the generic <br>equivalent of these interfaces, providing better compile-time type safety as well as better <br>performance.<br>
The CLR team didn't want System.Array to implement IEnumerable&lt;T&gt;, ICollection&lt;T&gt;, <br>and IList&lt;T&gt;, though, because of issues related to multi-dimensional arrays and  <br>non-zero­based arrays. Defining these interfaces on System.Array would have enabled <br>these interfaces for all array types. Instead, the CLR performs a little trick: when a single-<br>dimensional, zero­lower bound array type is created, the CLR automatically makes the array <br>type implement IEnumerable&lt;T&gt;, ICollection&lt;T&gt;, and IList&lt;T&gt; (where T is the array's <br>element type) and also implements the three interfaces for all of the array type's base types <br>as long as they are reference types. The following hierarchy diagram helps make this clear:<br>
Object  <br>   Array (non-generic IEnumerable, ICollection, IList)  <br>      Object[]           (IEnumerable, ICollection, IList of Object)  <br>         String[]        (IEnumerable, ICollection, IList of String)  <br>         Stream[]        (IEnumerable, ICollection, IList of Stream)  <br>            FileStream[] (IEnumerable, ICollection, IList of FileStream)  <br>         .  <br>         .      (other arrays of reference types)  <br>         .<br>
So, for example, if you have the following line of code,<br>
FileStream[] fsArray;<br>
then when the CLR creates the FileStream[] type, it will cause this type to automatically  <br>implement the IEnumerable&lt;FileStream&gt;, ICollection&lt;FileStream&gt;, and <br>IList&lt;FileStream&gt; interfaces. Furthermore, the FileStream[] type will also implement  <br>the interfaces for the base types: IEnumerable&lt;Stream&gt;, IEnumerable&lt;Object&gt;, <br>ICollection&lt;Stream&gt;, ICollection&lt;Object&gt;, IList&lt;Stream&gt;, and IList&lt;Object&gt;. Since <br>all of these interfaces are automatically implemented by the CLR, the fsArray variable could <br>be used wherever any of these interfaces exist. For example, the fsArray variable could be <br>passed to methods that have any of the following prototypes:<br>
void M1(IList&lt;FileStream&gt; fsList) { ... }  <br>void M2(ICollection&lt;Stream&gt; sCollection) { ... }  <br>void M3(IEnumerable&lt;Object&gt; oEnumerable) { ... }<br>
<hr>
<A name=412></a><b>394 </b><br>
<b>Part III  Essential Types</b><br>
Note that if the array contains value type elements, the array type will not implement the <br>interfaces for the element's base types. For example, if you have the following line of code,<br>
DateTime[] dtArray; // An array of value types<br>
then the DateTime[] type will implement IEnumerable&lt;DateTime&gt;, <br>ICollection&lt;DateTime&gt;, and IList&lt;DateTime&gt; only; it will not implement versions of <br>these interfaces that are generic over System.ValueType or System.Object. This means that <br>the dtArray variable cannot be passed as an argument to the M3 method shown earlier. The <br>reason for this is because arrays of value types are laid out in memory differently than arrays <br>of reference types. Array memory layout was discussed earlier in this chapter.<br>
<b>Passing and Returning Arrays</b><br>
When passing an array as an argument to a method, you are real y passing a reference to that <br>array. Therefore, the called method is able to modify the elements in the array. If you don't <br>want to allow this, you must make a copy of the array and pass the copy into the method. <br>Note that the Array.Copy method performs a shallow copy, and therefore, if the array's  <br>elements are reference types, the new array refers to the already existing objects.<br>
Similarly, some methods return a reference to an array. If the method constructs and initial-<br>izes the array, returning a reference to the array is fine. But if the method wants to return a <br>reference to an internal array maintained by a field, you must decide if you want the method's <br>caller to have direct access to this array and its elements. If you do, just return the array's <br>reference. But most often, you won't want the method's caller to have such access, so the <br>method should construct a new array and call Array.Copy, returning a reference to the new <br>array. Again, be aware that Array.Copy makes a shallow copy of the original array.<br>
If you define a method that returns a reference to an array, and if that array has no elements <br>in it, your method can return either null or a reference to an array with zero elements in it. <br>When you're implementing this kind of method, Microsoft strongly recommends that you <br>implement the method by having it return a zero-length array because doing so simplifies the <br>code that a developer calling the method must write. For example, this easy-to-understand <br>code runs correctly even if there are no appointments to iterate over:<br>
// This code is easier to write and understand.   <br>Appointment[] appointments = GetAppointmentsForToday();  <br>for (Int32 a = 0; a &lt; appointments.Length; a++) {  <br>   ...   <br>}<br>
The following code also runs correctly if there are no appointments to iterate over. However, <br>this code is slightly more difficult to write and understand:<br>
<hr>
<A name=413></a><b> </b><br>
<b>Chapter 16  Arrays </b><br>
<b>395</b><br>
// This code is harder to write and understand.  <br>Appointment[] appointments = GetAppointmentsForToday();  <br>if (appointments != null) {  <br>   for (Int32 a = 0, a &lt; appointments.Length; a++) {  <br>      // Do something with appointments[a]  <br>   }  <br>}<br>
If you design your methods to return arrays with zero elements instead of null, callers of <br>your methods will have an easier time working with them. By the way, you should do the <br>same for fields. If your type has a field that's a reference to an array, you should consider <br>having the field refer to an array even if the array has no elements in it.<br>
<b>Creating Non-Zero­Lower Bound Arrays</b><br>
Earlier I mentioned that it's possible to create and work with arrays that have non-zero <br>lower bounds. You can dynamically create your own arrays by calling Array's static <br>CreateInstance method. Several overloads of this method exist, allowing you to specify the <br>type of the elements in the array, the number of dimensions in the array, the lower bounds of <br>each dimension, and the number of elements in each dimension. CreateInstance allocates <br>memory for the array, saves the parameter information in the overhead portion of the array's <br>memory block, and returns a reference to the array. If the array has two or more dimensions, <br>you can cast the reference returned from CreateInstance to an ElementType[] variable <br>(where ElementType is some type name), making it easier for you to access the elements in <br>the array. If the array has just one dimension, in C#, you have to use Array's GetValue and <br>SetValue methods to access the elements of the array.<br>
Here's some code that demonstrates how to dynamically create a two-dimensional array <br>of System.Decimal values. The first dimension represents calendar years from 2005 to 2009 <br>inclusive, and the second dimension represents quarters from 1 to 4 inclusive. The code  <br>iterates over all the elements in the dynamic array. I could have hard-coded the array's <br>bounds into the code, which would have given better performance, but I decided to use <br>System.Array's GetLowerBound and GetUpperBound methods to demonstrate their use:<br>
using System;  <br> <br>public static class DynamicArrays {  <br>   public static void Main() {  <br>      // I want a two-dimensional array [2005..2009][1..4].  <br>      Int32[] lowerBounds = { 2005, 1 };  <br>      Int32[] lengths     = {    5, 4 };  <br>      Decimal[,] quarterlyRevenue = (Decimal[,])   <br>         Array.CreateInstance(typeof(Decimal), lengths, lowerBounds);  <br> <br>      Console.WriteLine(&quot;{0,4}  {1,9}  {2,9}  {3,9}  {4,9}&quot;,  <br>         &quot;Year&quot;, &quot;Q1&quot;, &quot;Q2&quot;, &quot;Q3&quot;, &quot;Q4&quot;);  <br>      Int32 firstYear    = quarterlyRevenue.GetLowerBound(0);  <br>
<hr>
<A name=414></a><b>396 </b><br>
<b>Part III  Essential Types</b><br>
      Int32 lastYear     = quarterlyRevenue.GetUpperBound(0);  <br>      Int32 firstQuarter = quarterlyRevenue.GetLowerBound(1);  <br>      Int32 lastQuarter  = quarterlyRevenue.GetUpperBound(1);  <br> <br>      for (Int32 year = firstYear; year &lt;= lastYear; year++) {  <br>         Console.Write(year + &quot;  &quot;);  <br>         for (Int32 quarter = firstQuarter; quarter &lt;= lastQuarter; quarter++) {  <br>            Console.Write(&quot;{0,9:C}  &quot;, quarterlyRevenue[year, quarter]);  <br>         }  <br>         Console.WriteLine();  <br>      }  <br>   }  <br>}<br>
If you compile and run this code, you get the following output:<br>
Year         Q1         Q2         Q3         Q4  <br>2005      $0.00      $0.00      $0.00      $0.00  <br>2006      $0.00      $0.00      $0.00      $0.00  <br>2007      $0.00      $0.00      $0.00      $0.00  <br>2008      $0.00      $0.00      $0.00      $0.00  <br>2009      $0.00      $0.00      $0.00      $0.00<br>
<b>Array Access Performance</b><br>
Internally, the CLR actually supports two different kinds of arrays:<br>
  Single-dimensional arrays with a lower bound of 0. These arrays are sometimes called <br>
SZ (for single-dimensional, zero-based) arrays or vectors.<br>
  Single-dimensional and multi-dimensional arrays with an unknown lower bound.<br>
You can actually see the different kinds of arrays by executing the following code (the output <br>is shown in the code's comments):<br>
using System;  <br> <br>public sealed class Program {  <br>      public static void Main() {  <br>      Array a;  <br> <br>      // Create a 1-dim, 0-based array, with no elements in it  <br>      a = new String[0];  <br>      Console.WriteLine(a.GetType());   // &quot;System.String[]&quot;  <br> <br>      // Create a 1-dim, 0-based array, with no elements in it  <br>      a = Array.CreateInstance(typeof(String),   <br>         new Int32[] { 0 }, new Int32[] { 0 });  <br>      Console.WriteLine(a.GetType());   // &quot;System.String[]&quot;  <br> <br>      // Create a 1-dim, 1-based array, with no elements in it  <br>      a = Array.CreateInstance(typeof(String),    <br>
<hr>
<A name=415></a><b> </b><br>
<b>Chapter 16  Arrays </b><br>
<b>397</b><br>
         new Int32[] { 0 }, new Int32[] { 1 });  <br>      Console.WriteLine(a.GetType());   // &quot;System.String[*]&quot;  &lt;-- INTERESTING!  <br> <br>      Console.WriteLine();  <br> <br>      // Create a 2-dim, 0-based array, with no elements in it  <br>      a = new String[0, 0];  <br>      Console.WriteLine(a.GetType());   // &quot;System.String[,]&quot;  <br> <br>      // Create a 2-dim, 0-based array, with no elements in it  <br>      a = Array.CreateInstance(typeof(String),   <br>         new Int32[] { 0, 0 }, new Int32[] { 0, 0 });  <br>      Console.WriteLine(a.GetType());   // &quot;System.String[,]&quot;  <br> <br>      // Create a 2-dim, 1-based array, with no elements in it  <br>      a = Array.CreateInstance(typeof(String),   <br>         new Int32[] { 0, 0 }, new Int32[] { 1, 1 });  <br>      Console.WriteLine(a.GetType());   // &quot;System.String[,]&quot;  <br>   }  <br>}<br>
Next to each Console.WriteLine is a comment that indicates the output. For the single-<br>dimensional arrays, the zero-based arrays display a type name of System.String[], whereas <br>the 1-based array displays a type name of System.String[*]. The * indicates that the CLR <br>knows that this array is not zero-based. Note that C# does not allow you to declare a variable  <br>of type String[*], and therefore it is not possible to use C# syntax to access a single-<br>dimensional, non-zero­based array. Although you can call Array's GetValue and SetValue <br>methods to access the elements of the array, this access will be slow due to the overhead of <br>the method call.<br>
For multi-dimensional arrays, the zero-based and 1-based arrays all display the same type <br>name: System.String[,]. The CLR treats all multi-dimensional arrays as though they are <br><i>not</i> zero-based at runtime. This would make you think that the type name should display as <br>System.String[*,*]; however, the CLR doesn't use the *s for multi-dimensional arrays  <br>because they would always be present, and the asterisks would just confuse most developers.<br>
Accessing the elements of a single-dimensional, zero-based array is slightly faster than  <br>accessing the elements of a non-zero­based, single-dimensional array or a multi-dimen-<br>sional array. There are several reasons for this. First, there are specific IL instructions--such as <br>newarr, ldelem, ldelema, ldlen, and stelem--to manipulate single-dimensional, zero-based <br>arrays, and these special IL instructions cause the JIT compiler to emit optimized code. For <br>example, the JIT compiler will emit code that assumes that the array is zero-based, and this <br>means that an offset doesn't have to be subtracted from the specified index when accessing <br>an element. Second, in common situations, the JIT compiler is able to hoist the index range­<br>checking code out of the loop, causing it to execute just once. For example, look at the  <br>following commonly written code:<br>
<hr>
<A name=416></a><b>398 </b><br>
<b>Part III  Essential Types</b><br>
using System;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      Int32[] a = new Int32[5];  <br>      for(Int32 index = 0; index &lt; a.Length; index++) {  <br>         // Do something with a[index]  <br>      }  <br>   }  <br>}<br>
The first thing to notice about this code is the call to the array's Length property in the for <br>loop's test expression. Since Length is a property, querying the length actually represents a <br>method call. However, the JIT compiler knows that Length is a property on the Array class, <br>and the JIT compiler will actually generate code that calls the property just once and stores <br>the result in a temporary variable that will be checked with each iteration of the loop. The <br>result is that the JITted code is fast. In fact, some developers have underestimated the abili-<br>ties of the JIT compiler and have tried to write "clever code" in an attempt to help the JIT <br>compiler. However, any clever attempts that you come up with will almost certainly impact <br>performance negatively and make your code harder to read, reducing its maintainability. You <br>are better off leaving the call to the array's Length property in the code above instead of  <br>attempting to cache it in a local variable yourself.<br>
The second thing to notice about the code above is that the JIT compiler knows that the for <br>loop is accessing array elements 0 through Length - 1. So the JIT compiler produces code <br>that, at runtime, tests that al  array accesses wil  be within the array's valid range. Specifical y, <br>the JIT compiler produces code to check if (0 &gt;= a.GetLowerBound(0)) &amp;&amp; ((Length ­ 1) <br>&lt;= a.GetUpperBound(0)). This check occurs just before the loop. If the check is good, the <br>JIT compiler will not generate code inside the loop to verify that each array access is within <br>the valid range. This allows array access within the loop to be very fast.<br>
Unfortunately, as I alluded to earlier in this chapter, accessing elements of a non-zero­based <br>single-dimensional array or of a multi-dimensional array is much slower than a <br>single-dimensional, zero-based array. For these array types, the JIT compiler doesn't hoist <br>index checking outside of loops, so each array access validates the specified indices. In  <br>addition, the JIT compiler adds code to subtract the array's lower bounds from the specified <br>index, which also slows the code down, even if you're using a multi-dimensional array that <br>happens to be zero-based.<br>
So if performance is a concern to you, you might want to consider using an array of arrays (a <br>jagged array) instead of a rectangular array. C# and the CLR also allow you to access an array  <br>by using unsafe (non-verifiable) code, which is, in effect, a technique that allows you to turn <br>off the index bounds checking when accessing an array. Note that this unsafe array  <br>manipulation technique is usable with arrays whose elements are SByte, Byte, Int16, <br>UInt16, Int32, UInt32, Int64, UInt64, Char, Single, Double, Decimal, Boolean, an enu-<br>merated type, or a value type structure whose fields are any of the aforementioned types.<br>
<hr>
<A name=417></a><b> </b><br>
<b>Chapter 16  Arrays </b><br>
<b>399</b><br>
This is a very powerful feature that should be used with extreme caution because it allows <br>you to perform direct memory accesses. If these memory accesses are outside the bounds of <br>the array, an exception will not be thrown; instead, you will be corrupting memory, violating <br>type safety, and possibly opening a security hole! For this reason, the assembly containing <br>the unsafe code must either be granted full trust or at least have the Security Permission with <br>Skip Verification turned on.<br>
The following C# code demonstrates three techniques (safe, jagged, and unsafe), for accessing <br>a two-dimensional array:<br>
using System; <br>using System.Diagnostics; <br> <br>public static class Program { <br>   private const Int32 c_numElements = 10000; <br> <br>   public static void Main() { <br>      const Int32 testCount = 10; <br>      Stopwatch sw; <br> <br>      // Declare a two-dimensional array <br>      Int32[,] a2Dim = new Int32[c_numElements, c_numElements]; <br> <br>      // Declare a two-dimensional array as a jagged array (a vector of vectors) <br>      Int32[][] aJagged = new Int32[c_numElements][]; <br>      for (Int32 x = 0; x &lt; c_numElements; x++) <br>         aJagged[x] = new Int32[c_numElements]; <br> <br> <br>      // 1: Access all elements of the array using the usual, safe technique <br>      sw = Stopwatch.StartNew(); <br>      for (Int32 test = 0; test &lt; testCount; test++) <br>         Safe2DimArrayAccess(a2Dim); <br>      Console.WriteLine(&quot;{0}: Safe2DimArrayAccess&quot;, sw.Elapsed); <br> <br>      // 2: Access all elements of the array using the jagged array technique <br>      sw = Stopwatch.StartNew(); <br>      for (Int32 test = 0; test &lt; testCount; test++) <br>         SafeJaggedArrayAccess(aJagged); <br>      Console.WriteLine(&quot;{0}: SafeJaggedArrayAccess&quot;, sw.Elapsed); <br> <br>      // 3: Access all elements of the array using the unsafe technique <br>      sw = Stopwatch.StartNew(); <br>      for (Int32 test = 0; test &lt; testCount; test++) <br>         Unsafe2DimArrayAccess(a2Dim); <br>      Console.WriteLine(&quot;{0}: Unsafe2DimArrayAccess&quot;, sw.Elapsed); <br>      Console.ReadLine(); <br>   } <br> <br>   private static Int32 Safe2DimArrayAccess(Int32[,] a) { <br>      Int32 sum = 0; <br>      for (Int32 x = 0; x &lt; c_numElements; x++) { <br>         for (Int32 y = 0; y &lt; c_numElements; y++) { <br>
<hr>
<A name=418></a><b>400 </b><br>
<b>Part III  Essential Types</b><br>
            sum += a[x, y]; <br>         } <br>      } <br>      return sum; <br>   } <br> <br>   private static Int32 SafeJaggedArrayAccess(Int32[][] a) { <br>      Int32 sum = 0; <br>      for (Int32 x = 0; x &lt; c_numElements; x++) { <br>         for (Int32 y = 0; y &lt; c_numElements; y++) { <br>            sum += a[x][y]; <br>         } <br>      } <br>      return sum; <br>   } <br> <br>   private static unsafe Int32 Unsafe2DimArrayAccess(Int32[,] a) { <br>      Int32 sum = 0; <br>      fixed (Int32* pi = a) { <br>         for (Int32 x = 0; x &lt; c_numElements; x++) { <br>            Int32 baseOfDim = x * c_numElements; <br>            for (Int32 y = 0; y &lt; c_numElements; y++) { <br>               sum += pi[baseOfDim + y]; <br>            } <br>         } <br>      } <br>      return sum; <br>   } <br>}<br>
The Unsafe2DimArrayAccess method is marked with the unsafe modifier, which is required <br>to use C#'s fixed statement. To compile this code, you'll have to specify the /unsafe switch <br>when invoking the C# compiler or check the "Allow Unsafe Code" check box on the Build tab <br>of the Project Properties pane in Microsoft Visual Studio.<br>
When I run this program on my machine, I get the following output:<br>
00:00:02.0017692: Safe2DimArrayAccess <br>00:00:01.5197844: SafeJaggedArrayAccess <br>00:00:01.7343436: Unsafe2DimArrayAccess<br>
As you can see, the safe two-dimensional array access technique is the slowest. The safe jag-<br>ged array access technique takes a little less time to complete than the safe two-dimensional <br>array access technique. However, you should note that creating the jagged array is more <br>time-consuming than creating the multi-dimensional array because creating the jagged array  <br>requires an object to be allocated on the heap for each dimension, causing the garbage <br>collector to kick in periodically. So there is a trade-off: If you need to create a lot of "multi-<br>dimensional arrays" and you intend to access the elements infrequently, it is quicker to create <br>a multi-dimensional array. If you need to create the "multi-dimensional array" just once, and <br>you access its elements frequently, a jagged array will give you better performance. Certainly, <br>in most applications, the latter scenario is more common.<br>
<hr>
<A name=419></a><b> </b><br>
<b>Chapter 16  Arrays </b><br>
<b>401</b><br>
Finally, notice that the unsafe two-dimensional array access technique is about as fast as the <br>safe two-dimensional array access technique, but it would be considered the fastest of them <br>all if you also took into account that it accesses a single two-dimensional array (which is one <br>memory allocation), as compared to creating the jagged array (which requires many memory <br>allocations). Obviously, the unsafe technique has a time and place when it can best be used <br>by your own code, but beware that there are three serious downsides to using this technique:<br>
  The code that manipulates the array elements is more complicated to read and write <br>
than that which manipulates the elements using the other techniques because you are <br>using C#'s fixed statement and performing memory-address calculations.<br>
  If you make a mistake in the calculation, you are accessing memory that is not part of <br>
the array. This can result in an incorrect calculation, corruption of memory, a type-safety <br>violation, and a potential security hole.<br>
  Due to the potential problems, the CLR forbids unsafe code from running in reduced-<br>
security environments (like Microsoft Silverlight).<br>
<b>Unsafe Array Access and Fixed-Size Array</b><br>
Unsafe array access is very powerful because it allows you to access:<br>
  Elements within a managed array object that resides on the heap (as the previous  <br>
section demonstrated).<br>
  Elements within an array that resides on an unmanaged heap. The SecureString  <br>
example in Chapter 14, "Chars, Strings, and Working with Text," demonstrated  <br>using unsafe array access on an array returned from calling the System.Runtime.<br>InteropServices.Marshal class's SecureStringToCoTaskMemUnicode method.<br>
  Elements within an array that resides on the thread's stack.<br>
In cases in which performance is extremely critical, you could avoid allocating a managed <br>array object on the heap and instead allocate the array on the thread's stack by using C#'s <br>stackalloc statement (which works a lot like C's alloca function). The stackalloc state-<br>ment can be used to create a single-dimensional, zero-based array of value type elements <br>only, and the value type must not contain any reference type fields. Really, you should think <br>of this as allocating a block of memory that you can manipulate by using unsafe pointers, <br>and therefore, you cannot pass the address of this memory buffer to the vast majority of FCL <br>methods. Of course, the stack-allocated memory (array) will automatically be freed when the <br>method returns; this is where we get the performance improvement. Using this feature also <br>requires you specify the /unsafe switch to the C# compiler.<br>
The StackallocDemo method in the code below shows an example of how to use C#'s <br>stackalloc statement:<br>
<hr>
<A name=420></a><b>402 </b><br>
<b>Part III  Essential Types</b><br>
using System;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      StackallocDemo();  <br>      InlineArrayDemo();  <br>   }  <br> <br>   private static void StackallocDemo() {  <br>      unsafe {  <br>         const Int32 width = 20;  <br>         Char* pc = stackalloc Char[width]; // Allocates array on stack  <br>        <br>         String s = &quot;Jeffrey Richter&quot;;      // 15 characters  <br>           <br>         for (Int32 index = 0; index &lt; width; index++) {  <br>            pc[width - index - 1] =  <br>               (index &lt; s.Length) ? s[index] : '.';  <br>         }  <br> <br>         // The line below displays &quot;.....rethciR yerffeJ&quot;  <br>         Console.WriteLine(new String(pc, 0, width));   <br>      }  <br>   }  <br> <br>   private static void InlineArrayDemo() {  <br>      unsafe {  <br>         CharArray ca;                 // Allocates array on stack  <br>         Int32 widthInBytes = sizeof(CharArray);  <br>         Int32 width = widthInBytes / 2;  <br> <br>         String s = &quot;Jeffrey Richter&quot;; // 15 characters  <br> <br>         for (Int32 index = 0; index &lt; width; index++) {  <br>            ca.Characters[width - index - 1] =  <br>               (index &lt; s.Length) ? s[index] : '.';  <br>         }  <br> <br>         // The line below displays &quot;.....rethciR yerffeJ&quot;  <br>         Console.WriteLine(new String(ca.Characters, 0, width));  <br>      }  <br>   }  <br>}  <br> <br>internal unsafe struct CharArray {  <br>   // This array is embedded inline inside the structure  <br>   public fixed Char Characters[20];  <br>}<br>
Normally, because arrays are reference types, an array field defined in a structure is really  <br>just a pointer or reference to an array; the array itself lives outside of the structure's  <br>memory. However, it is possible to embed an array directly inside a structure as shown by  <br>the CharArray structure in the preceding code. To embed an array directly inside a structure, <br>there are several requirements:<br>
<hr>
<A name=421></a><b> </b><br>
<b>Chapter 16  Arrays </b><br>
<b>403</b><br>
  The type must be a structure (value type); you cannot embed an array inside a class <br>
(reference type).<br>
  The field or its defining structure must be marked with the unsafe keyword.<br>
  The array field must be marked with the fixed keyword.<br>
  The array must be single-dimensional and zero-based.<br>
  The array's element type must be one of the following types: Boolean, Char, SByte, <br>
Byte, Int32, UInt32, Int64, UInt64, Single, or Double.<br>
Inline arrays are typically used for scenarios that involve interoperating with unmanaged <br>code where the unmanaged data structure also has an inline array. However, inline arrays can <br>be used in other scenarios as well. The InlineArrayDemo method in the code shown earlier <br>offers an example of how to use an inline array. The InlineArrayDemo method performs the <br>same function as the StackallocDemo method; it just does it in a different way.<br>
<hr>
<A name=422></a><hr>
<A name=423></a>Chapter 17<br><b>Delegates</b><br>
<b>In this chapter:<br>A First Look at Delegates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405<br>Using Delegates to Call Back Static Methods. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 408<br>Using Delegates to Call Back Instance Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 409<br>Demystifying Delegates. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410<br>Using Delegates to Call Back Many Methods (Chaining) . . . . . . . . . . . . . . . . . . . 415<br>Enough with the Delegate Definitions Already (Generic Delegates) . . . . . . . . . 422<br>C#'s Syntactical Sugar for Delegates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 423<br>Delegates and Reflection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 431</b><br>
In this chapter, I talk about callback functions. Callback functions are an extremely useful <br>programming mechanism that has been around for years. The Microsoft .NET Framework <br>exposes a callback function mechanism by using <i>delegates</i>. Unlike callback mechanisms used <br>in other platforms, such as unmanaged C++, delegates offer much more functionality. For <br>example, delegates ensure that the callback method is type-safe, in keeping with one of the <br>most important goals of the common language runtime (CLR). Delegates also integrate the <br>ability to call multiple methods sequentially and support the calling of static methods as well <br>as instance methods.<br>
<b>A First Look at Delegates</b><br>
The C runtime's qsort function takes a pointer to a callback function to sort elements within <br>an array. In Microsoft Windows, callback functions are required for window procedures, hook <br>procedures, asynchronous procedure calls, and more. In the .NET Framework, callback  <br>methods are used for a whole slew of things. For example, you can register callback methods <br>to get a variety of notifications such as unhandled exceptions, window state changes, menu <br>item selections, file system changes, form control events, and completed asynchronous <br>operations.<br>
In unmanaged C/C++, the address of a non-member function is just a memory address. This <br>address doesn't carry any additional information such as the number of parameters the  <br>function expects, the types of these parameters, the function's return value type, and the <br>function's calling convention. In short, unmanaged C/C++ callback functions are not type-<br>safe (although they are a very lightweight mechanism).<br>
<b> </b><br>
<b> </b><br>
<b>405</b><br>
<hr>
<A name=424></a><b>406 </b><br>
<b>Part III  Essential Types</b><br>
In the .NET Framework, callback functions are just as useful and pervasive as in unmanaged <br>Windows programming. However, the .NET Framework provides a type-safe mechanism <br>called <i>delegates</i>. I'll start off the discussion of delegates by showing you how to use them. <br>The following code demonstrates how to declare, create, and use delegates.<br>
using System;  <br>using System.Windows.Forms;  <br>using System.IO;  <br> <br> <br>// Declare a delegate type; instances refer to a method that  <br>// takes an Int32 parameter and returns void.  <br>internal delegate void Feedback(Int32 value);  <br> <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      StaticDelegateDemo();  <br>      InstanceDelegateDemo();  <br>      ChainDelegateDemo1(new Program());  <br>      ChainDelegateDemo2(new Program());  <br>   }  <br> <br>   private static void StaticDelegateDemo() {  <br>      Console.WriteLine(&quot;----- Static Delegate Demo -----&quot;);  <br>      Counter(1, 3, null);  <br>      Counter(1, 3, new Feedback(Program.FeedbackToConsole));  <br>      Counter(1, 3, new Feedback(FeedbackToMsgBox)); // &quot;Program.&quot; is optional  <br>      Console.WriteLine();  <br>   }  <br> <br>   private static void InstanceDelegateDemo() {  <br>      Console.WriteLine(&quot;----- Instance Delegate Demo -----&quot;);  <br>      Program p = new Program();  <br>      Counter(1, 3, new Feedback(p.FeedbackToFile));  <br> <br>      Console.WriteLine();  <br>   }  <br> <br>   private static void ChainDelegateDemo1(Program p) {  <br>      Console.WriteLine(&quot;----- Chain Delegate Demo 1 -----&quot;);  <br>      Feedback fb1 = new Feedback(FeedbackToConsole);  <br>      Feedback fb2 = new Feedback(FeedbackToMsgBox);  <br>      Feedback fb3 = new Feedback(p.FeedbackToFile);  <br> <br>      Feedback fbChain = null;  <br>      fbChain = (Feedback) Delegate.Combine(fbChain, fb1);  <br>      fbChain = (Feedback) Delegate.Combine(fbChain, fb2);  <br>      fbChain = (Feedback) Delegate.Combine(fbChain, fb3);  <br>      Counter(1, 2, fbChain);  <br> <br>      Console.WriteLine();  <br>      fbChain = (Feedback)   <br>         Delegate.Remove(fbChain, new Feedback(FeedbackToMsgBox));  <br>      Counter(1, 2, fbChain);  <br>   }  <br> <br>
<hr>
<A name=425></a><b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>407</b><br>
   private static void ChainDelegateDemo2(Program p) {  <br>      Console.WriteLine(&quot;----- Chain Delegate Demo 2 -----&quot;);  <br>      Feedback fb1 = new Feedback(FeedbackToConsole);  <br>      Feedback fb2 = new Feedback(FeedbackToMsgBox);  <br>      Feedback fb3 = new Feedback(p.FeedbackToFile);  <br> <br>      Feedback fbChain = null;  <br>      fbChain += fb1;  <br>      fbChain += fb2;  <br>      fbChain += fb3;  <br>      Counter(1, 2, fbChain);  <br> <br>      Console.WriteLine();  <br>      fbChain -= new Feedback(FeedbackToMsgBox);  <br>      Counter(1, 2, fbChain);  <br>   }  <br>     <br>   private static void Counter(Int32 from, Int32 to, Feedback fb) {  <br>      for (Int32 val = from; val &lt;= to; val++) {  <br>         // If any callbacks are specified, call them  <br>         if (fb != null)   <br>            fb(val);  <br>      }  <br>   }  <br> <br>   private static void FeedbackToConsole(Int32 value) {  <br>      Console.WriteLine(&quot;Item=&quot; + value);  <br>   }  <br> <br>   private static void FeedbackToMsgBox(Int32 value) {  <br>      MessageBox.Show(&quot;Item=&quot; + value);  <br>   }  <br> <br>   private void FeedbackToFile(Int32 value) {  <br>      StreamWriter sw = new StreamWriter(&quot;Status&quot;, true);  <br>      sw.WriteLine(&quot;Item=&quot; + value);  <br>      sw.Close();  <br>   }  <br>}<br>
Now I'll describe what this code is doing. At the top, notice the declaration of the internal <br>delegate, Feedback. A delegate indicates the signature of a callback method. In this example, <br>a Feedback delegate identifies a method that takes one parameter (an Int32) and returns <br>void. In a way, a delegate is very much like an unmanaged C/C++ typedef that represents <br>the address of a function.<br>
The Program class defines a private, static method named Counter.<b> </b>This method counts <br>integers from the from argument to the to argument. The Counter method also takes an <br>fb, which is a reference to a Feedback delegate object. Counter iterates through all of the <br>integers, and for each integer, if the fb variable is not null, the callback method (specified <br>by the fb variable) is called. This callback method is passed the value of the item being pro-<br>cessed, the item number. The callback method can be designed and implemented to process <br>each item in any manner deemed appropriate.<br>
<hr>
<A name=426></a><IMG src="CLRviaCsharp-426_1.jpg"><br>
<b>408 </b><br>
<b>Part III  Essential Types</b><br>
<b>Using Delegates to Call Back Static Methods</b><br>
Now that you understand how the Counter method is designed and how it works, let's see <br>how to use delegates to call back static methods. The StaticDelegateDemo method that  <br>appears in the previous code sample is the focus of this section.<br>
The StaticDelegateDemo method calls the Counter method, passing null in the third  <br>parameter, which corresponds to Counter's fb parameter. Because Counter's fb parameter <br>receives null, each item is processed without calling any callback method.<br>
Next, the StaticDelegateDemo method calls Counter a second time, passing a newly con-<br>structed Feedback delegate object in the third parameter of the method call. This delegate <br>object is a wrapper around a method, allowing the method to be called back indirectly via <br>the wrapper. In this example, the name of the static method, Program.FeedbackToConsole, <br>is passed to the Feedback type's constructor, indicating that it is the method to be wrapped. <br>The reference returned from the new operator is passed to Counter as its third parameter. <br>Now when Counter executes, it will call the Program type's static FeedbackToConsole <br>method for each item in the series. FeedbackToConsole simply writes a string to the console <br>indicating the item being processed.<br>
<b>Note  </b>The FeedbackToConsole method is defined as private inside the Program type, but <br>the Counter method is able to call Program's private method. In this case, you might not  <br>expect a problem because both Counter and FeedbackToConsole are defined in the same type. <br>However, this code would work just fine even if the Counter method was defined in another type. <br>In short, it is not a security or accessibility violation for one type to have code that calls another <br>type's private member via a delegate as long as the delegate object is created by code that has <br>ample security/accessibility.<br>
The third call to Counter in the StaticDelegateDemo method is almost identical to the  <br>second call. The only difference is that the Feedback delegate object wraps the static <br>Program.FeedbackToMsgBox method. FeedbackToMsgBox builds a string indicating the  <br>item being processed. This string is then displayed in a message box.<br>
Everything in this example is type-safe. For instance, when constructing a Feedback delegate <br>object, the compiler ensures that the signatures of Program's FeedbackToConsole and <br>FeedbackToMsgBox methods are compatible with the signature defined by the Feedback <br>delegate. Specifically, both methods must take one argument (an Int32), and both methods <br>must have the same return type (void). If FeedbackToConsole had been defined like this:<br>
private static Boolean FeedbackToConsole(String value) {  <br>   ...  <br>}<br>
the C# compiler wouldn't compile the code and would issue the following error: &quot;error <br>CS0123: No overload for 'FeedbackToConsole' matches delegate 'Feedback'.&quot;<br>
<hr>
<A name=427></a><b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>409</b><br>
Both C# and the CLR allow for covariance and contra-variance of reference types when <br>binding a method to a delegate. <i>Covariance</i> means that a method can return a type that is <br>derived from the delegate's return type. <i>Contra-variance</i> means that a method can take a <br>parameter that is a base of the delegate's parameter type. For example, given a delegate  <br>defined like this:<br>
delegate Object MyCallback(FileStream s);<br>
it is possible to construct an instance of this delegate type bound to a method that is proto-<br>typed like this:<br>
String SomeMethod(Stream s);<br>
Here, SomeMethod's return type (String) is a type that is derived from the delegate's return <br>type (Object); this covariance is allowed. SomeMethod's parameter type (Stream) is a type <br>that is a base class of the delegate's parameter type (FileStream); this contra-variance is <br>allowed.<br>
Note that covariance and contra-variance are supported only for reference types, not for val-<br>ue types or for void. So, for example, I cannot bind the following method to the MyCallback <br>delegate:<br>
Int32 SomeOtherMethod(Stream s);<br>
Even though SomeOtherMethod's return type (Int32) is derived from MyCallback's return  <br>type (Object), this form of covariance is not allowed because Int32 is a value type. <br>Obviously, the reason why value types and void cannot be used for covariance and  <br>contra-variance is because the memory structure for these things varies, whereas the  <br>memory structure for reference types is always a pointer. Fortunately, the C# compiler will <br>produce an error if you attempt to do something that is not supported.<br>
<b>Using Delegates to Call Back Instance Methods</b><br>
I just explained how delegates can be used to call static methods, but they can also be used <br>to call instance methods for a specific object. To understand how calling back an instance <br>method works, look at the InstanceDelegateDemo method that appears in the code shown <br>at the beginning of this chapter.<br>
Notice that a Program object named p is constructed in the InstanceDelegateDemo method. <br>This Program object doesn't have any instance fields or properties associated with it; I  <br>created it merely for demonstration purposes. When the new Feedback delegate object is <br>constructed in the call to the Counter method, its constructor is passed p.FeedbackToFile. <br>This causes the delegate to wrap a reference to the FeedbackToFile method, which is an <br>instance method (not a static method). When Counter calls the callback method identified <br>by its fb argument, the FeedbackToFile instance method is called, and the address of the <br>
<hr>
<A name=428></a><b>410 </b><br>
<b>Part III  Essential Types</b><br>
recently constructed object p will be passed as the implicit this argument to the instance <br>method.<br>
The FeedbackToFile method works as the FeedbackToConsole and FeedbackToMsgBox <br>methods, except that it opens a file and appends the string to the end of the file. (The Status <br>file that the method creates can be found in the application's AppBase directory.)<br>
Again, the purpose of this example is to demonstrate that delegates can wrap calls to instance <br>methods as well as static methods. For instance methods, the delegate needs to know the <br>instance of the object the method is going to operate on. Wrapping an instance method is <br>useful because code inside the object can access the object's instance members. This means <br>that the object can have some state that can be used while the callback method is doing its <br>processing.<br>
<b>Demystifying Delegates</b><br>
On the surface, delegates seem easy to use: you define them by using C#'s delegate key-<br>word, you construct instances of them by using the familiar new operator, and you invoke the <br>callback by using the familiar method-call syntax (except instead of a method name, you use <br>the variable that refers to the delegate object).<br>
However, what's really going on is quite a bit more complex than what the earlier examples <br>illustrate. The compilers and the CLR do a lot of behind-the-scenes processing to hide the <br>complexity. In this section, I'll focus on how the compiler and the CLR work together to  <br>implement delegates. Having this knowledge will improve your understanding of delegates <br>and will teach you how to use them efficiently and effectively. I'll also touch on some  <br>additional features delegates make available.<br>
Let's start by reexamining this line of code:<br>
internal delegate void Feedback(Int32 value);<br>
When it sees this line, the compiler actually defines a complete class that looks something <br>like this:<br>
internal class Feedback : System.MulticastDelegate {  <br>   // Constructor  <br>   public Feedback(Object object, IntPtr method);  <br> <br>   // Method with same prototype as specified by the source code  <br>   public virtual void Invoke(Int32 value);  <br> <br>   // Methods allowing the callback to be called asynchronously  <br>   public virtual IAsyncResult BeginInvoke(Int32 value,   <br>      AsyncCallback callback, Object object);  <br>   public virtual void EndInvoke(IAsyncResult result);  <br>}<br>
<hr>
<A name=429></a><IMG src="CLRviaCsharp-429_1.jpg"><br>
<b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>411</b><br>
The class defined by the compiler has four methods: a constructor, Invoke, BeginInvoke, <br>and EndInvoke. In this chapter, I'll concentrate on the constructor and Invoke methods. I'll <br>address the BeginInvoke and EndInvoke methods in Chapter 27, "I/O-Bound Asynchronous <br>Operations," in the "The APM and Compute-Bound Operations" section.<br>
In fact, you can verify that the compiler did indeed generate this class automatically by  <br>examining the resulting assembly with ILDasm.exe, as shown in Figure 17-1.<br>
<b>FIGURE 17-1  </b>ILDasm.exe showing the metadata produced by the compiler for the delegate<br>
In this example, the compiler has defined a class called Feedback that is derived from the <br>System.MulticastDelegate type defined in the Framework Class Library (FCL). (All  <br>delegate types are derived from MulticastDelegate.)<br>
<b>Important  </b>The System.MulticastDelegate class is derived from System.Delegate, <br>which is itself derived from System.Object. The reason why there are two delegate classes is <br>historical and unfortunate; there should be just one delegate class in the FCL. Sadly, you need <br>to be aware of both of these classes because even though all delegate types you create have <br>MulticastDelegate as a base class, you'll occasionally manipulate your delegate types by using <br>methods defined by the Delegate class instead of the MulticastDelegate class. For example, <br>the Delegate class has static methods called Combine and Remove. (I explain what these  <br>methods do later.) The signatures for both of these methods indicate that they take Delegate <br>parameters. Because your delegate type is derived from MulticastDelegate, which is derived <br>from Delegate, instances of your delegate type can be passed to these methods.<br>
The class has private visibility because the delegate is declared as internal in the source <br>code. If the source code had indicated public visibility, the Feedback class the compiler <br>generated would also be public. You should be aware that delegate types can be defined <br>within a type (nested within another type) or at global scope. Basically, because delegates are <br>classes, a delegate can be defined anywhere a class can be defined.<br>
Because all delegate types are derived from MulticastDelegate, they inherit <br>MulticastDelegate's fields, properties, and methods. Of all of these members, three  <br>non-public fields are probably most significant. Table 17-1 describes these significant fields.<br>
<hr>
<A name=430></a><b>412 </b><br>
<b>Part III  Essential Types</b><br>
<b>TABLE 17-1  </b>MulticastDelegate<b>'s Significant Non-Public Fields</b><br>
<b>Field</b><br>
<b>Type</b><br>
<b>Description</b><br>
_target<br>
System.Object<br>
When the delegate object wraps a static method, this <br>field is null. When the delegate objects wraps an <br>instance method, this field refers to the object that <br>should be operated on when the callback method is <br>called. In other words, this field indicates the value that <br>should be passed for the instance method's implicit <br>this parameter.<br>
_methodPtr<br>
System.IntPtr<br>
An internal integer the CLR uses to identify the method <br>that is to be called back.<br>
_invocationList<br>
System.Object<br>
This field is usually null. It can refer to an array of  <br>delegates when building a delegate chain (discussed <br>later in this chapter).<br>
Notice that all delegates have a constructor that takes two parameters: a reference to an <br>object and an integer that refers to the callback method. However, if you examine the <br>source code, you'll see that I'm passing in values such as Program.FeedbackToConsole or <br>p.FeedbackToFile. Everything you've learned about programming tells you that this code <br>shouldn't compile!<br>
However, the C# compiler knows that a delegate is being constructed and parses the source <br>code to determine which object and method are being referred to. A reference to the object <br>is passed for the constructor's object parameter, and a special IntPtr value (obtained from <br>a MethodDef or MemberRef metadata token) that identifies the method is passed for the <br>method parameter. For static methods, null is passed for the object parameter. Inside the <br>constructor, these two arguments are saved in the _target and _methodPtr private fields, <br>respectively. In addition, the constructor sets the _invocationList field to null. I'll post-<br>pone discussing this _invocationList field until the next section, "Using Delegates to Call <br>Back Many Methods (Chaining)."<br>
So each delegate object is really a wrapper around a method and an object to be operated <br>on when the method is called. So if I have two lines of code that look like this:<br>
Feedback fbStatic   = new Feedback(Program.FeedbackToConsole);  <br>Feedback fbInstance = new Feedback(new Program().FeedbackToFile);<br>
the fbStatic and fbInstance variables refer to two separate Feedback delegate objects <br>that are initialized, as shown in Figure 17-2.<br>
<hr>
<A name=431></a><b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>413</b><br>
_target<br>
null<br>
fbStatic<br>
_methodPtr<br>
FeedbackToConsole<br>
_invocationList null<br>
_target<br>
(Program Object)<br>
fbInstance<br>
_methodPtr<br>
FeedbackToFile<br>
_invocationList null<br>
<b>FIGURE 17-2  </b>A variable that refers to a delegate to a static method and a variable that refers to a delegate to <br>an instance method<br>
The Delegate class defines two read-only public instance properties: Target and Method. <br>Given a reference to a delegate object, you can query these properties. The Target prop-<br>erty returns a reference to the object that will be operated on if the method is called back. <br>Basically, the Target property returns the value stored in the private _target field. If the <br>delegate object wraps a static method, Target returns null. The Method property returns a <br>reference to a System.Reflection.MethodInfo object that identifies the callback method. <br>Basically, the Method property has an internal mechanism that converts the value in the  <br>private _methodPtr field to a MethodInfo object and returns it.<br>
You could use this information in several ways. For example, you could check to see if a  <br>delegate object refers to an instance method of a specific type:<br>
Boolean DelegateRefersToInstanceMethodOfType(MulticastDelegate d, Type type) {  <br>   return((d.Target != null) &amp;&amp; d.Target.GetType() == type);  <br>}<br>
You could also write code to check if the callback method has a specific name (such as <br>FeedbackToMsgBox):<br>
Boolean DelegateRefersToMethodOfName(MulticastDelegate d, String methodName) {  <br>   return(d.Method.Name == methodName);  <br>}<br>
There are many other potential uses of these properties.<br>
Now that you know how delegate objects are constructed and what their internal structure <br>looks like, let's talk about how the callback method is invoked. For convenience, I've repeated <br>the code for the Counter method here:<br>
private static void Counter(Int32 from, Int32 to, Feedback fb) {  <br>   for (Int32 val = from; val &lt;= to; val++) {  <br>      // If any callbacks are specified, call them  <br>      if (fb != null)   <br>         fb(val);  <br>   }  <br>}<br>
<hr>
<A name=432></a><b>414 </b><br>
<b>Part III  Essential Types</b><br>
Look at the line of code just below the comment. The if statement first checks to see if fb <br>is not null. If fb is not null, on the next line, you see the code that invokes the callback <br>method. The null check is required because fb is really just a variable that <i>can</i> refer to a <br>Feedback delegate object; it could also be null. It might seem as if I'm calling a function <br>named fb and passing it one parameter (val). However, there is no function called fb. Again, <br>because it knows that fb is a variable that refers to a delegate object, the compiler generates <br>code to call the delegate object's Invoke method. In other words, the compiler sees this:<br>
fb(val);<br>
But the compiler generates code as though the source code said this:<br>
fb.Invoke(val);<br>
You can verify that the compiler produces code to call the delegate type's Invoke method by <br>using ILDasm.exe to examine the Intermediate Language (IL) code created for the Counter <br>method. Here is the IL for the Counter method. The instruction at IL_0009 in the figure indi-<br>cates the call to Feedback's Invoke method.<br>
.method private hidebysig static void  Counter(int32 from, <br>                                               int32 'to', <br>                                               class Feedback fb) cil managed <br>{ <br>  // Code size       23 (0x17) <br>  .maxstack  2 <br>  .locals init (int32 V_0) <br>  IL_0000:  ldarg.0 <br>  IL_0001:  stloc.0 <br>  IL_0002:  br.s       IL_0012 <br>  IL_0004:  ldarg.2 <br>  IL_0005:  brfalse.s  IL_000e <br>  IL_0007:  ldarg.2 <br>  IL_0008:  ldloc.0 <br>  IL_0009:  callvirt   instance void Feedback::Invoke(int32) <br>  IL_000e:  ldloc.0 <br>  IL_000f:  ldc.i4.1 <br>  IL_0010:  add <br>  IL_0011:  stloc.0 <br>  IL_0012:  ldloc.0 <br>  IL_0013:  ldarg.1 <br>  IL_0014:  ble.s      IL_0004 <br>  IL_0016:  ret <br>} // end of method Program::Counter<br>
In fact, you could modify the Counter method to call Invoke explicitly, as shown here:<br>
private static void Counter(Int32 from, Int32 to, Feedback fb) {  <br>   for (Int32 val = from; val &lt;= to; val++) {  <br>      // If any callbacks are specified, call them  <br>      if (fb != null)   <br>         fb.Invoke(val);  <br>   }  <br>}<br>
<hr>
<A name=433></a><b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>415</b><br>
You'll recall that the compiler defined the Invoke method when it defined the Feedback <br>class. When Invoke is called, it uses the private _target and <b>_</b>methodPtr fields to call the <br>desired method on the specified object. Note that the signature of the Invoke method <br>matches the signature of the delegate; because the Feedback delegate takes one Int32 <br>parameter and returns void, the Invoke method (as produced by the compiler) takes one <br>Int32 parameter and returns void.<br>
<b>Using Delegates to Call Back Many Methods (Chaining)</b><br>
By themselves, delegates are incredibly useful. But add in their support for chaining, and <br>delegates become even more useful. <i>Chaining</i> is a set or collection of delegate objects, and <br>it provides the ability to invoke, or call, all of the methods represented by the delegates in <br>the set. To understand this, see the ChainDelegateDemo1 method that appears in the code <br>shown at the beginning of this chapter. In this method, after the Console.WriteLine state-<br>ment, I construct three delegate objects and have variables--fb1, fb2,<b> </b>and fb3--refer to <br>each object, as shown in Figure 17-3.<br>
_target<br>
null<br>
fb1<br>
_methodPtr<br>
FeedbackToConsole<br>
_invocationList null<br>
_target<br>
null<br>
fb2<br>
_methodPtr<br>
FeedbackToMsgBox<br>
_invocationList null<br>
_target<br>
(Program Object)<br>
fb3<br>
_methodPtr<br>
FeedbackToFile<br>
_invocationList null<br>
<b>FIGURE 17-3  </b>Initial state of the delegate objects referred to by the fb1, fb2, and fb3 variables<br>
The reference variable to a Feedback delegate object, fbChain, is intended to refer to a <br>chain or set of delegate objects that wrap methods that can be called back. Initializing  <br>fbChain to null indicates that there currently are no methods to be called back. The <br>Delegate class's public, static Combine method is used to add a delegate to the chain:<br>
fbChain = (Feedback) Delegate.Combine(fbChain, fb1);<br>
When this line of code executes, the Combine method sees that we are trying to combine <br>null and fb1. Internally, Combine will simply return the value in fb1, and the fbChain vari-<br>able will be set to refer to the same delegate object referred to by the fb1 variable, as shown <br>in Figure 17-4.<br>
<hr>
<A name=434></a><b>416 </b><br>
<b>Part III  Essential Types</b><br>
fbChain<br>
_target<br>
null<br>
fb1<br>
_methodPtr<br>
FeedbackToConsole<br>
_invocationList null<br>
_target<br>
null<br>
fb2<br>
_methodPtr<br>
FeedbackToMsgBox<br>
_invocationList null<br>
_target<br>
(Program Object)<br>
fb3<br>
_methodPtr<br>
FeedbackToFile<br>
_invocationList null<br>
<b>FIGURE 17-4  </b>State of the delegate objects after inserting the first delegate in the chain<br>
To add another delegate to the chain, the Combine method is called again:<br>
fbChain = (Feedback) Delegate.Combine(fbChain, fb2);<br>
Internally, the Combine method sees that fbChain already refers to a delegate object, so <br>Combine will construct a new delegate object. This new delegate object initializes its private <br>_target and <b>_</b>methodPtr fields to values that are not important for this discussion. However, <br>what is important is that the <b>_</b>invocationList field is initialized to refer to an array of delegate <br>objects. The first element of this array (index 0) will be initialized to refer to the delegate that <br>wraps the FeedbackToConsole method (this is the delegate that fbChain currently refers <br>to). The second element of the array (index 1) will be initialized to refer to the delegate that <br>wraps the FeedbackToMsgBox method (this is the delegate that fb2 refers to). Finally,  <br>fbChain will be set to refer to the newly created delegate object, shown in Figure 17-5.<br>
To add the third delegate to the chain, the Combine method is called once again:<br>
fbChain = (Feedback) Delegate.Combine(fbChain, fb3);<br>
Again, Combine sees that fbChain already refers to a delegate object, and this causes a new <br>delegate object to be constructed, as shown in Figure 17-6. As before, this new delegate  <br>object initializes the private _target and _methodPtr fields to values unimportant to this <br>discussion, and the _invocationList field is initialized to refer to an array of delegate <br>objects. The first and second elements of this array (indexes 0 and 1) will be initialized to <br>refer to the same delegates the previous delegate object referred to in its array. The third <br>element of the array (index 2) will be initialized to refer to the delegate that wraps the <br>FeedbackToFile method (this is the delegate that fb3 refers to). Finally, fbChain will be set <br>to refer to this newly created delegate object. Note that the previously created delegate and <br>the array referred to by its _invocationList field are now candidates for garbage collection.<br>
<hr>
<A name=435></a><b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>417</b><br>
_target<br>
(not important)<br>
fbChain<br>
[0]<br>
_methodPtr<br>
(not important)<br>
[1]<br>
_invocationList<br>
_target<br>
null<br>
fb1<br>
_methodPtr<br>
FeedbackToConsole<br>
_invocationList null<br>
_target<br>
null<br>
fb2<br>
_methodPtr<br>
FeedbackToMsgBox<br>
_invocationList null<br>
_target<br>
(Program Object)<br>
fb3<br>
_methodPtr<br>
FeedbackToFile<br>
_invocationList null<br>
<b>FIGURE 17-5  </b>State of the delegate objects after inserting the second delegate in the chain<br>
_target<br>
(not important)<br>
[0]<br>
fbChain<br>
_methodPtr<br>
(not important)<br>
[1]<br>
_invocationList<br>
[2]<br>
_target<br>
(not important)<br>
[0]<br>
_methodPtr<br>
(not important)<br>
[1]<br>
_invocationList<br>
_target<br>
null<br>
fb1<br>
_methodPtr<br>
FeedbackToConsole<br>
_invocationList null<br>
_target<br>
null<br>
fb2<br>
_methodPtr<br>
FeedbackToMsgBox<br>
_invocationList null<br>
_target<br>
(Program Object)<br>
fb3<br>
_methodPtr<br>
FeedbackToFile<br>
_invocationList null<br>
<b>FIGURE 17-6  </b>Final state of the delegate objects when the chain is complete<br>
<hr>
<A name=436></a><b>418 </b><br>
<b>Part III  Essential Types</b><br>
After all of the code has executed to set up the chain, the fbChain variable is then passed to <br>the Counter method:<br>
Counter(1, 2, fbChain);<br>
Inside the Counter method is the code that implicitly calls the Invoke method on the <br>Feedback delegate object as I detailed earlier. When Invoke is called on the delegate  <br>referred to by fbChain, the delegate sees that the private _invocationList field is not <br>null, causing it to execute a loop that iterates through all of the elements in the array, calling <br>the method wrapped by each delegate. In this example, FeedbackToConsole will get called <br>first, followed by FeedbackToMsgBox, followed by FeedbackToFile.<br>
Feedback's Invoke method is essentially implemented something like this (in pseudocode):<br>
public void Invoke(Int32 value) {  <br>   Delegate[] delegateSet = _invocationList as Delegate[];  <br>   if (delegateSet != null) {  <br>      // This delegate's array indicates the delegates that should be called  <br>      foreach (Feedback d in delegateSet)  <br>         d(value);   // Call each delegate  <br>   } else {  <br>      // This delegate identifies a single method to be called back  <br>      // Call the callback method on the specified target object.  <br>      _methodPtr.Invoke(_target, value);   <br>      // The line above is an approximation of the actual code.  <br>      // What really happens cannot be expressed in C#.  <br>   }  <br>}<br>
Note that it is also possible to remove a delegate from a chain by calling Delegate's public, <br>static Remove method. This is demonstrated toward the end of the ChainDelegateDemo1 <br>method:<br>
fbChain = (Feedback) Delegate.Remove(fbChain, new Feedback(FeedbackToMsgBox));<br>
When Remove is called, it scans the delegate array (from the end toward index 0) maintained <br>inside the delegate object referred to by the first parameter (fbChain, in my example). <br>Remove is looking for a delegate entry whose _target and _methodPtr fields match those in <br>the second argument (the new Feedback delegate, in my example). If a match is found and <br>there is only one item left in the array, that array item is returned. If a match is found and <br>there are multiple items left in the array, a new delegate object is constructed--the  <br>_invocationList array created and initialized will refer to all items in the original array  <br>except for the item being removed, of course--and a reference to this new delegate object  <br>is returned. If you are removing the only element in the chain, Remove returns null. Note <br>that each call to Remove removes just one delegate from the chain; it does not remove all <br>delegates that have matching _target and _methodPtr fields.<br>
So far, I've shown examples in which my delegate type, Feedback, is defined as having a void <br>return value. However, I could have defined my Feedback delegate as follows:<br>
public delegate Int32 Feedback(Int32 value);<br>
<hr>
<A name=437></a><b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>419</b><br>
If I had, its Invoke method would have internally looked like this (again, in pseudocode):<br>
public Int32 Invoke(Int32 value) {  <br>   Int32 result;  <br>   Delegate[] delegateSet = _invocationList as Delegate[];  <br>   if (delegateSet != null) {  <br>      // This delegate's array indicates the delegates that should be called  <br>      foreach (Feedback d in delegateSet)  <br>         result = d(value);   // Call each delegate  <br>   } else {  <br>      // This delegate identifies a single method to be called back  <br>      // Call the callback method on the specified target object.  <br>      result = _methodPtr.Invoke(_target, value);  <br>      // The line above is an approximation of the actual code.  <br>      // What really happens cannot be expressed in C#.  <br>   }  <br>   return result;  <br>}<br>
As each delegate in the array is called, its return value is saved in the result variable. When <br>the loop is complete, the result variable will contain only the result of the last delegate <br>called (previous return values are discarded); this value is returned to the code that called <br>Invoke.<br>
<b>C#'s Support for Delegate Chains</b><br>
To make things easier for C# developers, the C# compiler automatically provides overloads of <br>the += and -= operators for instances of delegate types. These operators call  <br>Delegate.Combine and Delegate.Remove, respectively. Using these operators simplifies the <br>building of delegate chains. The ChainDelegateDemo1 and ChainDelegateDemo2 methods <br>in the source code shown at the beginning of this chapter produce absolutely identical IL <br>code. The only difference between the methods is that the ChainDelegateDemo2 method <br>simplifies the source code by taking advantage of C#'s <b>+=</b> and <b>-=</b> operators.<br>
If you require proof that the resulting IL code is identical for the two methods, you can build <br>the code and look at its IL for both methods by using ILDasm.exe. This will confirm that the <br>C# compiler did in fact replace all <b>+=</b> and <b>-=</b> operators with calls to the Delegate type's <br>public static Combine and Remove methods, respectively.<br>
<b>Having More Control over Delegate Chain Invocation</b><br>
At this point, you understand how to build a chain of delegate objects and how to invoke all <br>of the objects in that chain. All items in the chain are invoked because the delegate type's <br>Invoke method includes code to iterate through all of the items in the array, invoking each <br>item. This is obviously a very simple algorithm. And although this simple algorithm is good <br>enough for a lot of scenarios, it has many limitations. For example, the return values of <br>the callback methods are all discarded except for the last one. Using this simple algorithm, <br>
<hr>
<A name=438></a><b>420 </b><br>
<b>Part III  Essential Types</b><br>
there's no way to get the return values for all of the callback methods called. But this isn't the <br>only limitation. What happens if one of the invoked delegates throws an exception or blocks <br>for a very long time? Because the algorithm invoked each delegate in the chain serially, a <br>"problem" with one of the delegate objects stops all of the subsequent delegates in the chain <br>from being called. Clearly, this algorithm isn't robust.<br>
For those scenarios in which this algorithm is insufficient, the MulticastDelegate class offers <br>an instance method, GetInvocationList, that you can use to call each delegate in a chain <br>explicitly, using any algorithm that meets your needs:<br>
public abstract class MulticastDelegate : Delegate {  <br>   // Creates a delegate array where each element refers   <br>   // to a delegate in the chain.  <br>   public sealed override Delegate[] GetInvocationList();  <br>}<br>
The GetInvocationList method operates on a MulticastDelegate-derived object and <br>returns an array of Delegate references where each reference points to one of the chain's <br>delegate objects. Internally, GetInvocationList constructs an array and initializes it with <br>each element referring to a delegate in the chain; a reference to the array is then returned. If <br>the _invocationList field is null, the returned array contains one element that references <br>the only delegate in the chain: the delegate instance itself.<br>
You can easily write an algorithm that explicitly calls each object in the array. The following <br>code demonstrates:<br>
using System;  <br>using System.Text;  <br> <br>// Define a Light component.  <br>internal sealed class Light {  <br>   // This method returns the light's status.  <br>   public String SwitchPosition() {  <br>      return &quot;The light is off&quot;;  <br>   }  <br>}  <br> <br>// Define a Fan component.  <br>internal sealed class Fan {  <br>   // This method returns the fan's status.  <br>   public String Speed() {  <br>      throw new InvalidOperationException(&quot;The fan broke due to overheating&quot;);  <br>   }  <br>}  <br> <br>// Define a Speaker component.  <br>internal sealed class Speaker {  <br>   // This method returns the speaker's status.  <br>   public String Volume() {  <br>      return &quot;The volume is loud&quot;;  <br>   }  <br>}  <br> <br>
<hr>
<A name=439></a><b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>421</b><br>
public sealed class Program {  <br> <br>   // Definition of delegate that allows querying a component's status.  <br>   private delegate String GetStatus();  <br> <br>   public static void Main() {  <br>      // Declare an empty delegate chain.  <br>      GetStatus getStatus = null;  <br> <br>      // Construct the three components, and add their status methods   <br>      // to the delegate chain.  <br>      getStatus += new GetStatus(new Light().SwitchPosition);  <br>      getStatus += new GetStatus(new Fan().Speed);  <br>      getStatus += new GetStatus(new Speaker().Volume);  <br> <br>      // Show consolidated status report reflecting   <br>      // the condition of the three components.  <br>      Console.WriteLine(GetComponentStatusReport(getStatus));  <br>   }  <br> <br>   // Method that queries several components and returns a status report  <br>   private static String GetComponentStatusReport(GetStatus status) {  <br> <br>      // If the chain is empty, there is nothing to do.  <br>      if (status == null) return null;  <br> <br>      // Use this to build the status report.  <br>      StringBuilder report = new StringBuilder();  <br> <br>      // Get an array where each element is a delegate from the chain.  <br>      Delegate[] arrayOfDelegates = status.GetInvocationList();  <br> <br>      // Iterate over each delegate in the array.   <br>      foreach (GetStatus getStatus in arrayOfDelegates) {  <br> <br>         try {  <br>            // Get a component's status string, and append it to the report.  <br>            report.AppendFormat(&quot;{0}{1}{1}&quot;, getStatus(), Environment.NewLine);  <br>         }  <br>         catch (InvalidOperationException e) {  <br>            // Generate an error entry in the report for this component.  <br>            Object component = getStatus.Target;  <br>            report.AppendFormat(  <br>               &quot;Failed to get status from {1}{2}{0}   Error: {3}{0}{0}&quot;,  <br>               Environment.NewLine,  <br>               ((component == null) ? &quot;&quot; : component.GetType() + &quot;.&quot;),  <br>               getStatus.Method.Name,   <br>               e.Message);  <br>         }  <br>      }  <br> <br>      // Return the consolidated report to the caller.  <br>      return report.ToString();  <br>   }  <br>}<br>
<hr>
<A name=440></a><b>422 </b><br>
<b>Part III  Essential Types</b><br>
When you build and run this code, the following output appears:<br>
The light is off  <br> <br>Failed to get status from Fan.Speed  <br>   Error: The fan broke due to overheating  <br> <br>The volume is loud<br>
<b>Enough with the Delegate Definitions Already (Generic </b><br>
<b>Delegates)</b><br>
Many years ago, when the .NET Framework was just starting to be developed, Microsoft <br>introduced the notion of delegates. As programmers were adding classes to the FCL, they <br>would define new delegate types any place they introduced a callback method. Over time, <br>many, many delegates got defined. In fact, in MSCorLib.dll alone, close to 50 delegate types <br>are now defined. Let's just look at a few of them:<br>
public delegate void TryCode(Object userData); <br>public delegate void WaitCallback(Object state); <br>public delegate void TimerCallback(Object state); <br>public delegate void ContextCallback(Object state); <br>public delegate void SendOrPostCallback(Object state); <br>public delegate void ParameterizedThreadStart(Object obj);<br>
Do you notice anything similar about the few delegate definitions that I selected? They are <br>really all the same: a variable of any of these delegate types must refer to a method that <br>takes an Object and returns void. There is really no reason to have all of these delegate <br>types defined; there really just needs to be one.<br>
In fact, now that the .NET Framework supports generics, we really just need a few generic <br>delegates (defined in the System namespace) that represent methods that take up to 16 <br>arguments:<br>
public delegate void Action(); <br>
// OK, this one is not generic <br>
public delegate void Action&lt;T&gt;(T obj);  <br>public delegate void Action&lt;T1, T2&gt;(T1 arg1, T2 arg2);  <br>public delegate void Action&lt;T1, T2, T3&gt;(T1 arg1, T2 arg2, T3 arg3);  <br>... <br>public delegate void Action&lt;T1, ..., T16&gt;(T1 arg1, ..., T16 arg16);<br>
So the .NET Framework now ships with 17 Action delegates that range from having no  <br>arguments to having 16 arguments. If you ever need to call a method that has more than 16 <br>arguments, you will be forced to define your own delegate type, but this is very unlikely.<br>
In addition to the Action delegates, the .NET Framework ships with 17 Func delegates, which <br>allow the callback method to return a value:<br>
<hr>
<A name=441></a><IMG src="CLRviaCsharp-441_1.jpg"><br>
<b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>423</b><br>
public delegate TResult Func&lt;TResult&gt;(); <br>public delegate TResult Func&lt;T, TResult&gt;(T arg); <br>public delegate TResult Func&lt;T1, T2, TResult&gt;(T1 arg1, T2 arg2); <br>public delegate TResult Func&lt;T1, T2, T3, TResult&gt;(T1 arg1, T2 arg2, T3 arg3); <br>... <br>public delegate TResult Func&lt;T1,..., T16, TResult&gt;(T1 arg1, ..., T16 arg16);<br>
It is now recommended that these delegate types be used wherever possible instead of  <br>developers defining even more delegate types in their code. This reduces the number of <br>types in the system and also simplifies coding. However, you might have to define your own <br>delegate if you need to pass an argument by reference using the ref or out keyword:<br>
delegate void Bar(ref Int32 z);<br>
You may also have to do this if you want your delegate to take a variable number of argu-<br>ments via C#'s params keyword, if you want to specify any default values for any of your  <br>delegate's arguments, or if you need to constrain a delegate's generic type argument, as in <br>the following code:<br>
delegate void EventHandler&lt;TEventArgs&gt;(Object sender, TEventArgs e)  <br>   where TEventArgs : EventArgs;<br>
<b>Note  </b>The Action and Func delegate types that take 0 to 8 arguments are defined in  <br>MSCorLib.dll since methods that take this many of arguments are fairly commonplace. However, <br>the Action and Func delegate types that take 9 to 16 arguments are defined in System.Core.dll, <br>as methods that take this many arguments are rare. And, in fact, these delegate definitions are <br>mostly used internally by dynamic programming languages and are not generally used by  <br>developers directly.<br>
When using delegates that take generic arguments and return values, contra-variance and <br>covariance come into play, and it is recommended that you always take advantage of these <br>features because they have no ill effects and enable your delegates to be used in more  <br>scenarios. For more information about this, see the &quot;Delegate and Interface Contravariant <br>and Covariant Generic Type Arguments&quot; section in Chapter 12, &quot;Generics.&quot;<br>
<b>C#'s Syntactical Sugar for Delegates</b><br>
Most programmers find working with delegates to be cumbersome because the syntax is so <br>strange. For example, take this line of code:<br>
button1.Click += new EventHandler(button1_Click);<br>
where button1_Click is a method that looks something like this:<br>
void button1_Click(Object sender, EventArgs e) {  <br>   // Do something, the button was clicked...  <br>}<br>
<hr>
<A name=442></a><b>424 </b><br>
<b>Part III  Essential Types</b><br>
The idea behind the first line of code is to register the address of the button1_Click method <br>with a button control so that when the button is clicked, the method wil  be called. To most <br>programmers, it feels quite unnatural to construct an EventHandler delegate object just to <br>specify the address of the button1_Click method. However, constructing the EventHandler <br>delegate object is required for the CLR because this object provides a wrapper that ensures <br>that the method can be called only in a type-safe fashion. The wrapper also allows the call-<br>ing of instance methods and chaining. Unfortunately, most programmers don't want to think <br>about these details. Programmers would prefer to write the code above as follows:<br>
button1.Click += button1_Click;<br>
Fortunately, Microsoft's C# compiler offers programmers some syntax shortcuts when work-<br>ing with delegates. I'll explain all of these shortcuts in this section. One last point before we <br>begin: what I'm about to describe really boils down to C# syntactical sugar; these new syntax <br>shortcuts are really just giving programmers an easier way to produce the IL that must be <br>generated so that the CLR and other programming languages can work with delegates. This <br>also means that what I'm about to describe is specific to C#; other compilers might not offer <br>the additional delegate syntax shortcuts.<br>
<b>Syntactical Shortcut #1: No Need to Construct a Delegate </b><br>
<b>Object</b><br>
As demonstrated already, C# allows you to specify the name of a callback method without <br>having to construct a delegate object wrapper. Here is another example:<br>
internal sealed class AClass {  <br>   public static void CallbackWithoutNewingADelegateObject() {  <br>      ThreadPool.QueueUserWorkItem(SomeAsyncTask, 5);  <br>   }  <br> <br>   private static void SomeAsyncTask(Object o) {  <br>      Console.WriteLine(o);  <br>   }  <br>}<br>
Here, the ThreadPool class's static QueueUserWorkItem method expects a reference to a <br>WaitCallback delegate object that contains a reference to the SomeAsyncTask method. <br>Since the C# compiler is capable of inferring this on its own, it allows me to omit code that <br>constructs the WaitCallback delegate object, making the code much more readable and <br>understandable. Of course, when the code is compiled, the C# compiler does produce IL that <br>does, in fact, new up the WaitCallback delegate object--we just got a syntactical shortcut.<br>
<b>Syntactical Shortcut #2: No Need to Define a Callback Method</b><br>
In the code above, the name of the callback method, SomeAsyncTask, is passed to the <br>ThreadPool's QueueUserWorkItem method. C# allows you to write the code for the callback <br>
<hr>
<A name=443></a><IMG src="CLRviaCsharp-443_1.jpg"><br>
<b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>425</b><br>
method inline so it doesn't have to be written inside its very own method. For example, the <br>code above could be rewritten as follows:<br>
internal sealed class AClass {  <br>   public static void CallbackWithoutNewingADelegateObject() {  <br>      ThreadPool.QueueUserWorkItem( obj =&gt; Console.WriteLine(obj), 5);  <br>   }  <br>}<br>
Notice that the first "argument" to the QueueUserWorkItem method is code (which I itali-<br>cized)! More formally, the italicized code is called a C# <i>lambda expression, </i>and it is easy to <br>detect due to the use of C#'s lambda expression operator: =&gt;. You may use a lambda  <br>expression in your code where the compiler would normally expect to see a delegate. And, <br>when the compiler sees the use of this lambda expression, the compiler automatically defines <br>a new private method in the class (AClass, in this example). This new method is called an <br><i>anonymous function</i> because the compiler creates the name of the method for you auto-<br>matically, and normally, you wouldn't know its name. However, you could use a tool such as <br>ILDasm.exe to examine the compiler-generated code. After I wrote the code above and  <br>compiled it, I was able to see, by using ILDasm.exe, that the C# compiler decided to name <br>this method &lt;CallbackWithoutNewingADelegateObject&gt;b__0 and ensured that this  <br>method took a single Object argument and returned void.<br>
The compiler chose to start the method name with a &lt; sign because in C#, an identifier can-<br>not contain a &lt; sign; this ensures that you will not accidentally define a method that  <br>coincides with the name the compiler has chosen for you. Incidentally, while C# forbids  <br>identifiers to contain a &lt; sign, the CLR allows it, and that is why this works. Also, note that <br>while you could access the method via reflection by passing the method name as a string, <br>the C# language specification states that there is no guarantee of how the compiler gener-<br>ates the name. For example, each time you compile the code, the compiler could produce a <br>different name for the method.<br>
Using ILDasm.exe, you might also notice that the C# compiler applies the  <br>System.Runtime.CompilerServices.CompilerGeneratedAttribute attribute to this <br>method to indicate to various tools and utilities that this method was produced by a compiler <br>as opposed to a programmer. The code to the right of the =&gt; operator is then placed in this <br>compiler-generated method.<br>
<b>Note  </b>When writing a lambda expression, there is no way to apply your own custom attribute to  <br>the compiler-generated method. Furthermore, you cannot apply any method modifiers (such as <br>unsafe) to the method. But this is usually not a problem because anonymous methods gener-<br>ated by the compiler always end up being private, and the method is either static or nonstatic <br>depending on whether the method accesses any instance members. So there is no need to apply <br>modifiers such as public, protected, internal, virtual, sealed, override, or abstract to <br>the method.<br>
<hr>
<A name=444></a><b>426 </b><br>
<b>Part III  Essential Types</b><br>
Finally, if you write the code shown above and compile it, it's as if the C# compiler rewrote <br>your code to look like this (comments inserted by me):<br>
internal sealed class AClass {  <br>   // This private field is created to cache the delegate object.  <br>   // Pro: CallbackWithoutNewingADelegateObject will not create   <br>   //      a new object each time it is called.  <br>   // Con: The cached object never gets garbage collected  <br>   [CompilerGenerated]  <br>   private static WaitCallback &lt;&gt;9__CachedAnonymousMethodDelegate1;  <br> <br>   public static void CallbackWithoutNewingADelegateObject() {  <br>      if (&lt;&gt;9__CachedAnonymousMethodDelegate1 == null) {  <br>         // First time called, create the delegate object and cache it.  <br>         &lt;&gt;9__CachedAnonymousMethodDelegate1 =   <br>            new WaitCallback(&lt;CallbackWithoutNewingADelegateObject&gt;b__0);  <br>      }  <br>      ThreadPool.QueueUserWorkItem(&lt;&gt;9__CachedAnonymousMethodDelegate1, 5);  <br>   }  <br> <br>   [CompilerGenerated]  <br>   private static void &lt;CallbackWithoutNewingADelegateObject&gt;b__0(Object obj) {  <br>      Console.WriteLine(obj);  <br>   }  <br>}<br>
The lambda expression must match that of the WaitCallback delegate: it returns void and <br>takes an Object parameter. However, I specified the name of the parameter by simply put-<br>ting obj to the left of the =&gt; operator. On the right of the =&gt; operator, Console.WriteLine <br>happens to return void. However, if I had placed an expression that did not return void, the <br>compiler-generated code would just ignore the return value because the method that the <br>compiler generates must have a void return type to satisfy the WaitCallback delegate.<br>
It is also worth noting that the anonymous function is marked as private; this forbids <br>any code not defined within the type from accessing the method (although reflection will <br>reveal that the method does exist). Also, note that the anonymous method is marked as <br>static; this is because the code doesn't access any instance members (which it can't since <br>CallbackWithoutNewingADelegateObject is itself a static method. However, the code can <br>reference any static fields or static methods defined within the class. Here is an example:<br>
internal sealed class AClass {  <br>   private static String sm_name;  // A static field  <br> <br>   public static void CallbackWithoutNewingADelegateObject() {  <br>      ThreadPool.QueueUserWorkItem(  <br>         // The callback code can reference static members.  <br>         obj =&gt;Console.WriteLine(sm_name+ &quot;: &quot; + obj),  <br>         5);  <br>   }  <br>}<br>
<hr>
<A name=445></a><b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>427</b><br>
If the CallbackWithoutNewingADelegateObject method had not been static, the anony-<br>mous method's code could contain references to instance members. If it doesn't contain <br>references to instance members, the compiler will still produce a static anonymous method <br>since this is more efficient than an instance method because the additional this parameter is <br>not necessary. But, if the anonymous method's code does reference an instance member, the <br>compiler will produce a nonstatic anonymous method:<br>
internal sealed class AClass {  <br>   private String m_name;  // An instance field  <br> <br>   // An instance method  <br>   public void CallbackWithoutNewingADelegateObject() {  <br>      ThreadPool.QueueUserWorkItem(  <br>         // The callback code can reference instance members.  <br>         obj =&gt; Console.WriteLine(m_name+ &quot;: &quot; + obj),  <br>         5);  <br>   }  <br>}<br>
On the left-hand side of the =&gt; operator is where you specify the names of any arguments <br>that are to be passed to the lambda expression. There are some rules you must follow here. <br>See the examples below:<br>
// If the delegate takes no arguments, use () <br>Func&lt;String&gt; f = () =&gt; &quot;Jeff&quot;; <br> <br>// If the delegate takes 1+ arguments, you can explicitly specify the types <br>Func&lt;Int32, String&gt; f2 = (Int32 n) =&gt; n.ToString(); <br>Func&lt;Int32, Int32, String&gt; f3 = (Int32 n1, Int32 n2) =&gt; (n1 + n2).ToString(); <br> <br>// If the delegate takes 1+ arguments, the compiler can infer the types <br>Func&lt;Int32, String&gt; f4 = (n) =&gt; n.ToString(); <br>Func&lt;Int32, Int32, String&gt; f5 = (n1, n2) =&gt; (n1 + n2).ToString(); <br> <br>// If the delegate takes 1 argument, you can omit the ()s <br>Func&lt;Int32, String&gt; f6 = n =&gt; n.ToString(); <br> <br>// If the delegate has ref/out arguments, you must explicitly specify ref/out and the type <br>Bar b = (out Int32 n) =&gt; n = 5;<br>
For the last example, assume that Bar is defined as follows:<br>
delegate void Bar(out Int32 z);<br>
On the right-hand side of the =&gt; operator is where you specify the anonymous function <br>body. It is very common for the body to consist of a simple or complex expression that  <br>ultimately returns a non-void value. In the code just above, I was assigning lambda  <br>expressions that returned Strings to all the Func delegate variables. It is also quite  <br>common for the body to consist of a single statement. An example of this is when I called <br>ThreadPool.QueueUserWorkItem, passing it a lambda expression that called  <br>Console.WriteLine (which returns void).<br>
<hr>
<A name=446></a><IMG src="CLRviaCsharp-446_1.jpg"><br>
<IMG src="CLRviaCsharp-446_2.jpg"><br>
<b>428 </b><br>
<b>Part III  Essential Types</b><br>
If you want the body to consist of two or more statements, then you must enclose it in curly <br>braces. And if the delegate expects a return value, then you must have a return statement <br>inside the body. Here is an example:<br>
Func&lt;Int32, Int32, String&gt; f7 = (n1, n2) =&gt; { Int32 sum = n1 + n2; return sum.ToString(); };<br>
<b>Important  </b>In case it's not obvious, let me explicitly point out that the main benefit of lambda <br>expressions is that they remove a level of indirection from within your source code. Normally, <br>you'd have to write a separate method, give that method a name, and then pass the name of that <br>method where a delegate is required. The name gives you a way to refer to a body of code, and <br>if you need to refer to the same body of code from multiple locations in your source code, then <br>writing a method and giving it a name is a great way to go. However, if you need to have a body <br>of code that is referred to only once within your source code, then a lambda expression allows you <br>to put that code directly inline without having to assign it a name, thus increasing programmer <br>productivity.<br>
<b>Note  </b>When C# 2.0 came out, it introduced a feature called <i>anonymous methods.</i> Like lambda  <br>expressions (introduced in C# 3.0), anonymous methods describes a syntax for creating anony-<br>mous functions. It is now recommended (in section 7.14 of the C# Language Specification) that <br>developers use the newer lambda expression syntax rather than the older anonymous method <br>syntax because the lambda expression syntax is more terse, making code easier to write, read,  <br>and maintain. Of course, Microsoft's C# compiler continues to support parsing both syntaxes for <br>creating anonymous functions so that developers are not forced to modify any code that was <br>originally written for C# 2.0. In this book, I will explain and use only the lambda expression syntax.<br>
<b>Syntactical Shortcut #3: No Need to Wrap Local Variables in a </b><br>
<b>Class Manually to Pass Them to a Callback Method</b><br>
I've already shown how the callback code can reference other members defined in the class. <br>However, sometimes, you might like the callback code to reference local parameters or vari-<br>ables that exist in the defining method. Here's an interesting example:<br>
internal sealed class AClass {  <br>   public static void UsingLocalVariablesInTheCallbackCode(Int32 numToDo) {  <br>      // Some local variables  <br>      Int32[] squares = new Int32[numToDo];  <br>      AutoResetEvent done = new AutoResetEvent(false);  <br> <br>      // Do a bunch of tasks on other threads  <br>      for (Int32 n = 0; n &lt; squares.Length; n++) {  <br>         ThreadPool.QueueUserWorkItem(  <br>            obj =&gt; {   <br>               Int32 num = (Int32) obj;   <br> <br>               // This task would normally be more time consuming  <br>               squares[num] = num * num;   <br>                 <br>
<hr>
<A name=447></a><IMG src="CLRviaCsharp-447_1.jpg"><br>
<b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>429</b><br>
               // If last task, let main thread continue running  <br>               if (Interlocked.Decrement(ref numToDo) == 0)   <br>                  done.Set();   <br>            },   <br>            n);  <br>      }  <br> <br>      // Wait for all the other threads to finish  <br>      done.WaitOne();  <br> <br>      // Show the results  <br>      for (Int32 n = 0; n &lt; squares.Length; n++)   <br>         Console.WriteLine(&quot;Index {0}, Square={1}&quot;, n, squares[n]);  <br>   }  <br>}<br>
This example really shows off how easy C# makes implementing what used to be a pretty <br>complex task. The method above defines one parameter, numToDo, and two local variables, <br>squares and done. And the body of the lambda expression refers to these variables.<br>
Now imagine that the code in the body of the lambda expression is placed in a separate <br>method (as is required by the CLR). How would the values of the variables be passed to  <br>the separate method? The only way to do this is to define a new helper class that also  <br>defines a field for each value that you want passed to the callback code. In addition, the <br>callback code would have to be defined as an instance method in this helper class. Then, the <br>UsingLocalVariablesInTheCallbackCode method would have to construct an instance of <br>the helper class, initialize the fields from the values in its local variables, and then construct <br>the delegate object bound to the helper object/instance method.<br>
<b>Note  </b> When a lambda expression causes the compiler to generate a class with parameter/local <br>variables turned into fields, the lifetime of the objects that the variables refer to are lengthened. <br>Usually, a parameter/local variable goes out of scope at the last usage of the variable within a <br>method. However, turning the variable into a field causes the field to keep the object that it refers <br>to alive for the whole lifetime of the object containing the field. This is not a big deal in most  <br>applications, but it is something that you should be aware of.<br>
This is very tedious and error-prone work, and, of course, the C# compiler does all this for <br>you automatically. When you write the code shown above, it's as if the C# compiler rewrites <br>your code so that it looks something like this (comments inserted by me):<br>
internal sealed class AClass {  <br>   public static void UsingLocalVariablesInTheCallbackCode(Int32 numToDo) {  <br> <br>      // Some local variables  <br>      WaitCallback callback1 = null;  <br> <br>      // Construct an instance of the helper class  <br>      &lt;&gt;c__DisplayClass2 class1 = new &lt;&gt;c__DisplayClass2();  <br> <br>
<hr>
<A name=448></a><IMG src="CLRviaCsharp-448_1.jpg"><br>
<b>430 </b><br>
<b>Part III  Essential Types</b><br>
      // Initialize the helper class's fields  <br>      class1.numToDo = numToDo;  <br>      class1.squares = new Int32[class1.numToDo];  <br>      class1.done = new AutoResetEvent(false);  <br> <br>      // Do a bunch of tasks on other threads  <br>      for (Int32 n = 0; n &lt; class1.squares.Length; n++) {  <br>         if (callback1 == null) {  <br>            // New up delegate object bound to the helper object and  <br>            // its anonymous instance method  <br>            callback1 = new WaitCallback(  <br>               class1.&lt;UsingLocalVariablesInTheCallbackCode&gt;b__0);  <br>         }  <br> <br>         ThreadPool.QueueUserWorkItem(callback1, n);  <br>      }  <br> <br>      // Wait for all the other threads to finish  <br>      class1.done.WaitOne();  <br> <br>      // Show the results  <br>      for (Int32 n = 0; n &lt; class1.squares.Length; n++)   <br>         Console.WriteLine(&quot;Index {0}, Square={1}&quot;, n, class1.squares[n]);  <br>   }  <br> <br>   // The helper class is given a strange name to avoid potential   <br>   // conflicts and is private to forbid access from outside AClass  <br>   [CompilerGenerated]  <br>   private sealed class &lt;&gt;c__DisplayClass2 : Object {  <br> <br>      // One public field per local variable used in the callback code  <br>      public Int32[] squares;  <br>      public Int32 numToDo;  <br>      public AutoResetEvent done;  <br> <br>      // public parameterless constructor  <br>      public &lt;&gt;c__DisplayClass2 { }  <br> <br>      // Public instance method containing the callback code  <br>      public void &lt;UsingLocalVariablesInTheCallbackCode&gt;b__0(Object obj) {  <br>         Int32 num = (Int32) obj;  <br>         squares[num] = num * num;  <br>         if (Interlocked.Decrement(ref numToDo) == 0)  <br>            done.Set();  <br>      }  <br>   }  <br>}<br>
<b>Important  </b>Without a doubt, it doesn't take much for programmers to start abusing C#'s <br>lambda expression feature. When I first started using lambda expressions, it definitely took me <br>some time to get used to them. After all, the code that you write in a method is not actually in-<br>side that method, and this also can make debugging and single-stepping through the code a bit <br>more challenging. In fact, I'm amazed at how well the Microsoft Visual Studio debugger actually <br>handles stepping through lambda expressions in my source code.<br>
<hr>
<A name=449></a><b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>431</b><br>
I've set up a rule for myself: If I need my callback method to contain more than three lines of <br>code, I will not use a lambda expression; instead, I'll write the method manually and assign it  <br>a name of my own creation. But, used judiciously, lambda expressions can greatly increase  <br>programmer productivity as well as the maintainability of your code. Below is some code in <br>which using lambda expressions feels very natural. Without them, this code would be tedious  <br>to write, harder to read, and harder to maintain:<br>
// Create an initialize a String array  <br>String[] names = { &quot;Jeff&quot;, &quot;Kristin&quot;, &quot;Aidan&quot;, &quot;Grant&quot; };  <br> <br>// Get just the names that have a lowercase 'a' in them.  <br>Char charToFind = 'a';  <br>names = Array.FindAll(names, name =&gt; name.IndexOf(charToFind) &gt;= 0);  <br> <br>// Convert each string's characters to uppercase  <br>names = Array.ConvertAll(names, name =&gt; name.ToUpper());  <br> <br>// Display the results  <br>Array.ForEach(names, Console.WriteLine);<br>
<b>Delegates and Reflection</b><br>
So far in this chapter, the use of delegates has required the developer to know up front the <br>prototype of the method that is to be called back. For example, if fb is a variable that refer-<br>ences a Feedback delegate (see this chapter's first program listing), to invoke the delegate, <br>the code would look like this:<br>
fb(item);   // item is defined as Int32<br>
As you can see, the developer must know when coding how many parameters the callback <br>method requires and the types of those parameters. Fortunately, the developer almost  <br>always has this information, so writing code like the preceding code isn't a problem.<br>
In some rare circumstances, however, the developer doesn't have this information at compile <br>time. I showed an example of this in Chapter 11, "Events," when I discussed the EventSet <br>type. In this example, a dictionary maintained a set of different delegate types. At runtime, to <br>raise an event, one of the delegates was looked up in the dictionary and invoked. At compile <br>time, it wasn't possible to know exactly which delegate would be called and which parameters <br>were necessary to pass to the delegate's callback method.<br>
Fortunately, System.Delegate offers a few methods that allow you to create and invoke a <br>delegate when you just don't have all the necessary information about the delegate at  <br>compile time. Here are the corresponding methods that Delegate defines:<br>
public abstract class Delegate {  <br>   // Construct a 'type' delegate wrapping the specified static method.  <br>   public static Delegate CreateDelegate(Type type, MethodInfo method);  <br>   public static Delegate CreateDelegate(Type type, MethodInfo method,   <br>      Boolean throwOnBindFailure);  <br> <br>
<hr>
<A name=450></a><IMG src="CLRviaCsharp-450_1.jpg"><br>
<b>432 </b><br>
<b>Part III  Essential Types</b><br>
   // Construct a 'type' delegate wrapping the specified instance method.  <br>   public static Delegate CreateDelegate(Type type,   <br>      Object firstArgument, MethodInfo method); // firstArgument means 'this'  <br>   public static Delegate CreateDelegate(Type type,   <br>      Object firstArgument, MethodInfo method, Boolean throwOnBindFailure);  <br> <br>   // Invoke a delegate passing it parameters  <br>   public Object DynamicInvoke(params Object[] args);  <br>}<br>
All of the CreateDelegate methods here construct a new object of a Delegate-derived type <br>identified by the first parameter, type. The MethodInfo parameter indicates the method that <br>should be called back; you'd use reflection APIs (discussed in Chapter 23, "Assembly Loading <br>and Reflection") to obtain this value. If you want the delegate to wrap an instance method, <br>you will also pass to CreateDelegate a firstArgument parameter indicating the object that <br>should be passed as the this parameter (first argument) to the instance method. Finally, <br>CreateDelegate normally throws an ArgumentException if the delegate cannot bind to the <br>method specified by the method parameter. This can happen if the signature of the method <br>identified by method doesn't match the signature required by the delegate identified by the <br>type parameter. However, if you pass false for the throwOnBindFailure parameter, an <br>ArgumentException will not be thrown; null will be returned instead.<br>
<b>Important  </b>The System.Delegate class has many more overloads of the CreateDelegate <br>method that I do not show here. You should never call any of these other methods. As a matter <br>of fact, Microsoft regrets even defining them in the first place. The reason is because these other <br>methods identify the method to bind to by using a String instead of a MethodInfo. This means <br>that an ambiguous bind is possible causing your application to behave unpredictably.<br>
System.Delegate's DynamicInvoke method allows you to invoke a delegate object's call-<br>back method, passing a set of parameters that you determine at runtime. When you call <br>DynamicInvoke, it internally ensures that the parameters you pass are compatible with the <br>parameters the callback method expects. If they're compatible, the callback method is called. <br>If they're not, an ArgumentException is thrown. DynamicInvoke returns the object the  <br>callback method returned.<br>
The following code shows how to use the CreateDelegate and DynamicInvoke methods:<br>
using System;  <br>using System.Reflection;  <br>using System.IO;  <br> <br> <br>// Here are some different delegate definitions  <br>internal delegate Object TwoInt32s(Int32 n1, Int32 n2);  <br>internal delegate Object OneString(String s1);  <br> <br> <br>
<hr>
<A name=451></a><b> </b><br>
<b>Chapter 17  Delegates </b><br>
<b>433</b><br>
public static class Program {  <br>   public static void Main(String[] args) {  <br>      if (args.Length &lt; 2) {  <br>         String fileName = Path.GetFileNameWithoutExtension(  <br>             Assembly.GetEntryAssembly().Location);  <br>      String usage =  <br>         @&quot;Usage:&quot; +  <br>         &quot;{0}{1} delType methodName [Arg1] [Arg2]&quot; +  <br>         &quot;{0}   where delType must be TwoInt32s or OneString&quot;+  <br>         &quot;{0}   if delType is TwoInt32s, methodName must be Add or Subtract&quot; +  <br>         &quot;{0}   if delType is OneString, methodName must be NumChars or Reverse&quot; +  <br>         &quot;{0}&quot; +  <br>         &quot;{0}Examples:&quot; +  <br>         &quot;{0}   {1} TwoInt32s Add 123 321&quot; +  <br>         &quot;{0}   {1} TwoInt32s Subtract 123 321&quot; +  <br>         &quot;{0}   {1} OneString NumChars \&quot;Hello there\&quot;&quot; +  <br>         &quot;{0}   {1} OneString Reverse  \&quot;Hello there\&quot;&quot;;  <br>         Console.WriteLine(usage, Environment.NewLine, fileName);  <br>         return;  <br>      }  <br> <br>      // Convert the delType argument to a delegate type  <br>      Type delType = Type.GetType(args[0]);  <br>      if (delType == null) {  <br>         Console.WriteLine(&quot;Invalid delType argument: &quot; + args[0]);  <br>         return;  <br>      }  <br> <br>      Delegate d;  <br>      try {  <br>         // Convert the Arg1 argument to a method  <br>         MethodInfo mi = typeof(Program).GetMethod(args[1],   <br>            BindingFlags.NonPublic | BindingFlags.Static);  <br> <br>         // Create a delegate object that wraps the static method  <br>         d = Delegate.CreateDelegate(delType, mi);  <br>      }  <br>      catch (ArgumentException) {  <br>         Console.WriteLine(&quot;Invalid methodName argument: &quot; + args[1]);  <br>         return;  <br>      }  <br> <br>      // Create an array that will contain just the arguments  <br>      // to pass to the method via the delegate object  <br>      Object[] callbackArgs = new Object[args.Length - 2];  <br> <br>      if (d.GetType() == typeof(TwoInt32s)) {  <br>         try {  <br>            // Convert the String arguments to Int32 arguments  <br>            for (Int32 a = 2; a &lt; args.Length; a++)  <br>               callbackArgs[a - 2] = Int32.Parse(args[a]);  <br>         }  <br>         catch (FormatException) {  <br>            Console.WriteLine(&quot;Parameters must be integers.&quot;);  <br>            return;  <br>         }  <br>      }  <br> <br>
<hr>
<A name=452></a><b>434 </b><br>
<b>Part III  Essential Types</b><br>
      if (d.GetType() == typeof(OneString)) {  <br>         // Just copy the String argument  <br>         Array.Copy(args, 2, callbackArgs, 0, callbackArgs.Length);  <br>      }  <br> <br>      try {  <br>         // Invoke the delegate and show the result  <br>         Object result = d.DynamicInvoke(callbackArgs);  <br>         Console.WriteLine(&quot;Result = &quot; + result);  <br>      }  <br>      catch (TargetParameterCountException) {  <br>         Console.WriteLine(&quot;Incorrect number of parameters specified.&quot;);  <br>      }  <br>   }  <br> <br> <br>   // This callback method takes 2 Int32 arguments  <br>   private static Object Add(Int32 n1, Int32 n2) {  <br>      return n1 + n2;  <br>   }  <br> <br>   // This callback method takes 2 Int32 arguments  <br>   private static Object Subtract(Int32 n1, Int32 n2) {  <br>      return n1 - n2;  <br>   }  <br> <br>   // This callback method takes 1 String argument  <br>   private static Object NumChars(String s1) {  <br>      return s1.Length;  <br>   }  <br> <br>   // This callback method takes 1 String argument  <br>   private static Object Reverse(String s1) {  <br>      Char[] chars = s1.ToCharArray();  <br>      Array.Reverse(chars);  <br>      return new String(chars);  <br>   }  <br>}<br>
<hr>
<A name=453></a>Chapter 18<br><b>Custom Attributes</b><br>
<b>In this chapter:<br>Using Custom Attributes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435<br>Defining Your Own Attribute Class  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439<br>Attribute Constructor and Field/Property Data Types . . . . . . . . . . . . . . . . . . . . . 443<br>Detecting the Use of a Custom Attribute . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 444<br>Matching Two Attribute Instances Against Each Other . . . . . . . . . . . . . . . . . . . . 448<br>Detecting the Use of a Custom Attribute Without Creating  <br>   Attribute-Derived Objects . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451<br>Conditional Attribute Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 454</b><br>
In this chapter, I'll discuss one of the most innovative features the Microsoft .NET Framework <br>has to offer: <i>custom attributes</i>. Custom attributes allow you to declaratively annotate your <br>code constructs, thereby enabling special features. Custom attributes allow information to be <br>defined and applied to almost any metadata table entry. This extensible metadata information <br>can be queried at runtime to dynamically alter the way code executes. As you use the various <br>.NET Framework technologies (Windows Forms, Web Forms, XML Web services, and so on), <br>you'll see that they all take advantage of custom attributes, allowing developers to express <br>their intentions within code very easily. A solid understanding of custom attributes is neces-<br>sary for any .NET Framework developer.<br>
<b>Using Custom Attributes</b><br>
Attributes, such as public, private, static, and so on, can be applied to types and  <br>members. I think we'd all agree on the usefulness of applying attributes, but wouldn't it be <br>even more useful if we could define our own attributes? For example, what if I could define a <br>type and somehow indicate that the type can be remoted via serialization? Or maybe I could <br>apply an attribute to a method to indicate that certain security permissions must be granted <br>before the method can execute.<br>
Of course, creating and applying user-defined attributes to types and methods would be <br>great and convenient, but it would require the compiler to be aware of these attributes so it <br>would emit the attribute information into the resulting metadata. Because compiler vendors <br>usually prefer not to release the source code for their compiler, Microsoft came up with  <br>another way to allow user-defined attributes. This mechanism, called <i>custom attributes</i>, is an <br>
<b> </b><br>
<b> </b><br>
<b>435</b><br>
<hr>
<A name=454></a><b>436 </b><br>
<b>Part III  Essential Types</b><br>
incredibly powerful mechanism that's useful at both application design time and runtime. <br>Anyone can define and use custom attributes, and all compilers that target the common  <br>language runtime (CLR) must be designed to recognize custom attributes and emit them into <br>the resulting metadata.<br>
The first thing you should realize about custom attributes is that they're just a way to  <br>associate additional information with a target. The compiler emits this additional information <br>into the managed module's metadata. Most attributes have no meaning for the compiler; <br>the compiler simply detects the attributes in the source code and emits the corresponding <br>metadata.<br>
The .NET Framework Class Library (FCL) defines literally hundreds of custom attributes that <br>can be applied to items in your own source code. Here are some examples:<br>
  Applying the DllImport attribute to a method informs the CLR that the implementa-<br>
tion of the method is actually in unmanaged code contained in the specified DLL.<br>
  Applying the Serializable attribute to a type informs the serialization formatters that <br>
an instance's fields may be serialized and deserialized.<br>
  Applying the AssemblyVersion attribute to an assembly sets the version number of <br>
the assembly.<br>
  Applying the Flags attribute to an enumerated type causes the enumerated type to <br>
act as a set of bit flags.<br>
Following is some C# code with many attributes applied to it. In C#, you apply a custom at-<br>tribute to a target by placing the attribute in square brackets immediately before the target. <br>It's not important to understand what this code does. I just want you to see what attributes <br>look like.<br>
using System;  <br>using System.Runtime.InteropServices;  <br> <br>[StructLayout(LayoutKind.Sequential, CharSet = CharSet.Auto)]  <br>internal sealed class OSVERSIONINFO {   <br>   public OSVERSIONINFO() {  <br>      OSVersionInfoSize = (UInt32) Marshal.SizeOf(this);  <br>   }  <br> <br>   public UInt32 OSVersionInfoSize = 0;  <br>   public UInt32 MajorVersion      = 0;   <br>   public UInt32 MinorVersion      = 0;   <br>   public UInt32 BuildNumber       = 0;   <br>   public UInt32 PlatformId        = 0;  <br> <br>   [MarshalAs(UnmanagedType.ByValTStr, SizeConst = 128)]  <br>   public String CSDVersion        = null;  <br>}  <br> <br>
<hr>
<A name=455></a><b> </b><br>
<b>Chapter 18  Custom Attributes </b><br>
<b>437</b><br>
internal sealed class MyClass {  <br>   [DllImport(&quot;Kernel32&quot;, CharSet = CharSet.Auto, SetLastError = true)]  <br>   public static extern Boolean GetVersionEx([In, Out] OSVERSIONINFO ver);  <br>}<br>
In this case, the StructLayout attribute is applied to the OSVERSIONINFO class, the <br>MarshalAs attribute is applied to the CSDVersion field, the DllImport attribute is applied <br>to the GetVersionEx method, and the In and Out attributes are applied to GetVersionEx's <br>ver parameter. Every programming language defines the syntax a developer must use in or-<br>der to apply a custom attribute to a target. Microsoft Visual Basic .NET, for example, requires <br>angle brackets (&lt;, &gt;) instead of square brackets.<br>
The CLR allows attributes to be applied to just about anything that can be represented in a <br>file's metadata. Most commonly, attributes are applied to entries in the following definition <br>tables: TypeDef (classes, structures, enumerations, interfaces, and delegates), MethodDef <br>(including constructors), ParamDef, FieldDef, PropertyDef, EventDef, AssemblyDef, and <br>ModuleDef. Specifically, C# allows you to apply an attribute only to source code that defines <br>any of the following targets: assembly, module, type (class, struct, enum, interface, delegate), <br>field, method (including constructors), method parameter, method return value, property, <br>event, and generic type parameter.<br>
When you're applying an attribute, C# allows you to specify a prefix specifically indicating <br>the target the attribute applies to. The following code shows all of the possible prefixes. In <br>many cases, if you leave out the prefix, the compiler can still determine the target an attri-<br>bute applies to, as shown in the previous example. In some cases, the prefix must be speci-<br>fied to make your intentions clear to the compiler. The prefixes shown in italics below are <br>mandatory.<br>
using System;  <br> <br>[assembly: SomeAttr]           // Applied to assembly  <br>[module:   SomeAttr]           // Applied to module  <br> <br>[type:     SomeAttr]           // Applied to type  <br>internal sealed class SomeType&lt;[typevar: SomeAttr] T&gt; {   // Applied to generic type variable <br> <br>   [field: SomeAttr]           // Applied to field  <br>   public Int32 SomeField = 0;  <br> <br>   [return: SomeAttr]          // Applied to return value  <br>   [method: SomeAttr]          // Applied to method  <br>   public Int32 SomeMethod(  <br>      [param: SomeAttr]        // Applied to parameter  <br>      Int32 SomeParam) { return SomeParam; }  <br> <br>   [property: SomeAttr]        // Applied to property  <br>   public String SomeProp {   <br>      [method: SomeAttr]       // Applied to get accessor method  <br>      get { return null; }   <br>
<hr>
<A name=456></a><IMG src="CLRviaCsharp-456_1.jpg"><br>
<b>438 </b><br>
<b>Part III  Essential Types</b><br>
   }  <br> <br>   [event:  SomeAttr]          // Applied to event  <br>   [field:  SomeAttr]          // Applied to compiler-generated field  <br>   [method: SomeAttr]          // Applied to compiler-generated add &amp; remove methods  <br>   public event EventHandler SomeEvent;  <br>}<br>
Now that you know how to apply a custom attribute, let's find out what an attribute really <br>is. A custom attribute is simply an instance of a type. For Common Language Specification <br>(CLS) compliance, custom attribute classes must be derived, directly or indirectly, from <br>the public abstract System.Attribute class. C# allows only CLS-compliant attributes. By <br>examining the .NET Framework SDK documentation, you'll see that the following classes <br>(from the earlier example) are defined: StructLayoutAttribute, MarshalAsAttribute, <br>DllImportAttribute, InAttribute, and OutAttribute.<b> </b>All of these classes happen to be <br>defined in the System.Runtime.InteropServices namespace, but attribute classes can be <br>defined in any namespace. Upon further examination, you'll notice that all of these classes <br>are derived from System.Attribute, as all CLS-compliant attribute classes must be.<br>
<b>Note  </b>When applying an attribute to a target in source code, the C# compiler allows you to <br>omit the Attribute suffix to reduce programming typing and to improve the readability of the <br>source code. My code examples in this chapter take advantage of this C# convenience. For exam-<br>ple, my source code contains [DllImport(...)] instead of [DllImportAttribute(...)].<br>
As I mentioned earlier, an attribute is an instance of a class. The class must have a public <br>constructor so that instances of it can be created. So when you apply an attribute to a target, <br>the syntax is similar to that for calling one of the class's instance constructors. In addition, a <br>language might permit some special syntax to allow you to set any public fields or proper-<br>ties associated with the attribute class. Let's look at an example. Recall the application of the <br>DllImport attribute as it was applied to the GetVersionEx method earlier:<br>
[DllImport(&quot;Kernel32&quot;, CharSet = CharSet.Auto, SetLastError = true)]<br>
The syntax of this line should look pretty strange to you because you could never use syntax <br>like this when calling a constructor. If you examine the DllImportAttribute class in the <br>documentation, you'll see that its constructor requires a single String parameter. In this  <br>example, &quot;Kernel32&quot; is being passed for this parameter. A constructor's parameters are <br>called <i>positional parameters</i> and are mandatory; the parameter must be specified when the <br>attribute is applied.<br>
What are the other two "parameters"? This special syntax allows you to set any public fields <br>or properties of the DllImportAttribute object after the object is constructed. In this <br>example, when the DllImportAttribute object is constructed and &quot;Kernel32&quot; is passed <br>to the constructor, the object's public instance fields, CharSet and SetLastError, are set <br>to CharSet.Auto and true, respectively. The "parameters" that set fields or properties are <br>
<hr>
<A name=457></a><b> </b><br>
<b>Chapter 18  Custom Attributes </b><br>
<b>439</b><br>
called <i>named parameters</i> and are optional because the parameters don't have to be specified <br>when you're applying an instance of the attribute. A little later on, I'll explain what causes an <br>instance of the DllImportAttribute class to actually be constructed.<br>
Also note that it's possible to apply multiple attributes to a single target. For example, in <br>this chapter's first program listing, the GetVersionEx method's ver parameter has both the <br>In and Out attributes applied to it. When applying multiple attributes to a single target, be <br>aware that the order of attributes has no significance. Also, in C#, each attribute can be en-<br>closed in square brackets, or multiple attributes can be comma-separated within a single set <br>of square brackets. If the attribute class's constructor takes no parameters, the parentheses <br>are optional. Finally, as mentioned earlier, the Attribute suffix is also optional. The following  <br>lines behave identically and demonstrate all of the possible ways of applying multiple <br>attributes:<br>
[Serializable][Flags]  <br>[Serializable, Flags]  <br>[FlagsAttribute, SerializableAttribute]  <br>[FlagsAttribute()][Serializable()]<br>
<b>Defining Your Own Attribute Class</b><br>
You know that an attribute is an instance of a class derived from System.Attribute, and <br>you also know how to apply an attribute. Let's now look at how to define your own custom  <br>attribute classes. Say you're the Microsoft employee responsible for adding the bit flag <br>support to enumerated types. To accomplish this, the first thing you have to do is define a <br>FlagsAttribute class:<br>
namespace System {  <br>   public class FlagsAttribute : System.Attribute {  <br>      public FlagsAttribute() {  <br>      }  <br>   }  <br>}<br>
Notice that the FlagsAttribute class inherits from Attribute; this is what makes the <br>FlagsAttribute class a CLS-compliant custom attribute. In addition, the class's name <br>has a suffix of Attribute; this follows the standard convention but is not mandatory. <br>Finally, all non-abstract attributes must contain at least one public constructor. The simple <br>FlagsAttribute constructor takes no parameters and does absolutely nothing.<br>
<hr>
<A name=458></a><IMG src="CLRviaCsharp-458_1.jpg"><br>
<b>440 </b><br>
<b>Part III  Essential Types</b><br>
<b>Important  </b>You should think of an attribute as a logical state container. That is, while an attribute <br>type is a class, the class should be simple. The class should offer just one public constructor that <br>accepts the attribute's mandatory (or positional) state information, and the class can offer public  <br>fields/properties that accept the attribute's optional (or named) state information. The class <br>should not offer any public methods, events, or other members.<br>
In general, I always discourage the use of public fields, and I still discourage them for attributes. <br>It is much better to use properties because this allows more flexibility if you ever decide to <br>change how the attribute class is implemented.<br>
So far, instances of the FlagsAttribute class can be applied to any target, but this attribute <br>should really be applied to enumerated types only. It doesn't make sense to apply the  <br>attribute to a property or a method. To tell the compiler where this attribute can legally be <br>applied, you apply an instance of the System.AttributeUsageAttribute class to the  <br>attribute class. Here's the new code:<br>
namespace System {  <br>   [AttributeUsage(AttributeTargets.Enum, Inherited = false)]  <br>   public class FlagsAttribute : System.Attribute {  <br>      public FlagsAttribute() {  <br>      }  <br>   }  <br>}<br>
In this new version, I've applied an instance of AttributeUsageAttribute to the attribute. <br>After all, the attribute type is just a class, and a class can have attributes applied to it. The <br>AttributeUsage attribute is a simple class that allows you to specify to a compiler where <br>your custom attribute can legally be applied. All compilers have built-in support for this  <br>attribute and generate errors when a user-defined custom attribute is applied to an invalid <br>target. In this example, the AttributeUsage attribute specifies that instances of the Flags <br>attribute can be applied only to enumerated type targets.<br>
Because all attributes are just types, you can easily understand the <br>AttributeUsageAttribute class. Here's what the FCL source code for the class looks like:<br>
[Serializable]  <br>[AttributeUsage(AttributeTargets.Class, Inherited=true)]  <br>public sealed class AttributeUsageAttribute : Attribute {  <br>   internal static AttributeUsageAttribute Default =   <br>      new AttributeUsageAttribute(AttributeTargets.All);  <br> <br>   internal Boolean m_allowMultiple = false;  <br>   internal AttributeTargets m_attributeTarget = AttributeTargets.All;  <br>   internal Boolean m_inherited = true;  <br> <br>   // This is the one public constructor  <br>   public AttributeUsageAttribute(AttributeTargets validOn) {  <br>      m_attributeTarget = validOn;  <br>   }  <br> <br>
<hr>
<A name=459></a><b> </b><br>
<b>Chapter 18  Custom Attributes </b><br>
<b>441</b><br>
   internal AttributeUsageAttribute(AttributeTargets validOn,   <br>      Boolean allowMultiple, Boolean inherited) {  <br>      m_attributeTarget = validOn;  <br>      m_allowMultiple = allowMultiple;  <br>      m_inherited = inherited;  <br>   }  <br> <br>   public Boolean AllowMultiple {   <br>      get { return m_allowMultiple; }  <br>      set { m_allowMultiple = value; }  <br>   }  <br> <br>   public Boolean Inherited {   <br>      get { return m_inherited; }  <br>      set { m_inherited = value; }  <br>   }  <br> <br>   public AttributeTargets ValidOn {   <br>      get { return m_attributeTarget; }  <br>   }  <br>}<br>
As you can see, the AttributeUsageAttribute class has a public constructor that allows <br>you to pass bit flags that indicate where your attribute can legally be applied. The  <br>System.AttributeTargets enumerated type is defined in the FCL as follows:<br>
[Flags, Serializable]  <br>public enum AttributeTargets {  <br>   Assembly         = 0x0001,  <br>   Module           = 0x0002,  <br>   Class            = 0x0004,  <br>   Struct           = 0x0008,  <br>   Enum             = 0x0010,  <br>   Constructor      = 0x0020,  <br>   Method           = 0x0040,  <br>   Property         = 0x0080,  <br>   Field            = 0x0100,  <br>   Event            = 0x0200,  <br>   Interface        = 0x0400,  <br>   Parameter        = 0x0800,  <br>   Delegate         = 0x1000,  <br>   ReturnValue      = 0x2000,  <br>   GenericParameter = 0x4000,  <br>   All           = Assembly    | Module    | Class    | Struct | Enum  |   <br>                   Constructor | Method    | Property | Field  | Event |   <br>                   Interface   | Parameter | Delegate | ReturnValue |   <br>                   GenericParameter  <br>}<br>
The AttributeUsageAttribute class offers two additional public properties that can <br>optionally be set when the attribute is applied to an attribute class: AllowMultiple and <br>Inherited.<br>
<hr>
<A name=460></a><IMG src="CLRviaCsharp-460_1.jpg"><br>
<b>442 </b><br>
<b>Part III  Essential Types</b><br>
For most attributes, it makes no sense to apply them to a single target more than once. For <br>example, nothing is gained by applying the Flags or Serializable attributes more than <br>once to a single target. In fact, if you tried to compile the code below, the compiler would <br>report the following message: &quot;error CS0579: Duplicate 'Flags' attribute.&quot;<br>
[Flags][Flags]  <br>internal enum Color {  <br>   Red  <br>}<br>
For a few attributes, however, it does make sense to apply the attribute multiple times to a <br>single target. In the FCL, the ConditionalAttribute attribute class allows multiple instances <br>of itself to be applied to a single target. If you don't explicitly set AllowMultiple to true, <br>your attribute can be applied no more than once to a selected target.<br>
AttributeUsageAttribute's other property, Inherited, indicates if the attribute should  <br>be applied to derived classes and overriding methods when applied on the base class. The <br>following code demonstrates what it means for an attribute to be inherited:<br>
[AttributeUsage(AttributeTargets.Class | AttributeTargets.Method, Inherited=true)]  <br>internal class TastyAttribute : Attribute {  <br>}  <br> <br>[Tasty][Serializable]  <br>internal class BaseType {  <br> <br>   [Tasty] protected virtual void DoSomething() { }  <br>}  <br> <br>internal class DerivedType : BaseType {  <br>   protected override void DoSomething() { }  <br>}<br>
In this code, DerivedType and its DoSomething method are both considered Tasty because <br>the TastyAttribute class is marked as inherited. However, DerivedType is not serializable <br>because the FCL's SerializableAttribute class is marked as a noninherited attribute.<br>
Be aware that the .NET Framework considers targets only of classes, methods, properties, <br>events, fields, method return values, and parameters to be inheritable. So when you're defin-<br>ing an attribute type, you should set Inherited to true only if your targets include any of <br>these targets. Note that inherited attributes do not cause additional metadata to be emitted <br>for the derived types into the managed module. I'll say more about this a little later in the <br>"Detecting the Use of a Custom Attribute" section.<br>
<b>Note  </b>If you define your own attribute class and forget to apply an AttributeUsage attribute <br>to your class, the compiler and the CLR will assume that your attribute can be applied to all tar-<br>gets, can be applied only once to a single target, and is inherited. These assumptions mimic the <br>default field values in the AttributeUsageAttribute class.<br>
<hr>
<A name=461></a><b> </b><br>
<b>Chapter 18  Custom Attributes </b><br>
<b>443</b><br>
<b>Attribute Constructor and Field/Property Data Types</b><br>
When defining your own custom attribute class, you can define its constructor to take pa-<br>rameters that must be specified by developers when they apply an instance of your attribute <br>type. In addition, you can define nonstatic public fields and properties in your type that iden-<br>tify settings that a developer can optionally choose for an instance of your attribute class.<br>
When defining an attribute class's instance constructor, fields, and properties, you must  <br>restrict yourself to a small subset of data types. Specifically, the legal set of data types is <br>limited to the following: Boolean, Char, Byte, SByte, Int16, UInt16, Int32, UInt32, Int64, <br>UInt64, Single, Double, String, Type,<b> </b>Object, or an enumerated type. In addition, you  <br>can use a single-dimensional, zero-based array of any of these types. However, you should <br>avoid using arrays because a custom attribute class whose constructor takes an array is not <br>CLS-compliant.<br>
When applying an attribute, you must pass a compile-time constant expression that matches <br>the type defined by the attribute class. Wherever the attribute class defines a Type parameter, <br>Type field, or Type property, you must use C#'s typeof operator, as shown in the following <br>code. Wherever the attribute class defines an Object parameter, Object field, or Object <br>property, you can pass an Int32, String, or any other constant expression (including null). <br>If the constant expression represents a value type, the value type will be boxed at runtime <br>when an instance of the attribute is constructed.<br>
Here's an example of an attribute and its usage:<br>
using System;  <br> <br>internal enum Color { Red }  <br> <br>[AttributeUsage(AttributeTargets.All)]  <br>internal sealed class SomeAttribute : Attribute {  <br>   public SomeAttribute(String name, Object o, Type[] types) {  <br>      // 'name' refers to a String  <br>      // 'o' refers to one of the legal types (boxing if necessary)  <br>      // 'types' refers to a 1-dimension, 0-based array of Types  <br>   }  <br>}  <br> <br>[Some(&quot;Jeff&quot;, Color.Red, new Type[] { typeof(Math), typeof(Console) })]  <br>internal sealed class SomeType {  <br>}<br>
Logically, when a compiler detects a custom attribute applied to a target, the compiler  <br>constructs an instance of the attribute class by calling its constructor, passing it any specified <br>parameters. Then the compiler initializes any public fields and properties using the values <br>specified via the enhanced constructor syntax. Now that the custom attribute object is  <br>initialized, the compiler serializes the attribute object's state out to the target's metadata <br>table entry.<br>
<hr>
<A name=462></a><IMG src="CLRviaCsharp-462_1.jpg"><br>
<b>444 </b><br>
<b>Part III  Essential Types</b><br>
<b>Important  </b>I've found this to be the best way for developers to think of custom attributes: in-<br>stances of classes that have been serialized to a byte stream that resides in metadata. Later, at <br>runtime, an instance of the class can be constructed by deserializing the bytes contained in the <br>metadata. In reality, what actually happens is that the compiler emits the information necessary <br>to create an instance of the attribute class into metadata. Each constructor parameter is written <br>out with a 1-byte type ID followed by the value. After "serializing" the constructor's parameters, <br>the compiler emits each of the specified field and property values by writing out the field/prop-<br>erty name followed by a 1-byte type ID and then the value. For arrays, the count of elements is <br>saved first, followed by each individual element.<br>
<b>Detecting the Use of a Custom Attribute</b><br>
Defining an attribute class is useless by itself. Sure, you could define attribute classes all you <br>want and apply instances of them all you want, but this would just cause additional metadata <br>to be written out to the assembly--the behavior of your application code wouldn't change.<br>
In Chapter 15, "Enumerated Types and Bit Flags," you saw that applying the Flags attribute to <br>an enumerated type altered the behavior of System.Enum's ToString and Format methods. <br>The reason that these methods behave differently is that they check at runtime if the  <br>enumerated type that they're operating on has the Flags attribute metadata associated <br>with it. Code can look for the presence of attributes by using a technology called <i>reflection</i>. <br>I'll give some brief demonstrations of reflection here, but I'll discuss it fully in Chapter 23, <br>"Assembly Loading and Reflection."<br>
If you were the Microsoft employee responsible for implementing Enum's Format method, <br>you would implement it like this:<br>
public static String Format(Type enumType, Object value, String format) {  <br> <br>   // Does the enumerated type have an instance of  <br>   // the FlagsAttribute type applied to it?   <br>   if (enumType.IsDefined(typeof(FlagsAttribute), false)) {  <br>      // Yes; execute code treating value as a bit flag enumerated type.  <br>      ...  <br>   } else {  <br>      // No; execute code treating value as a normal enumerated type.  <br>      ...  <br>   }  <br>   ...  <br>}<br>
This code calls Type's IsDefined method, effectively asking the system to look up the meta-<br>data for the enumerated type and see whether an instance of the FlagsAttribute class is <br>associated with it. If IsDefined returns true, an instance of FlagsAttribute is associated <br>with the enumerated type, and the Format method knows to treat the value as though it <br>contained a set of bit flags. If IsDefined returns false, Format treats the value as a normal <br>enumerated type.<br>
<hr>
<A name=463></a><b> </b><br>
<b>Chapter 18  Custom Attributes </b><br>
<b>445</b><br>
So if you define your own attribute classes, you must also implement some code that checks <br>for the existence of an instance of your attribute class (on some target) and then execute <br>some alternate code path. This is what makes custom attributes so useful!<br>
The FCL offers many ways to check for the existence of an attribute. If you're checking for <br>the existence of an attribute via a System.Type object, you can use the IsDefined method <br>as shown earlier. However, sometimes you want to check for an attribute on a target other <br>than a type, such as an assembly, a module, or a method. For this discussion, let's concentrate <br>on the methods defined by the System.Attribute class. You'll recall that all CLS-compliant <br>attributes are derived from System.Attribute. This class defines three static methods for <br>retrieving the attributes associated with a target: IsDefined, GetCustomAttributes, and <br>GetCustomAttribute. Each of these functions has several overloaded versions. For example, <br>each method has a version that works on type members (classes, structs, enums, interfaces, <br>delegates, constructors, methods, properties, fields, events, and return types), parameters, <br>modules, and assemblies. There are also versions that allow you to tell the system to walk up <br>the derivation hierarchy to include inherited attributes in the results. Table 18-1 briefly  <br>describes what each method does.<br>
<b>TABLE 18-1  </b>System.Attribute<b>'s Methods That Reflect over Metadata Looking for <br>Instances of CLS-Compliant Custom Attributes</b><br>
<b>Method</b><br>
<b>Description</b><br>
IsDefined<br>
Returns true if there is at least one instance of the specified <br>Attribute-derived class associated with the target. This method <br>is efficient because it doesn't construct (deserialize) any instances of <br>the attribute class.<br>
GetCustomAttributes<br>
Returns an array in which each element is an instance of the speci-<br>fied attribute class that was applied to the target. If no attribute <br>class is given to the method, the array contains the instances of all <br>applied attributes, whatever class they have. Each instance is con-<br>structed (deserialized) by using the parameters, fields, and proper-<br>ties specified during compilation. If the target has no instances of the <br>specified attribute class, an empty array is returned. This method is <br>typically used with attributes that have AllowMultiple set to true <br>or to list all applied attributes.<br>
GetCustomAttribute<br>
Returns an instance of the specified attribute class that was ap-<br>plied to the target. The instance is constructed (deserialized) <br>by using the parameters, fields, and properties specified during <br>compilation. If the target has no instances of the specified at-<br>tribute class, null is returned. If the target has multiple instances <br>of the specified attribute applied to it, a System.Reflection.<br>AmbiguousMatchException exception is thrown. This method <br>is typically used with attributes that have AllowMultiple set to <br>false.<br>
<hr>
<A name=464></a><IMG src="CLRviaCsharp-464_1.jpg"><br>
<b>446 </b><br>
<b>Part III  Essential Types</b><br>
If you just want to see if an attribute has been applied to a target, you should call IsDefined <br>because it's more efficient than the other two methods. However, you know that when an <br>attribute is applied to a target, you can specify parameters to the attribute's constructor and <br>optionally set fields and properties. Using IsDefined won't construct an attribute object, call <br>its constructor, or set its fields and properties.<br>
If you want to construct an attribute object, you must call either GetCustomAttributes or <br>GetCustomAttribute. Every time one of these methods is called, it constructs new instances <br>of the specified attribute type and sets each of the instance's fields and properties based on <br>the values specified in the source code. These methods return references to fully constructed <br>instances of the applied attribute classes.<br>
When you call any of these methods, internally, they must scan the managed module's meta-<br>data, performing string comparisons to locate the specified custom attribute class. Obviously, <br>these operations take time. If you're performance conscious, you should consider caching <br>the result of calling these methods rather than calling them repeatedly asking for the same <br>information.<br>
The System.Reflection namespace defines several classes that allow you to examine the <br>contents of a module's metadata: Assembly, Module, ParameterInfo, MemberInfo, Type, <br>MethodInfo, ConstructorInfo, FieldInfo, EventInfo,<b> </b>PropertyInfo, and their respective  <br>*Builder classes. All of these classes also offer IsDefined and GetCustomAttributes <br>methods. Only System.Attribute offers the very convenient GetCustomAttribute method.<br>
The version of GetCustomAttributes defined by the reflection classes returns an array of <br>Object instances (Object[]) instead of an array of Attribute instances (Attribute[]). This <br>is because the reflection classes are able to return objects of non­CLS-compliant attribute <br>classes. You shouldn't be concerned about this inconsistency because non­CLS-compliant <br>attributes are incredibly rare. In fact, in all of the time I've been working with the .NET <br>Framework, I've never even seen one.<br>
<b>Note  </b>Be aware that only Attribute, Type, and MethodInfo classes implement reflection <br>methods that honor the Boolean inherit parameter. All other reflection methods that look up <br>attributes ignore the inherit parameter and do not check the inheritance hierarchy. If you need <br>to check the presence of an inherited attribute for events, properties, fields, constructors, or  <br>parameters, you must call one of Attribute's methods.<br>
There's one more thing you should be aware of: When you pass a class to IsDefined, <br>GetCustomAttribute, or GetCustomAttributes, these methods search for the application <br>of the attribute class you specify or any attribute class derived from the specified class. If your <br>code is looking for a specific attribute class, you should perform an additional check on the <br>returned value to ensure that what these methods returned is the exact class you're looking <br>
<hr>
<A name=465></a><b> </b><br>
<b>Chapter 18  Custom Attributes </b><br>
<b>447</b><br>
for. You might also want to consider defining your attribute class to be sealed to reduce  <br>potential confusion and eliminate this extra check.<br>
Here's some sample code that lists all of the methods defined within a type and displays the <br>attributes applied to each method. The code is for demonstration purposes; normally, you <br>wouldn't apply these particular custom attributes to these targets as I've done here.<br>
using System;  <br>using System.Diagnostics;  <br>using System.Reflection;  <br> <br> <br>[assembly: CLSCompliant(true)]  <br> <br> <br>[Serializable]  <br>[DefaultMemberAttribute(&quot;Main&quot;)]  <br>[DebuggerDisplayAttribute(&quot;Richter&quot;, Name = &quot;Jeff&quot;, Target = typeof(Program))]  <br>public sealed class Program {  <br>   [Conditional(&quot;Debug&quot;)]  <br>   [Conditional(&quot;Release&quot;)]  <br>   public void DoSomething() { }  <br> <br>   public Program() {  <br>   }  <br> <br>   [CLSCompliant(true)]  <br>   [STAThread]  <br>   public static void Main() {  <br>      // Show the set of attributes applied to this type  <br>      ShowAttributes(typeof(Program));  <br> <br>      // Get the set of methods associated with the type  <br>      MemberInfo[] members = typeof(Program).FindMembers(  <br>         MemberTypes.Constructor | MemberTypes.Method,  <br>         BindingFlags.DeclaredOnly | BindingFlags.Instance |  <br>         BindingFlags.Public | BindingFlags.Static,  <br>         Type.FilterName, &quot;*&quot;);  <br> <br>      foreach (MemberInfo member in members) {  <br>         // Show the set of attributes applied to this member  <br>         ShowAttributes(member);  <br>      }  <br>   }  <br> <br>   private static void ShowAttributes(MemberInfo attributeTarget) {  <br>      Attribute[] attributes = Attribute.GetCustomAttributes(attributeTarget);  <br>        <br>      Console.WriteLine(&quot;Attributes applied to {0}: {1}&quot;,  <br>         attributeTarget.Name, (attributes.Length == 0 ? &quot;None&quot; : String.Empty));  <br> <br>      foreach (Attribute attribute in attributes) {  <br>         // Display the type of each applied attribute  <br>         Console.WriteLine(&quot;  {0}&quot;, attribute.GetType().ToString());  <br>
<hr>
<A name=466></a><b>448 </b><br>
<b>Part III  Essential Types</b><br>
           <br>         if (attribute is DefaultMemberAttribute)  <br>            Console.WriteLine(&quot;    MemberName={0}&quot;,  <br>               ((DefaultMemberAttribute) attribute).MemberName);  <br> <br>         if (attribute is ConditionalAttribute)  <br>            Console.WriteLine(&quot;    ConditionString={0}&quot;,  <br>               ((ConditionalAttribute) attribute).ConditionString);  <br> <br>         if (attribute is CLSCompliantAttribute)  <br>            Console.WriteLine(&quot;    IsCompliant={0}&quot;,  <br>               ((CLSCompliantAttribute) attribute).IsCompliant);  <br> <br>         DebuggerDisplayAttribute dda = attribute as DebuggerDisplayAttribute;  <br>         if (dda != null) {  <br>            Console.WriteLine(&quot;    Value={0}, Name={1}, Target={2}&quot;,  <br>               dda.Value, dda.Name, dda.Target);  <br>         }  <br>      }  <br>      Console.WriteLine();  <br>   }  <br>}<br>
Building and running this application yields the following output:<br>
Attributes applied to Program:  <br>  System.SerializableAttribute  <br>  System.Diagnostics.DebuggerDisplayAttribute  <br>    Value=Richter, Name=Jeff, Target=Program  <br>  System.Reflection.DefaultMemberAttribute  <br>    MemberName=Main  <br> <br>Attributes applied to DoSomething:  <br>  System.Diagnostics.ConditionalAttribute  <br>    ConditionString=Release  <br>  System.Diagnostics.ConditionalAttribute  <br>    ConditionString=Debug  <br> <br>Attributes applied to Main:  <br>  System.CLSCompliantAttribute  <br>    IsCompliant=True  <br>  System.STAThreadAttribute  <br> <br>Attributes applied to .ctor: None<br>
<b>Matching Two Attribute Instances Against Each Other</b><br>
Now that your code knows how to check if an instance of an attribute is applied to a target, <br>it might want to check the fields of the attribute to see what values they have. One way to <br>do this is to write code that explicitly checks the values of the attribute class's fields. However, <br>System.Attribute overrides Object's Equals method, and internal y, this method compares <br>the types of the two objects. If they are not identical, Equals returns false. If the types are <br>
<hr>
<A name=467></a><b> </b><br>
<b>Chapter 18  Custom Attributes </b><br>
<b>449</b><br>
identical, then Equals uses reflection to compare the values of the two attribute objects' <br>fields (by calling Equals for each field). If all the fields match, then true is returned; other-<br>wise, false is returned. You might override Equals in your own attribute class to remove the <br>use of reflection, improving performance.<br>
System.Attribute also exposes a virtual Match method that you can override to provide <br>richer semantics. The default implementation of Match simply calls Equals and returns its <br>result. The following code demonstrates how to override Equals and Match (which returns <br>true if one attribute represents a subset of the other) and then shows how Match is used:<br>
using System;  <br> <br> <br>[Flags]  <br>internal enum Accounts {  <br>   Savings   = 0x0001,  <br>   Checking  = 0x0002,  <br>   Brokerage = 0x0004  <br>}  <br> <br> <br>[AttributeUsage(AttributeTargets.Class)]  <br>internal sealed class AccountsAttribute : Attribute {  <br>   private Accounts m_accounts;  <br> <br>   public AccountsAttribute(Accounts accounts) {  <br>      m_accounts = accounts;  <br>   }  <br> <br> <br>   public override Boolean Match(Object obj) {  <br>      // If the base class implements Match and the base class  <br>      // is not Attribute, then uncomment the line below.  <br>      // if (!base.Match(obj)) return false;  <br> <br>      // Since 'this' isn't null, if obj is null,   <br>      // then the objects can't match  <br>      // NOTE: This line may be deleted if you trust   <br>      // that the base type implemented Match correctly.  <br>      if (obj == null) return false;  <br> <br>      // If the objects are of different types, they can't match  <br>      // NOTE: This line may be deleted if you trust   <br>      // that the base type implemented Match correctly.  <br>      if (this.GetType() != obj.GetType()) return false;  <br> <br>      // Cast obj to our type to access fields. NOTE: This cast  <br>      // can't fail since we know objects are of the same type  <br>      AccountsAttribute other = (AccountsAttribute) obj;  <br> <br>      // Compare the fields as you see fit  <br>      // This example checks if 'this' accounts is a subset   <br>      // of others' accounts  <br>
<hr>
<A name=468></a><b>450 </b><br>
<b>Part III  Essential Types</b><br>
      if ((other.m_accounts &amp; m_accounts) != m_accounts)   <br>         return false;  <br> <br>      return true;   // Objects match  <br>   }  <br> <br> <br>   public override Boolean Equals(Object obj) {  <br>      // If the base class implements Equals, and the base class  <br>      // is not Object, then uncomment the line below.  <br>      // if (!base.Equals(obj)) return false;  <br> <br>      // Since 'this' isn't null, if obj is null,   <br>      // then the objects can't be equal  <br>      // NOTE: This line may be deleted if you trust   <br>      // that the base type implemented Equals correctly.  <br>      if (obj == null) return false;  <br> <br>      // If the objects are of different types, they can't be equal  <br>      // NOTE: This line may be deleted if you trust   <br>      // that the base type implemented Equals correctly.  <br>      if (this.GetType() != obj.GetType()) return false;  <br> <br>      // Cast obj to our type to access fields. NOTE: This cast  <br>      // can't fail since we know objects are of the same type  <br>      AccountsAttribute other = (AccountsAttribute) obj;  <br> <br>      // Compare the fields to see if they have the same value  <br>      // This example checks if 'this' accounts is the same  <br>      // as other's accounts  <br>      if (other.m_accounts != m_accounts)   <br>         return false;  <br> <br>      return true;   // Objects are equal  <br>   }  <br> <br> <br>   // Override GetHashCode since we override Equals  <br>   public override Int32 GetHashCode() {  <br>      return (Int32) m_accounts;  <br>   }  <br>}  <br> <br> <br>[Accounts(Accounts.Savings)]  <br>internal sealed class ChildAccount { }  <br> <br> <br>[Accounts(Accounts.Savings | Accounts.Checking | Accounts.Brokerage)]  <br>internal sealed class AdultAccount { }  <br> <br> <br>public sealed class Program {  <br>   public static void Main() {  <br>      CanWriteCheck(new ChildAccount());  <br>
<hr>
<A name=469></a><b> </b><br>
<b>Chapter 18  Custom Attributes </b><br>
<b>451</b><br>
      CanWriteCheck(new AdultAccount());  <br> <br>      // This just demonstrates that the method works correctly on a  <br>      // type that doesn't have the AccountsAttribute applied to it.  <br>      CanWriteCheck(new Program());  <br>   }  <br> <br>   private static void CanWriteCheck(Object obj) {  <br>      // Construct an instance of the attribute type and initialize it  <br>      // to what we are explicitly looking for.  <br>      Attribute checking = new AccountsAttribute(Accounts.Checking);  <br> <br>      // Construct the attribute instance that was applied to the type  <br>      Attribute validAccounts = Attribute.GetCustomAttribute(  <br>         obj.GetType(), typeof(AccountsAttribute), false);  <br> <br>      // If the attribute was applied to the type AND the   <br>      // attribute specifies the &quot;Checking&quot; account, then the  <br>      // type can write a check  <br>      if ((validAccounts != null) &amp;&amp; checking.Match(validAccounts)) {  <br>         Console.WriteLine(&quot;{0} types can write checks.&quot;, obj.GetType());  <br>      } else {  <br>         Console.WriteLine(&quot;{0} types can NOT write checks.&quot;, obj.GetType());  <br>      }  <br>   }  <br>}<br>
Building and running this application yields the following output:<br>
ChildAccount types can NOT write checks.  <br>AdultAccount types can write checks.  <br>Program types can NOT write checks.<br>
<b>Detecting the Use of a Custom Attribute Without </b><br>
<b>Creating Attribute-Derived Objects</b><br>
In this section, I discuss an alternate technique for detecting custom attributes applied to <br>a metadata entry. In some security-conscious scenarios, this alternate technique ensures that <br>no code in an Attribute-derived class will execute. After all, when you call Attribute's <br>GetCustomAttribute(s) methods, internally, these methods call the attribute class's con-<br>structor and can also call property set accessor methods. In addition, the first access to a <br>type causes the CLR to invoke the type's type constructor (if it exists). The constructor, set <br>accessor, and type constructor methods could contain code that will execute whenever code <br>is just looking for an attribute. This allows unknown code to run in the AppDomain, and this <br>is a potential security vulnerability.<br>
To discover attributes without allowing attribute class code to execute, you use the  <br>System.Reflection.CustomAttributeData class. This class defines one static method for <br>retrieving the attributes associated with a target: GetCustomAttributes. This method  <br>
<hr>
<A name=470></a><b>452 </b><br>
<b>Part III  Essential Types</b><br>
has four overloads: one that takes an Assembly, one that takes a Module, one that takes a <br>ParameterInfo, and one that takes a MemberInfo. This class is defined in the  <br>System.Reflection namespace, which is discussed in Chapter 23. Typically, you'll use the <br>CustomAttributeData class to analyze attributes in metadata for an assembly that is loaded <br>via Assembly's static ReflectionOnlyLoad method (also discussed in Chapter 23). Briefly, <br>ReflectionOnlyLoad loads an assembly in such a way that prevents the CLR from executing <br>any code in it; this includes type constructors.<br>
CustomAttributeData's GetCustomAttributes method acts as a factory. That is, when <br>you call it, it returns a collection of CustomAttributeData objects in an object of type <br>IList&lt;CustomAttributeData&gt;. The collection contains one element per custom attribute <br>applied to the specified target. For each CustomAttributeData object, you can query some <br>read-only properties to determine how the attribute object would be constructed and initial-<br>ized. Specifically, the Constructor property indicates which constructor method <i>would be</i> <br>called, the ConstructorArguments property returns the arguments that <i>would be</i> passed <br>to this constructor as an instance of IList&lt;CustomAttributeTypedArgument&gt;, and the <br>NamedArguments property returns the fields/properties that <i>would be</i> set as an instance of  <br>IList&lt;CustomAttributeNamedArgument&gt;. Notice that I say "would be" in the previous  <br>sentences because the constructor and set accessor methods will not actually be called--we <br>get the added security by preventing any attribute class methods from executing.<br>
Here's a modified version of a previous code sample that uses the CustomAttributeData <br>class to securely obtain the attributes applied to various targets:<br>
using System;  <br>using System.Diagnostics;  <br>using System.Reflection;  <br>using System.Collections.Generic;  <br> <br> <br>[assembly: CLSCompliant(true)]  <br> <br> <br>[Serializable]  <br>[DefaultMemberAttribute(&quot;Main&quot;)]  <br>[DebuggerDisplayAttribute(&quot;Richter&quot;, Name=&quot;Jeff&quot;, Target=typeof(Program))]  <br>public sealed class Program {  <br>   [Conditional(&quot;Debug&quot;)]  <br>   [Conditional(&quot;Release&quot;)]  <br>   public void DoSomething() { }  <br> <br>   public Program() {  <br>   }  <br> <br>   [CLSCompliant(true)]  <br>   [STAThread]  <br>   public static void Main() {  <br>      // Show the set of attributes applied to this type  <br>      ShowAttributes(typeof(Program));  <br>
<hr>
<A name=471></a><b> </b><br>
<b>Chapter 18  Custom Attributes </b><br>
<b>453</b><br>
 <br>      // Get the set of methods associated with the type  <br>      MemberInfo[] members = typeof(Program).FindMembers(  <br>         MemberTypes.Constructor | MemberTypes.Method,  <br>         BindingFlags.DeclaredOnly | BindingFlags.Instance |  <br>         BindingFlags.Public | BindingFlags.Static,  <br>         Type.FilterName, &quot;*&quot;);  <br> <br>      foreach (MemberInfo member in members) {  <br>         // Show the set of attributes applied to this member  <br>         ShowAttributes(member);  <br>      }  <br>   }  <br> <br>   private static void ShowAttributes(MemberInfo attributeTarget) {  <br>      IList&lt;CustomAttributeData&gt; attributes =   <br>         CustomAttributeData.GetCustomAttributes(attributeTarget);  <br> <br>      Console.WriteLine(&quot;Attributes applied to {0}: {1}&quot;,   <br>         attributeTarget.Name, (attributes.Count == 0 ? &quot;None&quot; : String.Empty));  <br> <br>      foreach (CustomAttributeData attribute in attributes) {  <br>         // Display the type of each applied attribute  <br>         Type t = attribute.Constructor.DeclaringType;  <br>         Console.WriteLine(&quot;  {0}&quot;, t.ToString());  <br>         Console.WriteLine(&quot;    Constructor called={0}&quot;, attribute.Constructor);  <br> <br>         IList&lt;CustomAttributeTypedArgument&gt; posArgs = attribute.ConstructorArguments;  <br>         Console.WriteLine(&quot;    Positional arguments passed to constructor:&quot; +  <br>            ((posArgs.Count == 0) ? &quot; None&quot; : String.Empty));  <br>         foreach (CustomAttributeTypedArgument pa in posArgs) {  <br>             Console.WriteLine(&quot;      Type={0}, Value={1}&quot;, pa.ArgumentType, pa.Value);  <br>         }  <br> <br> <br>         IList&lt;CustomAttributeNamedArgument&gt; namedArgs = attribute.NamedArguments;  <br>         Console.WriteLine(&quot;    Named arguments set after construction:&quot; +  <br>            ((namedArgs.Count == 0) ? &quot; None&quot; : String.Empty));  <br>         foreach(CustomAttributeNamedArgument na in namedArgs) {  <br>            Console.WriteLine(&quot;     Name={0}, Type={1}, Value={2}&quot;,   <br>               na.MemberInfo.Name, na.TypedValue.ArgumentType, na.TypedValue.Value);  <br>         }  <br> <br>         Console.WriteLine();  <br>      }  <br>      Console.WriteLine();  <br>   }  <br>}<br>
Building and running this application yields the following output:<br>
Attributes applied to Program:  <br>  System.SerializableAttribute  <br>    Constructor called=Void .ctor()  <br>    Positional arguments passed to constructor: None  <br>
<hr>
<A name=472></a><b>454 </b><br>
<b>Part III  Essential Types</b><br>
    Named arguments set after construction: None  <br> <br>  System.Diagnostics.DebuggerDisplayAttribute  <br>    Constructor called=Void .ctor(System.String)  <br>    Positional arguments passed to constructor:  <br>      Type=System.String, Value=Richter  <br>    Named arguments set after construction:  <br>     Name=Name, Type=System.String, Value=Jeff  <br>     Name=Target, Type=System.Type, Value=Program  <br> <br>  System.Reflection.DefaultMemberAttribute  <br>    Constructor called=Void .ctor(System.String)  <br>    Positional arguments passed to constructor:  <br>      Type=System.String, Value=Main  <br>    Named arguments set after construction: None  <br> <br> <br>Attributes applied to DoSomething:  <br>  System.Diagnostics.ConditionalAttribute  <br>    Constructor called=Void .ctor(System.String)  <br>    Positional arguments passed to constructor:  <br>      Type=System.String, Value=Release  <br>    Named arguments set after construction: None  <br> <br>  System.Diagnostics.ConditionalAttribute  <br>    Constructor called=Void .ctor(System.String)  <br>    Positional arguments passed to constructor:  <br>      Type=System.String, Value=Debug  <br>    Named arguments set after construction: None  <br> <br> <br>Attributes applied to Main:  <br>  System.CLSCompliantAttribute  <br>    Constructor called=Void .ctor(Boolean)  <br>    Positional arguments passed to constructor:  <br>      Type=System.Boolean, Value=True  <br>    Named arguments set after construction: None  <br> <br>  System.STAThreadAttribute  <br>    Constructor called=Void .ctor()  <br>    Positional arguments passed to constructor: None  <br>    Named arguments set after construction: None  <br> <br> <br>Attributes applied to .ctor: None<br>
<b>Conditional Attribute Classes</b><br>
Over time, the ease of defining, applying, and reflecting over attributes has caused  <br>developers to use them more and more. Using attributes is also a very easy way to  <br>annotate your code while simultaneously implementing rich features. Lately, developers  <br>have been using attributes to assist them with design time and debugging. For example,  <br>
<hr>
<A name=473></a><b> </b><br>
<b>Chapter 18  Custom Attributes </b><br>
<b>455</b><br>
the Microsoft Visual Studio code analysis tool (FxCopCmd.exe) offers a  <br>System.Diagnostics.CodeAnalysis.SuppressMessageAttribute which you can apply  <br>to types and members in order to suppress the reporting of a specific static analysis tool rule <br>violation. This attribute is only looked for by the code analysis utility; the attribute is never <br>looked for when the program is running normally. When not using code analysis,  <br>having SuppressMessage attributes sitting in the metadata just bloats the metadata, which <br>makes your file bigger, increases your process's working set, and hurts your application's <br>performance. It would be great if there were an easy way to have the compiler emit the <br>SuppressMessage attributes only when you intend to use the code analysis tool. Fortunately, <br>there is a way to do this by using conditional attribute classes.<br>
An attribute class that has the System.Diagnostics.ConditionalAttribute applied to it is <br>called a <i>conditional attribute class</i>. Here is an example:<br>
//#define TEST  <br>#define VERIFY  <br> <br>using System;  <br>using System.Diagnostics;  <br> <br> <br>[Conditional(&quot;TEST&quot;)][Conditional(&quot;VERIFY&quot;)]  <br>public sealed class CondAttribute : Attribute {  <br>}  <br> <br>[Cond]  <br>public sealed class Program {  <br>   public static void Main() {  <br>      Console.WriteLine(&quot;CondAttribute is {0}applied to Program type.&quot;,  <br>         Attribute.IsDefined(typeof(Program),   <br>            typeof(CondAttribute)) ? &quot;&quot; : &quot;not &quot;);  <br>   }  <br>}<br>
When a compiler sees an instance of the CondAttribute being applied to a target, the  <br>compiler will emit the attribute information into the metadata only if the TEST or VERIFY <br>symbol is defined when the code containing the target is compiled. However, the attribute <br>class definition metadata and implementation is still present in the assembly.<br>
<hr>
<A name=474></a><hr>
<A name=475></a><IMG src="CLRviaCsharp-475_1.jpg"><br>
Chapter 19<br><b>Nullable Value Types</b><br>
<b>In this chapter:<br>C#'s Support for Nullable Value Types  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 459<br>C#'s Null-Coalescing Operator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 462<br>The CLR Has Special Support for Nullable Value Types . . . . . . . . . . . . . . . . . . . . 463</b><br>
As you know, a variable of a value type can never be null; it always contains the value type's <br>value itself. In fact, this is why they call these types <i>value</i> types. Unfortunately, there are <br>some scenarios in which this is a problem. For example, when designing a database, it's  <br>possible to define a column's data type to be a 32-bit integer that would map to the Int32 <br>data type of the Framework Class Library (FCL). But a column in a database can indicate that <br>the value is nullable. That is, it is OK to have no value in the row's column. Working with <br>database data by using the Microsoft .NET Framework can be quite difficult because in the <br>common language runtime (CLR), there is no way to represent an Int32 value as null.<br>
<b>Note  </b>Microsoft ADO.NET's table adapters do support nullable types. But unfortunately, <br>the types in the System.Data.SqlTypes namespace are not replaced by nullable types, <br>partially because there isn't a one-to-one correspondence between types. For example, the <br>SqlDecimal type has a maximum of 38 digits, whereas the regular Decimal type can reach only <br>29. In addition, the SqlString type supports its own locale and compare options, which are not <br>supported by the normal String type.<br>
Here is another example: in Java, the java.util.Date class is a reference type, and therefore, <br>a variable of this type can be set to null. However, in the CLR, a System.DateTime is a value <br>type, and a DateTime variable can never be null.<b> </b>If an application written in Java wants to <br>communicate a date/time to a Web service running the CLR, there is a problem if the Java  <br>application sends null because the CLR has no way to represent this and operate on it.<br>
To improve this situation, Microsoft added the concept of nullable value types to the CLR. To <br>understand how they work, we first need to look at the System.Nullable&lt;T&gt; class, which is <br>defined in the FCL. Here is the logical representation of how the System.Nullable&lt;T&gt; type <br>is defined:<br>
[Serializable, StructLayout(LayoutKind.Sequential)]  <br>public struct Nullable&lt;T&gt; where T : struct {  <br> <br>   // These 2 fields represent the state  <br>   private Boolean hasValue = false; // Assume null  <br>   internal T value = default(T);    // Assume all bits zero  <br> <br>
<b> </b><br>
<b> </b><br>
<b>457</b><br>
<hr>
<A name=476></a><b>458 </b><br>
<b>Part III  Essential Types</b><br>
   public Nullable(T value) {  <br>      this.value = value;  <br>      this.hasValue = true;  <br>   }  <br> <br>   public Boolean HasValue { get { return hasValue; } }  <br> <br>   public T Value {   <br>      get {   <br>         if (!hasValue) {  <br>            throw new InvalidOperationException(  <br>               &quot;Nullable object must have a value.&quot;);  <br>         }  <br>         return value;  <br>      }  <br>   }  <br> <br>   public T GetValueOrDefault() { return value; }  <br> <br>   public T GetValueOrDefault(T defaultValue) {  <br>      if (!HasValue) return defaultValue;  <br>      return value;  <br>   }  <br> <br>   public override Boolean Equals(Object other) {  <br>      if (!HasValue) return (other == null);  <br>      if (other == null) return false;  <br>      return value.Equals(other);  <br>   }  <br> <br>   public override int GetHashCode() {  <br>      if (!HasValue) return 0;  <br>      return value.GetHashCode();  <br>   }  <br> <br>   public override string ToString() {  <br>      if (!HasValue) return &quot;&quot;;  <br>      return value.ToString();  <br>   }  <br> <br>   public static implicit operator Nullable&lt;T&gt;(T value) {  <br>      return new Nullable&lt;T&gt;(value);  <br>   }  <br> <br>   public static explicit operator T(Nullable&lt;T&gt; value) {  <br>      return value.Value;  <br>   }  <br>}<br>
As you can see, this class encapsulates the notion of a value type that can also be null. Since <br>Nullable&lt;T&gt; is itself a value type, instances of it are still fairly lightweight. That is, instances <br>can still be on the stack, and an instance is the same size as the original value type plus the <br>size of a Boolean field. Notice that Nullable's type parameter, T, is constrained to struct.<b> <br></b>This was done because reference type variables can already be null.<br>
<hr>
<A name=477></a><b> </b><br>
<b>Chapter 19  Nullable Value Types </b><br>
<b>459</b><br>
So now, if you want to use a nullable Int32 in your code, you can write something like this:<br>
Nullable&lt;Int32&gt; x = 5;  <br>Nullable&lt;Int32&gt; y = null;  <br>Console.WriteLine(&quot;x: HasValue={0}, Value={1}&quot;,  x.HasValue, x.Value);  <br>Console.WriteLine(&quot;y: HasValue={0}, Value={1}&quot;,  y.HasValue, y.GetValueOrDefault());<br>
When I compile and run this code, I get the following output:<br>
x: HasValue=True, Value=5  <br>y: HasValue=False, Value=0<br>
<b>C#'s Support for Nullable Value Types</b><br>
Notice in the code that C# allows you to use fairly simple syntax to initialize the two <br>Nullable&lt;Int32&gt; variables, x and y. In fact, the C# team wants to integrate nullable value <br>types into the C# language, making them first-class citizens. To that end, C# offers an  <br>(arguably) cleaner syntax for working with nullable value types. C# allows the code to declare <br>and initialize the x and y variables to be written using question-mark notation:<br>
Int32? x = 5;  <br>Int32? y = null;<br>
In C#, Int32? is a synonym notation for Nullable&lt;Int32&gt;. But C# takes this further. C#  <br>allows you to perform conversions and casts on nullable instances. And C# also supports  <br>applying operators to nullable instances. The following code shows examples of these:<br>
private static void ConversionsAndCasting() {  <br>   // Implicit conversion from non-nullable Int32 to Nullable&lt;Int32&gt; <br>   Int32? a = 5;  <br> <br>   // Implicit conversion from 'null' to Nullable&lt;Int32&gt; <br>   Int32? b = null;  <br> <br>   // Explicit conversion from Nullable&lt;Int32&gt; to non-nullable Int32  <br>   Int32 c = (Int32) a;  <br> <br>   // Casting between nullable primitive types  <br>   Double? d = 5; // Int32-&gt;Double?  (d is 5.0 as a double)  <br>   Double? e = b; // Int32?-&gt;Double? (e is null)  <br>}<br>
C# also allows you to apply operators to nullable instances. The following code shows  <br>examples of this:<br>
private static void Operators() {  <br>   Int32? a = 5;  <br>   Int32? b = null;  <br>     <br>
<hr>
<A name=478></a><b>460 </b><br>
<b>Part III  Essential Types</b><br>
   // Unary operators (+  ++  -  --  !  ~)  <br>   a++;    // a = 6  <br>   b = -b; // b = null  <br> <br>   // Binary operators (+  -  *  /  %  &amp;  |  ^  &lt;&lt;  &gt;&gt;)  <br>   a = a + 3;  // a = 9  <br>   b = b * 3;  // b = null;  <br> <br>   // Equality operators (==  !=)  <br>   if (a == null) { /* no  */ } else { /* yes */ }  <br>   if (b == null) { /* yes */ } else { /* no  */ }  <br>   if (a != b)    { /* yes */ } else { /* no  */ }  <br> <br>   // Comparison operators (&lt;&gt;  &lt;=  &gt;=)  <br>   if (a &lt; b)     { /* no  */ } else { /* yes */ }  <br>}<br>
Here is how C# interprets the operators:<br>
<b>  Unary operators (</b>+++,<b> </b>-,<b> </b>--,<b> </b>!<b> </b>,<b> </b>~<b>)  </b>If the operand is null, the result is null.<br>
<b>  Binary operators (</b>+,<b> </b>-,<b> </b>*,<b> </b>/,<b> </b>%,<b> </b>&amp;,<b> </b>|,<b> </b>^,<b> </b>&lt;&lt;<b>, </b>&gt;&gt;<b>)  </b>If either operand is null, the result is <br>
null. However, an exception is made when the &amp; and | operators are operating on <br>Boolean? operands so that the behavior of these two operators gives the same  <br>behavior as demonstrated by SQL's three-valued logic. For these two operators, if  <br>neither operand is null, the operator performs as expected, and if both operands are <br>null, the result is null. The special behavior comes into play when just one of the  <br>operands is null. The table below lists the results produced by these two operators  <br>for all combinations of true, false, and null:<br>
<b>Operand1   <br>Operand2</b><br>
true<br>
false<br>
null<br>
&amp; = true <br>
&amp; = false <br>
&amp; = null <br>
true<br>
| = true<br>
| = true<br>
| = true<br>
false<br>
&amp; = false <br>
&amp; = false <br>
&amp; = false <br>
| = true<br>
| = false<br>
| = null<br>
null<br>
&amp; = null <br>
&amp; = false <br>
&amp; = null <br>
| = true<br>
| = null<br>
| = null<br>
<b>  Equality operators (</b>==<b>, </b>!=<b>)  </b>If both operands are null, they are equal. If one  <br>
operand is null, they are not equal. If neither operand is null, compare the values  <br>to determine if they are equal.<br>
<b>  Relational operators (</b>&lt;<b>, </b>&gt;<b>, </b>&lt;=<b>, </b>&gt;=<b>)  </b>If either operand is null, the result is false. If  <br>
neither operand is null, compare the values.<br>
You should be aware that manipulating nullable instances does generate a lot of code. For <br>example, see the following method:<br>
private static Int32? NullableCodeSize(Int32? a, Int32? b) {  <br>   return a + b;  <br>}<br>
<hr>
<A name=479></a><b> </b><br>
<b>Chapter 19  Nullable Value Types </b><br>
<b>461</b><br>
When I compile this method, there is quite a bit of resulting Intermediate Language (IL) code, <br>which also makes performing operations on nullable types slower than performing the same <br>operation on non-nullable types. Here is the C# equivalent of the compiler-produced IL code:<br>
private static Nullable&lt;Int32&gt; NullableCodeSize(Nullable&lt;Int32&gt; a, Nullable&lt;Int32&gt; b) {  <br> <br>   Nullable&lt;Int32&gt; nullable1 = a;  <br>   Nullable&lt;Int32&gt; nullable2 = b;  <br>   if (!(nullable1.HasValue &amp; nullable2.HasValue)) {  <br>      return new Nullable&lt;Int32&gt;();  <br>   }  <br>   return new Nullable&lt;Int32&gt;(nullable1.GetValueOrDefault() + nullable2.GetValueOrDefault()); <br>}<br>
Finally, let me point out that you can define your own value types that overload the various <br>operators mentioned above. I discuss how to do this in the "Operator Overload Methods" <br>section in Chapter 8, "Methods." If you then use a nullable instance of your own value type, <br>the compiler does the right thing and invokes your overloaded operator. For example,  <br>suppose that you have a Point value type that defines overloads for the == and != operators <br>as follows:<br>
using System; <br> <br>internal struct Point { <br>   private Int32 m_x, m_y; <br>   public Point(Int32 x, Int32 y) { m_x = x; m_y = y; } <br> <br>   public static Boolean operator==(Point p1, Point p2) {  <br>      return (p1.m_x == p2.m_x) &amp;&amp; (p1.m_y == p2.m_y); <br>   } <br> <br>   public static Boolean operator!=(Point p1, Point p2) {  <br>      return !(p1 == p2); <br>   } <br>}<br>
At this point, you can use nullable instances of the <b>Point</b> type and the compiler will invoke <br>your overloaded operators:<br>
internal static class Program { <br>   public static void Main() {  <br>      Point? p1 = new Point(1, 1); <br>      Point? p2 = new Point(2, 2); <br> <br>      Console.WriteLine(&quot;Are points equal? &quot; + (p1 == p2).ToString()); <br>      Console.WriteLine(&quot;Are points not equal? &quot; + (p1 != p2).ToString()); <br>   } <br>}<br>
When I build and run the code above, I get the following output:<br>
Are points equal? False <br>Are points not equal? True<br>
<hr>
<A name=480></a><b>462 </b><br>
<b>Part III  Essential Types</b><br>
<b>C#'s Null-Coalescing Operator</b><br>
C# has an operator called the <i>null-coalescing operator</i> (??), which takes two operands. If the <br>operand on the left is not null, the operand's value is returned. If the operand on the left is <br>null, the value of the right operand is returned. The null-coalescing operator offers a very <br>convenient way to set a variable's default value.<br>
A cool feature of the null-coalescing operator is that it can be used with reference types  <br>as well as nullable value types. Here is some code that demonstrates the use of the null-<br>coalescing operator:<br>
private static void NullCoalescingOperator() {  <br>   Int32? b = null;  <br> <br>   // The line below is equivalent to:  <br>   // x = (b.HasValue) ? b.Value : 123  <br>   Int32 x = b ?? 123;      <br>   Console.WriteLine(x);  // &quot;123&quot;  <br> <br>   // The line below is equivalent to:  <br>   // String temp = GetFilename();  <br>   // filename = (temp != null) ? temp : &quot;Untitled&quot;;  <br>   String filename = GetFilename() ?? &quot;Untitled&quot;;  <br>}<br>
Some people argue that the null-coalescing operator is simply syntactic sugar for the ?:  <br>operator, and that the C# compiler team should not have added this operator to the  <br>language. However, the null-coalescing operator offers two significant syntactic improve-<br>ments. The first is that the ?? operator works better with expressions:<br>
Func&lt;String&gt; f = () =&gt; SomeMethod() ?? &quot;Untitled&quot;;<br>
This code is much easier to read and understand than the line below, which requires variable <br>assignments and multiple statements:<br>
Func&lt;String&gt; f = () =&gt; { var temp = SomeMethod();  <br>  return temp != null ? temp : &quot;Untitled&quot;;};<br>
The second improvement is that ?? works better in composition scenarios. For example, the <br>single line<br>
String s = SomeMethod1() ?? SomeMethod2() ?? &quot;Untitled&quot;;<br>
is far easier to read and understand than this chunk of code:<br>
String s; <br>var sm1 = SomeMethod1(); <br>if (sm1 != null) s = sm1; <br>else { <br>   var sm2 = SomeMethod2(); <br>   if (sm2 != null) s = sm2; <br>   else s = &quot;Untitled&quot;; <br>}<br>
<hr>
<A name=481></a><b> </b><br>
<b>Chapter 19  Nullable Value Types </b><br>
<b>463</b><br>
<b>The CLR Has Special Support for Nullable Value Types</b><br>
The CLR has built-in support for nullable value types. This special support is provided for <br>boxing, unboxing, calling GetType, and calling interface methods, and it is given to nullable <br>types to make them fit more seamlessly into the CLR. This also makes them behave more <br>naturally and as most developers would expect. Let's take a closer look at the CLR's special <br>support for nullable types.<br>
<b>Boxing Nullable Value Types</b><br>
Imagine a Nullable&lt;Int32&gt; variable that is logical y set to null. If this variable is passed to a <br>method prototyped as expecting an Object, the variable must be boxed, and a reference to <br>the boxed Nullable&lt;Int32&gt; is passed to the method. This is not ideal because the method <br>is now being passed a non-null value even though the Nullable&lt;Int32&gt; variable logically <br>contained the value of null. To fix this, the CLR executes some special code when boxing <br>a nullable variable to keep up the illusion that nullable types are first-class citizens in the <br>environment.<br>
Specifically, when the CLR is boxing a Nullable&lt;T&gt; instance, it checks to see if it is null, and <br>if so, the CLR doesn't actually box anything, and null is returned. If the nullable instance is <br>not null, the CLR takes the value out of the nullable instance and boxes it. In other words, <br>a Nullable&lt;Int32&gt; with a value of 5 is boxed into a boxed-Int32 with a value of 5. Here is <br>some code that demonstrates this behavior:<br>
// Boxing Nullable&lt;T&gt; is null or boxed T  <br>Int32? n = null;  <br>Object o = n;  // o is null  <br>Console.WriteLine(&quot;o is null={0}&quot;, o == null);  // &quot;True&quot;  <br> <br>n = 5;  <br>o = n;   // o refers to a boxed Int32  <br>Console.WriteLine(&quot;o's type={0}&quot;, o.GetType()); // &quot;System.Int32&quot;<br>
<b>Unboxing Nullable Value Types</b><br>
The CLR allows a boxed value type T to be unboxed into a T or a Nullable&lt;T&gt;. If the  <br>reference to the boxed value type is null, and you are unboxing it to a Nullable&lt;T&gt;, the <br>CLR sets Nullable&lt;T&gt;'s value to null. Here is some code to demonstrate this behavior:<br>
// Create a boxed Int32  <br>Object o = 5;  <br> <br>// Unbox it into a Nullable&lt;Int32&gt; and into an Int32  <br>Int32? a = (Int32?) o;  // a = 5  <br>Int32  b = (Int32)  o;  // b = 5  <br> <br>
<hr>
<A name=482></a><b>464 </b><br>
<b>Part III  Essential Types</b><br>
// Create a reference initialized to null  <br>o = null;  <br> <br>// &quot;Unbox&quot; it into a Nullable&lt;Int32&gt; and into an Int32  <br>a = (Int32?) o;       // a = null  <br>b = (Int32)  o;       // NullReferenceException<br>
<b>Calling </b>GetType<b> via a Nullable Value Type</b><br>
When calling GetType on a Nullable&lt;T&gt; object, the CLR actually lies and returns the type T <br>instead of the type Nullable&lt;T&gt;. Here is some code that demonstrates this behavior:<br>
Int32? x = 5;  <br> <br>// The line below displays &quot;System.Int32&quot;; not &quot;System.Nullable&lt;Int32&gt;&quot;  <br>Console.WriteLine(x.GetType());<br>
<b>Calling Interface Methods via a Nullable Value Type</b><br>
In the code below, I'm casting n,<b> </b>a Nullable&lt;Int32&gt;, to IComparable&lt;Int32&gt;, an interface <br>type. However, the Nullable&lt;T&gt; type does not implement the IComparable&lt;Int32&gt; inter-<br>face as Int32 does. The C# compiler allows this code to compile anyway, and the CLR's veri-<br>fier considers this code verifiable to allow you a more convenient syntax.<br>
Int32? n = 5;  <br>Int32 result = ((IComparable) n).CompareTo(5);  // Compiles &amp; runs OK  <br>Console.WriteLine(result);                      // 0<br>
If the CLR didn't provide this special support, it would be more cumbersome for you to write <br>code to call an interface method on a nullable value type. You'd have to cast the unboxed <br>value type first before casting to the interface to make the call:<br>
Int32 result = ((IComparable) (Int32) n).CompareTo(5);  // Cumbersome<br>
<hr>
<A name=483></a>Chapter 20<br><b>Exceptions and State Management</b><br>
<b>In this chapter:<br>Defining "Exception"  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 466<br>Exception-Handling Mechanics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 467<br>The </b>System.Exception<b> Class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 474<br>FCL-Defined Exception Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 478<br>Throwing an Exception. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 480<br>Defining Your Own Exception Class . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 481<br>Trading Reliability for Productivity  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 484<br>Guidelines and Best Practices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 492<br>Unhandled Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 500<br>Debugging Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 504<br>Exception-Handling Performance Considerations. . . . . . . . . . . . . . . . . . . . . . . . . 506<br>Constrained Execution Regions (CERs)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 509<br>Code Contracts  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 512</b><br>
This chapter is all about error handling. But it's not just about that. There are several parts <br>to error handling. First, we'll define what an error actually is. Then, we'll talk about how to <br>discover when your code is experiencing an error and about how to recover from this error. <br>At this point, state becomes an issue because errors tend to come at inopportune times. It is <br>likely that your code will be in the middle of mutating some state when it experiences the  <br>error, and your code likely will have to restore some state back to what it was prior to  <br>attempting to mutate it. Of course, we'll also talk about how your code can notify its callers <br>that it has detected an error.<br>
In my opinion, exception handling is the weakest area of the common language runtime <br>(CLR) and therefore causes many problems for developers writing managed code. Over the <br>years, Microsoft has made some significant improvements to help developers deal with  <br>errors, but I believe that there is much more that must be done before we can really have a <br>good, reliable system. I will talk a lot about the various enhancements that have been made <br>when dealing with unhandled exceptions, constrained execution regions, code contracts, <br>runtime wrapped exceptions, uncatchable exceptions, and so on.<br>
<b> </b><br>
<b> </b><br>
<b>465</b><br>
<hr>
<A name=484></a><IMG src="CLRviaCsharp-484_1.jpg"><br>
<b>466 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Defining "Exception"</b><br>
When designing a type, you first imagine the various situations in which the type will be <br>used. The type name is usually a noun, such as FileStream or StringBuilder. Then you <br>define the properties, methods, events, and so on for the type. The way you define these <br>members (property data types, method parameters, return values, and so forth) becomes <br>the programmatic interface for your type. These members indicate actions that can be per-<br>formed by the type itself or on an instance of the type. These action members are usually <br>verbs such as Read, Write, Flush, Append, Insert, Remove, etc. When an action member <br>cannot complete its task, the member should throw an exception.<br>
<b>Important  </b> An exception is when a member fails to complete the task it is supposed to perform <br>as indicated by its name.<br>
Look at the following class definition:<br>
internal sealed class Account {  <br>   public static void Transfer(Account from, Account to, Decimal amount) {  <br>      from -= amount; <br>      to += amount; <br>   }  <br>}<br>
The Transfer method accepts two Account objects and a Decimal value that identifies <br>an amount of money to transfer between accounts. Obviously, the goal of the Transfer <br>method is to subtract money from one account and add money to another. The Transfer <br>method could fail for many reasons: the from or to argument might be null; the from or <br>to argument might not refer to an open account; the from account might have insufficient <br>funds; the to account might have so much money in it that adding more would cause it to <br>overflow; or the amount argument might be 0, negative, or have more than two digits after <br>the decimal place.<br>
When the Transfer method is called, its code must check for all of these possibilities, and <br>if any of them are detected, it cannot transfer the money and should notify the caller that <br>it failed by throwing an exception. In fact, notice that the Transfer method's return type is <br>void. This is because the Transfer method has no meaningful value to return; if it returns at <br>all, it was successful. If it fails, it throws a meaningful exception.<br>
Object-oriented programming allows developers to be very productive because you get to <br>write code like this:<br>
Boolean f = &quot;Jeff&quot;.Substring(1, 1).ToUpper().EndsWith(&quot;E&quot;); // true<br>
<hr>
<A name=485></a><IMG src="CLRviaCsharp-485_1.jpg"><br>
<b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>467</b><br>
Here I'm composing my intent by chaining several operations together.1 This code was easy <br>for me to write and is easy for others to read and maintain because the intent is obvious: <br>Take a string, grab a portion of it, uppercase that portion, and see if it ends with an "E." This <br>is great, but there is a big assumption being made here: no operation fails. But, of course, <br>errors are always possible, so we need a way to handle those errors. In fact, there are many <br>object-oriented constructs--constructors, getting/setting a property, adding/removing an <br>event, calling an operator overload, calling a conversion operator--that have no way to  <br>return error codes, but these constructs must still be able to report an error. The mechanism <br>provided by the Microsoft .NET Framework and all programming languages that support it is <br>called <i>exception handling</i>.<br>
<b>Important  </b>Many developers incorrectly believe that an exception is related to how <i>frequently</i> <br>something happens. For example, a developer designing a file Read method is likely to say the <br>following: "When reading from a file, you will eventually reach the end of its data. Since reaching <br>the end will <i>always </i>happen, I'll design my Read method so that it reports the end by returning a <br>special value; I won't have it throw an exception." The problem with this statement is that it is  <br>being made by the developer designing the Read method, not by the developer calling the Read <br>method.<br>
When designing the Read method, it is impossible for the developer to know all of the possible <br>situations in which the method gets called. Therefore, the developer can't possibly know how <br><i>often</i> the caller of the Read method will attempt to read past the end of the file. In fact, since <br>most files contain structured data, attempting to read past the end of a file is something that <br><i>rarely </i>happens.<br>
<b>Exception-Handling Mechanics</b><br>
In this section, I'll introduce the mechanics and C# constructs needed in order to use excep-<br>tion handling, but it's not my intention to explain them in great detail. The purpose of this <br>chapter is to offer useful guidelines for when and how to use exception handling in your <br>code. If you want more information about the mechanics and language constructs for using <br>exception handling, see the .NET Framework documentation and the C# language specifica-<br>tion. Also, the .NET Framework exception-handling mechanism is built using the Structured <br>Exception Handling (SEH) mechanism offered by Microsoft Windows. SEH has been discussed <br>in many resources, including my own book, <i>Windows via C/C++, </i>5th ed. (Microsoft Press, <br>2007), which contains three chapters devoted to SEH.<br>
The following C# code shows a standard usage of the exception-handling mechanism. This <br>code gives you an idea of what exception-handling blocks look like and what their purpose <br>is. In the subsections after the code, I'll formally describe the try, catch, and finally blocks <br>and their purpose and provide some notes about their use.<br>
1  In fact, C#'s extension method feature exists in the language to allow you to chain more methods together that <br>
would not have been chainable otherwise.<br>
<hr>
<A name=486></a><IMG src="CLRviaCsharp-486_1.jpg"><br>
<b>468 </b><br>
<b>Part IV  Core Facilities</b><br>
private void SomeMethod() {  <br>  <br>   try {  <br>      // Put code requiring graceful recovery and/or cleanup operations here... <br>   }  <br>   catch (InvalidOperationException) {  <br>      // Put code that recovers from an InvalidOperationException here... <br>   }  <br>   catch (IOException) {  <br>      // Put code that recovers from an IOException here... <br>   }  <br>   catch {  <br>      // Put code that recovers from any kind of exception other than those above here... <br>  <br>      // When catching any exception, you usually re-throw the exception. <br>      // I explain re-throwing later in this chapter.  <br>      throw;  <br>   }  <br>   finally {  <br>      // Put code that cleans up any operations started within the try block here... <br>      // The code in here ALWAYS executes, regardless of whether an exception is thrown.  <br>   }  <br>   // Code below the finally block executes if no exception is thrown within the try block <br>   // or if a catch block catches the exception and doesn't throw or re-throw an exception.  <br>}<br>
This code demonstrates one possible way to use exception-handling blocks. Don't let the <br>code scare you--most methods have simply a try block matched with a single finally <br>block or a try block matched with a single catch block. It's unusual to have as many catch <br>blocks as in this example. I put them there for illustration purposes.<br>
<b>The </b>try<b> Block</b><br>
A try<i> block</i> contains code that requires common cleanup operations, exception-recovery op-<br>erations, or both. The cleanup code should be placed in a single finally block. A try block <br>can also contain code that might potentially throw an exception. The exception-recovery <br>code should be placed in one or more catch blocks. You create one catch block for each <br>kind of exception that your application can safely recover from. A try block must be associ-<br>ated with at least one catch or finally block; it makes no sense to have a try block that <br>stands by itself, and C# will prevent you from doing this.<br>
<b>Important  </b>Sometimes developers ask how much code they should put inside a single try <br>block. The answer to this depends on state management. If, inside a try block, you execute  <br>multiple operations that could all throw the same exception type and the way that you'd recover <br>this exception type is different depending on the operation, then you should put each operation <br>in its own try block so that you can recover your state correctly.<br>
<hr>
<A name=487></a><IMG src="CLRviaCsharp-487_1.jpg"><br>
<b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>469</b><br>
<b>The </b>catch<b> Block</b><br>
A catch<i> block</i> contains code to execute in response to an exception. A try block can have <br>zero or more catch blocks associated with it. If the code in a try block doesn't cause an  <br>exception to be thrown, the CLR will never execute the code contained within any of its <br>catch blocks. The thread will simply skip over all of the catch blocks and execute the code <br>in the finally block (if one exists). After the code in the finally block executes, execution <br>continues with the statement following the finally block.<br>
The parenthetical expression appearing after the catch<b> </b>keyword is called the <i>catch type</i>.  <br>In C#, you must specify a catch type of System.Exception or a type derived from  <br>System.Exception. For example, the previous code contains catch blocks for handling an <br>InvalidOperationException (or any exception derived from it) and an IOException (or <br>any exception derived from it). The last catch block (which doesn't specify a catch type) <br>handles any exception at all except for the exception type specified by earlier catch blocks; <br>this is equivalent to having a catch block that specifies a catch type of System.Exception <br>except that you cannot access the exception information via code inside the catch block's <br>braces.<br>
<b>Note  </b>When debugging through a catch block by using Microsoft Visual Studio, you can see <br>the currently thrown exception object by adding the special <i>$exception</i> variable name to a watch <br>window.<br>
The CLR searches from top to bottom for a matching catch type, and therefore you should <br>place the more specific exception types at the top. The most-derived exception types should <br>appear first, followed by their base types (if any), down to System.Exception (or an excep-<br>tion block that doesn't specify a catch type). In fact, the C# compiler generates an error if <br>more specific catch blocks appear closer to the bottom because the catch block would be <br>unreachable.<br>
If an exception is thrown by code executing within the try block (or any method called from <br>within the try block), the CLR starts searching for catch blocks whose catch type is the same <br>type as or a base type of the thrown exception. If none of the catch types matches the excep-<br>tion, the CLR continues searching up the call stack looking for a catch type that matches the <br>exception. If after reaching the top of the call stack, no catch block is found with a matching <br>catch type, an unhandled exception occurs. I'll talk more about unhandled exceptions later in <br>this chapter.<br>
Once the CLR locates a catch block with a matching catch type, it executes the code in all <br>inner finally blocks, starting from within the try block whose code threw the exception <br>and stopping with the catch block that matched the exception. Note that any finally block <br>associated with the catch block that matched the exception is not executed yet. The code <br>in this finally block won't execute until after the code in the handling catch block has <br>executed.<br>
<hr>
<A name=488></a><IMG src="CLRviaCsharp-488_1.jpg"><br>
<b>470 </b><br>
<b>Part IV  Core Facilities</b><br>
After all the code in the inner finally blocks has executed, the code in the handling catch <br>block executes. This code typically performs some operations to deal with the exception. At <br>the end of the catch block, you have three choices:<br>
  Re-throw the same exception, notifying code higher up in the call stack of the <br>
exception.<br>
  Throw a different exception, giving richer exception information to code higher up in <br>
the call stack.<br>
  Let the thread fall out of the bottom of the catch block.<br>
Later in this chapter, I'll offer some guidelines for when you should use each of these tech-<br>niques. If you choose either of the first two techniques, you're throwing an exception, and <br>the CLR behaves just as it did before: It walks up the call stack looking for a catch block <br>whose type matches the type of the exception thrown.<br>
If you pick the last technique, when the thread falls out of the bottom of the catch block, <br>it immediately starts executing code contained in the finally block (if one exists). After all <br>of the code in the finally block executes, the thread drops out of the finally block and <br>starts executing the statements immediately following the finally block. If no finally <br>block exists, the thread continues execution at the statement following the last catch block.<br>
In C#, you can specify a variable name after a catch type. When an exception is caught, this <br>variable refers to the System.Exception-derived object that was thrown. The catch block's <br>code can reference this variable to access information specific to the exception (such as the <br>stack trace leading up to the exception). Although it's possible to modify this object, you <br>shouldn't; consider the object to be read-only. I'll explain the Exception<b> </b>type and what you <br>can do with it later in this chapter.<br>
<b>Note  </b>Your code can register with AppDomain's FirstChanceException event to receive notifi-<br>cations as soon as an exception occurs within an AppDomain. This notification occurs  <br>before the CLR searches for any catch blocks. For more information about this event, see <br>Chapter 22, "CLR Hosting and AppDomains."<br>
<b>The </b>finally<b> Block</b><br>
A finally<i> </i>block contains code that's guaranteed to execute.2 Typically, the code in a  <br>finally block performs the cleanup operations required by actions taken in the try block. <br>
2  Aborting a thread or unloading an AppDomain causes the CLR to throw a ThreadAbortException, which allows  <br>
the finally block to execute. If a thread is simply killed via the Win32 TerminateThread function, or if the <br>process is killed via the Win32 TerminateProcess function or System.Environment's FailFast method, then <br>the finally block will not execute. Of course Windows cleans up all resources that a process was using when a <br>process terminates.<br>
<hr>
<A name=489></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>471</b><br>
For example, if you open a file in a try block, you'd put the code to close the file in a finally <br>block:<br>
private void ReadData(String pathname) {  <br>  <br>   FileStream fs = null;  <br>   try {  <br>      fs = new FileStream(pathname, FileMode.Open);  <br>      // Process the data in the file... <br>   }  <br>   catch (IOException) {  <br>      // Put code that recovers from an IOException here... <br>   }  <br>   finally {  <br>      // Make sure that the file gets closed.  <br>      if (fs != null) fs.Close();  <br>   }  <br>}<br>
If the code in the try block executes without throwing an exception, the file is guaranteed <br>to be closed. If the code in the try block does throw an exception, the code in the finally <br>block still executes, and the file is guaranteed to be closed, regardless of whether the excep-<br>tion is caught. It's improper to put the statement to close the file after the finally block; the <br>statement wouldn't execute if an exception were thrown and not caught, which would result <br>in the file being left open (until the next garbage collection).<br>
A try block doesn't require a finally block associated with it; sometimes the code in a try <br>block just doesn't require any cleanup code. However, if you do have a finally block, it <br>must appear after any and all catch blocks. A try block can have no more than one finally <br>block associated with it.<br>
When a thread reaches the end of the code contained in a finally block, the thread simply <br>starts executing the statements immediately following the finally block. Remember that <br>the code in the finally block is cleanup code. This code should execute only what is neces-<br>sary to clean up operations initiated in the try block. The code inside catch and finally <br>blocks should be very short and should have a high likelihood of succeeding without itself <br>throwing an exception. Usually the code in these blocks is just one or two lines of code.<br>
It is always possible that exception-recovery code or cleanup code could fail and throw an <br>exception. While possible, it is unlikely and if it does happen it usually means that there is <br>something very wrong somewhere. Most likely some state has gotten corrupted somewhere. <br>If an exception is inadvertently thrown within a catch or finally block, the world will not <br>come to an end--the CLR's exception mechanism will execute as though the exception were <br>thrown after the finally block. However, the CLR does not keep track of the first exception  <br>that was thrown in the corresponding try block (if any), and you will lose any and all infor-<br>mation (such as the stack trace) available about the first exception. Probably (and hopefully), <br>this new exception will not be handled by your code and the exception will turn into an  <br>
<hr>
<A name=490></a><hr>
<A name=491></a><hr>
<A name=492></a><hr>
<A name=493></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>475</b><br>
<b>Property</b><br>
<b>Access</b><br>
<b>Type</b><br>
<b>Description</b><br>
Data<br>
Read-only<br>
IDictionary<br>
A reference to a collection of key-value pairs. <br>Usually, the code throwing the exception adds <br>entries to this collection prior to throwing it; <br>code that catches the exception can query the <br>entries and use the information in its exception-<br>recovery processing.<br>
Source<br>
Read/write<br>
String<br>
Contains the name of the assembly that gener-<br>ated the exception.<br>
StackTrace<br>
Read-only<br>
String<br>
Contains the names and signatures of meth-<br>ods called that led up to the exception being <br>thrown. This property is invaluable for debug-<br>ging.<br>
TargetSite<br>
Read-only<br>
MethodBase<br>
Contains the method that threw the exception.<br>
HelpLink<br>
Read-only<br>
String<br>
Contains a URL (such as file://C:\MyApp\Help.<br>htm#MyExceptionHelp) to documentation that <br>can help a user understand the exception. Keep <br>in mind that sound programming and security <br>practices prevent users from ever being able to <br>see raw unhandled exceptions, so unless you are <br>trying to convey information to other program-<br>mers, this property is seldom used.<br>
InnerException<br>
Read-only<br>
Exception<br>
Indicates the previous exception if the cur-<br>rent exception were raised while handling an <br>exception. This read-only property is usually <br>null. The Exception type also offers a public <br>GetBaseException method that traverses the <br>linked list of inner exceptions and returns the <br>originally thrown exception.<br>
I'd like to say a few words about System.Exception's read-only StackTrace property. A <br>catch block can read this property to obtain the stack trace indicating what methods were <br>called that led up to the exception. This information can be extremely valuable when you're <br>trying to detect the cause of an exception so that you can correct your code. When you <br>access this property, you're actually calling into code in the CLR; the property doesn't sim-<br>ply return a string. When you construct a new object of an Exception-derived type, the <br>StackTrace property is initialized to null. If you were to read the property, you wouldn't <br>get back a stack trace; you would get back null.<br>
When an exception is thrown, the CLR internally records where the throw instruction  <br>occurred. When a catch block accepts the exception, the CLR records where the exception  <br>was caught. If, inside a catch block, you now access the thrown exception object's <br>StackTrace property, the code that implements the property calls into the CLR, which builds <br>a string identifying all of the methods between the place where the exception was thrown <br>and the filter that caught the exception.<br>
<hr>
<A name=494></a><IMG src="CLRviaCsharp-494_1.jpg"><br>
<b>476 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Important  </b>When you throw an exception, the CLR resets the starting point for the exception;  <br>that is, the CLR remembers only the location where the most recent exception object was thrown.<br>
The following code throws the same exception object that it caught and causes the CLR to <br>reset its starting point for the exception:<br>
private void SomeMethod() {  <br>   try { ... }  <br>   catch (Exception e) {  <br>      ...  <br>      throw e;  // CLR thinks this is where exception originated.   <br>                // FxCop reports this as an error  <br>   }  <br>}<br>
In contrast, if you re-throw an exception object by using the throw keyword by itself, the <br>CLR doesn't reset the stack's starting point. The following code re-throws the same exception <br>object that it caught, causing the CLR to not reset its starting point for the exception:<br>
private void SomeMethod() {  <br>   try { ... }  <br>   catch (Exception e) {  <br>      ...  <br>      throw;  // This has no effect on where the CLR thinks the exception  <br>              // originated. FxCop does NOT report this as an error  <br>   }  <br>}<br>
In fact, the only difference between these two code fragments is what the CLR thinks is the <br>original location where the exception was thrown. Unfortunately, when you throw or re-<br>throw an exception, Windows does reset the stack's starting point. So if the exception  <br>becomes unhandled, the stack location that gets reported to Windows Error Reporting is the <br>location of the last throw or re-throw, even though the CLR knows the stack location where <br>the original exception was thrown. This is unfortunate because it makes debugging applica-<br>tions that have failed in the field much more difficult. Some developers have found this so <br>intolerable that they have chosen a different way to implement their code to ensure that the <br>stack trace truly reflects the location where an exception was originally thrown:<br>
private void SomeMethod() {  <br>   Boolean trySucceeds = false;  <br>   try {   <br>      ...   <br>      trySucceeds = true;  <br>   }  <br>   finally {  <br>      if (!trySucceeds) { /* catch code goes in here */ }  <br>   }  <br>}<br>
<hr>
<A name=495></a><IMG src="CLRviaCsharp-495_1.jpg"><br>
<b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>477</b><br>
The string returned from the StackTrace property doesn't include any of the methods in the <br>call stack that are above the point where the catch block accepted the exception object. If <br>you want the complete stack trace from the start of the thread up to the exception handler, <br>you can use the System.Diagnostics.StackTrace type. This type defines some properties <br>and methods that allow a developer to programmatically manipulate a stack trace and the <br>frames that make up the stack trace.<br>
You can construct a StackTrace object by using several different constructors. Some con-<br>structors build the frames from the start of the thread to the point where the StackTrace <br>object is constructed. Other constructors initialize the frames of the StackTrace object by <br>using an Exception-derived object passed as an argument.<br>
If the CLR can find debug symbols (located in the .pdb files) for your assemblies, the <br>string returned by System.Exception's StackTrace property or System.Diagnostics.<br>StackTrace's ToString method will include source code file paths and line numbers. This <br>information is incredibly useful for debugging.<br>
Whenever you obtain a stack trace, you might find that some methods in the actual call stack <br>don't appear in the stack trace string. There are two reasons for this. First, the stack is really <br>a record of where the thread should return to, not where the thread has come from. Second, <br>the just-in-time (JIT) compiler can inline methods to avoid the overhead of calling and re-<br>turning from a separate method. Many compilers (including the C# compiler) offer a /debug <br>command-line switch. When this switch is used, these compilers embed information into the <br>resulting assembly to tell the JIT compiler not to inline any of the assembly's methods,  <br>making stack traces more complete and meaningful to the developer debugging the code.<br>
<b>Note  </b>The JIT compiler examines the System.Diagnostics.DebuggableAttribute custom <br>attribute applied to the assembly. The C# compiler applies this attribute automatically. If this  <br>attribute has the DisableOptimizations flag specified, the JIT compiler won't inline the  <br>assembly's methods. Using the C# compiler's /debug switch sets this flag. By applying the <br>System.Runtime.CompilerServices.MethodImplAttribute custom attribute to a method, <br>you can forbid the JIT compiler from inlining the method for both debug and release builds. The <br>following method definition shows how to forbid the method from being inlined:<br>
using System;  <br>using System.Runtime.CompilerServices;  <br>  <br>internal sealed class SomeType {  <br>  <br>   [MethodImpl(MethodImplOptions.NoInlining)]  <br>   public void SomeMethod() {   <br>      ...  <br>   }  <br>}<br>
<hr>
<A name=496></a><b>478 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>FCL-Defined Exception Classes</b><br>
The Framework Class Library (FCL) defines many exception types (all ultimately derived <br>from System.Exception). The following hierarchy shows the exception types defined in the <br>MSCorLib.dll assembly; other assemblies define even more exception types. (The application <br>used to obtain this hierarchy is shown in Chapter 23, "Assembly Loading and Reflection.")<br>
System.Exception <br>   System.AggregateException <br>   System.ApplicationException <br>      System.Reflection.InvalidFilterCriteriaException <br>      System.Reflection.TargetException <br>      System.Reflection.TargetInvocationException <br>      System.Reflection.TargetParameterCountException <br>      System.Threading.WaitHandleCannotBeOpenedException <br>   System.InvalidTimeZoneException <br>   System.IO.IsolatedStorage.IsolatedStorageException <br>   System.Runtime.CompilerServices.RuntimeWrappedException <br>   System.SystemException <br>      System.AccessViolationException <br>      System.AppDomainUnloadedException <br>      System.ArgumentException <br>         System.ArgumentNullException <br>         System.ArgumentOutOfRangeException <br>         System.DuplicateWaitObjectException <br>         System.Globalization.CultureNotFoundException <br>         System.Text.DecoderFallbackException <br>         System.Text.EncoderFallbackException <br>      System.ArithmeticException <br>         System.DivideByZeroException <br>         System.NotFiniteNumberException <br>         System.OverflowException <br>      System.ArrayTypeMismatchException <br>      System.BadImageFormatException <br>      System.CannotUnloadAppDomainException <br>      System.Collections.Generic.KeyNotFoundException <br>      System.ContextMarshalException <br>      System.DataMisalignedException <br>      System.ExecutionEngineException <br>      System.FormatException <br>         System.Reflection.CustomAttributeFormatException <br>      System.IndexOutOfRangeException <br>      System.InsufficientExecutionStackException <br>      System.InvalidCastException <br>      System.InvalidOperationException <br>         System.ObjectDisposedException <br>      System.InvalidProgramException <br>      System.IO.IOException <br>         System.IO.DirectoryNotFoundException <br>         System.IO.DriveNotFoundException <br>         System.IO.EndOfStreamException <br>         System.IO.FileLoadException <br>         System.IO.FileNotFoundException <br>         System.IO.PathTooLongException <br>      System.MemberAccessException <br>         System.FieldAccessException <br>
<hr>
<A name=497></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>479</b><br>
         System.MethodAccessException <br>         System.MissingMemberException <br>            System.MissingFieldException <br>            System.MissingMethodException <br>      System.MulticastNotSupportedException <br>      System.NotImplementedException <br>      System.NotSupportedException <br>         System.PlatformNotSupportedException <br>      System.NullReferenceException <br>      System.OperationCanceledException <br>         System.Threading.Tasks.TaskCanceledException <br>      System.OutOfMemoryException <br>         System.InsufficientMemoryException <br>      System.RankException <br>      System.Reflection.AmbiguousMatchException <br>      System.Reflection.ReflectionTypeLoadException <br>      System.Resources.MissingManifestResourceException <br>      System.Resources.MissingSatelliteAssemblyException <br>      System.Runtime.InteropServices.ExternalException <br>         System.Runtime.InteropServices.COMException <br>         System.Runtime.InteropServices.SEHException <br>      System.Runtime.InteropServices.InvalidComObjectException <br>      System.Runtime.InteropServices.InvalidOleVariantTypeException <br>      System.Runtime.InteropServices.MarshalDirectiveException <br>      System.Runtime.InteropServices.SafeArrayRankMismatchException <br>      System.Runtime.InteropServices.SafeArrayTypeMismatchException <br>      System.Runtime.Remoting.RemotingException <br>         System.Runtime.Remoting.RemotingTimeoutException <br>      System.Runtime.Remoting.ServerException <br>      System.Runtime.Serialization.SerializationException <br>      System.Security.Cryptography.CryptographicException <br>         System.Security.Cryptography.CryptographicUnexpectedOperationException <br>      System.Security.HostProtectionException <br>      System.Security.Policy.PolicyException <br>      System.Security.Principal.IdentityNotMappedException <br>      System.Security.SecurityException <br>      System.Security.VerificationException <br>      System.Security.XmlSyntaxException <br>      System.StackOverflowException <br>      System.Threading.AbandonedMutexException <br>      System.Threading.SemaphoreFullException <br>      System.Threading.SynchronizationLockException <br>      System.Threading.ThreadAbortException <br>      System.Threading.ThreadInterruptedException <br>      System.Threading.ThreadStartException <br>      System.Threading.ThreadStateException <br>      System.TimeoutException <br>      System.TypeInitializationException <br>      System.TypeLoadException <br>         System.DllNotFoundException <br>         System.EntryPointNotFoundException <br>      System.TypeUnloadedException <br>      System.UnauthorizedAccessException <br>         System.Security.AccessControl.PrivilegeNotHeldException <br>   System.Threading.LockRecursionException <br>   System.Threading.Tasks.TaskSchedulerException <br>   System.TimeZoneNotFoundException<br>
<hr>
<A name=498></a><b>480 </b><br>
<b>Part IV  Core Facilities</b><br>
Microsoft's original idea was that System.Exception<b> </b>would be the base type for <br>all exceptions and that two other types, System.SystemException and System.<br>ApplicationException, would be the only two types immediately derived from Exception. <br>Furthermore, exceptions thrown by the CLR would be derived from SystemException, and <br>all application-thrown exceptions would be derived from ApplicationException. This way, <br>developers could write a catch block that catches all CLR-thrown exceptions or all applica-<br>tion-thrown exceptions.<br>
However, as you can see, this rule was not followed very well; some exception types are im-<br>mediately derived from Exception (IsolatedStorageException), some CLR-thrown excep-<br>tions are derived from ApplicationException (TargetInvocationException), and some <br>application-thrown exceptions are derived from SystemException (FormatException). So <br>it is all a big mess, and the result is that the SystemException and ApplicationException <br>types have no special meaning at all. At this point, Microsoft would like to remove them from <br>the exception class hierarchy, but they can't because it would break any code that already <br>references these two types.<br>
<b>Throwing an Exception</b><br>
When implementing your own methods, you should throw an exception when the method <br>cannot complete its task as indicated by its name. When you want to throw an exception, <br>there are two issues that you really need to think about and consider.<br>
The first issue is about deciding what Exception-derived type are you going to throw. You <br>really want to select a type that is meaningful here. Consider the code that is higher up the <br>call stack and how that code might want to determine that a method failed in order to  <br>execute some graceful recovery code. You can use a type that is already defined in the FCL, <br>but there may not be one in the FCL that matches your exact semantics. So you'll probably <br>need to define your own type, ultimately derived from System.Exception.<br>
If you want to define an exception type hierarchy, it is highly recommended that the hierar-<br>chy be shallow and wide in order to create as few base classes as possible. The reason is that <br>base classes act as a way of treating lots of errors as one error, and this is usually dangerous. <br>Along these lines, you should never throw a System.Exception object,3 and you should use <br>extreme caution if you throw any other base class exception type.<br>
3  In fact, the System.Exception class should have been marked as abstract, which would forbid code that tried <br>
to throw it from even compiling. <br>
<hr>
<A name=499></a><IMG src="CLRviaCsharp-499_1.jpg"><br>
<b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>481</b><br>
<b>Important  </b>There are versioning ramifications here, too. If you define a new exception type de-<br>rived from an existing exception type, then all code that catches the existing base type will now <br>catch your new type as well. In some scenarios this may be desired and in some scenarios, it may <br>not be desired. The problem is that it really depends on how code that catches the base class <br>responds to the exception type and types derived from it. Code that never anticipated the new <br>exception may now behave unpredictably and open security holes. The person defining the new <br>exception type can't know about all the places where the base exception is caught and how it is <br>handled. And so, in practice, it is impossible to make a good intelligent decision here.<br>
The second issue is about deciding what string message are you going to pass to the  <br>exception type's constructor. When you throw an exception, you should include a string mes-<br>sage with detailed information indicating why the method couldn't complete its task. If the <br>exception is caught and handled, this string message is not seen. However, if the exception <br>becomes an unhandled exception, this message is usually logged. An unhandled exception <br>indicates a true bug in the application, and a developer must get involved to fix the bug. An <br>end user will not have the source code or the ability to fix the code and recompile it. In fact, <br>this string message should not be shown to an end user. So these string messages can be <br>very technically detailed and as geeky as is necessary to help developers fix their code.<br>
Furthermore, since all developers have to speak English (at least to some degree, since  <br>programming languages and the FCL classes and methods are in English), there is usually no <br>need to localize exception string messages. However, you may want to localize the strings if <br>you are building a class library that will be used by developers who speak different languages. <br>Microsoft localizes the exception messages thrown by the FCL, since developers all over the <br>world will be using this class library.<br>
<b>Defining Your Own Exception Class</b><br>
Unfortunately, designing your own exception is tedious and error prone. The main reason for <br>this is because all Exception-derived types should be serializable so that they can cross an <br>AppDomain boundary or be written to a log or database. There are many issues related to <br>serialization and they are discussed in Chapter 24, "Runtime Serialization." So, in an effort to <br>simplify things, I made my own generic Exception&lt;TExceptionArgs&gt; class, which is defined <br>as follows:<br>
[Serializable] <br>public sealed class Exception&lt;TExceptionArgs&gt; : Exception, ISerializable  <br>   where TExceptionArgs : ExceptionArgs { <br> <br>   private const String c_args = &quot;Args&quot;;  // For (de)serialization <br>   private readonly TExceptionArgs m_args; <br> <br>   public  TExceptionArgs Args { get { return m_args; } } <br> <br>
<hr>
<A name=500></a><b>482 </b><br>
<b>Part IV  Core Facilities</b><br>
   public Exception(String message = null, Exception innerException = null) <br>      : this(null, message, innerException) { } <br> <br>   public Exception(TExceptionArgs args, String message = null,  <br>      Exception innerException = null): base(message, innerException) { m_args = args; } <br> <br>   // The constructor is for deserialization; since the class is sealed, the constructor is <br>   // private. If this class were not sealed, this constructor should be protected  <br>   [SecurityPermission(SecurityAction.LinkDemand, <br>      Flags=SecurityPermissionFlag.SerializationFormatter)] <br>   private Exception(SerializationInfo info, StreamingContext context)  <br>      : base(info, context) { <br>      m_args = (TExceptionArgs)info.GetValue(c_args, typeof(TExceptionArgs)); <br>   } <br> <br>   // The method for serialization; it's public because of the ISerializable interface <br>   [SecurityPermission(SecurityAction.LinkDemand, <br>      Flags=SecurityPermissionFlag.SerializationFormatter)] <br>   public override void GetObjectData(SerializationInfo info, StreamingContext context) { <br>      info.AddValue(c_args, m_args); <br>      base.GetObjectData(info, context); <br>   } <br> <br>   public override String Message {  <br>      get { <br>         String baseMsg = base.Message; <br>         return (m_args == null) ? baseMsg : baseMsg + &quot; (&quot; + m_args.Message + &quot;)&quot;; <br>      } <br>   } <br> <br>   public override Boolean Equals(Object obj) { <br>      Exception&lt;TExceptionArgs&gt; other = obj as Exception&lt;TExceptionArgs&gt;; <br>      if (obj == null) return false; <br>      return Object.Equals(m_args, other.m_args) &amp;&amp; base.Equals(obj); <br>   } <br>   public override int GetHashCode() { return base.GetHashCode(); } <br>}<br>
And the ExceptionArgs base class that TExceptionArgs is constrained to is very simple <br>and looks like this:<br>
[Serializable] <br>public abstract class ExceptionArgs { <br>   public virtual String Message { get { return String.Empty; } } <br>}<br>
Now, with these two classes defined, I can trivially define more exception classes when I need <br>to. To define an exception type indicating the disk is full, I simply do this:<br>
[Serializable] <br>public sealed class DiskFullExceptionArgs : ExceptionArgs { <br>   private readonly String m_diskpath; // private field set at construction time <br> <br>   public DiskFullExceptionArgs(String diskpath) { m_diskpath = diskpath; } <br> <br>
<hr>
<A name=501></a><IMG src="CLRviaCsharp-501_1.jpg"><br>
<b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>483</b><br>
   // Public read-only property that returns the field <br>   public String DiskPath { get { return m_diskpath; } } <br> <br>   // Override the Message property to include our field (if set) <br>   public override String Message { <br>      get { <br>         return (m_diskpath == null) ? base.Message : &quot;DiskPath=&quot; + m_diskpath; <br>      } <br>   } <br>}<br>
And, if I have no additional data that I want to put inside the class, it gets as simple as this:<br>
[Serializable] <br>public sealed class DiskFullExceptionArgs : ExceptionArgs { }<br>
And now I can write code like this, which throws and catches one of these:<br>
public static void TextException() { <br>   try { <br>      throw new Exception&lt;DiskFullExceptionArgs&gt;( <br>         new DiskFullExceptionArgs(@&quot;C:\&quot;), &quot;The disk is full&quot;); <br>   } <br>   catch (Exception&lt;DiskFullExceptionArgs&gt; e) { <br>      Console.WriteLine(e.Message); <br>   } <br>}<br>
<b>Note  </b>There are two issues to note about my Exception&lt;TExceptionArgs&gt; class. The first is-<br>sue is that any exception type you define with it is always derived from System.Exception. In <br>most scenarios, this is not a problem at all and, in fact, having a shallow and wide exception type <br>hierarchy is preferred. The second issue is that Visual Studio's unhandled exception dialog box <br>doesn't display Exception&lt;T&gt; type's generic type parameter, as you can see here:<br>
<hr>
<A name=502></a><b>484 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Trading Reliability for Productivity</b><br>
I started writing software in 1975. I did a fair amount of BASIC programming, and as I got <br>more interested in hardware, I switched to assembly language. Over time, I switched to the C <br>programming language because it allowed me access to hardware with a much higher level <br>of abstraction, making my programming easier. My background is in writing operating sys-<br>tems code and platform/library code, so I always work hard to make my code as small and as <br>fast as possible since applications can only be as good as the OS and libraries they consume.<br>
In addition to creating small and fast code, I always focused on error recovery. When allocat-<br>ing memory (by using C++'s new operator or by calling malloc, HeapAlloc, VirtualAlloc, <br>etc.), I would always check the return value to ensure that the memory I requested was  <br>actually given to me. And, if the memory request failed, I always had an alternate code path <br>ensuring that the rest of the program's state was unaffected and would let any of my callers <br>know that I failed so that the calling code can take corrective measures too.<br>
For some reason that I can't quite explain, this attention to detail is not done when writing <br>code for the .NET Framework. Getting an out-of-memory situation is always possible  <br>and yet I almost never see any code containing a catch block to recover from an <br>OutOfMemoryException. In fact, I've even had some developers tell me that the CLR doesn't <br>let a program catch an OutOfMemoryException. For the record, this is absolutely not true; <br>you can catch this exception. In fact, there are many errors that are possible when executing <br>managed code and I hardly ever see developers write code that attempts to recover from <br>these potential failures. In this section, I'd like to point out some of the potential failures and <br>why it has become culturally acceptable to ignore them. I'd also like to point out some of the <br>significant problems that can occur when ignoring these failures and suggest some ways to <br>help mitigate these problems.<br>
Object-oriented programming allows developers to be very productive. A big part of this is <br>composability which makes it easy to write, read and maintain code. Take this line of code, <br>for example:<br>
Boolean f = &quot;Jeff&quot;.Substring(1, 1).ToUpper().EndsWith(&quot;E&quot;);<br>
There is a big assumption being made with the code above: no errors occur. But, of course, <br>errors are always possible, and so we need a way to handle those errors. This is what the  <br>exception handling constructs and mechanisms are all about and why we need them as  <br>opposed to having methods that return true/false to indicate success/failure the way that <br>Win32 and COM functions do.<br>
In addition to code composability, we are productive due to all kinds of great features  <br>provided by our compilers. For example, the compiler implicitly:<br>
  Inserts optional parameters when calling a method<br>
  Boxes value type instances<br>
<hr>
<A name=503></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>485</b><br>
  Constructs/initializes parameter arrays<br>
  Binds to members of dynamic variables and expressions<br>
  Binds to extension methods<br>
  Binds/invokes overloaded operators<br>
  Constructs delegate objects<br>
  Infers types when cal ing generic methods, declaring a local variable, and using a lambda <br>
expression<br>
  Defines/constructs closure classes for lambda expressions and iterators<br>
  Defines/constructs/initializes anonymous types and instances of them<br>
  Rewrites code to support Language Integrated Queries (LINQs; query expressions and <br>
expression trees)<br>
And, the CLR itself does all kinds of great things for developers to make our lives even easier. <br>For example, the CLR implicitly:<br>
  Invokes virtual methods and interface methods<br>
  Loads assemblies and JIT-compiles methods which can potentially throw <br>
FileLoadException, BadImageFormatException, InvalidProgramException, <br>FieldAccessException, MethodAccessException, MissingFieldException, <br>MissingMethodException, and VerificationException<br>
  Transitions across AppDomain boundaries when accessing an object of a  <br>
MarshalByRefObject-derived type which can potentially throw <br>AppDomainUnloadedException<br>
  Serializes and deserializes objects when crossing an AppDomain boundary<br>
  Causes thread(s) to throw a ThreadAbortException when Thread.Abort or <br>
AppDomain.Unload is called<br>
  Invokes Finalize methods after a garbage collection before objects have their  <br>
memory reclaimed<br>
  Creates type objects in the loader heap when using generic types<br>
  Invokes a type's static constructor potential throwing of TypeInitializationException<br>
  Throws various exceptions, including OutOfMemoryException, <br>
DivideByZeroException, NullReferenceException, RuntimeWrappedException, <br>TargetInvocationException, OverflowException, NotFiniteNumberException, <br>ArrayTypeMismatchException, DataMisalignedException, <br>IndexOutOfRangeException, InvalidCastException, RankException, <br>SecurityException, and more<br>
<hr>
<A name=504></a><b>486 </b><br>
<b>Part IV  Core Facilities</b><br>
And, of course, the .NET Framework ships with a massive class library which contains tens of <br>thousands of types each type encapsulating common, reusable functionality. There are types <br>for building Web form applications, Web services, rich GUI applications, working with security, <br>manipulation of images, speech recognition, and the list goes on and on. Any of this code <br>could throw an exception, indicating failure. And, future versions could introduce new excep-<br>tion types derived from existing exception types and now your catch blocks catch exception <br>types that never existed before.<br>
All of this stuff--object-oriented programming, compiler features, CLR features, and the <br>enormous class library--is what makes the .NET Framework such a compelling software  <br>development platform.4 My point is that all of this stuff introduces points of failure into your <br>code which you have little control over. As long as everything is working great, all is well: we <br>write code easily, the code is easy to read and maintain. But, when something goes wrong, it <br>is nearly impossible to fully understand what went wrong and why. Here is an example that <br>should really help get my point across:<br>
private static Object OneStatement(Stream stream, Char charToFind) { <br>   return (charToFind + &quot;: &quot; + stream.GetType() + String.Empty + (stream.Position + 512M)) <br>      .Where(c=&gt;c == charToFind).ToArray(); <br>}<br>
This slightly contrived method contains just one C# statement in it, but this statement does <br>an awful lot of work. In fact, here is the Intermediate Language (IL) the C# compiler pro-<br>duced for this method. (I've put some lines in boldface italics that are potential points of fail-<br>ure due to implicit operations that are occurring.)<br>
.method private hidebysig static object OneStatement( <br>   class [mscorlib]System.IO.Stream stream, char charToFind) cil managed { <br>   .maxstack 5 <br>   .locals init ( <br>      [0] class Program/&lt;&gt;c__DisplayClass1 CS$&lt;&gt;8__locals2, <br>      [1] object[] CS$0$0000) <br>   L_0000: newobj instance void Program/&lt;&gt;c__DisplayClass1::.ctor() <br>   L_0005: stloc.0  <br>   L_0006: ldloc.0  <br>   L_0007: ldarg.1  <br>   L_0008: stfld char Program/&lt;&gt;c__DisplayClass1::charToFind <br>   L_000d: ldc.i4.5  <br>   L_000e: newarr object <br>   L_0013: stloc.1  <br>   L_0014: ldloc.1  <br>   L_0015: ldc.i4.0  <br>   L_0016: ldloc.0  <br>   L_0017: ldfld char Program/&lt;&gt;c__DisplayClass1::charToFind <br>
4  I should also add that Visual Studio's editor, IntelliSense support, code snippet support, templates, extensibility <br>
system, debugging system, and various other tools also contribute to making the platform compelling for devel-<br>opers. However, I leave this out of the main discussion because it has no impact on the behavior of the code at <br>runtime.<br>
<hr>
<A name=505></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>487</b><br>
   L_001c: box char <br>   L_0021: stelem.ref  <br>   L_0022: ldloc.1  <br>   L_0023: ldc.i4.1  <br>   L_0024: ldstr &quot;: &quot; <br>   L_0029: stelem.ref  <br>   L_002a: ldloc.1  <br>   L_002b: ldc.i4.2  <br>   L_002c: ldarg.0  <br>   L_002d: callvirt instance class [mscorlib]System.Type [mscorlib]System.Object::GetType() <br>   L_0032: stelem.ref  <br>   L_0033: ldloc.1  <br>   L_0034: ldc.i4.3  <br>   L_0035: ldsfld string [mscorlib]System.String::Empty <br>   L_003a: stelem.ref  <br>   L_003b: ldloc.1  <br>   L_003c: ldc.i4.4  <br>   L_003d: ldc.i4 0x200 <br>   L_0042: newobj instance void [mscorlib]System.Decimal::.ctor(int32) <br>   L_0047: ldarg.0  <br>   L_0048: callvirt instance int64 [mscorlib]System.IO.Stream::get_Position() <br>   L_004d: call valuetype [mscorlib]System.Decimal  <br>                [mscorlib]System.Decimal::op_Implicit(int64) <br>   L_0052: call valuetype [mscorlib]System.Decimal [mscorlib]System.Decimal::op_Addition <br>              (valuetype [mscorlib]System.Decimal, valuetype [mscorlib]System.Decimal) <br>   L_0057: box [mscorlib]System.Decimal <br>   L_005c: stelem.ref  <br>   L_005d: ldloc.1  <br>   L_005e: call string [mscorlib]System.String::Concat(object[]) <br>   L_0063: ldloc.0  <br>   L_0064: ldftn instance bool Program/&lt;&gt;c__DisplayClass1::&lt;M&gt;b__0(char) <br>   L_006a: newobj instance  <br>           void [mscorlib]System.Func`2&lt;char, bool&gt;::.ctor(object, native int) <br>   L_006f: call class [mscorlib]System.Collections.Generic.IEnumerable`1&lt;!!0&gt; <br>              [System.Core]System.Linq.Enumerable::Where&lt;char&gt;( <br>                 class [mscorlib]System.Collections.Generic.IEnumerable`1&lt;!!0&gt;,  <br>                 class [mscorlib]System.Func`2&lt;!!0, bool&gt;) <br>   L_0074: call !!0[] [System.Core]System.Linq.Enumerable::ToArray&lt;char&gt; <br>              (class [mscorlib]System.Collections.Generic.IEnumerable`1&lt;!!0&gt;) <br>   L_0079: ret  <br>}<br>
As you can see, an OutOfMemoryException is possible when constructing the  <br>&lt;&gt;c__DisplayClass1 class (a compiler-generated type), the Object[] array, the Func  <br>delegate, and boxing the char and Decimal. Memory is also allocated internally when <br>Concat, Where, and ToArray are called. Constructing the Decimal instance could cause its <br>type constructor to be invoked resulting in a TypeInitializationException.5 And then, <br>there are the implicit calls to Decimal's op_Implicit operator and its op_Addition operator <br>methods, which could do anything including throwing an OverflowException.<br>
5  By the way, System.Char, System.String, System.Type, and System.IO.Stream all define class constructors <br>
which could all potentially cause a TypeInitializationException to be thrown at some point in this  <br>application.<br>
<hr>
<A name=506></a><b>488 </b><br>
<b>Part IV  Core Facilities</b><br>
Querying Stream's Position property is interesting. First, it is a virtual property and <br>so my OneStatement method has no idea what code will actually execute which could <br>throw any exception at all. Second, Stream is derived from MarshalByRefObject and <br>so the stream argument could actually refer to a proxy object which itself refers to an <br>object in another AppDomain. The other AppDomain could be unloaded and so an <br>AppDomainUnloadedException could also be thrown here.<br>
Of course, all the methods that are being called are methods that I personally have no <br>control over since they are produced by Microsoft. And it's entirely possible that Microsoft <br>might change how these methods are implemented in the future, so they could throw new <br>exception types that I could not possibly know about on the day I wrote the OneStatement <br>method. How can I possibly write my OneStatement method to be completely robust against <br>all possible failures? By the way, the opposite is also a problem: a catch block could catch an <br>exception type derived from the specified exception type and now I'm executing recovery <br>code for a different kind of failure.<br>
So now that you have a sense of all the possible failures, you can probably see why it has  <br>become culturally acceptable to not write truly robust and reliable code: it is simply impracti-<br>cal. Moreover, one could argue that it is actually impossible. The fact that errors do not  <br>occur frequently is another reason why it has become culturally acceptable. Since errors (like <br>OutOfMemoryException) occur very infrequently, the community has decided to trade truly <br>reliable code for programmer productivity.<br>
One of the nice things about exceptions is that an unhandled one causes your application  <br>to terminate. This is nice because during testing, you will discover problems quickly and the <br>information you get with an unhandled exception (error message and stack trace) are  <br>usually enough to allow you to fix your code. Of course, a lot of companies don't want their <br>application to just terminate after it has been tested and deployed and so a lot of developers <br>insert code to catch System.Exception, the base class of all exception types. However, the <br>problem with catching System.Exception and allowing the application to continue running <br>is that state may be corrupted.<br>
Earlier in this chapter, I showed an Account class that defines a Transfer method whose <br>job is to transfer money from one account to another account. What if, when this Transfer <br>method is called, it successfully subtracts money from the from account and then throws <br>an exception before it adds money to the to account? If calling code catches System.<br>Exception and continues running, then the state of the application is corrupted: both the <br>from and to accounts have less money in them then they should. Since we are talking about <br>money here, this state corruption wouldn't just be considered a simple bug, it would definitely <br>be considered a security bug. If the application continues running, it will attempt to perform <br>more transfers to and from various accounts and now state corruption is running rampant <br>within the application.<br>
<hr>
<A name=507></a><IMG src="CLRviaCsharp-507_1.jpg"><br>
<b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>489</b><br>
One could say that the Transfer method itself should catch System.Exception and restore <br>money back into the from account. And this might actually work out OK if the Transfer <br>method is simple enough. But if the Transfer method produces an audit record of the with-<br>drawn money or if other threads are manipulating the same account at the same time, then <br>attempting to undo the operation could fail as well, producing yet another thrown exception. <br>And now, state corruption is getting worse, not better.<br>
<b>Note  </b>One could argue that knowing <i>where</i> something went wrong is more useful than know-<br>ing <i>what</i> error occurred. For example, it might be more useful to know that transferring money <br>out of an account failed instead of knowing that Transfer failed due to a SecurityException <br>or OutOfMemoryException, etc. In fact, the Win32 error model works this way: methods return <br>true/false to indicate success/failure so you know which method failed. Then, if your program <br>cares about <i>why</i> it failed, it calls the Win32 GetLastError method. System.Exception does <br>have a Source property that tells you the method that failed. But this property is a String that <br>you'd have to parse, and if two methods internally call the same method, you can't tell from the <br>Source property alone which method your code called that failed. Instead, you'd have to parse <br>the String returned from Exception's StackTrace property to get this information. Since this <br>is so difficult, I've never seen anyone actually write code to do it.<br>
There are several things you can do to <i>help</i> mitigate state corruption:<br>
  The CLR doesn't allow a thread to be aborted when executing code inside a catch or <br>
finally block. So, we could make the Transfer method more robust simply by doing <br>this:<br>
public static void Transfer(Account from, Account to, Decimal amount) { <br>   try { /* do nothing in here */ } <br>   finally { <br>      from -= amount; <br>      // Now, a thread abort (due to Thread.Abort/AppDomain.Unload) can't happen here <br>      to += amount; <br>   } <br>}<br>
However, it is absolutely not recommended that you write all your code in finally <br>blocks! You should only use this technique for modifying extremely sensitive state.<br>
  You can use the System.Diagnostics.Contracts.Contract class to apply code con-<br>
tracts to your methods. Code contracts give you a way to validate arguments and other <br>variables before you attempt to modify state using these arguments/variables. If the  <br>arguments/variables meet the contract, then the <i>chance</i> of corrupted state is minimized <br>(not completely eliminated). If a contract fails, then an exception is thrown before any <br>state has been modified. I will talk about code contracts later in this chapter.<br>
  You can use constrained execution regions (CERs), which give you a way to take <br>
some CLR uncertainty out of the picture. For example, before entering a try block, <br>you can have the CLR load any assemblies needed by code in any associated catch <br>
<hr>
<A name=508></a><b>490 </b><br>
<b>Part IV  Core Facilities</b><br>
and finally blocks. In addition, the CLR will compile all the code in the catch <br>and finally blocks including all the methods called from within those blocks. <br>This will eliminate a bunch of potential exceptions (including FileLoadException, <br>BadImageFormatException, InvalidProgramException, FieldAccessException, <br>MethodAccessException, MissingFieldException, and MissingMethodException) <br>from occurring when trying to execute error recovery code (in catch blocks) <br>or cleanup code (in the finally block). It will also reduce the potential for <br>OutOfMemoryException and some other exceptions as well. I talk about CERs later in <br>this chapter.<br>
  Depending on where the state lives, you can use transactions which ensure that all <br>
state is modified or no state is modified. If the data is in a database, for example, trans-<br>actions work well. Windows also now supports transacted registry and file operations <br>(on an NTFS volume only) and so you might be able to use this; however the .NET <br>Framework doesn't expose this functionality directly today. You will have to P/Invoke to <br>native code to leverage it. See the System.Transactions.TransactionScope class for <br>more details about this.<br>
  You can design your methods to be more explicit. For example, the Monitor class is <br>
typically used for taking/releasing a thread synchronization lock as follows:<br>
public static class SomeType { <br>   private static Object s_myLockObject = new Object(); <br> <br>   public static void SomeMethod () { <br>      Monitor.Enter(s_myLockObject);  // If this throws, did the lock get taken or  <br>                                      // not? If it did, then it won't get released! <br>      try { <br>         // Do thread-safe operation here... <br>      } <br>      finally { <br>         Monitor.Exit(s_myLockObject); <br>      } <br>   } <br>   // ... <br>}<br>
Due to the problem shown above, the overload of Monitor's Enter method used <br>above is now discouraged, and it is recommended that you rewrite the above code as <br>follows:<br>
public static class SomeType { <br>   private static Object s_myLockObject = new Object(); <br> <br>   public static void SomeMethod () { <br>      Boolean lockTaken = false;  // Assume the lock was not taken <br>      try { <br>         // This works whether an exception is thrown or not!  <br>         Monitor.Enter(s_myLockObject, ref lockTaken);  <br> <br>         // Do thread-safe operation here... <br>      } <br>
<hr>
<A name=509></a><IMG src="CLRviaCsharp-509_1.jpg"><br>
<b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>491</b><br>
      finally { <br>         // If the lock was taken, release it <br>         if (lockTaken) Monitor.Exit(s_myLockObject); <br>      } <br>   } <br>   // ... <br>}<br>
While the explicitness in this code is an improvement, in the case of thread synchronization  <br>locks, the recommendation now is to not use them with exception handling at all. See <br>Chapter 29, "Hybrid Thread Synchronization Constructs," for more details about this.<br>
If, in your code, you have determined that state has already been corrupted beyond repair, <br>then you should destroy any corrupted state so that it can cause no additional harm. Then, <br>restart your application so your state initializes itself to a good condition and hopefully, <br>the state corruption will not happen again. Since managed state cannot leak outside of an <br>AppDomain, you can destroy any corrupted state that lives within an AppDomain by un-<br>loading the entire AppDomain by calling AppDomain's Unload method (see Chapter 22 for <br>details).<br>
And, if you feel that your state is so bad that the whole process should be terminated, then <br>you can call Environment's static FailFast method:<br>
public static void FailFast(String message); <br>public static void FailFast(String message, Exception exception);<br>
This method terminates the process without running any active try/finally blocks or <br>Finalize methods. This is good because executing more code while state is corrupted could <br>easily make matters worse. However, FailFast will allow any CriticalFinalizerObject-<br>derived objects, discussed in Chapter 21, "Automatic Memory Management (Garbage <br>Collection), a chance to clean up. This is usually OK because they tend to just close native  <br>resources, and Windows state is probably fine even if the CLR's state or your application's <br>state is corrupted. The FailFast method writes the message string and optional exception <br>(usually the exception captured in a catch block) to the Windows Application event log,  <br>produces a Windows error report, creates a memory dump of your application, and then  <br>terminates the current process.<br>
<b>Important  </b>Most of Microsoft's FCL code does not ensure that state remains good in the case <br>of an unexpected exception. If your code catches an exception that passes through FCL code and <br>then continues to use FCL objects, there is a chance that these objects will behave unpredictably. <br>It's a shame that more FCL objects don't maintain their state better in the face of unexpected <br>exceptions or call FailFast if their state cannot be restored.<br>
The point of this discussion is to make you aware of the potential problems related to using <br>the CLR's exception-handling mechanism. Most applications cannot tolerate running with a <br>corrupted state because it leads to incorrect data and possible security holes. If you are  <br>writing an application that cannot tolerate terminating (like an operating system or database <br>
<hr>
<A name=510></a><IMG src="CLRviaCsharp-510_1.jpg"><br>
<b>492 </b><br>
<b>Part IV  Core Facilities</b><br>
engine), then managed code is not a good technology to use. And while Microsoft Exchange <br>Server is largely written in managed code, it uses a native database to store e-mail messages. <br>The native database is called the Extensible Storage Engine, it ships with Windows, and can <br>usually be found at C:\Windows\System32\EseNT.dll. Your applications can also use this  <br>engine if you'd like; search for "Extensible Storage Engine" on Microsoft's MSDN Web site.<br>
Managed code is a good choice for applications that can tolerate an application terminating <br>when state corruption has possibly occurred. There are many applications that fall into this <br>category. Also, it takes significantly more resources and skills to write a robust native class <br>library or application; for many applications, managed code is the better choice because it <br>greatly enhances programmer productivity.<br>
<b>Guidelines and Best Practices</b><br>
Understanding the exception mechanism is certainly important. It is equally important to <br>understand how to use exceptions wisely. All too often, I see library developers catching <br>all kinds of exceptions, preventing the application developer from knowing that a problem <br>occurred. In this section, I offer some guidelines for developers to be aware of when using <br>exceptions.<br>
<b>Important  </b>If you're a <i>class library developer</i> developing types that will be used by other devel-<br>opers, take these guidelines very seriously. You have a huge responsibility: You're trying to design <br>the type in your class library so that it makes sense for a wide variety of applications. Remember <br>that you don't have intimate knowledge of the code that you're calling back (via delegates, virtu-<br>al methods, or interface methods). And you don't know which code is calling you. It's not feasible <br>to anticipate every situation in which your type will be used, so don't make any policy decisions. <br>Your code must not decide what conditions constitute an error; let the caller make that decision.<br>
In addition, watch state very closely and try not to corrupt it. Verify arguments passed to your <br>method by using code contracts (discussed later in this chapter). Try not to modify state at all. <br>If you do modify state, then be ready for a failure and then try to restore state. If you follow the <br>guidelines in this chapter, application developers will not have a difficult time using the types in <br>your class library.<br>
If you're an <i>application developer</i>, define whatever policy you think is appropriate. Following <br>the design guidelines in this chapter will help you discover problems in your code before it is <br>released, allowing you to fix them and make your application more robust. However, feel free to <br>diverge from these guidelines after careful consideration. You get to set the policy. For example, <br>application code can get more aggressive about catching exceptions than class library code.<br>
<b>Use </b>finally<b> Blocks Liberally</b><br>
I think finally blocks are awesome! They allow you to specify a block of code that's guaran-<br>teed to execute no matter what kind of exception the thread throws. You should use finally <br>blocks to clean up from any operation that successfully started before returning to your call-<br>
<hr>
<A name=511></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>493</b><br>
er or allowing code following the finally block to execute. You also frequently use finally <br>blocks to explicitly dispose of any objects to avoid resource leaking. Here's an example that <br>has all cleanup code (closing the file) in a finally block:<br>
using System;  <br>using System.IO;  <br>  <br>public sealed class SomeType {  <br>   private void SomeMethod() {  <br>      FileStream fs = new FileStream(@&quot;C:\Data.bin &quot;, FileMode.Open);  <br>      try {  <br>         // Display 100 divided by the first byte in the file.  <br>         Console.WriteLine(100 / fs.ReadByte());  <br>      }  <br>      finally {  <br>         // Put cleanup code in a finally block to ensure that the file gets closed regardless <br>         // of whether or not an exception occurs (for example, the first byte was 0).  <br>         if (fs != null) fs.Dispose(); <br>      }  <br>   }  <br>}<br>
Ensuring that cleanup code always executes is so important that many programming lan-<br>guages offer constructs that make writing cleanup code easier. For example, the C# language <br>automatically emits try/finally blocks whenever you use the lock, using, and foreach <br>statements. The C# compiler also emits try/finally blocks whenever you override a class's <br>destructor (the Finalize method). When using these constructs, the compiler puts the code <br>you've written inside the try block and automatically puts the cleanup code inside the  <br>finally block. Specifically,<br>
  When you use the lock statement, the lock is released inside a finally block.<br>
  When you use the using statement, the object has its Dispose method called inside a <br>
finally block.<br>
  When you use the foreach statement, the IEnumerator object has its Dispose  <br>
method called inside a finally block.<br>
  When you define a destructor method, the base class's Finalize method is called  <br>
inside a finally block.<br>
For example, the following C# code takes advantage of the using statement. This code is <br>shorter than the code shown in the previous example, but the code that the compiler gener-<br>ates is identical to the code generated in the previous example.<br>
using System;  <br>using System.IO;  <br>  <br>internal sealed class SomeType {  <br>   private void SomeMethod() {  <br>      using (FileStream fs = new FileStream(@&quot;C:\Data.bin&quot;, FileMode.Open)) { <br>
<hr>
<A name=512></a><IMG src="CLRviaCsharp-512_1.jpg"><br>
<b>494 </b><br>
<b>Part IV  Core Facilities</b><br>
         // Display 100 divided by the first byte in the file.  <br>         Console.WriteLine(100 / fs.ReadByte());  <br>      }  <br>   }  <br>}<br>
For more about the using statement, see Chapter 21; and for more about the lock state-<br>ment, see Chapter 29, "Hybrid Thread Synchronization Constructs."<br>
<b>Don't </b>Catch<b> Everything</b><br>
A ubiquitous mistake made by developers who have not been properly trained on the proper <br>use of exceptions is to use catch blocks too often and improperly. When you catch an  <br>exception, you're stating that you expected this exception, you understand why it occurred, <br>and you know how to deal with it. In other words, you're defining a policy for the application. <br>This all goes back to the "Trading Reliability for Productivity" section earlier in this chapter.<br>
All too often, I see code like this:<br>
try {  <br>   // try to execute code that the programmer knows might fail...  <br>}  <br>catch (Exception) {  <br>   ...  <br>}<br>
This code indicates that it was expecting <i>any</i> and <i>all</i> exceptions and knows how to recover <br>from <i>any</i> and <i>all</i> situations. How can this possibly be? A type that's part of a class library <br>should <i>never, ever, under any circumstance</i> catch and swallow all exceptions because there is <br>no way for the type to know exactly how the application intends to respond to an exception. <br>In addition, the type will frequently call out to application code via a delegate, virtual method, <br>or interface method. If the application code throws an exception, another part of the applica-<br>tion is probably expecting to catch this exception. The exception should be allowed to filter <br>its way up the call stack and let the application code handle the exception as it sees fit.<br>
If the exception is unhandled, the CLR terminates the process. I'll discuss unhandled excep-<br>tions later in this chapter. Most unhandled exceptions will be discovered during testing of <br>your code. To fix these unhandled exceptions, you will either modify the code to look for a <br>specific exception, or you will rewrite the code to eliminate the conditions that cause the  <br>exception to be thrown. The final version of the code that will be running in a production  <br>environment should see very few unhandled exceptions and will be extremely robust.<br>
<b>Note  </b>In some cases, a method that can't complete its task will detect that some object's state <br>has been corrupted and cannot be restored. Allowing the application to continue running might <br>result in unpredictable behavior or security vulnerabilities. When this situation is detected, that <br>method should not throw an exception; instead, it should force the process to terminate immedi-<br>ately by calling System.Environment's FailFast method.<br>
<hr>
<A name=513></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>495</b><br>
By the way, it <i>is</i> OK to catch System.Exception and execute some code inside the catch <br>block's braces as long as you re-throw the exception at the bottom of that code. Catching <br>System.Exception and swallowing the exception (not re-throwing it) should never be done <br>because it hides failures that allow the application to run with unpredictable results and  <br>potential security vulnerabilities. Visual Studio's code analysis tool (FxCopCmd.exe) will flag <br>any code that contains a catch (Exception) block unless there is a throw statement  <br>included in the block's code. The "Backing Out of a Partially Completed Operation When an <br>Unrecoverable Exception Occurs--Maintaining State" section, coming shortly in this chapter, <br>will discuss this pattern.<br>
Finally, it is OK to catch an exception occurring in one thread and re-throw the exception <br>in another thread. The Asynchronous Programming Model (discussed in Chapter 27, "I/O-<br>Bound Asynchronous Operations") supports this. For example, if a thread pool thread  <br>executes code that throws an exception, the CLR catches and swallows the exception and  <br>allows the thread to return to the thread pool. Later, some thread should call an EndXxx <br>method to determine the result of the asynchronous operation. The EndXxx method will <br>throw the same exception object that was thrown by the thread pool thread that did the  <br>actual work. In this scenario, the exception is being swallowed by the first thread; however, <br>the exception is being re-thrown by the thread that called the EndXxx method, so it is not <br>being hidden from the application.<br>
<b>Recovering Gracefully from an Exception</b><br>
Sometimes you call a method knowing in advance some of the exceptions that the method <br>might throw. Because you expect these exceptions, you might want to have some code that <br>allows your application to recover gracefully from the situation and continue running. Here's <br>an example in pseudocode:<br>
public String CalculateSpreadsheetCell(Int32 row, Int32 column) {  <br>   String result;  <br>   try {  <br>      result = /* Code to calculate value of a spreadsheet's cell */  <br>   }  <br>   catch (DivideByZeroException) {  <br>      result = &quot;Can't show value: Divide by zero&quot;;  <br>   }  <br>   catch (OverflowException) {  <br>      result = &quot;Can't show value: Too big&quot;;  <br>   }  <br>   return result;  <br>}<br>
This pseudocode calculates the contents of a cell in a spreadsheet and returns a string rep-<br>resenting the value to the caller so that the caller can display the string in the application's <br>window. However, a cell's contents might be the result of dividing one cell by another cell. If <br>the cell containing the denominator contains 0, the CLR will throw a DivideByZeroException <br>object. In this case, the method catches this specific exception and returns a special string that <br>
<hr>
<A name=514></a><b>496 </b><br>
<b>Part IV  Core Facilities</b><br>
will be displayed to the user. Similarly, a cell's contents might be the result of multiplying one <br>cell by another. If the multiplied value doesn't fit in the number of bits allowed, the CLR will <br>throw an OverflowException object, and again, a special string wil  be displayed to the user.<br>
When you catch specific exceptions, fully understand the circumstances that cause the <br>exception to be thrown, and know what exception types are derived from the exception <br>type you're catching. Don't catch and handle System.Exception (without re-throwing) <br>because it's not feasible for you to know all of the possible exceptions that could be <br>thrown within your try block (especially if you consider the OutOfMemoryException or the <br>StackOverflowException, to name two).<br>
<b>Backing Out of a Partially Completed Operation When an </b><br>
<b>Unrecoverable Exception Occurs--Maintaining State</b><br>
Usually, methods call several other methods to perform a single abstract operation. Some of <br>the individual methods might complete successfully, and some might not. For example, let's <br>say that you're serializing a set of objects to a disk file. After serializing 10 objects, an excep-<br>tion is thrown. (Perhaps the disk is full or the next object to be serialized isn't marked with <br>the Serializable custom attribute.) At this point, the exception should filter up to the caller, <br>but what about the state of the disk file? The file is now corrupted because it contains a par-<br>tially serialized object graph. It would be great if the application could back out of the par-<br>tially completed operation so that the file would be in the state it was in before any objects <br>were serialized into it. The following code demonstrates the correct way to implement this:<br>
public void SerializeObjectGraph(FileStream fs, IFormatter formatter, Object rootObj) {  <br>  <br>   // Save the current position of the file.  <br>   Int64 beforeSerialization = fs.Position;   <br>  <br>   try {  <br>      // Attempt to serialize the object graph to the file.  <br>      formatter.Serialize(fs, rootObj);  <br>   }  <br>   catch {  // Catch any and all exceptions.  <br>      // If ANYTHING goes wrong, reset the file back to a good state.  <br>      fs.Position = beforeSerialization;  <br>  <br>      // Truncate the file.  <br>      fs.SetLength(fs.Position);  <br>  <br>      // NOTE: The preceding code isn't in a finally block because  <br>      // the stream should be reset only when serialization fails.   <br>  <br>      // Let the caller(s) know what happened by re-throwing the SAME exception.  <br>      throw;  <br>   }  <br>}<br>
To properly back out of the partially completed operation, write code that catches all ex-<br>ceptions. Yes, catch <i>all</i> exceptions here because you don't care what kind of error occurred; <br>
<hr>
<A name=515></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>497</b><br>
you need to put your data structures back into a consistent state. After you've caught and <br>handled the exception, don't swallow it--let the caller know that the exception occurred. You <br>do this by re-throwing the same exception. In fact, C# and many other languages make this <br>easy. Just use C#'s throw keyword without specifying anything after throw, as shown in the <br>previous code.<br>
Notice that the catch block in the previous example doesn't specify any exception type be-<br>cause I want to catch any and all exceptions. In addition, the code in the catch block doesn't <br>need to know exactly what kind of exception was thrown, just that something went wrong. <br>Fortunately, C# lets me do this easily just by not specifying any exception type and by mak-<br>ing the throw statement re-throw whatever object is caught.<br>
<b>Hiding an Implementation Detail to Maintain a "Contract"</b><br>
In some situations, you might find it useful to catch one exception and re-throw a different <br>exception. The only reason to do this is to maintain the meaning of a method's contract. <br>Also, the new exception type that you throw should be a specific exception (an exception <br>that's not used as the base type of any other exception type). Imagine a PhoneBook type that <br>defines a method that looks up a phone number from a name, as shown in the following <br>pseudocode:<br>
internal sealed class PhoneBook {  <br>   private String m_pathname;  // path name of file containing the address book  <br>  <br>   // Other methods go here.  <br>  <br>   public String GetPhoneNumber(String name) {  <br>      String phone;  <br>      FileStream fs = null;  <br>      try {  <br>         fs = new FileStream(m_pathname, FileMode.Open);  <br>         // Code to read from fs until name is found goes here  <br>         phone = /* the phone # found */  <br>      }  <br>      catch (FileNotFoundException e) {  <br>         // Throw a different exception containing the name, and  <br>         // set the originating exception as the inner exception.  <br>         throw new NameNotFoundException(name, e);  <br>      }  <br>      catch (IOException e) {  <br>         // Throw a different exception containing the name, and  <br>         // set the originating exception as the inner exception.  <br>         throw new NameNotFoundException(name, e);  <br>      }  <br>      finally {  <br>         if (fs != null) fs.Close();  <br>      }  <br>      return phone;  <br>   }  <br>}<br>
<hr>
<A name=516></a><IMG src="CLRviaCsharp-516_1.jpg"><br>
<b>498 </b><br>
<b>Part IV  Core Facilities</b><br>
The phone book data is obtained from a file (versus a network connection or database). <br>However, the user of the PhoneBook type doesn't know this because this is an imple-<br>mentation detail that could change in the future. So if the file isn't found or can't be read <br>for any reason, the caller would see a FileNotFoundException or IOException, which <br>wouldn't be anticipated. In other words, the file's existence and ability to be read is not <br>part of the method's implied contract: There is no way the caller could have guessed this. <br>So the GetPhoneNumber method catches these two exception types and throws a new <br>NameNotFoundException.<br>
When using this technique, you should catch specific exceptions that you fully understand <br>the circumstances that cause the exception to be thrown. And, you should also know what <br>exception types are derived from the exception type you're catching.<br>
Throwing an exception still lets the caller know that the method cannot complete its task, <br>and the NameNotFoundException type gives the caller an abstracted view as to why. Setting <br>the inner exception to FileNotFoundException or IOException is important so that the <br>real cause of the exception isn't lost. Besides, knowing what caused the exception could <br>be useful to the developer of the PhoneBook type and possibly to a developer using the <br>PhoneBook type.<br>
<b>Important  </b>When you use this technique, you are lying to callers about two things. First, you <br>are lying about what actually went wrong. In my example, a file was not found but I'm report-<br>ing that a name was not found. Second, you are lying about where the failure occurred. If the <br>FileNotFoundException were allowed to propagate up the call stack, its StackTrace property <br>would reflect that the error occurred inside FileStream's constructor. But when I swallow this <br>exception and throw a new NameNotFoundException, the stack trace will indicate that the error <br>occurred inside the catch block, several lines away from where the real exception was thrown. <br>This can make debugging very difficult, so this technique should be used with great care.<br>
Now let's say that the PhoneBook type was implemented a little differently. Assume that the <br>type offers a public PhoneBookPathname property that allows the user to set or get the path <br>name of the file in which to look up a phone number. Because the user is aware of the fact <br>that the phone book data comes from a file, I would modify the GetPhoneNumber method so <br>that it doesn't catch any exceptions; instead, I let whatever exception is thrown propagate out <br>of the method. Note that I'm not changing any parameters of the GetPhoneNumber method, <br>but I am changing how it's abstracted to users of the PhoneBook type. Users now expect a <br>path to be part of the PhoneBook's contract.<br>
Sometimes developers catch one exception and throw a new exception in order to add  <br>additional data or context to an exception. However, if this is all you want to do, you should <br>just catch the exception type you want, add data to the exception object's Data property  <br>collection, and then re-throw the same exception object:<br>
<hr>
<A name=517></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>499</b><br>
private static void SomeMethod(String filename) { <br>   try { <br>      // Do whatevere here... <br>   } <br>   catch (IOException e) { <br>      // Add the filename to the IOException object <br>      e.Data.Add(&quot;Filename&quot;, filename); <br> <br>      throw;   // re-throw the same exception object that now has additional data in it <br>   } <br>}<br>
Here is a good use of this technique: When a type constructor throws an exception that is  <br>not caught within the type constructor method, the CLR internally catches that exception  <br>and throws a new TypeInitializationException instead. This is useful because the CLR <br>emits code within your methods to implicitly call type constructors.6 If the type constructor  <br>threw a DivideByZeroException, your code might try to catch it and recover from it but <br>you didn't even know you were invoking the type constructor. So the CLR converts the <br>DivideByZeroException into a TypeInitializationException so that you know clearly <br>that the exception occurred due to a type constructor failing; the problem wasn't with your <br>code.<br>
On the other hand, here is a bad use of this technique: When you invoke a method via  <br>reflection, the CLR internally catches any exception thrown by the method and converts it <br>to a TargetInvocationException. This is incredibly annoying as you must now catch the <br>TargetInvocationException object and look at its InnerException property to discern <br>the real reason for the failure. In fact, when using reflection, it is common to see code that <br>looks like this:<br>
private static void Reflection(Object o) { <br>   try { <br>      // Invoke a DoSomething method on this object <br>      var mi = o.GetType().GetMethod(&quot;DoSomething&quot;); <br>      mi.Invoke(o, null);  // The DoSomething method might throw an exception <br>   } <br>   catch (System.Reflection.TargetInvocationException e) { <br>      // The CLR converts reflection-produced exceptions to TargetInvocationException <br>      throw e.InnerException; // Re-throw what was originally thrown <br>   } <br>}<br>
I have good news though: If you use C#'s dynamic primitive type (discussed in Chapter 5, <br>"Primitive, Reference, and Value Types") to invoke a member, the compiler-generated code <br>does not catch any and all exceptions and throw a TargetInvocationException object; the <br>originally thrown exception object simply walks up the stack. For many developers, this is a <br>good reason to prefer using C#'s dynamic primitive type rather than reflection.<br>
6  For more information about this, see the "Type Constructors" section in Chapter 8, "Methods."<br>
<hr>
<A name=518></a><b>500 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Unhandled Exceptions</b><br>
When an exception is thrown, the CLR climbs up the call stack looking for catch blocks that <br>match the type of the exception object being thrown. If no catch block matches the thrown <br>exception type, an <i>unhandled exception</i> occurs. When the CLR detects that any thread in the <br>process has had an unhandled exception, the CLR terminates the process. An unhandled  <br>exception identifies a situation that the application didn't anticipate and is considered to be <br>a true bug in the application. At this point, the bug should be reported back to the company <br>that publishes the application. Hopefully, the publisher will fix the bug and distribute a new <br>version of the application.<br>
Class library developers should not even think about unhandled exceptions. Only application  <br>developers need to concern themselves with unhandled exceptions, and the application <br>should have a policy in place for dealing with unhandled exceptions. Microsoft actually  <br>recommends that application developers just accept the CLR's default policy. That is, when <br>an application gets an unhandled exception, Windows writes an entry to the system's event <br>log. You can see this entry by opening the Event Viewer application and then looking under <br>Windows Logs   Application node in the tree, as shown in Figure 20-1.<br>
<b>FIGURE 20-1  </b>Windows Event log showing an application that terminated due to an unhandled exception<br>
However, you can get more interesting details about the problem by using the Windows <br>Action Center applet. To start the Action Center, click on the flag icon in the system tray,  <br>select Open Action Center, expand the Maintenance box, and then select the "View reliability <br>history" link. From here, you can see the applications that have terminated due to an  <br>unhandled exception in the bottom pane, as shown in Figure 20-2.<br>
<hr>
<A name=519></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>501</b><br>
<b>FIGURE 20-2  </b>Reliability Monitor showing an application that terminated due to an unhandled exception<br>
To see more details about the terminated application, double-click on a terminated applica-<br>tion in Reliability Monitor. The details will look something like Figure 20-3 and the meaning <br>of the problem signatures are described in Table 20-2. All unhandled exceptions produced by <br>managed applications are placed in the CLR20r3 bucket.<br>
<b>FIGURE 20-3  </b>Reliability Monitor showing more details about the failed application<br>
<hr>
<A name=520></a><b>502 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>TABLE 20-2  Problem Signatures</b><br>
<b>Problem Signature</b><br>
<b>Description*</b><br>
01<br>
EXE file's name (32-character limit)<br>
02<br>
EXE file's assembly version number<br>
03<br>
EXE file's timestamp<br>
04<br>
EXE file's full assembly name (64-character limit)<br>
05<br>
Faulting assembly's version<br>
06<br>
Faulting assembly's timestamp<br>
07<br>
Faulting assembly's type and method. This value is a MethodDef metadata <br>token (after stripping off the 0x06 high byte) identifying the method that <br>threw the exception. From this value, you can use ILDasm.exe to determine <br>the offending type and method. <br>
08<br>
Faulting method's IL instruction. This value is an offset within the faulting <br>method of the IL instruction that threw the exception. From this value, you <br>can use ILDasm.exe to determine the offending instruction.<br>
09<br>
Exception type thrown (32-character limit)<br>
* If a string is beyond the allowed limit, then some intelligent truncations are performed, like removing "Exception" from the exception type or <br>
".dll" from a file name. If the resulting string is still too long, then the CLR will create a value by hashing or base-64­encoding the string.<br>
After recording information about the failing application, Windows displays the message box <br>allowing the end user to send information about the failing application to Microsoft's servers.7 <br>This is called <i>Windows Error Reporting</i>, and more information about it can be found at the <br>Windows Quality Web site (<i>http://WinQual.Microsoft.com</i>).<br>
Companies can optionally sign up with Microsoft to view this information about their own <br>applications and components. Signing up is free, but it does require that your assemblies be <br>signed with a VeriSign ID (also called a Software Publisher's Digital ID for Authenticode).<br>
Naturally, you could also develop your own system for getting unhandled exception informa-<br>tion back to you so that you can fix bugs in your code. When your application initializes, you <br>can inform the CLR that you have a method that you want to be called whenever any thread <br>in your application experiences an unhandled exception.<br>
Unfortunately, every application model Microsoft produces has its own way of tapping into <br>unhandled exceptions. The members that you want to look up in the FCL documentation are:<br>
  For any application, look at System.AppDomain's UnhandledException event. <br>
Silverlight applications do not execute with enough security to register with this event.<br>
  For a Windows Forms application, look at System.Windows.Forms.NativeWindow's <br>
OnThreadException virtual method, System.Windows.Forms.Application's <br>OnThreadException virtual method, and System.Windows.Forms.Application's <br>ThreadException event.<br>
7  You can actually disable this message box by using P/Invoke to call Win32's SetErrorMode function, passing in <br>
SEM_NOGPFAULTERRORBOX.<br>
<hr>
<A name=521></a><IMG src="CLRviaCsharp-521_1.jpg"><br>
<b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>503</b><br>
  For a Windows Presentation Foundation (WPF) application, look at System.Windows.<br>
Application's DispatcherUnhandledException event and System.Windows.<br>Threading.Dispatcher's UnhandledException and UnhandledExceptionFilter <br>events.<br>
  For Silverlight, look at System.Windows.Application's UnhandledException event.<br>
  For an ASP.NET Web Form application, look at System.Web.UI.TemplateControl's <br>
Error event. TemplateControl is the base class of the System.Web.UI.Page <br>and System.Web.UI.UserControl classes. Furthermore, you should also look at <br>System.Web.HttpApplication's Error event.<br>
  For a Windows Communication Foundation application, look at System.<br>
ServiceModel.Dispatcher.ChannelDispatcher's ErrorHandlers property.<br>
Before I leave this section, I'd like to say a few words about unhandled exceptions that could <br>occur in a distributed application such as a Web site or Web service. In an ideal world, a <br>server application that experiences an unhandled exception should log it, send some kind of <br>notification back to the client indicating that the requested operation could not complete, <br>and then the server should terminate. Unfortunately, we don't live in an ideal world, and <br>therefore, it may not be possible to send a failure notification back to the client. For some <br>stateful servers (such as Microsoft SQL Server), it may not be practical to terminate the server <br>and start a brand new instance.<br>
For a server application, information about the unhandled exception should not be returned <br>to the client because there is little a client could do about it, especially if the client is imple-<br>mented by a different company. Furthermore, the server should divulge as little information <br>about itself as possible to its clients to reduce that potential of the server being hacked.<br>
<b>Note  </b>The CLR considers some exceptions thrown by native code as <i>corrupted state exceptions <br>(CSEs)</i> because they are usually the result of a bug in the CLR itself or in some native code for <br>which the managed developer has no control over. By default, the CLR will not let managed code <br>catch these exceptions and finally blocks will not execute. Here is the list of native Win32  <br>exceptions that are considered CSEs:<br>
EXCEPTION_ACCESS_VIOLATION         EXCEPTION_STACK_OVERFLOW <br>EXCEPTION_ILLEGAL_INSTRUCTION      EXCEPTION_IN_PAGE_ERROR <br>EXCEPTION_INVALID_DISPOSITION      EXCEPTION_NONCONTINUABLE_EXCEPTION <br>EXCEPTION_PRIV_INSTRUCTION         STATUS_UNWIND_CONSOLIDATE.<br>
Individual managed methods can override the default and catch these exceptions by applying  <br>the System.Runtime.ExceptionServices.HandleProcessCorruptedStateExceptionsAttribute <br>to the method. In addition, the method must have the System.Security.<br>SecurityCriticalAttribute applied to it. You can also override the default for an entire <br>process by setting the legacyCorruptedStateExceptionPolicy element in the application's <br>Extensible Markup Language (XML) configuration file to true. The CLR converts most of these <br>to a System.Runtime.InteropServices.SEHException object except for EXCEPTION_<br>ACCESS_VIOLATION, which is converted to a System.AccessViolationException object, and <br>EXCEPTION_STACK_OVERFLOW, which is converted to a System.StackOverflowException <br>object.<br>
<hr>
<A name=522></a><IMG src="CLRviaCsharp-522_1.jpg"><br>
<b>504 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Note  </b>Just before invoking a method, you could check for ample stack space by calling  <br>the RuntimeHelper class's EnsureSufficientExecutionStack method. This method  <br>checks if the calling thread has enough stack space available to execute the average  <br>method (which is not well defined). If there is insufficient stack space, the method <br>throws an InsufficientExecutionStackException which you can catch. The <br>EnsureSufficientExecutionStack method takes no arguments and returns void. This  <br>method is typically used by recursive methods.<br>
<b>Debugging Exceptions</b><br>
The Visual Studio debugger offers special support for exceptions. With a solution open, <br>choose Exceptions from the Debug menu, and you'll see the dialog box shown in Figure 20-4.<br>
<b>FIGURE 20-4  </b>The Exceptions dialog box, showing the different kinds of exceptions<br>
This dialog box shows the different kinds of exceptions that Visual Studio is aware of. <br>For Common Language Runtime Exceptions, expanding the corresponding branch in the <br>dialog box, as in Figure 20-5, shows the set of namespaces that the Visual Studio debugger is <br>aware of.<br>
<b>FIGURE 20-5  </b>The Exceptions dialog box, showing CLR exceptions by namespace<br>
<hr>
<A name=523></a><IMG src="CLRviaCsharp-523_1.jpg"><br>
<b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>505</b><br>
If you expand a namespace, you'll see all of the System.Exception-derived types defined <br>within that namespace. For example, Figure 20-6 shows what you'll see if you open the <br>System namespace.<br>
<b>FIGURE 20-6  </b>The Exceptions dialog box, showing CLR exceptions defined in the System namespace<br>
For any exception type, if its Thrown check box is selected, the debugger will break as soon <br>as that exception is thrown. At this point, the CLR has not tried to find any matching catch <br>blocks. This is useful if you want to debug your code that catches and handles an exception. <br>It is also useful when you suspect that a component or library may be swallowing or re-<br>throwing exceptions, and you are uncertain where exactly to set a break point to catch it in <br>the act.<br>
If an exception type's Thrown check box is not selected, the debugger will also break where <br>the exception was thrown, but only if the exception type was not handled. Developers usually <br>leave the Thrown check box cleared because a handled exception indicates that the applica-<br>tion anticipated the situation and dealt with it; the application continues running normally.<br>
If you define your own exception types, you can add them to this dialog box by clicking Add. <br>This causes the dialog box in Figure 20-7 to appear.<br>
<b>FIGURE 20-7  </b>Making Visual Studio aware of your own exception type: the New Exception dialog box<br>
In this dialog box, you first select the type of exception to be Common Language Runtime <br>Exceptions, and then, you can enter the fully qualified name of your own exception type. <br>Note that the type you enter doesn't have to be a type derived from System.Exception; <br>non­CLS-compliant types are fully supported. If you have two or more types with the same <br>name but in different assemblies, there is no way to distinguish the types from one another. <br>Fortunately, this situation rarely happens.<br>
<hr>
<A name=524></a><b>506 </b><br>
<b>Part IV  Core Facilities</b><br>
If your assembly defines several exception types, you must add them one at a time. In the <br>future, I'd like to see this dialog box allow me to browse for an assembly and automatically <br>import all Exception-derived types into Visual Studio's debugger. Each type could then be <br>identified by assembly as well, which would fix the problem of having two types with the <br>same name in different assemblies.<br>
<b>Exception-Handling Performance Considerations</b><br>
The developer community actively debates the performance of exception handling. Some <br>people claim that exception handling performance is so bad that they refuse to even use <br>exception handling. However, I contend that in an object-oriented platform, exception han-<br>dling is not an option; it is mandatory. And besides, if you didn't use it, what would you use <br>instead? Would you have your methods return true/false to indicate success/failure or <br>perhaps some error code enum type? Well, if you did this, then you have the worst of both <br>worlds: The CLR and the class library code will throw exceptions and your code will return  <br>error codes. You'd have to now deal with both of these in your code.<br>
It's difficult to compare performance between exception handling and the more conventional <br>means of reporting exceptions (such as HRESULTs, special return codes, and so forth). If you <br>write code to check the return value of every method call and filter the return value up to <br>your own callers, your application's performance will be seriously affected. But performance <br>aside, the amount of additional coding you must do and the potential for mistakes is incred-<br>ibly high when you write code to check the return value of every method. Exception handling <br>is a much better alternative.<br>
However, exception handling has a price: Unmanaged C++ compilers must generate code <br>to track which objects have been constructed successfully. The compiler must also generate <br>code that, when an exception is caught, calls the destructor of each successfully constructed <br>object. It's great that the compiler takes on this burden, but it generates a lot of bookkeeping <br>code in your application, adversely affecting code size and execution time.<br>
On the other hand, managed compilers have it much easier because managed objects are <br>allocated in the managed heap, which is monitored by the garbage collector. If an object is <br>successfully constructed and an exception is thrown, the garbage collector will eventually  <br>free the object's memory. Compilers don't need to emit any bookkeeping code to track <br>which objects are constructed successfully and don't need to ensure that a destructor has <br>been called. Compared to unmanaged C++, this means that less code is generated by the <br>compiler, and less code has to execute at runtime, resulting in better performance for your <br>application.<br>
Over the years, I've used exception handling in different programming languages, different  <br>operating systems, and different CPU architectures. In each case, exception handling is <br>implemented differently with each implementation having its pros and cons with respect to <br>
<hr>
<A name=525></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>507</b><br>
performance. Some implementations compile exception handling constructs directly into a <br>method, whereas other implementations store information related to exception handling in a <br>data table associated with the method--this table is accessed only if an exception is thrown. <br>Some compilers can't inline methods that contain exception handlers, and some compilers <br>won't enregister variables if the method contains exception handlers.<br>
The point is that you can't determine how much additional overhead is added to an applica-<br>tion when using exception handling. In the managed world, it's even more difficult to tell  <br>because your assembly's code can run on any platform that supports the .NET Framework.  <br>So the code produced by the JIT compiler to manage exception handling when your assem-<br>bly is running on an x86 machine will be very different from the code produced by the JIT <br>compiler when your code is running on an x64 or IA64 processor. Also, JIT compilers associ-<br>ated with other CLR implementations (such as Microsoft's .NET Compact Framework or the <br>open-source Mono project) are likely to produce different code.<br>
Actually, I've been able to test some of my own code with a few different JIT compilers that <br>Microsoft has internally, and the difference in performance that I've observed has been quite <br>dramatic and surprising. The point is that you must test your code on the various platforms <br>that you expect your users to run on, and make changes accordingly. Again, I wouldn't worry <br>about the performance of using exception handling; because the benefits typically far out-<br>weigh any negative performance impact.<br>
If you're interested in seeing how exception handling impacts the performance of your code, <br>you can use the Performance Monitor tool that comes with Windows. The screen in Figure 20-8 <br>shows the exception-related counters that are installed along with the .NET Framework.<br>
<b>FIGURE 20-8  </b>Performance Monitor showing the .NET CLR Exceptions counters<br>
<hr>
<A name=526></a><b>508 </b><br>
<b>Part IV  Core Facilities</b><br>
Occasionally, you come across a method that you call frequently that has a high failure <br>rate. In this situation, the performance hit of having exceptions thrown can be intolerable. <br>For example, Microsoft heard back from several customers who were calling Int32's Parse <br>method, frequently passing in data entered from an end user that could not be parsed. Since <br>Parse was called frequently, the performance hit of throwing and catching the exceptions <br>was taking a large toll on the application's overall performance.<br>
To address customers' concerns and to satisfy all the guidelines described in this chapter, <br>Microsoft added a new method to the Int32 class. This new method is called TryParse, and <br>it has two overloads that look like this:<br>
public static Boolean TryParse(String s, out Int32 result); <br>public static Boolean TryParse(String s, NumberStyles styles,  <br>   IFormatProvider, provider, out Int32 result);<br>
You'll notice that these methods return a Boolean that indicates whether the String passed <br>in contains characters that can be parsed into an Int32. These methods also return an out-<br>put parameter named result. If the methods return true, result will contain the result of <br>parsing the string into a 32-bit integer. If the methods return false, result will contain 0, <br>but you really shouldn't execute any code that looks at it anyway.<br>
One thing I want to make absolutely clear: A TryXxx method's Boolean return value returns  <br>false to indicate one and only one type of failure. The method should still throw exceptions  <br>for any other type of failure. For example, Int32's TryParse throws an ArgumentException <br>if the style's argument is not valid, and it is certainly still possible to have an <br>OutOfMemoryException thrown when calling TryParse.<br>
I also want to make it clear that object-oriented programming allows programmers to be <br>productive. One way that it does this is by not exposing error codes in a type's members. In <br>other words, constructors, methods, properties, etc. are all defined with the idea that calling <br>them won't fail. And, if defined correctly, for most uses of a member, it will not fail, and there <br>will be no performance hit because an exception will not be thrown.<br>
When defining types and their members, you should define the members so that it is unlikely <br>that they will fail for the common scenarios in which you expect your types to be used. If <br>you later hear from users that they are dissatisfied with the performance due to exceptions <br>being thrown, then and only then should you consider adding TryXxx methods. In other <br>words, you should produce the best object model first and then, if users push back, add <br>some TryXxx methods to your type so that the users who experience performance trouble <br>can benefit. Users who are not experiencing performance trouble should continue to use the <br>non-TryXxx versions of the methods because this is the better object model.<br>
<hr>
<A name=527></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>509</b><br>
<b>Constrained Execution Regions (CERs)</b><br>
Many applications don't need to be robust and recover from any and all kinds of failures. <br>This is true of many client applications like Notepad.exe and Calc.exe. And, of course, many <br>of us have seen Microsoft Office applications like WinWord.exe, Excel.exe, and Outlook.exe <br>terminate due to unhandled exceptions. Also, many server-side applications, like Web servers, <br>are stateless and are automatically restarted if they fail due to an unhandled exception. Of <br>course some servers, like SQL Server, are all about state management and having data lost <br>due to an unhandled exception is potentially much more disastrous.<br>
In the CLR, we have AppDomains (discussed in Chapter 22), which contain state. When an <br>AppDomain is unloaded, all its state is unloaded. And so, if a thread in an AppDomain  <br>experiences an unhandled exception, it is OK to unload the AppDomain (which destroys all <br>its state) without terminating the whole process.8<br>
By definition, a CER is a block of code that must be resilient to failure. Since AppDomains can <br>be unloaded, destroying their state, CERs are typically used to manipulate any state that is <br>shared by multiple AppDomains or processes. CERs are useful when trying to maintain state <br>in the face of exceptions that get thrown unexpectedly. Sometimes we refer to these kinds of <br>exceptions as <i>asynchronous exceptions</i>. For example, when calling a method, the CLR has to <br>load an assembly, create a type object in the AppDomain's loader heap, call the type's static <br>constructor, JIT IL into native code, and so on. Any of these operations could fail, and the CLR  <br>reports the failure by throwing an exception.<br>
If any of these operations fail within a catch or finally block, then your error recovery or <br>cleanup code won't execute in its entirety. Here is an example of code that exhibits the  <br>potential problem:<br>
private static void Demo1() { <br>   try { <br>      Console.WriteLine(&quot;In try&quot;); <br>   } <br>   finally { <br>      // Type1's static constructor is implicitly called in here <br>      Type1.M(); <br>   } <br>} <br> <br>private sealed class Type1 { <br>   static Type1() { <br>      // if this throws an exception, M won't get called <br>      Console.WriteLine(&quot;Type1's static ctor called&quot;); <br>   } <br> <br>   public static void M() { } <br>}<br>
8  This is definitely true if the thread lives its whole life inside a single AppDomain (like in the ASP.NET and managed <br>
SQL Server stored procedure scenarios). But you might have to terminate the whole process if a thread crosses <br>AppDomain boundaries during its lifetime.<br>
<hr>
<A name=528></a><b>510 </b><br>
<b>Part IV  Core Facilities</b><br>
When I run the code above, I get the following output:<br>
In try <br>Type1's static ctor called<br>
What we want is to not even start executing the code in the try block above unless we know <br>that the code in the associated catch and finally blocks is guaranteed (or as close as we <br>can get to guaranteed) to execute. We can accomplish this by modifying the code as follows:<br>
private static void Demo2() { <br>   // Force the code in the finally to be eagerly prepared <br>   RuntimeHelpers.PrepareConstrainedRegions();  // System.Runtime.CompilerServices namespace <br>   try { <br>      Console.WriteLine(&quot;In try&quot;); <br>   } <br>   finally { <br>      // Type2's static constructor is implicitly called in here <br>      Type2.M(); <br>   } <br>} <br> <br>public class Type2 { <br>   static Type2() { <br>      Console.WriteLine(&quot;Type2's static ctor called&quot;); <br>   } <br> <br>   // Use this attribute defined in the System.Runtime.ConstrainedExecution namespace <br>   [ReliabilityContract(Consistency.WillNotCorruptState, Cer.Success)] <br>   public static void M() { } <br>}<br>
Now, when I run this version of the code, I get the following output:<br>
Type2's static ctor called <br>In try<br>
The PrepareConstrainedRegions method is a very special method. When the JIT compiler <br>sees this method being called immediately before a try block, it will eagerly compile the <br>code in the try's catch and finally blocks. The JIT compiler will load any assemblies, create <br>any type objects, invoke any static constructors, and JIT any methods. If any of these opera-<br>tions result in an exception, then the exception occurs <i>before</i> the thread enters the try block.<br>
When the JIT compiler eagerly prepares methods, it also walks the entire call graph eagerly  <br>preparing called methods. However, the JIT compiler only prepares methods that have <br>the ReliabilityContractAttribute applied to them with either Consistency.<br>WillNotCorruptState or Consistency.MayCorruptInstance because the CLR can't  <br>make any guarantees about methods that might corrupt AppDomain or process  <br>state. Inside a catch or finally block that you are protecting with a call to <br>PrepareConstrainedRegions, you want to make sure that you only call methods with  <br>the ReliabillityContractAttribute set as I've just described.<br>
<hr>
<A name=529></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>511</b><br>
The ReliabilityContractAttribute looks like this:<br>
public sealed class ReliabilityContractAttribute : Attribute { <br>   public ReliabilityContractAttribute(Consistency consistencyGuarantee, Cer cer); <br>   public Cer Cer { get; } <br>   public Consistency ConsistencyGuarantee { get; } <br>}<br>
This attribute lets a developer document the reliability contract of a particular method9 to <br>the method's potential callers. Both the Cer and Consistency types are enumerated types <br>defined as follows:<br>
enum Consistency {  <br>   MayCorruptProcess, MayCorruptAppDomain, MayCorruptInstance, WillNotCorruptState <br>} <br> <br>enum Cer { None, MayFail, Success }<br>
If the method you are writing promises not to corrupt any state, use Consistency.<br>WillNotCorruptState. Otherwise, document what your method does by using one of the <br>other three possible values that match whatever state your method might corrupt. If the <br>method that you are writing promises not to fail, use Cer.Success. Otherwise, use Cer.<br>MayFail. Any method that does not have the ReliabiiltyContractAttribute applied to it <br>is equivalent to being marked like this:<br>
[ReliabilityContract(Consistency.MayCorruptProcess, Cer.None)]<br>
The Cer.None value indicates that the method makes no CER guarantees. In other words, it <br>wasn't written with CERs in mind; therefore, it may fail and it may or may not report that it <br>failed. Remember that most of these settings are giving a method a way to document what it <br>offers to potential callers so that they know what to expect. The CLR and JIT compiler do not <br>use this information.<br>
When you want to write a reliable method, make it small and constrain what it does. Make <br>sure that it doesn't allocate any objects (no boxing, for example), don't call any virtual meth-<br>ods or interface methods, use any delegates, or use reflection because the JIT compiler can't <br>tell what method will actually be called. However, you can manually prepare these methods <br>by calling one of these methods defined by the RuntimeHelpers's class:<br>
public static void PrepareMethod(RuntimeMethodHandle method) <br>public static void PrepareMethod(RuntimeMethodHandle method,  <br>   RuntimeTypeHandle[] instantiation) <br>public static void PrepareDelegate(Delegate d); <br>public static void PrepareContractedDelegate(Delegate d);<br>
9  You can also apply this attribute to an interface, a constructor, a structure, a class, or an assembly to affect the <br>
members inside it.<br>
<hr>
<A name=530></a><IMG src="CLRviaCsharp-530_1.jpg"><br>
<b>512 </b><br>
<b>Part IV  Core Facilities</b><br>
Note that the compiler and the CLR do nothing to verify that you've written your method to <br>actually live up to the guarantees you document via the ReliabiltyContractAttribute. If <br>you do something wrong, then state corruption is possible.<br>
<b>Note  </b>Even if all the methods are eagerly prepared, a method call could still result in a <br>StackOverflowException. When the CLR is not being hosted, a StackOverflowException <br>causes the process to terminate immediately by the CLR internally calling Environment.<br>FailFast. When hosted, the PreparedConstrainedRegions method checks the stack to <br>see if there is approximately 48KB of stack space remaining. If there is limited stack space, the <br>StackOverflowException occurs before entering the try block.<br>
You should also look at RuntimeHelper's ExecuteCodeWithGuaranteedCleanup method <br>which is another way to execute code with guaranteed cleanup:<br>
public static void ExecuteCodeWithGuaranteedCleanup(TryCode code, CleanupCode backoutCode,  <br>   Object userData);<br>
When calling this method, you pass the body of the try and finally block as callback <br>methods whose prototypes match these two delegates respectively:<br>
public delegate void TryCode(Object userData); <br>public delegate void CleanupCode(Object userData, Boolean exceptionThrown);<br>
And finally, another way to get guaranteed code execution is to use the <br>CriticalFinalizerObject class which is explained in great detail in Chapter 21.<br>
<b>Code Contracts</b><br>
Code contracts provide a way for you to declaratively document design decisions that you've <br>made about your code within the code itself. The contracts take the form of<br>
<b>  Preconditions  </b>Typically used to validate arguments.<br>
<b>  Postconditions  </b>Used to validate state when a method terminates either due to a  <br>
normal return or due to throwing an exception.<br>
<b>  Object Invariants  </b>Used to ensure an object's fields remain in a good state through an <br>
object's entire lifetime.<br>
Code contracts facilitate code usage, understanding, evolution, testing10, documentation, <br>and early error detection. You can think of preconditions, postconditions, and object invari-<br>ants as parts of a method's signature. As such, you can loosen a contract with a new version <br>of your code, but you cannot make a contract stricter with a new version without breaking <br>backward compatibility.<br>
10 To help with automated testing, see the Pex tool created by Microsoft Research: <i>http://research.microsoft.com </i><br>
<i>/en-us/projects/pex/.</i><br>
<hr>
<A name=531></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>513</b><br>
At the heart of the code contracts is the static System.Diagnostics.Contracts.Contract <br>class:<br>
public static class Contract { <br>   // Precondition methods: [Conditional(&quot;CONTRACTS_FULL&quot;)] <br>   public static void Requires(Boolean condition); <br>   public static void EndContractBlock(); <br> <br>   // Preconditions: Always <br>   public static void Requires&lt;TException&gt;(Boolean condition) where TException : Exception; <br> <br>   // Postcondition methods: [Conditional(&quot;CONTRACTS_FULL&quot;)] <br>   public static void Ensures(Boolean condition); <br>   public static void EnsuresOnThrow&lt;TException&gt;(Boolean condition) <br>      where TException : Exception; <br> <br>   // Special Postcondition methods: Always <br>   public static T Result&lt;T&gt;(); <br>   public static T OldValue&lt;T&gt;(T value); <br>   public static T ValueAtReturn&lt;T&gt;(out T value); <br> <br>   // Object Invariant methods: [Conditional(&quot;CONTRACTS_FULL&quot;)] <br>   public static void Invariant(Boolean condition); <br> <br>   // Quantifier methods: Always <br>   public static Boolean Exists&lt;T&gt;(IEnumerable&lt;T&gt; collection, Predicate&lt;T&gt; predicate); <br>   public static Boolean Exists(Int32 fromInclusive, Int32 toExclusive,  <br>      Predicate&lt;Int32&gt; predicate); <br>   public static Boolean ForAll&lt;T&gt;(IEnumerable&lt;T&gt; collection, Predicate&lt;T&gt; predicate); <br>   public static Boolean ForAll(Int32 fromInclusive, Int32 toExclusive,  <br>      Predicate&lt;Int32&gt; predicate); <br>   // Helper methods: [Conditional(&quot;CONTRACTS_FULL&quot;)] or [Conditional(&quot;DEBUG&quot;)] <br>   public static void Assert(Boolean condition); <br>   public static void Assume(Boolean condition); <br> <br>   // Infrastructure event: usually your code will not use this event  <br>   public static event EventHandler&lt;ContractFailedEventArgs&gt; ContractFailed; <br>}<br>
As indicated above, many of these static methods have the [Conditional(&quot;CONTRACTS_<br>FULL&quot;)] attribute applied to them. Some of the helper methods also have the <br>[Conditional(&quot;DEBUG&quot;)] attribute applied to them. This means that the compiler will  <br>ignore any code you write that calls these methods unless the appropriate symbol is defined <br>when compiling your code. Any methods marked with "Always" mean that the compiler  <br>always emits code to call the method. Also, the Requires, Requires&lt;TException&gt;, Ensures, <br>EnsuresOnThrow, Invariant, Assert, and Assume methods have an additional overload <br>(not shown) that takes a String message argument so you can explicitly specify a string <br>message that should appear when the contract is violated.<br>
By default, contracts merely serve as documentation as you would not define the <br>CONTRACTS_FULL symbol when you build your project. In order to get some additional value <br>out of using contracts, you must download additional tools and a Visual Studio property <br>pane from <i>http://msdn.microsoft.com/en-us/devlabs/dd491992.aspx.</i> The reason why all the <br>
<hr>
<A name=532></a><IMG src="CLRviaCsharp-532_1.jpg"><br>
<b>514 </b><br>
<b>Part IV  Core Facilities</b><br>
code contract tools are not included with Visual Studio is because this technology is relatively <br>new and is being improved rapidly. Microsoft's DevLabs Web site can offer new versions and <br>improvements more quickly than Visual Studio itself. After downloading and installing the <br>additional tools, you will see your projects have a new property pane available to them, as <br>shown in Figure 20-9.<br>
<b>FIGURE 20-9  </b>The Code Contracts pane for a Visual Studio project<br>
To turn on code contract features, select the Perform Runtime Contract Checking check box <br>and select Full from the combo box next to it. This defines the CONTRACTS_FULL symbol <br>when you build your project and invokes the appropriate tools (described shortly) after build-<br>ing your project. Now, at runtime, when a contract is violated, Contract's ContractFailed <br>event is raised. Usually, developers do not register any methods with this event, but if you do, <br>then any methods you register will receive a ContractFailedEventArgs object that looks <br>like this:<br>
public sealed class ContractFailedEventArgs : EventArgs { <br>   public ContractFailedEventArgs(ContractFailureKind failureKind,  <br>      String message, String condition, Exception originalException); <br> <br>   public ContractFailureKind FailureKind       { get; } <br>   public String              Message           { get; } <br>   public String              Condition         { get; } <br>   public Exception           OriginalException { get; } <br> <br>   public Boolean Handled { get; }   // true if any handler called SetHhandled <br>   public void SetHandled();         // Call to ignore the violation; sets Handled to true <br> <br>   public Boolean Unwind { get; }    // true if any handler called SetUnwind or threw <br>   public void SetUnwind();          // Call to force ContractException; set Unwind to true <br>}<br>
<hr>
<A name=533></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>515</b><br>
Multiple event handler methods can be registered with this event. Each method can process  <br>the contract violation any way it chooses. For example, a handler can log the violation,  <br>ignore the violation (by calling SetHandled), or terminate the process. If any method calls <br>SetHandled, then the violation will be considered handled and, after all the handler  <br>methods return, the application code is allowed to continue running unless any handler calls <br>SetUnwind. If a handler calls SetUnwind, then, after all the handler methods have completed <br>running, a System.Diagnostics.Contracts.ContractException is thrown. Note that this <br>type is internal to MSCorLib.dll and therefore you cannot write a catch block to catch it  <br>explicitly. Also note that if any handler method throws an unhandled exception, then the  <br>remaining handler methods are invoked and then a ContractException is thrown.<br>
If there are no event handlers or if none of them call SetHandled, SetUnwind, or throw an <br>unhandled exception, then default processing of the contract violation happens next. If the <br>CLR is being hosted, then the host is notified that a contract failed. If the CLR is running an <br>application on a non-interactive window station (which would be the case for a Windows <br>service application), then Environment.FailFast is called to instantly terminate the process. <br>If you compile with the Assert On Contract Failure option checked, then an assert dialog <br>box will appear allowing you to connect a debugger to your application. If this option is not <br>checked, then a ContractException is thrown.<br>
Let's look at a sample class that is using code contracts:<br>
public sealed class Item { /* ... */ } <br> <br>public sealed class ShoppingCart { <br>   private List&lt;Item&gt; m_cart      = new List&lt;Item&gt;(); <br>   private Decimal    m_totalCost = 0; <br> <br>   public ShoppingCart() { <br>   } <br> <br>   public void AddItem(Item item) { <br>      AddItemHelper(m_cart, item, ref m_totalCost); <br>   } <br> <br>   private static void AddItemHelper(List&lt;Item&gt; m_cart, Item newItem,  <br>      ref Decimal totalCost) { <br> <br>      // Preconditions:  <br>      Contract.Requires(newItem != null); <br>      Contract.Requires(Contract.ForAll(m_cart, s =&gt; s != newItem)); <br> <br>      // Postconditions: <br>      Contract.Ensures(Contract.Exists(m_cart, s =&gt; s == newItem)); <br>      Contract.Ensures(totalCost &gt;= Contract.OldValue(totalCost)); <br>      Contract.EnsuresOnThrow&lt;IOException&gt;(totalCost == Contract.OldValue(totalCost)); <br> <br>      // Do some stuff (which could throw an IOException)... <br>      m_cart.Add(newItem); <br>      totalCost += 1.00M; <br>   } <br> <br>
<hr>
<A name=534></a><IMG src="CLRviaCsharp-534_1.jpg"><br>
<IMG src="CLRviaCsharp-534_2.jpg"><br>
<b>516 </b><br>
<b>Part IV  Core Facilities</b><br>
   // Object invariant <br>   [ContractInvariantMethod] <br>   private void ObjectInvariant() { <br>      Contract.Invariant(m_totalCost &gt;= 0); <br>   } <br>}<br>
The AddItemHelper method defines a bunch of code contracts. The preconditions indicate <br>that newItem must not be null and that the item being added to the cart is not already in <br>the cart. The postconditions indicate that the new item must be in the cart and that the total <br>cost must be at least as much as it was before the item was added to the cart. The postcondi-<br>tions also indicate that if AddItemHelper were to throw an IOException for some reason, <br>then totalCost is unchanged from what it was when the method started to execute. The <br>ObjectInvariant method is just a private method that, when called, makes sure that the <br>object's m_totalCost field never contains a negative value.<br>
<b>Important  </b>All members referenced in a precondition, postcondition, or invariant test must be <br>side-effect free. This is required because testing conditions should not change the state of the <br>object itself. In addition, all members referenced in a precondition test must be at least as  <br>accessible as the method defining the precondition. This is required because callers of the <br>method should be able to verify that they have met all the preconditions prior to invoking the <br>method. On the other hand, members referenced in a postcondition or invariant test can have <br>any accessibility as long as the code can compile. The reason why accessibility isn't important <br>here is because postcondition and invariant tests do not affect the callers' ability to invoke the <br>method correctly.<br>
<b>Important  </b>In regard to inheritance, a derived type cannot override and change the precondi-<br>tions of a virtual member defined in a base type. Similarly, a type implementing an interface <br>member cannot change the preconditions defined by that interface member. If a member does <br>not have an explicit contract defined for it, then the member has an implicit contract that  <br>logically looks like this:<br>
Contract.Requires(true);<br>
And since a contract cannot be made stricter with new versions (without breaking compatibility), <br>you should carefully consider preconditions when introducing a new virtual, abstract, or interface <br>member. For postconditions and object invariants, contracts can be added and removed at will as <br>the conditions expressed in the virtual/abstract/interface member and the conditions expressed <br>in the overriding member are just logically AND-ed together.<br>
So now you see how to declare contracts. Let's now talk about how they function at runtime. <br>You get to declare all your precondition and postcondition contracts at the top of your meth-<br>ods where they are easy to find. Of course, the precondition contracts will validate their tests <br>when the method is invoked. However, we don't want the postcondition contracts to validate <br>their tests until the method returns. In order to get the desired behavior, the assembly  <br>produced by the C# compiler must be processed by the Code Contract Rewriter tool <br>(CCRewrite.exe, found in C:\Program Files (x86)\Microsoft\Contracts\Bin), which produces a <br>
<hr>
<A name=535></a><b> </b><br>
<b>Chapter 20  Exceptions and State Management </b><br>
<b>517</b><br>
modified version of the assembly. After you select the Perform Runtime Contract Checking <br>check box for your project, Visual Studio will invoke this tool for you automatically whenever <br>you build the project. This tool analyzes the IL in all your methods and it rewrites the IL so <br>that any postcondition contracts are executed at the end of each method. If your method has <br>multiple return points inside it, then the CCRewrite.exe tool modifies the method's IL code so <br>that all return points execute the postcondition code prior to the method returning.<br>
The CCRewrite.exe tool looks in the type for any method marked with the <br>[ContractInvariantMethod] attribute. The method can have any name but, by convention,  <br>people usually name the method ObjectInvariant and mark the method as private (as <br>I've done above). The method must accept no arguments and have a void return type. <br>When the CCRewrite.exe tool sees a method marked with this attribute, it inserts IL code at <br>the end of every public instance method to call the ObjectInvariant method. This way, <br>the object's state is checked as each method returns to ensure that no method has violated <br>the contract. Note that the CCRewrite.exe tool does not modify a Finalize method or an <br>IDisposable's Dispose method to call the ObjectInvariant method because it is OK for <br>an object's state to be altered if it is considered to be destroyed or disposed. Also note that <br>a single type can define multiple methods with the [ContractInvariantMethod] attribute; <br>this is useful when working with partial types. The CCRewrite.exe tool will modify the IL to <br>call all of these methods (in an undefined order) at the end of each public method.<br>
The Assert and Assume methods are unlike the other methods. First, you should not consider <br>them to be part of the method's signature, and you do not have to put them at the beginning <br>of a method. At runtime, these two methods perform identically: They just verify that the <br>condition passed to them is true and throw an exception if it is not. However, there is another <br>tool, the Code Contract Checker (CCCheck.exe) which analyzes the IL produced by the C# <br>compiler in an attempt to statically verify that no code in the method violates a contract. This <br>tool will attempt to prove that any condition passed to Assert is true, but it will just assume <br>that any condition passed to Assume is true and the tool will add the expression to its body <br>of facts known to be true. Usually, you will use Assert and then change an Assert to an <br>Assume if the CCCheck.exe tool can't statically prove that the expression is true.<br>
Let's walk through an example. Assume that I have the following type definition:<br>
internal sealed class SomeType { <br>   private static String s_name = &quot;Jeffrey&quot;; <br> <br>   public static void ShowFirstLetter() { <br>      Console.WriteLine(s_name[0]);   // warning: requires unproven: index &lt; this.Length <br>   } <br>}<br>
When I build this code with the Perform Static Contract Checking function turned on, the <br>CCCheck.exe tool produces the warning shown as a comment above. This warning is notify-<br>ing me that querying the first letter of s_name may fail and throw an exception because it is <br>unproven that s_name <i>always</i> refers to a string consisting of at least one character.<br>
<hr>
<A name=536></a><b>518 </b><br>
<b>Part IV  Core Facilities</b><br>
Therefore, what we'd like to do is add an assertion to the ShowFirstLetter method:<br>
public static void ShowFirstLetter() { <br>   Contract.Assert(s_name.Length &gt;= 1);   // warning: assert unproven <br>   Console.WriteLine(s_name[0]); <br>}<br>
Unfortunately, when the CCCheck.exe tool analyzes this code, it is still unable to validate that <br>s_name <i>always</i> refers to a string containing at least one letter, so the tool produces a similar <br>warning. Sometimes the tool is unable to validate assertions due to limitations in the tool; <br>future versions of the tool will be able to perform a more complete analysis.<br>
To override shortcomings in the tool or to claim that something is true that the tool would <br>never be able to prove, we can change Assert to Assume. If we know for a fact that no other <br>code will modify s_name, then we can change ShowFirstLetter to this:<br>
public static void ShowFirstLetter() { <br>   Contract.Assume(s_name.Length &gt;= 1);   // No warning at all now! <br>   Console.WriteLine(s_name[0]); <br>}<br>
With this version of the code, the CCCheck.exe tool just takes our word for it and concludes <br>that s_name <i>always</i> refers to a string containing at least one letter. This version of the <br>ShowFirstLetter method passes the code contract static checker without any warnings at <br>all.<br>
Now, let's talk about the Code Contract Reference Assembly Generator tool (CCRefGen.exe). <br>Running the CCRewrite.exe tool to enable contract checking helps you find bugs more quickly, <br>but all the code emitted during contract checking makes your assembly bigger and hurts its <br>runtime performance. To improve this situation, you use the CCRefGen.exe tool to create a <br>separate <i>contract reference assembly</i>. Visual Studio invokes this tool for you automatically if <br>you set the Contract Reference Assembly combo box to Build. Contract assemblies are  <br>usually named <i>AssemName</i>.Contracts.dll (for example, MSCorLib.Contracts.dll), and these  <br>assemblies contain only metadata and the IL that describes the contracts--nothing else. You <br>can identify a contract reference assembly because it will have the System.Diagnostics.<br>Contracts.ContractReferenceAssemblyAttribute applied to the assembly's assembly <br>definition metadata table. The CCRewrite.exe tool and the CCCheck.exe tool can use contract <br>reference assemblies as input when these tools are performing their instrumentation and <br>analysis.<br>
The last tool, the Code Contract Document Generator tool (CCDocGen.exe), adds contract <br>information to the XML documentation files already produced by the C# compiler when you <br>use the compiler's /doc:file switch. This XML file, enhanced by the CCDocGen.exe tool, can <br>be processed by Microsoft's Sandcastle tool to produce MSDN-style documentation that will <br>now include contract information.<br>
<hr>
<A name=537></a>Chapter 21<br><b>Automatic Memory Management </b><br>
<b>(Garbage Collection)</b><br>
<b>In this chapter:<br>Understanding the Basics of Working in a Garbage-Collected Platform  . . . . . 520<br>The Garbage Collection Algorithm  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 523<br>Garbage Collections and Debugging. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 527<br>Using Finalization to Release Native Resources . . . . . . . . . . . . . . . . . . . . . . . . . . . 530<br>Using Finalization with Managed Resources  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 537<br>What Causes </b>Finalize<b> Methods to Be Called? . . . . . . . . . . . . . . . . . . . . . . . . . . . 540<br>Finalization Internals. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 541<br>The Dispose Pattern: Forcing an Object to Clean Up . . . . . . . . . . . . . . . . . . . . . . 544<br>Using a Type That Implements the Dispose Pattern . . . . . . . . . . . . . . . . . . . . . . . 548<br>C#'s </b>using<b> Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 551<br>An Interesting Dependency Issue. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 554<br>Monitoring and Controlling the Lifetime of Objects Manually. . . . . . . . . . . . . . 555<br>Resurrection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 566<br>Generations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 568<br>Other Garbage Collection Features for Use with Native Resources . . . . . . . . . . 574<br>Predicting the Success of an Operation that Requires a Lot of Memory. . . . . . 578<br>Programmatic Control of the Garbage Collector. . . . . . . . . . . . . . . . . . . . . . . . . . 580<br>Thread Hijacking . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 583<br>Garbage Collection Modes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 585<br>Large Objects. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 588<br>Monitoring Garbage Collections  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 589</b><br>
In this chapter, I'll discuss how managed applications construct new objects, how the man-<br>aged heap controls the lifetime of these objects, and how the memory for these objects gets <br>reclaimed. In short, I'll explain how the garbage collector in the common language runtime <br>(CLR) works, and I'll explain various performance issues related to it. I'll also discuss how to <br>design applications so that they use memory most efficiently.<br>
<b> </b><br>
<b> </b><br>
<b>519</b><br>
<hr>
<A name=538></a><b>520 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Understanding the Basics of Working in a Garbage-</b><br>
<b>Collected Platform</b><br>
Every program uses resources of one sort or another, be they files, memory buffers, screen <br>space, network connections, database resources, and so on. In fact, in an object-oriented <br>environment, every type identifies some resource available for a program's use. To use any of <br>these resources requires memory to be allocated to represent the type. The following steps <br>are required to access a resource:<br>
<b> </b><br>
<b>1.  </b>Allocate memory for the type that represents the resource by calling the Intermediate <br>
Language's (IL) newobj instruction, which is emitted when you use the new operator in <br>C#.<br>
<b> </b><br>
<b>2.  </b>Initialize the memory to set the initial state of the resource and to make the resource <br>
usable. The type's instance constructor is responsible for setting this initial state.<br>
<b> </b><br>
<b>3.  </b>Use the resource by accessing the type's members (repeating as necessary).<br>
<b> </b><br>
<b>4.  </b>Tear down the state of a resource to clean up. I'll address this topic in the section "The <br>
Dispose Pattern: Forcing an Object to Clean Up" later in this chapter.<br>
<b> </b><br>
<b>5.  </b>Free the memory. The garbage collector is solely responsible for this step.<br>
This seemingly simple paradigm has been one of the major sources of programming errors. <br>How many times have programmers forgotten to free memory when it is no longer needed? <br>How many times have programmers attempted to use memory after it had already been <br>freed?<br>
In the native programming world, these two application bugs are worse than most others <br>because you usually can't predict the consequences or the timing of them. For other bugs, <br>when you see your application misbehaving, you just fix the problem. But these two bugs <br>cause resource leaks (memory consumption) and object corruption (destabilization), mak-<br>ing the application perform unpredictably. In fact, there are many tools (such as Microsoft's <br>Windows Task Manager, Process Explorer, and Performance Monitor, and Rational's Purify) <br>that are specifically designed to help developers locate these types of bugs.<br>
Proper resource management is very difficult and quite tedious. It distracts developers from <br>concentrating on the real problems that they're trying to solve. It would be wonderful if <br>some mechanism existed that simplified the mind-numbing memory-management task for <br>developers. Fortunately, there is: garbage collection.<br>
Garbage collection completely absolves the developer from having to track memory usage <br>and know when to free memory. However, the garbage collector doesn't know anything <br>about the resource represented by the type in memory, which means that a garbage collec-<br>tor can't know how to perform step 4 in the preceding list: tear down the state of a resource <br>to clean up. To get a resource to clean up properly, the developer must write code that <br>
<hr>
<A name=539></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>521</b><br>
knows how to properly clean up a resource. The developer writes this code in the Finalize, <br>Dispose, and Close methods, as described later in this chapter. However, as you'll see, the <br>garbage collector can offer some assistance here too, allowing developers to skip step 4 in <br>many circumstances.<br>
Also, most types, including value types (including all enumeration types), collection types, <br>String, Attribute, Delegate, and Exception, represent resources that don't require any <br>special cleanup. For example, a String resource can be completely cleaned up simply by  <br>destroying the character array maintained in the object's memory.<br>
On the other hand, a type that represents (or wraps) an unmanaged or native resource, such <br>as a file, a database connection, a socket, a mutex, a bitmap, an icon, and so on, always  <br>requires the execution of some cleanup code when the object is about to have its memory <br>reclaimed. In this chapter, I'll explain how to properly define types that require explicit clean-<br>up, and I'll show you how to properly use types that offer this explicit cleanup. For now, let's <br>examine how memory is allocated and how resources are initialized.<br>
<b>Allocating Resources from the Managed Heap</b><br>
The CLR requires that all resources be allocated from a heap called the <i>managed heap</i>. This <br>heap is similar to a C-runtime heap, except that you never delete objects from the managed <br>heap--objects are automatically deleted when the application no longer needs them. This, of <br>course, raises the question, "How does the managed heap know when the application is no <br>longer using an object?" I'll address this question shortly.<br>
Several garbage collection algorithms are in use today. Each algorithm is fine-tuned for a <br>particular environment to provide the best performance. In this chapter, I'll concentrate on <br>the garbage collection algorithm used by the Microsoft .NET Framework's CLR. Let's start off <br>with the basic concepts.<br>
When a process is initialized, the CLR reserves a contiguous region of address space that  <br>initially contains no backing storage. This address space region is the managed heap. The <br>heap also maintains a pointer, which I'll call NextObjPtr. This pointer indicates where the <br>next object is to be allocated within the heap. Initially, NextObjPtr is set to the base address <br>of the reserved address space region.1<br>
1  During initialization, the CLR reserves two segments of virtual address space: one for the normal heap and one <br>
for the large object heap (discussed in the section "Large Objects" later in this chapter). The size of each segment <br>varies. For a client application, each segment is approximately 16 MB, and for a server application, each segment is <br>approximately 64 MB. However, there are other things that affect the segment size, such as if you are running on a <br>32-bit or 64-bit operating system, and also the number of CPUs in the machine (the segment size gets smaller on <br>a machine with more CPUs). As segments fill with non-garbage objects, the CLR allocates more segments. It will <br>continue to do this until the whole process's address space is full. So, your application's memory is limited by the <br>process's virtual address space. You can allocate a lot more memory in a 64-bit process than you can in a 32-bit <br>process.<br>
<hr>
<A name=540></a><b>522 </b><br>
<b>Part IV  Core Facilities</b><br>
The newobj IL instruction creates an object. Many languages (including C#, C++/CLI, and <br>Microsoft Visual Basic) offer a new operator that causes the compiler to emit a newobj  <br>instruction into the method's IL code. The newobj instruction causes the CLR to perform the <br>following steps:<br>
<b> </b><br>
<b>1.  </b>Calculate the number of bytes required for the type's (and all of its base type's) fields.<br>
<b> </b><br>
<b>2.  </b>Add the bytes required for an object's overhead. Each object has two overhead fields: a <br>
type object pointer and a sync block index. For a 32-bit application, each of these fields <br>requires 32 bits, adding 8 bytes to each object. For a 64-bit application, each field is 64 <br>bits, adding 16 bytes to each object.<br>
<b> </b><br>
<b>3.  </b>The CLR then checks that the bytes required to allocate the object are available in the <br>
reserved region (committing storage if necessary). If there is enough free space in the <br>managed heap, the object will fit, starting at the address pointed to by NextObjPtr, <br>and these bytes are zeroed out. The type's constructor is called (passing NextObjPtr <br>for the this parameter), and the newobj IL instruction (or C#'s new operator) returns <br>the address of the object. Just before the address is returned, NextObjPtr is advanced <br>past the object and now points to the address where the next object will be placed in <br>the heap.<br>
Figure 21-1 shows a managed heap consisting of three objects: A, B, and C. If a new object <br>were to be allocated, it would be placed where NextObjPtr points to (immediately after <br>object C).<br>
A<br>
B<br>
C<br>
NextObjPtr<br>
<b>FIGURE 21-1  </b>Newly initialized managed heap with three objects constructed in it<br>
By contrast, let's look at how the C-runtime heap allocates memory. In a C-runtime heap, <br>allocating memory for an object requires walking through a linked list of data structures. <br>Once a large enough block is found, that block is split, and pointers in the linked-list nodes <br>are modified to keep everything intact. For the managed heap, allocating an object simply <br>means adding a value to a pointer--this is blazingly fast by comparison. In fact, allocating an <br>object from the managed heap is nearly as fast as allocating memory from a thread's stack! <br>In addition, most heaps (such as the C-runtime heap) allocate objects wherever they find free <br>space. Therefore, if I create several objects consecutively, it's quite possible for these objects <br>to be separated by megabytes of address space. In the managed heap, however, allocating <br>several objects consecutively ensures that the objects are contiguous in memory.<br>
In many applications, objects allocated around the same time tend to have strong relation-<br>ships to each other and are frequently accessed around the same time. For example, it's <br>very common to allocate a FileStream object immediately before a BinaryWriter object <br>is created. Then the application would use the BinaryWriter object, which internally uses <br>
<hr>
<A name=541></a><IMG src="CLRviaCsharp-541_1.jpg"><br>
<b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>523</b><br>
the FileStream object. In a garbage-collected environment, new objects are allocated <br>contiguously in memory, providing performance gains resulting from locality of reference. <br>Specifically, this means that your process's working set will be smaller than a similar applica-<br>tion running in a non-managed environment. It's also likely that the objects that your code <br>is using can all reside in the CPU's cache. Your application will access these objects with phe-<br>nomenal speed because the CPU will be able to perform most of its manipulations without <br>having cache misses that would force slower access to RAM.<br>
So far, it sounds as if the managed heap is far superior to the C-runtime heap because of its <br>simplicity of implementation and speed. But there's one little detail you should know about <br>before getting too excited. The managed heap gains these advantages because it makes one <br>really big assumption: that address space and storage are infinite. Obviously, this assumption <br>is ridiculous, and the managed heap must employ a mechanism to allow it to make this as-<br>sumption. This mechanism is the garbage collector. Here's how it works:<br>
When an application calls the new operator to create an object, there might not be enough <br>address space left in the region to allocate to the object. The heap detects this lack of space <br>by adding the bytes that the object requires to the address in NextObjPtr. If the resulting <br>value is beyond the end of the address space region, the heap is full, and a garbage collec-<br>tion must be performed.<br>
<b>Important  </b>What I've just said is an oversimplification. In reality, a garbage collection occurs <br>when generation 0 is full. Some garbage collectors use generations, a mechanism whose sole <br>purpose is to improve performance. The idea is that newly created objects are part of a young <br>generation and objects created early in the application's lifecycle are in an old generation. <br>Objects in generation 0 are objects that have recently been allocated and have never been  <br>examined by the garbage collector algorithm. Objects that survive a collection are promoted to <br>another generation (such as generation 1). Separating objects into generations allows the garbage <br>collector to collect specific generations instead of collecting all of the objects in the managed <br>heap. I'll explain generations in more detail later in this chapter. Until then, it's easiest for you to <br>think that a garbage collection occurs when the heap is full.<br>
<b>The Garbage Collection Algorithm</b><br>
The garbage collector checks to see if any objects in the heap are no longer being used by <br>the application. If such objects exist, the memory used by these objects can be reclaimed. <br>(If no more memory is available in the heap after a garbage collection, new<i> </i>throws an <br>OutOfMemoryException.) How does the garbage collector know whether the application is <br>using an object? As you might imagine, this isn't a simple question to answer.<br>
Every application has a set of <i>roots</i>. A single root is a storage location containing a memory <br>pointer to a reference type object. This pointer either refers to an object in the managed <br>heap or is set to null. For example, a static field (defined within a type) is considered a root. <br>In addition, any method parameter or local variable is considered a root. Only variables that <br>
<hr>
<A name=542></a><b>524 </b><br>
<b>Part IV  Core Facilities</b><br>
are of a reference type are considered roots; value type variables are never considered roots. <br>Now, let's look at a concrete example starting with the following class definition:<br>
internal sealed class SomeType {  <br>   private TextWriter m_textWriter;  <br>  <br>   public SomeType(TextWriter tw) {   <br>      m_textWriter = tw;  <br>   }  <br>  <br>   public void WriteBytes(Byte[] bytes) {  <br>      for (Int32 x = 0; x &lt; bytes.Length; x++) {  <br>         m_textWriter.Write(bytes[x]);  <br>      }  <br>   }  <br>}<br>
The first time the WriteBytes method is called, the just-in-time (JIT) compiler converts the <br>method's IL code into native CPU instructions. Let's say the CLR is running on an <i>x</i>86 CPU, <br>and the JIT compiler compiles the WriteBytes method into the CPU instructions shown in <br>Figure 21-2. (I added comments on the right to help you understand how the native code <br>maps back to the original source code.)<br>
00000000 push<br>
edi<br>
// Prolog<br>
00000001 push<br>
esi<br>
00000002 push<br>
ebx<br>
<b>EBX</b><br>
00000003 mov<br>
ebx,ecx<br>
// ebx = this (argument)<br>
00000005 mov<br>
esi,edx<br>
// esi = bytes array (argument)<br>
<b>ESI </b>00000007 xor edi,edi<br>
// edi = x (a value type)<br>
00000009 cmp<br>
dword ptr [esi+4],0<br>
// compare bytes.Length with 0<br>
0000000d jle<br>
0000002A<br>
// if bytes.Length &lt;=0, go to 2a<br>
<b>ECX </b>0000000f mov ecx,dword ptr [ebx+4]<br>
// ecx = m_textWriter (field)<br>
00000012 cmp<br>
edi,dword ptr [esi+4]<br>
// compare x with bytes.Length<br>
00000015 jae<br>
0000002E<br>
// if x &gt;= bytes.Length, go to 2e<br>
<b>EAX </b>00000017 movzx edx,byte prt [esi+edi+8] // edx = bytes[x]<br>
0000001c mov<br>
eax,dword ptr [ecx]<br>
// eax = m_textWriter's type object<br>
0000001e call<br>
dword ptr [eax+000000BCh] // Call m_textWriter's Write method<br>
00000024 inc<br>
edi<br>
// x++<br>
00000025 cmp<br>
dword ptr [esi+4],edi<br>
// compare bytes.Length with x<br>
00000028 jg<br>
0000000F<br>
// if bytes.Length &gt; x, go to f<br>
0000002a pop<br>
ebx<br>
// Epilog<br>
0000002b pop<br>
esi<br>
0000002c pop<br>
edi<br>
0000002d ret<br>
// return to caller<br>
0000002e call<br>
76B6E337<br>
// Throw IndexOutOfRangeException<br>
00000033 int<br>
3<br>
// Break in debugger<br>
<b>FIGURE 21-2  </b>Native code produced by the JIT compiler with ranges of roots shown<br>
<hr>
<A name=543></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>525</b><br>
As the JIT compiler produces the native code, it also creates an internal table. Logically, each <br>entry in the table indicates a range of byte offsets in the method's native CPU instructions, <br>and for each range, a set of memory addresses and CPU registers that contain roots.<br>
For the WriteBytes method, this table reflects that the EBX register starts being a root at <br>offset 0x00000003, the ESI register starts being a root at offset 0x00000005, and the ECX <br>register starts being a root at offset 0x0000000f. All three of these registers stop being roots <br>at the end of the loop (offset 0x00000028). Also note that the EAX register is a root from <br>0x0000001c to 0x0000001e. The EDI register is used to hold the Int32 value represented <br>by the variable x in the original source code. Since Int32 is a value type, the JIT compiler <br>doesn't consider the EDI register to be a root.<br>
The WriteBytes method is a fairly simple method, and all of the variables that it uses can be <br>enregistered. A more complex method could use all of the available CPU registers, and some <br>roots would be in memory locations relative to the method's stack frame. Also note that on <br>an <i>x</i>86 architecture, the CLR passes the first two arguments to a method via the ECX and EDX <br>registers. For instance methods, the first argument is the this pointer, which is always passed <br>in the ECX register. For the WriteBytes method, this is how I know that the this pointer is <br>passed in the ECX register and stored in the EBX register right after the method prolog. This <br>is also how I know that the bytes argument is passed in the EDX register and stored in the <br>ESI register after the prolog.<br>
If a garbage collection were to start while code was executing at offset 0x00000017 in the <br>WriteBytes method, the garbage collector would know that the objects referred to by the <br>EBX (this argument), ESI (bytes argument), and ECX (the m_textWriter field) registers were <br>all roots and refer to objects in the heap that shouldn't be considered garbage. In addition, <br>the garbage collector can walk up the thread's call stack and determine the roots for all of <br>the calling methods by examining each method's internal table. The garbage collector iterates <br>through all the type objects to obtain the set of roots stored in static fields.<br>
When a garbage collection starts, it assumes that all objects in the heap are garbage. In <br>other words, it is assumed that the thread's stack contains no variables that refer to objects <br>in the heap, that no CPU registers refer to objects in the heap, and that no static fields refer <br>to objects in the heap. The garbage collector starts what is called the <i>marking</i> phase of the <br>collection. This is when the collector walks up the thread's stack checking all of the roots. If <br>a root is found to refer to an object, a bit will be turned on in the object's sync block index <br>field--this is how the object is <i>marked</i>. For example, the garbage collector might locate a <br>local variable that points to an object in the heap. Figure 21-3 shows a heap containing sev-<br>eral allocated objects, and the application's roots refer directly to objects A, C, D, and F. All <br>of these objects are marked. When marking object D, the garbage collector notices that this <br>object contains a field that refers to object H, causing object H to be marked as well. The <br>garbage collector continues to walk through all reachable objects recursively.<br>
<hr>
<A name=544></a><b>526 </b><br>
<b>Part IV  Core Facilities</b><br>
Roots:<br>
tatic fields<br>
arameters<br>
ariables<br>
egisters<br>
Managed heap<br>
 <br>
A<br>
B<br>
D<br>
E<br>
F<br>
G H I<br>
J<br>
<b>FIGURE 21-3  </b>Managed heap before a collection<br>
After a root and the objects referenced by its fields are marked, the garbage collector checks <br>the next root and continues marking objects. If the garbage collector is going to mark an  <br>object that it previously marked, it can stop walking down that path. This behavior serves <br>two purposes. First, performance is enhanced significantly because the garbage collector <br>doesn't walk through a set of objects more than once. Second, infinite loops are prevented if <br>you have any circular linked lists of objects.<br>
Once all of the roots have been checked, the heap contains a set of marked and unmarked <br>objects. The marked objects are reachable via the application's code, and the unmarked <br>objects are unreachable. The unreachable objects are considered garbage, and the memory <br>that they occupy can be reclaimed. The garbage collector now starts what is called the  <br><i>compact phase</i> of the collection. This is when the collector traverses the heap linearly looking <br>for contiguous blocks of unmarked (garbage) objects.<br>
If small blocks are found, the garbage collector leaves the blocks alone. If large free contigu-<br>ous blocks are found, however, the garbage collector shifts the nongarbage objects down in <br>memory to compact the heap.<br>
Naturally, moving the objects in memory invalidates all variables and CPU registers that  <br>contain pointers to the objects. So the garbage collector must revisit all of the application's <br>roots and modify them so that each root's value points to the objects' new memory location. <br>In addition, if any object contains a field that refers to another moved object, the garbage col-<br>lector is responsible for correcting these fields as wel . After the heap memory is compacted, <br>the managed heap's NextObjPtr pointer is set to point to a location just after the last non-<br>garbage object. Figure 21-4 shows the managed heap after a collection.<br>
As you can see, a garbage collection generates a considerable performance hit, which is the <br>major downside of using a managed heap. But keep in mind that garbage collections occur <br>only when generation 0 is full, and until then, the managed heap is significantly faster than <br>a C-runtime heap. Finally, the CLR's garbage collector offers some optimizations that greatly <br>improve the performance of garbage collection. I'll discuss these optimizations later in this <br>chapter, in the "Generations" and "Other Garbage Collection Features for Use with Native <br>Resources" sections.<br>
<hr>
<A name=545></a><IMG src="CLRviaCsharp-545_1.jpg"><br>
<b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>527</b><br>
Roots:<br>
tatic fields<br>
arameters<br>
ariables<br>
egisters<br>
Managed heap<br>
A<br>
D<br>
F<br>
H<br>
<b>FIGURE 21-4  </b>Managed heap after a collection<br>
As a programmer, you should take away a couple of important points from this discussion. <br>To start, you no longer have to implement any code to manage the lifetime of objects your <br>application uses. And notice how the two bugs described at the beginning of this chapter <br>no longer exist. First, it's not possible to leak objects because any object not accessible from <br>your application's roots can be collected at some point. Second, it's not possible to access <br>an object that is freed because the object won't be freed if it is reachable, and if it's not <br>reachable, your application has no way to access it. Also, since a collection causes memory <br>compaction, it is not possible for managed objects to fragment your process's virtual address <br>space. This would sometimes be a severe problem with unmanaged heaps but is no longer <br>an issue when using the managed heap. Using large objects (discussed later in this chapter) is <br>an exception to this, and fragmentation of the large object heap is possible.<br>
<b>Important  </b> A type's static field roots whatever object it refers to forever or until the <br>AppDomain that the types are loaded into is unloaded. A common way to leak memory is to <br>have a static field refer to a collection object and then to keep adding items to the collection  <br>object. The static field keeps the collection object alive and the collection object keeps all its <br>items alive. For this reason, it is best to avoid static fields whenever possible.<br>
<b>Garbage Collections and Debugging</b><br>
In Figure 21-2, notice that the method's bytes argument (stored in the ESI register) isn't <br>referred to after the CPU instruction at offset 0x00000028. This means that the Byte array <br>object that the bytes argument refers to can be collected any time after the instruction at <br>offset 0x00000028 executes (assuming that there are no other roots in the application that <br>also refer to this array object). In other words, as soon as an object becomes unreachable, it is <br>a candidate for collection--objects aren't guaranteed to live throughout a method's lifetime. <br>This can have an interesting impact on your application. For example, examine the following <br>code:<br>
<hr>
<A name=546></a><b>528 </b><br>
<b>Part IV  Core Facilities</b><br>
using System;  <br>using System.Threading;  <br>  <br>public static class Program {  <br>   public static void Main() {  <br>       // Create a Timer object that knows to call our TimerCallback   <br>       // method once every 2000 milliseconds.  <br>       Timer t = new Timer(TimerCallback, null, 0, 2000);  <br>  <br>       // Wait for the user to hit &lt;Enter&gt;  <br>       Console.ReadLine();  <br>   }  <br>  <br>   private static void TimerCallback(Object o) {  <br>      // Display the date/time when this method got called.  <br>      Console.WriteLine(&quot;In TimerCallback: &quot; + DateTime.Now);  <br>  <br>      // Force a garbage collection to occur for this demo.  <br>      GC.Collect();  <br>   }  <br>}<br>
Compile this code from the command prompt without using any special compiler switches. <br>When you run the resulting executable file, you'll see that the TimerCallback method is <br>called just once!<br>
From examining the code above, you'd think that the TimerCallback method would get <br>called once every 2,000 milliseconds. After all, a Timer object is created, and the variable t <br>refers to this object. As long as the timer object exists, the timer should keep firing. But you'll <br>notice in the TimerCallback method that I force a garbage collection to occur by calling <br>GC.Collect().<br>
When the collection starts, it first assumes that all objects in the heap are unreachable  <br>(garbage); this includes the Timer object. Then, the collector examines the application's roots <br>and sees that Main doesn't use the t variable after the initial assignment to it. Therefore, the <br>application has no variable referring to the Timer object, and the garbage collection reclaims <br>the memory for it; this stops the timer and explains why the TimerCallback method is called <br>just once.<br>
Let's say that you're using a debugger to step through Main, and a garbage collection just <br>happens to occur just after t is assigned the address of the new Timer object. Then, let's say <br>that you try to view the object that t refers to by using the debugger's Quick Watch window. <br>What do you think will happen? The debugger can't show you the object because it was just <br>garbage collected. This behavior would be considered very unexpected and undesirable by <br>most developers, so Microsoft has come up with a solution.<br>
When the JIT compiler compiles the IL for a method into native code, it checks to see if <br>the assembly defining the method was compiled without optimizations and if the process <br>is currently being executed under a debugger. If both are true, the JIT compiler generates <br>the method's internal root table in such a way as to artificially extend the lifetime of all of <br>the variables to the end of the method. In other words, the JIT compiler will trick itself into <br>
<hr>
<A name=547></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>529</b><br>
believing that the t variable in Main must live until the end of the method. So, if a garbage <br>collection were to occur, the garbage collector now thinks that t is still a root and that the <br>Timer object that t refers to will continue to be reachable. The Timer object will survive <br>the collection, and the TimerCallback method will get called repeatedly until Console.<br>ReadLine returns and Main exits. This is easy to see. Just run the same executable file under a <br>debugger, and you'll see that the TimerCallback method is called repeatedly!<br>
Now, recompile the program from a command prompt, but this time, specify the C# compiler's <br>/debug+ compiler-line switch. When you run the resulting executable file, you'll now see that <br>the TimerCallback method is called repeatedly--even if you don't run this program under a <br>debugger! What is happening here?<br>
Well, when the JIT compiler compiles a method, the JIT compiler looks to see if the assembly <br>that defines the method contains the System.Diagnostics.DebuggableAttribute attribute <br>with its DebuggingModes' DisableOptimizations flag set. If the JIT compiler sees this flag <br>set, it also compiles the method, artificially extending the lifetime of all variables until the end <br>of the method. When you specify the /debug+ compiler switch, the C# compiler emits this <br>attribute and flag into the resulting assembly for you. Note, the C# compiler's /optimize+  <br>compiler switch can turn optimizations back on so this compiler switch should not be specified <br>when performing this experiment.<br>
The JIT compiler does this to help you with JIT debugging. You may now start your application <br>normally (without a debugger), and if the method is called, the JIT compiler will artificially <br>extend the lifetime of the variables to the end of the method. Later, if you decide to attach <br>a debugger to the process, you can put a breakpoint in a previously compiled method and <br>examine the variables.<br>
So now you know how to build a program that works in a debug build but doesn't work  <br>correctly when you make a release build! Since no developer wants a program that works <br>only when debugging it, there should be something we can do to the program so that it <br>works all of the time regardless of the type of build.<br>
You could try modifying the Main method to this:<br>
public static void Main() {  <br>    // Create a Timer object that knows to call our TimerCallback   <br>    // method once every 2000 milliseconds.  <br>    Timer t = new Timer(TimerCallback, null, 0, 2000);  <br>  <br>    // Wait for the user to hit &lt;Enter&gt;  <br>    Console.ReadLine();  <br>  <br>    // Refer to t after ReadLine (this gets optimized away)  <br>    t = null;  <br>}<br>
However, if you compile this (without the /debug+ switch) and run the resulting executable <br>file (not under the debugger), you'll see that the TimerCallback method is still called just <br>once. The problem here is that the JIT compiler is an optimizing compiler, and setting a local <br>
<hr>
<A name=548></a><IMG src="CLRviaCsharp-548_1.jpg"><br>
<b>530 </b><br>
<b>Part IV  Core Facilities</b><br>
variable or parameter variable to null is the same as not referencing the variable at all. In <br>other words, the JIT compiler optimizes the t = null; line out of the code completely, and <br>therefore, the program still does not work as we desire. The correct way to modify the Main <br>method is as follows:<br>
public static void Main() {  <br>    // Create a Timer object that knows to call our TimerCallback   <br>    // method once every 2000 milliseconds.  <br>    Timer t = new Timer(TimerCallback, null, 0, 2000);  <br>  <br>    // Wait for the user to hit &lt;Enter&gt;  <br>    Console.ReadLine();  <br>  <br>    // Refer to t after ReadLine (t will survive GCs until Dispose returns)  <br>    t.Dispose ();  <br>}<br>
Now, if you compile this code (without the /debug+ switch) and run the resulting executable <br>file (not under the debugger), you'll see that the TimerCallback method is called multiple <br>times, and the program is fixed. What's happening here is that the object t refers to is  <br>required to stay alive so that the Dispose instance method can be called on it (the value in t <br>needs to be passed as the this argument to Dispose).<br>
<b>Note  </b>Please don't read this whole discussion and then worry about your own objects being  <br>garbage collected prematurely. I use the Timer class in this discussion because it has special <br>behavior that no other class exhibits. The "problem/feature" of Timer is that the existence of <br>a Timer object in the heap causes something else to happen: A thread pool thread invokes <br>a method periodically. No other type exhibits this behavior. For example, the existence of a <br>String object in memory doesn't cause anything else to happen; the string just sits there. So, I <br>use Timer to show how roots work and how object-lifetime works as related to the debugger, <br>but the discussion is <i>not</i> really about how to keep objects alive. All non-Timer objects will live as <br>needed by the application automatically.<br>
<b>Using Finalization to Release Native Resources</b><br>
At this point, you should have a basic understanding of garbage collection and the managed  <br>heap, including how the garbage collector reclaims an object's memory. Fortunately for us,  <br>most types need only memory to operate. However, some types require more than just <br>memory to be useful; some types require the use of a native resource in addition to memory.<br>
The System.IO.FileStream type, for example, needs to open a file (a native resource) and <br>store the file's handle. Then the type's Read and Write methods use this handle to manipulate <br>the file. Similarly, the System.Threading.Mutex type opens a Windows mutex kernel object <br>(a native resource) and stores its handle, using it when the Mutex's methods are called.<br>
<hr>
<A name=549></a><IMG src="CLRviaCsharp-549_1.jpg"><br>
<b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>531</b><br>
<i>Finalization</i> is a mechanism offered by the CLR that allows an object to perform some grace-<br>ful cleanup prior to the garbage collector reclaiming the object's memory. Any type that <br>wraps a native resource, such as a file, network connection, socket, mutex, or other type, <br>must support finalization. Basically, the type implements a method named Finalize. When <br>the garbage collector determines that an object is garbage, it calls the object's Finalize <br>method (if it exists). I think of it this way: Any type that implements the Finalize method is <br>in effect stating that all of its objects want a last meal before they are killed.<br>
Microsoft's C# team felt that Finalize methods were a special kind of method requiring <br>special syntax in the programming language (similar to how C# requires special syntax to  <br>define a constructor). So, in C#, you must define a Finalize method by placing a tilde  <br>symbol (~) in front of the class name, as shown in the following code sample:<br>
internal sealed class SomeType {  <br>   // This is the Finalize method  <br>   ~SomeType() {  <br>      // The code here is inside the Finalize method  <br>   }  <br>}<br>
If you were to compile this code and examine the resulting assembly with ILDasm.exe, you'd <br>see that the C# compiler did, in fact, emit a protected override method named Finalize <br>into the module's metadata. If you examined the Finalize method's IL code, you'd also see <br>that the code inside the method's body is emitted into a try block, and that a call to base.<br>Finalize is emitted into a finally block.<br>
<b>Important  </b>If you're familiar with C++, you'll notice that the special syntax C# requires for  <br>defining a Finalize method looks just like the syntax you'd use to define a C++ destructor. <br>In fact, the C# Programming Language Specification calls this method a <i>destructor</i>. However, a <br>Finalize method doesn't work like an unmanaged C++ destructor at all, and this has caused a <br>great deal of confusion for developers migrating from one language to another.<br>
The problem is that developers mistakenly believe that using the C# destructor syntax means <br>that the type's objects will be deterministically destructed, just as they would be in C++. <br>However, the CLR doesn't support deterministic destruction, preventing C# from providing this <br>mechanism.<br>
A Finalize method is usually implemented to call the Win32 CloseHandle function,  <br>passing in the handle of the native resource. The FileStream type defines a file handle field, <br>which identifies the native resource. The FileStream type also defines a Finalize method, <br>which internally calls CloseHandle, passing it the file handle field; this ensures that the native <br>file handle is closed when the managed FileStream object is determined to be garbage. If <br>a type that wraps a native resource fails to define a Finalize method, the native resource <br>won't be closed and will cause a resource leak that will exist until the process terminates, at <br>which time the operating system will reclaim the native resources.<br>
<hr>
<A name=550></a><b>532 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Guaranteed Finalization Using </b>CriticalFinalizerObject<b> </b><br>
<b>Types</b><br>
To make things simpler for developers, the System.Runtime.ConstrainedExecution <br>namespace defines a CriticalFinalizerObject class that looks like this:<br>
public abstract class CriticalFinalizerObject {  <br>   protected CriticalFinalizerObject() { /* there is no code in here */ }  <br>  <br>   // This is the Finalize method  <br>   ~CriticalFinalizerObject() { /* there is no code in here */ }  <br>}<br>
I know that you're thinking that this class doesn't look too exciting, but the CLR treats this <br>class and classes derived from it in a very special manner. In particular, the CLR endows this <br>class with three cool features:<br>
  The first time an object of any CriticalFinalizerObject-derived type is constructed, <br>
the CLR immediately JIT-compiles all of the Finalize methods in the inheritance hier-<br>archy. Compiling these methods upon object construction guarantees that the native <br>resource will be released when the object is determined to be garbage. Without this <br>eager compiling of the Finalize method, it would be possible to allocate the native <br>resource and use it, but not to get rid of it. Under low memory conditions, the CLR <br>might not be able to find enough memory to compile the Finalize method, which <br>would prevent it from executing, causing the native resource to leak. Or the resource <br>might not be freed if the Finalize method contained code that referred to a type in <br>another assembly, and the CLR failed to locate this other assembly.<br>
  The CLR calls the Finalize method of CriticalFinalizerObject-derived types  <br>
after calling the Finalize methods of non­CriticalFinalizerObject-derived types. <br>This ensures that managed resource classes that have a Finalize method can access <br>CriticalFinalizerObject-derived objects within their Finalize methods success-<br>fully. For example, the FileStream class's Finalize method can flush data from a <br>memory buffer to an underlying disk with confidence that the disk file has not been <br>closed yet.<br>
  The CLR calls the Finalize method of CriticalFinalizerObject-derived types if <br>
an AppDomain is rudely aborted by a host application (such as Microsoft SQL Server <br>or Microsoft ASP.NET). This also is part of ensuring that the native resource is released <br>even in a case in which a host application no longer trusts the managed code running <br>inside of it.<br>
SafeHandle<b> and Its Derived Types<br></b>Now, Microsoft realizes that the most-used native resources are those resources provided <br>by Windows. And Microsoft also realizes that most Windows resources are manipulated <br>with handles (32-bit values on a 32-bit system and 64-bit values on a 64-bit system). Again, <br>
<hr>
<A name=551></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>533</b><br>
to make life easier and safer for developers, the System.Runtime.InteropServices <br>namespace includes a class called SafeHandle, which looks like this (I've added comments in <br>the methods to indicate what they do):<br>
public abstract class SafeHandle : CriticalFinalizerObject, IDisposable {  <br>   // This is the handle to the native resource  <br>   protected IntPtr handle;  <br>  <br>   protected SafeHandle(IntPtr invalidHandleValue, Boolean ownsHandle) {  <br>      this.handle = invalidHandleValue;   <br>      // If ownsHandle is true, then the native resource is closed when  <br>      // this SafeHandle-derived object is collected  <br>   }  <br>  <br>   protected void SetHandle(IntPtr handle) {  <br>      this.handle = handle;  <br>   }  <br>  <br>  <br>   // You can explicitly release the resource by calling Dispose or Close  <br>   public void Dispose() { Dispose(true); }  <br>   public void Close()   { Dispose(true); }  <br>  <br>   // The default Dispose implementation (shown here) is exactly what you want. <br>   // Overriding this method is strongly discouraged.  <br>   protected virtual void Dispose(Boolean disposing) {  <br>      // The default implementation ignores the disposing argument. <br>      // If resource was already released, just return  <br>      // If ownsHandle is false, return  <br>      // Set flag indicating that this resource has been released  <br>      // Call the virtual ReleaseHandle method  <br>      // Call GC.SuppressFinalize(this) to prevent Finalize from being called  <br>      // If ReleaseHandle returned true, return  <br>      // Fire the ReleaseHandleFailed Managed Debugging Assistant (MDA)  <br>   }  <br>  <br>   // The default Finalize implementation (shown here) is exactly what you want. <br>   // Overriding this method is very strongly discouraged.  <br>   ~SafeHandle() { Dispose(false); }  <br>  <br>   // A derived class overrides this method to implement the code that releases the resource  <br>   protected abstract Boolean ReleaseHandle();  <br>  <br>   public void SetHandleAsInvalid() {  <br>      // Set flag indicating that this resource has been released  <br>      // Call GC.SuppressFinalize(this) to prevent Finalize from being called  <br>   }  <br>  <br>   public Boolean IsClosed {   <br>      get {   <br>         // Returns flag indicating whether resource was released  <br>      }  <br>   }  <br>  <br>
<hr>
<A name=552></a><b>534 </b><br>
<b>Part IV  Core Facilities</b><br>
   public abstract Boolean IsInvalid {   <br>       get { <br>         // A derived class overrides this property. <br>         // The implementation should return true if the handle's value doesn't <br>         // represent a resource (this usually means that the handle is 0 or -1) <br>      } <br>    }  <br>  <br>   // These three methods have to do with security and reference counting;  <br>   // I'll talk about them at the end of this section <br>   public void   DangerousAddRef(ref Boolean success) {...}  <br>   public IntPtr DangerousGetHandle() {...}  <br>   public void   DangerousRelease() {...}  <br>}<br>
The first thing to notice about the SafeHandle class is that it is derived from <br>CriticalFinalizerObject; this ensures it gets the CLR's special treatment. The second <br>thing to notice is that the class is abstract; it is expected that another class will be derived <br>from SafeHandle, and this class will override the protected constructor, the abstract method <br>ReleaseHandle, and the abstract IsInvalid property get accessor method.<br>
In Windows, most handles are invalid if they have a value of 0 or -1. The <br>Microsoft.Win32.SafeHandles namespace contains another helper class called <br>SafeHandleZeroOrMinusOneIsInvalid, which looks like this:<br>
public abstract class SafeHandleZeroOrMinusOneIsInvalid : SafeHandle {  <br>   protected SafeHandleZeroOrMinusOneIsInvalid(Boolean ownsHandle)   <br>      : base(IntPtr.Zero, ownsHandle) {  <br>   }  <br>  <br>   public override Boolean IsInvalid {   <br>      get {  <br>         if (base.handle == IntPtr.Zero) return true;  <br>         if (base.handle == (IntPtr) (-1)) return true;  <br>         return false;  <br>      }  <br>   }  <br>}<br>
Again, you'll notice that the SafeHandleZeroOrMinusOneIsInvalid class is abstract, and <br>therefore, another class must be derived from this one to override the protected constructor <br>and the abstract method ReleaseHandle. The .NET Framework provides just a few public <br>classes derived from SafeHandleZeroOrMinusOneIsInvalid, including SafeFileHandle, <br>SafeRegistryHandle, SafeWaitHandle, and SafeBuffer. Here is what the SafeFileHandle <br>class looks like:<br>
public sealed class SafeFileHandle : SafeHandleZeroOrMinusOneIsInvalid {  <br>   public SafeFileHandle(IntPtr preexistingHandle, Boolean ownsHandle)  <br>      : base(ownsHandle) {  <br>      base.SetHandle(preexistingHandle);  <br>   }  <br>  <br>
<hr>
<A name=553></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>535</b><br>
   protected override Boolean ReleaseHandle() {  <br>      // Tell Windows that we want the native resource closed.  <br>      return Win32Native.CloseHandle(base.handle);  <br>   }  <br>}<br>
The SafeWaitHandle class is implemented similarly to the SafeFileHandle class shown <br>above. The only reason why there are different classes with similar implementations is to <br>achieve type safety; the compiler won't let you use a file handle as an argument to a method <br>that expects a wait handle, and vice versa. The SafeRegistryHandle class's ReleaseHandle <br>method calls the Win32 RegCloseKey function.<br>
It would be nice if the .NET Framework included additional classes that wrap various native  <br>resources. For example, one could imagine classes such as SafeProcessHandle, <br>SafeThreadHandle, SafeTokenHandle, SafeFileMappingHandle, SafeViewOfFileHandle <br>(its ReleaseHandle method would call the Win32 UnmapViewOfFile function), <br>SafeLibraryHandle (its ReleaseHandle method would call the Win32 FreeLibrary  <br>function), SafeLocalAllocHandle (its ReleaseHandle method would call the Win32 <br>LocalFree function), and so on.<br>
All of the classes just listed (and more) actually do ship with the Framework Class Library <br>(FCL). However, these classes are not publicly exposed; they are all internal to MSCorLib.dll or <br>System.dll. Microsoft didn't expose these classes publicly because they didn't want to do full <br>testing of them, and they didn't want to have to take the time to document them. However, <br>if you need any of these classes for your own work, I'd recommend that you use a tool such <br>as ILDasm.exe or some IL decompiler tool to extract the code for these classes and integrate <br>that code into your own project's source code. All of these classes are trivial to implement, <br>and writing them yourself from scratch would also be quite easy.<br>
<b>Interoperating with Unmanaged Code by Using </b>SafeHandle<b> </b><br>
<b>Types</b><br>
As already shown, the SafeHandle-derived classes are extremely useful because they ensure <br>that the native resource is freed when a garbage collection occurs. In addition to what we've <br>already discussed, SafeHandle offers two more capabilities. First, the CLR gives SafeHandle-<br>derived types special treatment when used in scenarios in which you are interoperating with <br>unmanaged code. For example, let's examine the following code:<br>
using System;  <br>using System.Runtime.InteropServices;  <br>using Microsoft.Win32.SafeHandles;  <br>  <br>internal static class SomeType {  <br>   [DllImport(&quot;Kernel32&quot;, CharSet=CharSet.Unicode, EntryPoint=&quot;CreateEvent&quot;)]  <br>   // This prototype is not robust  <br>   private static extern IntPtr CreateEventBad( <br>      IntPtr pSecurityAttributes, Boolean manualReset, Boolean initialState, String name);  <br>  <br>
<hr>
<A name=554></a><b>536 </b><br>
<b>Part IV  Core Facilities</b><br>
   // This prototype is robust  <br>   [DllImport(&quot;Kernel32&quot;, CharSet=CharSet.Unicode, EntryPoint=&quot;CreateEvent&quot;)]  <br>   private static extern SafeWaitHandle CreateEventGood( <br>      IntPtr pSecurityAttributes, Boolean manualReset, Boolean initialState, String name);  <br>  <br>   public static void SomeMethod() {  <br>      IntPtr         handle = CreateEventBad(IntPtr.Zero, false, false, null);  <br>      SafeWaitHandle swh    = CreateEventGood(IntPtr.Zero, false, false, null);  <br>   }  <br>}<br>
You'll notice that the CreateEventBad method is prototyped as returning an IntPtr. Prior <br>to version 2.0 of the .NET Framework, the SafeHandle class didn't exist, and you'd have to <br>use the IntPtr type to represent handles. What Microsoft's CLR team discovered was that <br>this code was not robust. You see, after CreateEventBad was called (which creates the native <br>event resource), it was possible that a ThreadAbortException could be thrown prior to the <br>handle being assigned to the handle variable. In the rare cases when this would happen, the <br>managed code would be leaking the native resource. The only way to get the event closed <br>would be to terminate the process.<br>
Now, with version 2.0 and later of the .NET Framework, we can use the SafeHandle class to <br>fix this potential resource leak. Notice that the CreateEventGood method is prototyped as <br>returning a SafeWaitHandle (instead of an IntPtr). When CreateEventGood is called, the <br>CLR calls the Win32 CreateEvent function. As the CreateEvent function returns to managed <br>code, the CLR knows that SafeWaitHandle is derived from SafeHandle, causing the CLR <br>to automatically construct an instance of the SafeWaitHandle class, passing in the handle <br>value returned from CreateEvent. The newing up of the SafeWaitHandle object and the <br>assignment of the handle happen in unmanaged code, which cannot be interrupted by a <br>ThreadAbortException. Now, it is impossible for managed code to leak this native resource. <br>Eventually, the SafeWaitHandle object will be garbage collected and its Finalize method <br>will be called, ensuring that the resource is released.<br>
One last feature of SafeHandle-derived classes is that they prevent someone from trying <br>to exploit a potential security hole. The problem is that one thread could be trying to use a <br>native resource while another thread tries to free the resource. This could manifest itself as a <br>handle-recycling exploit. The SafeHandle class prevents this security vulnerability by using  <br>reference counting. Internally, the SafeHandle class defines a private field that maintains <br>a count. When a SafeHandle-derived object is set to a valid handle, the count is set to 1. <br>Whenever a SafeHandle-derived object is passed as an argument to an unmanaged method,  <br>the CLR knows to automatically increment the counter. Likewise, when the unmanaged  <br>method returns to managed code, the CLR knows to decrement the counter. For example, <br>you would prototype the Win32 SetEvent function as follows:<br>
[DllImport(&quot;Kernel32&quot;, ExactSpelling=true)]  <br>private static extern Boolean SetEvent(SafeWaitHandle swh);<br>
<hr>
<A name=555></a><IMG src="CLRviaCsharp-555_1.jpg"><br>
<b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>537</b><br>
Now when you call this method passing in a reference to a SafeWaitHandle object, the CLR <br>will increment the counter just before the call and decrement the counter just after the call. <br>Of course, the manipulation of the counter is performed in a thread-safe fashion. How does <br>this improve security? Well, if another thread tries to release the native resource wrapped by <br>the SafeHandle object, the CLR knows that it cannot actually release it because the resource <br>is being used by an unmanaged function. When the unmanaged function returns, the counter <br>is decremented to 0, and the resource will be released.<br>
If you are writing or calling code to manipulate a handle as an IntPtr, you can access it out <br>of a SafeHandle object, but you should manipulate the reference counting explicitly. You <br>accomplish this via SafeHandle's DangerousAddRef and DangerousRelease methods. You <br>gain access to the raw handle via the DangerousGetHandle method.<br>
I would be remiss if I didn't mention that the System.Runtime.InteropServices <br>namespace also defines a CriticalHandle class. This class works exactly as the SafeHandle <br>class in all ways except that it does not offer the reference-counting feature. The <br>CriticalHandle class and the classes derived from it sacrifice security for better perfor-<br>mance when you use it (since counters don't get manipulated). As does SafeHandle, the <br>CriticalHandle class has two types derived from it: CriticalHandleMinusOneIsInvalid <br>and CriticalHandleZeroOrMinusOneIsInvalid. Since Microsoft favors a more secure <br>system over a faster system, the class library includes no types derived from either of these <br>two classes. For your own work, I would recommend that you use CriticalHandle-derived <br>types only if performance is an issue. If you can justify reducing security, you can switch to a <br>CriticalHandle-derived type.<br>
<b>Using Finalization with Managed Resources</b><br>
<b>Important  </b>There are some people who are of the mindset that you should never use finaliza-<br>tion with managed resources. For the most part, I agree with these people. Therefore, you may <br>want to skip this section entirely. Using finalization with managed resources is a super-advanced <br>way of coding and should be used only in very rare circumstances. You must have complete and <br>intimate knowledge of the code you are calling from within a Finalize method. Furthermore, <br>you must know that the behavior of code you are calling will not change with future versions. <br>Specifically, you must know that any code you call from within a Finalize method does not use <br>any other object that could have already been finalized.<br>
While finalization is almost exclusively used to release a native resource, it can occasionally <br>be useful with managed resources too. Here's a class that causes the computer to beep every <br>time the garbage collector performs a collection:<br>
<hr>
<A name=556></a><IMG src="CLRviaCsharp-556_1.jpg"><br>
<b>538 </b><br>
<b>Part IV  Core Facilities</b><br>
internal sealed class GCBeep {  <br>   ~GCBeep() { // This is the Finalize method  <br>      Console.Beep();  <br> <br>      // If the AppDomain isn't unloading and if the process isn't shutting down, <br>      // create a new object that will get finalized at the next collection.  <br>      if (!AppDomain.CurrentDomain.IsFinalizingForUnload() &amp;&amp;!Environment.HasShutdownStarted) <br>
 <br>
         new GCBeep();  <br>   }  <br>}<br>
To use this class, you need just to construct one instance of the class. Then whenever a  <br>garbage collection occurs, the object's Finalize method is called, which calls Beep and  <br>constructs a new GCBeep object. This new GCBeep object will have its Finalize method <br>called when the next garbage collection occurs. Here's a sample program that demonstrates <br>the GCBeep class:<br>
public static class Program {  <br>   public static void Main() {  <br>      // Constructing a single GCBeep object causes a beep to occur every time a GC starts.  <br>      new GCBeep();  <br>  <br>      // Construct a lot of 100-byte objects.  <br>      for (Int32 x = 0; x &lt; 10000; x++) {   <br>         Console.WriteLine(x);  <br>         Byte[] b = new Byte[100];  <br>      }  <br>   }  <br>}<br>
<b>Note  </b>While the GCBeep class is useful, I provide a much more useful GCNotification class <br>that allows you to instrument your application, thereby providing you a way to learn more about <br>your application's memory usage. You'll find this class presented at the end of the "Generations" <br>section later in this chapter.<br>
Also be aware that a type's Finalize method is called even if the type's instance constructor  <br>throws an exception. So your Finalize method shouldn't assume that the object is in a good, <br>consistent state. The following code demonstrates this:<br>
internal sealed class TempFile {  <br>   private String m_filename = null;  <br>   private FileStream m_fs;  <br>  <br>   public TempFile(String filename) {  <br>      // The following line might throw an exception.  <br>      m_fs = new FileStream(filename, FileMode.Create);  <br>  <br>      // Save the name of this file.  <br>      m_filename = filename;  <br>   }  <br>  <br>
<hr>
<A name=557></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>539</b><br>
   ~TempFile() {         // This is the Finalize method <br>      // The right thing to do here is to test filename against null because  <br>      // you can't be sure that filename was initialized in the constructor.  <br>      if (m_filename != null)  File.Delete(m_filename);  <br>   }  <br>}<br>
You could write the following code instead:<br>
internal sealed class TempFile {  <br>   private String m_filename;  <br>   private FileStream m_fs;  <br>  <br>   public TempFile(String filename) {  <br>      try {  <br>         // The following line might throw an exception.  <br>         m_fs = new FileStream(filename, FileMode.Create);  <br>  <br>         // Save the name of this file.  <br>         m_filename = filename;  <br>      }  <br>      catch {  <br>         // If anything goes wrong, tell the GC not to call the Finalize method. <br>         // I'll discuss SuppressFinalize later in this chapter.  <br>         GC.SuppressFinalize(this);  <br>  <br>         // Let the caller know something failed.  <br>         throw;  <br>      }  <br>   }  <br>  <br>   ~TempFile() { // This is the Finalize method <br>      // No if statement because this  executes only if the constructor ran successfully. <br>      File.Delete(m_filename);  <br>   }  <br>}<br>
When designing a type, it's best if you avoid using a Finalize method for several reasons all <br>related to performance:<br>
  Finalizable objects take longer to allocate because pointers to them must be placed on <br>
the finalization list (which I'll discuss in the "Finalization Internals" section a little later in <br>this chapter).<br>
  Finalizable objects get promoted to older generations, which increases memory pres-<br>
sure and prevents the object's memory from being collected at the time the garbage <br>collector determines that the object is garbage. In addition, all objects referred to <br>directly or indirectly by this object get promoted as well. (I'll discuss promotions and <br>generations in more detail in the "Generations" section later in this chapter.)<br>
  Finalizable objects cause your application to run slower since extra processing must  <br>
occur for each object when collected.<br>
<hr>
<A name=558></a><b>540 </b><br>
<b>Part IV  Core Facilities</b><br>
Furthermore, be aware of the fact that you have no control over when the Finalize method <br>will execute. Finalize methods run when a garbage collection occurs, which may happen <br>when your application requests more memory. Also, the CLR doesn't make any guarantees as <br>to the order in which Finalize methods are called, so you should avoid writing a Finalize <br>method that accesses other objects whose type defines a Finalize method; those other <br>objects could have been finalized already. However, it is perfectly OK to access value type <br>instances or reference type objects that do not define a Finalize method. You also need to <br>be careful when calling static methods because these methods can internally access objects <br>that have been finalized, causing the behavior of the static method to become unpredictable.<br>
<b>What Causes </b>Finalize<b> Methods to Be Called?</b><br>
Finalize methods are called at the completion of a garbage collection, which is started by <br>one of the following five events:<br>
<b>  Generation 0 is full  </b>When generation 0 is full, a garbage collection starts. This event <br>
is by far the most common way for Finalize methods to be called because it occurs <br>naturally as the application code runs, allocating new objects.<br>
<b>  Code explicitly calls </b>System.GC<b>'s static </b>Collect<b> method  </b>Code can explicitly request <br>
that the CLR perform a collection. Although Microsoft strongly discourages such re-<br>quests, at times it might make sense for an application to force a collection. <br>
<b>  Windows is reporting low memory conditions  </b>The CLR internally uses the Win32 <br>
CreateMemoryResourceNotification and QueryMemoryResourceNotification <br>functions to monitor system memory overall. If Windows reports low memory, the CLR <br>will force a garbage collection in an effort to free up dead objects to reduce the size of <br>a process's working set.<br>
<b>  The CLR is unloading an AppDomain  </b>When an AppDomain unloads, the CLR con-<br>
siders nothing in the AppDomain to be a root, and a garbage collection consisting of <br>all generations is performed. I'll discuss AppDomains in Chapter 22, "CLR Hosting and <br>AppDomains."<br>
<b>  The CLR is shutting down  </b>The CLR shuts down when a process terminates normally <br>
(as opposed to an external shutdown via Task Manager, for example). During this shut-<br>down, the CLR considers nothing in the process to be a root and calls the Finalize <br>method for all objects in the managed heap. Note that the CLR does not attempt to <br>compact or free memory here because the whole process is terminating, and Windows <br>will reclaim all of the processes' memory.<br>
The CLR uses a special, dedicated thread to call Finalize methods. For the first four events, <br>if a Finalize method enters an infinite loop, this special thread is blocked, and no more <br>Finalize methods can be called. This is a very bad situation because the application will <br>never be able to reclaim the memory occupied by the finalizable objects--the application <br>will leak memory as long as it runs.<br>
<hr>
<A name=559></a><IMG src="CLRviaCsharp-559_1.jpg"><br>
<b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>541</b><br>
For the fifth event, each Finalize method is given approximately 2 seconds to return. If <br>a Finalize method doesn't return within 2 seconds, the CLR just kills the process--no <br>more Finalize methods are called. Also, if it takes more than 40 seconds to call all objects' <br>Finalize methods, again, the CLR just kills the process.<br>
<b>Note  </b>These timeout values were correct at the time I wrote this text, but Microsoft might <br>change them in the future. Code in a Finalize method can construct new objects. If this hap-<br>pens during CLR shutdown, the CLR continues collecting objects and calling their Finalize <br>methods until no more objects exist or until the 40 seconds have elapsed.<br>
Recall the GCBeep type presented earlier in this chapter. If a GCBeep object is being finalized <br>because of the first, second, or third garbage collection reason, a new GCBeep object is con-<br>structed. This is OK because the application continues to run, assuming that more collections <br>will occur in the future. However, if a GCBeep object is being finalized because of the fourth <br>or fifth garbage collection reason, a new GCBeep object shouldn't be constructed because <br>this object would be created while the AppDomain is unloading or the CLR is shutting down. <br>If these new objects are created, the CLR will have a bunch of useless work to do because it <br>will continue to call Finalize methods.<br>
To prevent the construction of new GCBeep objects, GCBeep's Finalize method calls <br>AppDomain's IsFinalizingForUnload method and also queries System.Environment's <br>HasShutdownStarted property. The IsFinalizingForUnload method returns true if <br>the object's Finalize method is being called because the AppDomain is unloading. The <br>HasShutdownStarted property returns true if the object's Finalize method is being called <br>because the process is terminating.<br>
<b>Finalization Internals</b><br>
On the surface, finalization seems pretty straightforward: you create an object and its <br>Finalize method is called when it is collected. But once you dig in, finalization is more com-<br>plicated than this.<br>
When an application creates a new object, the new<i> </i>operator allocates the memory from the <br>heap. If the object's type defines a Finalize method, a pointer to the object is placed on <br>the <i>finalization list </i>just before the type's instance constructor is called. The finalization list is <br>an internal data structure controlled by the garbage collector. Each entry in the list points to <br>an object that should have its Finalize method called before the object's memory can be <br>reclaimed.<br>
Figure 21-5 shows a heap containing several objects. Some of these objects are reachable <br>from the application's roots, and some are not. When objects C, E, F, I, and J were created, <br>the system detected that these objects' types defined a Finalize method and so added <br>pointers to these objects in the finalization list.<br>
<hr>
<A name=560></a><IMG src="CLRviaCsharp-560_1.jpg"><br>
<b>542 </b><br>
<b>Part IV  Core Facilities</b><br>
Roots:<br>
tatic fields<br>
arameters<br>
ariables<br>
egisters<br>
Managed heap<br>
 <br>
A<br>
B<br>
D<br>
E<br>
F<br>
G H I<br>
J<br>
 <br>
E F<br>
 <br>
I J<br>
 <br>
Finalization list<br>
Freachable queue<br>
<b>FIGURE 21-5  </b>The managed heap showing pointers in its finalization list<br>
<b>Note  </b>Even though System.Object defines a Finalize method, the CLR knows to ignore it; <br>that is, when constructing an instance of a type, if the type's Finalize method is the one inher-<br>ited from System.Object, the object isn't considered finalizable. One of the derived types must <br>override Object's Finalize method.<br>
When a garbage collection occurs, objects B, E, G, H, I, and J are determined to be garbage. <br>The garbage collector scans the finalization list looking for pointers to these objects. When <br>a pointer is found, the pointer is removed from the finalization list and appended to the <br><i>freachable queue</i>. The freachable queue (pronounced "F-reachable") is another of the garbage <br>collector's internal data structures. Each pointer in the freachable queue identifies an object <br>that is ready to have its Finalize method called. After the collection, the managed heap <br>looks like Figure 21-6.<br>
In this figure, you see that the memory occupied by objects B, G, and H has been reclaimed <br>because these objects didn't have a Finalize method. However, the memory occupied by <br>objects E, I, and J couldn't be reclaimed because their Finalize methods haven't been called <br>yet.<br>
A special high-priority CLR thread is dedicated to calling Finalize methods. A dedicated <br>thread is used to avoid potential thread synchronization situations that could arise if one <br>of the application's normal-priority threads were used instead. When the freachable queue <br>is empty (the usual case), this thread sleeps. But when entries appear, this thread wakes,  <br>removes each entry from the queue, and then calls each object's Finalize method. Because <br>of the way this thread works, you shouldn't execute any code in a Finalize method that <br>makes any assumptions about the thread that's executing the code. For example, avoid  <br>accessing thread-local storage in the Finalize method.<br>
<hr>
<A name=561></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>543</b><br>
Roots:<br>
tatic fields<br>
arameters<br>
ariables<br>
egisters<br>
Managed heap<br>
A<br>
D<br>
E<br>
F<br>
I<br>
J<br>
 <br>
E I<br>
  F<br>
  J<br>
Finalization list<br>
Freachable queue<br>
<b>FIGURE 21-6  </b>The managed heap showing pointers that moved from the finalization list to the freachable <br>queue<br>
In the future, the CLR may use multiple finalizer threads. So you should avoid writing any <br>code that assumes that Finalize methods will be called serially. In other words, you will <br>need to use thread synchronization locks if code in a Finalize method touches shared <br>state. With just one finalizer thread, there could be performance and scalability issues in <br>the scenario in which you have multiple CPUs allocating finalizable objects but only one <br>thread executing Finalize methods--the one thread might not be able to keep up with the <br>allocations.<br>
The interaction between the finalization list and the freachable queue is fascinating. First  <br>I'll tell you how the freachable queue got its name. Well, the "f" is obvious and stands for <br><i>finalization</i>; every entry in the freachable queue is a reference to an object in the managed <br>heap that should have its Finalize method called. But the <i>reachable</i> part of the name <br>means that the objects are reachable. To put it another way, the freachable queue is consid-<br>ered a root, just as static fields are roots. So if an object is in the freachable queue, the object <br>is reachable and is <i>not </i>garbage.<br>
In short, when an object isn't reachable, the garbage collector considers the object to be gar-<br>bage. Then when the garbage collector moves an object's reference from the finalization list <br>to the freachable queue, the object is no longer considered garbage and its memory can't be <br>reclaimed. As freachable objects are marked, objects referred to by their reference type fields <br>are also marked recursively; all these objects must survive the collection. At this point, the <br>garbage collector has finished identifying garbage. Some of the objects identified as garbage <br>have been reclassified as not garbage--in a sense, the object has become <i>resurrected</i>. The <br>garbage collector compacts the reclaimable memory, and the special CLR thread empties the <br>freachable queue, executing each object's Finalize method.<br>
<hr>
<A name=562></a><b>544 </b><br>
<b>Part IV  Core Facilities</b><br>
The next time the garbage collector is invoked, it will see that the finalized objects are truly <br>garbage because the application's roots don't point to it and the freachable queue no longer <br>points to it either. The memory for the object is simply reclaimed. The important point to get <br>from al  of this is that two garbage col ections are required to reclaim memory used by objects <br>that require finalization. In reality, more than two collections will be necessary because the <br>objects get promoted to another generation (which I'll explain later). Figure 21-7 shows what <br>the managed heap looks like after the second garbage collection.<br>
Roots:<br>
tatic fields<br>
arameters<br>
ariables<br>
egisters<br>
Managed heap<br>
A<br>
D<br>
F<br>
    F<br>
 <br>
Finalization list<br>
Freachable queue<br>
<b>FIGURE 21-7  </b>Status of the managed heap after second garbage collection<br>
<b>The Dispose Pattern: Forcing an Object to Clean Up</b><br>
The Finalize method is incredibly useful because it ensures that native resources aren't <br>leaked when managed objects have their memory reclaimed. However, the problem with <br>the Finalize method is there is no guarantee of when it will be called, and because it isn't a <br>public method, a user of the class can't call it explicitly.<br>
The capability to deterministically dispose of or close an object is frequently useful when <br>you're working with managed types that wrap native resources such as files, database connec-<br>tions, and bitmaps. For example, you might want to open a database connection, query some <br>records, and close the database connection--you wouldn't want the database connection to <br>stay open until the next garbage collection occurs, especially because the next garbage col-<br>lection could occur hours or even days after you retrieve the database records.<br>
Types that offer the capability to be deterministically disposed of or closed implement what <br>is known as the <i>dispose pattern</i>. The dispose pattern defines conventions a developer should <br>adhere to when defining a type that wants to offer explicit cleanup to a user of the type. In <br>addition, if a type implements the dispose pattern, a developer using the type knows exactly <br>how to explicitly dispose of the object when it's no longer needed.<br>
<hr>
<A name=563></a><IMG src="CLRviaCsharp-563_1.jpg"><br>
<b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>545</b><br>
<b>Note  </b>Any type that defines a Finalize method should also implement the dispose pattern as <br>described in this section so that users of the type have a lot of control over the lifetime of the re-<br>source. However, a type can implement the dispose pattern and not define a Finalize method. <br>For example, the System.IO.BinaryWriter class falls into this category. I'll explain the reason <br>for this exception in the section "An Interesting Dependency Issue" later in this chapter.<br>
Earlier I showed you the SafeHandle class. This class implements a Finalize method that <br>ensures that a native resource wrapped by the object is closed (or released) when the object <br>is collected. However, a developer using a SafeHandle object has a way to explicitly close the <br>native resource because the SafeHandle class implements the IDisposable interface.<br>
Let's take another look at the SafeHandle class. But for brevity, let's just focus on the parts <br>that have to do with the dispose pattern:<br>
// Implementing the IDisposable interface signals users of  <br>// this class that it offers the dispose pattern.  <br>public abstract class SafeHandle : CriticalFinalizerObject, IDisposable {  <br>  <br>   // This public method can be called to deterministically close  <br>   // the resource. This method implements IDisposable's Dispose.  <br>   public void Dispose() {   <br>      // Call the method that actually does the cleanup.  <br>      Dispose(true);   <br>   }  <br>  <br>   // This public method can be called instead of Dispose.  <br>   public void Close() {  <br>      Dispose(true);   <br>   }  <br>  <br>   // When garbage collected, this Finalize method runs to close the resource  <br>   ~SafeHandle() {   <br>      // Call the method that actually does the cleanup.  <br>      Dispose(false);   <br>   }  <br>  <br>   // This is the common method that does the actual cleanup.  <br>   // Finalize, Dispose, and Close call this method.  <br>   // Because this class isn't sealed, this method is protected &amp; virtual.  <br>   // If this class were sealed, this method should be private.  <br>   protected virtual void Dispose(Boolean disposing) {  <br>      if (disposing) {  <br>         // The object is being explicitly disposed/closed, not   <br>         // finalized. It is therefore safe for code in this if   <br>         // statement to access fields that reference other   <br>         // objects because the Finalize method of these other objects   <br>         // hasn't yet been called.  <br>  <br>         // For the SafeHandle class, there is nothing to do in here.  <br>      }  <br>  <br>
<hr>
<A name=564></a><IMG src="CLRviaCsharp-564_1.jpg"><br>
<IMG src="CLRviaCsharp-564_2.jpg"><br>
<b>546 </b><br>
<b>Part IV  Core Facilities</b><br>
      // The object is being disposed/closed or finalized, do the following:  <br>      // If resource was already released, just return  <br>      // If ownsHandle is false, return  <br>      // Set flag indicating that this resource has been released  <br>      // Call the virtual ReleaseHandle method  <br>      // Call GC.SuppressFinalize(this) to prevent Finalize from being called  <br>   }  <br>}<br>
Implementing the dispose pattern is hardly trivial. Now let me explain what all this code <br>does. First, the SafeHandle class implements the System.IDisposable interface. This  <br>interface is defined in the FCL as follows:<br>
public interface IDisposable {  <br>   void Dispose();  <br>}<br>
Any type that implements this interface is stating that it adheres to the dispose pattern. <br>Simply put, this means that the type offers a public, parameterless Dispose method that can <br>be explicitly called to release the resource wrapped by the object. Note that the memory for <br>the object itself is <i>not </i>freed from the managed heap's memory; the garbage collector is still <br>responsible for freeing the object's memory, and there's no telling exactly when this will hap-<br>pen. The parameterless Dispose and Close methods should be both public and nonvirtual.<br>
<b>Note  </b>You might notice that this SafeHandle class also offers a public Close method. This <br>method simply calls Dispose. Some classes that offer the dispose pattern also offer a Close <br>method for convenience; but the dispose pattern doesn't require this method. For example, <br>the System.IO.FileStream class offers the dispose pattern, and this class also offers a Close <br>method. Programmers find it more natural to close a file rather than dispose of a file. However, <br>the System.Threading.Timer class doesn't offer a Close method even though it adheres to <br>the dispose pattern.<br>
<b>Important  </b>If a class defines a field in which the field's type implements the dispose pattern, <br>the class itself should also implement the dispose pattern. The Dispose method should dispose <br>of the object referred to by the field. This allows someone using the class to call Dispose on it, <br>which in turn releases the resources used by the object itself. In fact, this is one of the main rea-<br>sons why types might implement the dispose pattern but not implement the Finalize method.<br>
For example, the BinaryWriter class implements the dispose pattern. When Dispose is called <br>on a BinaryWriter object, BinaryWriter's Dispose method calls Dispose on the stream ob-<br>ject maintained as a field inside the BinaryWriter object. So when the BinaryWriter object is <br>disposed, the underlying stream is disposed, which, in turn, releases the native stream resource.<br>
So now you know three ways to clean up a SafeHandle object: a programmer can write code <br>to call Dispose, a programmer can write code to call Close, or the garbage collector can call <br>the object's Finalize method. The cleanup code is placed in a separate, protected, virtual <br>
<hr>
<A name=565></a><IMG src="CLRviaCsharp-565_1.jpg"><br>
<b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>547</b><br>
method, which is also called Dispose, but this Dispose method takes a Boolean parameter <br>named disposing.<br>
This Dispose method is where you put all of the cleanup code. In the SafeHandle example, <br>the method sets a flag indicating that the resource has been released and then calls the vir-<br>tual ReleaseHandle method to actually perform the releasing of the resource. Note that the <br>dispose pattern states that a single object can have Dispose or Close called on it multiple <br>times; the first time, the resource should be released; for future calls, the method should just <br>return (no exception should be thrown).<br>
<b>Note  </b>It is possible to have multiple threads call Dispose/Close on a single object simultane-<br>ously. However, the dispose pattern states that thread synchronization is not required. The  <br>reason is because code should be calling Dispose/Close only if the code knows for a fact that <br>no other thread is using the object. If you don't know if an object is still in use at a certain point <br>in your code, you should not be calling Dispose/Close. Instead, wait for a garbage collection to <br>kick in so that it can determine if the object is no longer being used, and then release the  <br>resource.<br>
When an object's Finalize method is called by the CLR, the Dispose method's disposing  <br>parameter is set to false. This tells the Dispose method that it shouldn't execute any code <br>that references other managed objects whose classes implement a Finalize method. <br>Imagine that the CLR is shutting down, and inside a Finalize method, you attempt to write <br>to a FileStream. This might not work because the FileStream might have already had its <br>Finalize method called, closing the underlying disk file.<br>
On the other hand, when you call Dispose or Close in your code, the Dispose method's <br>disposing parameter must be set to true. This indicates that the object is being explicitly <br>disposed of, not finalized. In this case, the Dispose method is allowed to execute code that <br>references another object (such as a FileStream); because you have control over the pro-<br>gram's logic, you know that the FileStream object is still open.<br>
By the way, if the SafeHandle class were sealed, the Dispose method that takes a Boolean <br>should be implemented as a private method instead of a protected virtual method. But since <br>the SafeHandle class is not sealed, any class that derives from SafeHandle can override the <br>Dispose method that takes a Boolean in order to override the cleanup code. The derived <br>class wouldn't implement the parameterless Dispose or Close methods, and it wouldn't <br>override the Finalize method. The derived class would simply inherit the implementation of <br>all of these methods. Note that the derived class's override of the Dispose method that takes <br>a Boolean should call the base class's version of the Dispose method that takes a Boolean, <br>allowing the base class to perform whatever cleanup it needs to do. This is exactly the case of <br>the FileStream type that I used as an example: it derives from Stream that implements the <br>Close and the parameterless IDisposable.Dispose method. FileStream simply overrides <br>the Dispose method, which takes a Boolean parameter to dispose of the SafeHandle field <br>wrapping the unmanaged file resource.<br>
<hr>
<A name=566></a><IMG src="CLRviaCsharp-566_1.jpg"><br>
<b>548 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Important  </b>You need to be aware of some versioning issues here. If in version 1, a base type <br>doesn't implement the IDisposable interface, it can never implement this interface in a later <br>version. If the base type were to add the IDisposable interface in the future, all of the derived  <br>types wouldn't know to call the base type's methods, and the base type wouldn't get a chance <br>to clean itself up properly. On the other hand, if in version 1 a base type implements the <br>IDisposable interface, it can never remove this interface in a later version because the derived <br>type would try to call methods that no longer exist in the base type.<br>
Another noteworthy part of this code is the call to GC's static SuppressFinalize method in-<br>side the Dispose method that takes a Boolean. You see, if code using a SafeHandle  <br>object explicitly calls Dispose or Close, there is no need for the object's <b>Finalize</b> method to <br>execute, because if Finalize did execute, there would be an unnecessary attempt to release <br>the resource a second time. The call to GC's SuppressFinalize turns on a bit flag associated <br>with the object referred to by its single this parameter. When this flag is on, the CLR knows <br>not to move this object's pointer from the finalization list to the freachable queue, preventing <br>the object's Finalize method from being called and ensuring that the object doesn't live <br>until the next garbage collection. Note that the SafeHandle class calls SuppressFinalize <br>even when the object is being finalized. This has no ill effect because the object is already in <br>the process of being finalized.<br>
<b>Using a Type That Implements the Dispose Pattern</b><br>
Now that you know how a type implements the dispose pattern, let's take a look at how <br>a developer uses a type that offers the dispose pattern. Instead of talking about the <br>SafeHandle class, let's talk about the more common System.IO.FileStream class. The <br>FileStream class offers the ability to open a file, read bytes from the file, write bytes to the <br>file, and close the file. When a FileStream object is constructed, the Win32 CreateFile <br>function is called, the returned handle is saved in a SafeFileHandle object, and a reference <br>to this object is maintained via a private field in the FileStream object. The FileStream <br>class also offers several additional properties (such as Length,<b> </b>Position,<b> </b>CanRead) and <br>methods (such as Read,<b> </b>Write,<b> </b>Flush).<br>
Let's say that you want to write some code that creates a temporary file, writes some bytes to <br>the file, and then deletes the file. You might start writing the code like this:<br>
using System;  <br>using System.IO;  <br>  <br>public static class Program {  <br>   public static void Main() {  <br>      // Create the bytes to write to the temporary file.  <br>      Byte[] bytesToWrite = new Byte[] { 1, 2, 3, 4, 5 };  <br>  <br>      // Create the temporary file.  <br>      FileStream fs = new FileStream(&quot;Temp.dat&quot;, FileMode.Create);  <br>  <br>
<hr>
<A name=567></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>549</b><br>
      // Write the bytes to the temporary file.  <br>      fs.Write(bytesToWrite, 0, bytesToWrite.Length);  <br>  <br>      // Delete the temporary file.  <br>      File.Delete(&quot;Temp.dat&quot;);  // Throws an IOException  <br>   }  <br>}<br>
Unfortunately, if you build and run this code, it might work, but most likely it won't. The <br>problem is that the call to File's static Delete method requests that Windows delete a file <br>while it is still open. And so Delete throws a System.IO.IOException exception with the <br>following string message: &quot;The process cannot access the file &quot;Temp.dat&quot; because <br>it is being used by another process.&quot;<br>
Be aware that in some cases, the file might actually be deleted! If another thread somehow <br>caused a garbage collection to start after the call to Write and before the call to Delete, the <br>FileStream's SafeFileHandle field would have its Finalize method called, which would <br>close the file and allow Delete to work. The likelihood of this situation is extremely rare, <br>however, and therefore the previous code will fail more than 99 percent of the time.<br>
Fortunately, the FileStream class implements the dispose pattern, allowing you to modify <br>the source code to explicitly close the file. Here's the corrected source code:<br>
using System;  <br>using System.IO;  <br>  <br>public static class Program {  <br>   public static void Main() {  <br>      // Create the bytes to write to the temporary file.  <br>      Byte[] bytesToWrite = new Byte[] { 1, 2, 3, 4, 5 };  <br>  <br>      // Create the temporary file.  <br>      FileStream fs = new FileStream(&quot;Temp.dat&quot;, FileMode.Create);  <br>  <br>      // Write the bytes to the temporary file.  <br>      fs.Write(bytesToWrite, 0, bytesToWrite.Length);  <br>  <br>      // Explicitly close the file when finished writing to it.  <br>      fs.Dispose();  <br>  <br>      // Delete the temporary file.  <br>      File.Delete(&quot;Temp.dat&quot;);  // This always works now.  <br>   }  <br>}<br>
The only difference here is that I've added a call to FileStream's Dispose method. The <br>Dispose method calls the Dispose method that takes a Boolean as parameter, which calls <br>Dispose on the SafeFileHandle object, which ends up calling the Win32 CloseHandle <br>function, which causes Windows to close the file. Now, when File's Delete method is called, <br>Windows sees that the file isn't open and successfully deletes it.<br>
<hr>
<A name=568></a><IMG src="CLRviaCsharp-568_1.jpg"><br>
<b>550 </b><br>
<b>Part IV  Core Facilities</b><br>
Because the FileStream class also offers a public Close method, the earlier code could be <br>written as follows with identical results:<br>
using System;  <br>using System.IO;  <br>  <br>public static class Program {  <br>   public static void Main() {  <br>      // Create the bytes to write to the temporary file.  <br>      Byte[] bytesToWrite = new Byte[] { 1, 2, 3, 4, 5 };  <br>  <br>      // Create the temporary file.  <br>      FileStream fs = new FileStream(&quot;Temp.dat&quot;, FileMode.Create);  <br>  <br>      // Write the bytes to the temporary file.  <br>      fs.Write(bytesToWrite, 0, bytesToWrite.Length);  <br>  <br>      // Explicitly close the file when finished writing to it.  <br>      fs.Close();  <br>  <br>      // Delete the temporary file.  <br>      File.Delete(&quot;Temp.dat&quot;);  // This always works now.  <br>   }  <br>}<br>
<b>Note  </b>Again, remember that the Close method isn't officially part of the dispose pattern; some <br>types will offer it and some won't.<br>
Keep in mind that calling Dispose or Close simply gives the programmer a way to force <br>the object to do its cleanup at a deterministic time; these methods have no control over the <br>lifetime of the memory used by the object in the managed heap. This means you can still <br>call methods on the object even though it has been cleaned up. The following code calls the <br>Write method after the file is closed, attempting to write more bytes to the file. Obviously, <br>the bytes can't be written, and when the code executes, the second call to the Write method <br>throws a System.ObjectDisposedException exception with the following string message: <br>&quot;Cannot access a closed file.&quot;<br>
using System;  <br>  <br>using System.IO;  <br>  <br>public static class Program {  <br>   public static void Main() {  <br>      // Create the bytes to write to the temporary file.  <br>      Byte[] bytesToWrite = new Byte[] { 1, 2, 3, 4, 5 };  <br>  <br>      // Create the temporary file.  <br>      FileStream fs = new FileStream(&quot;Temp.dat&quot;, FileMode.Create);  <br>  <br>      // Write the bytes to the temporary file.  <br>
<hr>
<A name=569></a><IMG src="CLRviaCsharp-569_1.jpg"><br>
<IMG src="CLRviaCsharp-569_2.jpg"><br>
<b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>551</b><br>
      fs.Write(bytesToWrite, 0, bytesToWrite.Length);  <br>  <br>      // Explicitly close the file when finished writing to it.  <br>      fs.Close();  <br>  <br>      // Try to write to the file after closing it.  <br>      // The following line throws an ObjectDisposedException.  <br>      fs.Write(bytesToWrite, 0, bytesToWrite.Length);  <br>  <br>      // Delete the temporary file.  <br>      File.Delete(&quot;Temp.dat&quot;);  <br>   }  <br>}<br>
No memory corruption has occurred here because the memory for the FileStream object <br>still exists; it's just that the object can't successfully execute its methods after it is explicitly <br>disposed.<br>
<b>Important  </b>When defining your own type that implements the dispose pattern, be sure to write <br>code in all of your methods and properties to throw a System.ObjectDisposedException if <br>the object has been explicitly cleaned up. The Dispose and Close methods should never throw <br>an ObjectDisposedException if cal ed multiple times, though; these methods should just return.<br>
<b>Important  </b>In general, I strongly discourage calling a Dispose or Close method. The reason is <br>that the CLR's garbage collector is well written, and you should let it do its job. The garbage  <br>collector knows when an object is no longer accessible from application code, and only then will <br>it collect the object. When application code calls Dispose or Close, it is effectively saying that <br>it knows when the application no longer has a need for the object. For many applications, it is <br>impossible to know for sure when an object is no longer required.<br>
For example, if you have code that constructs a new object, and you then pass a reference to this <br>object to another method, the other method could save a reference to the object in some inter-<br>nal field variable (a root). There is no way for the calling method to know that this has happened. <br>Sure, the calling method can call Dispose or Close, but later, some other code might try to  <br>access the object, causing an ObjectDisposedException to be thrown.<br>
I recommend that you call Dispose or Close either at a place in your code where you know <br>you must clean up the resource (as in the case of attempting to delete an open file) or at a place <br>where you know it is safe to call one of the methods and you want to improve performance by <br>removing the object from the finalization list, thus preventing object promotion.<br>
<b>C#'s </b>using<b> Statement</b><br>
The previous code examples show how to explicitly call a type's Dispose or Close method. <br>If you decide to call either of these methods explicitly, I highly recommend that you place the <br>call in an exception-handling finally block. This way, the cleanup code is guaranteed to  <br>execute. So it would be better to write the previous code example as follows:<br>
<hr>
<A name=570></a><b>552 </b><br>
<b>Part IV  Core Facilities</b><br>
using System;  <br>using System.IO;  <br>  <br>public static class Program {  <br>   public static void Main() {  <br>      // Create the bytes to write to the temporary file.  <br>      Byte[] bytesToWrite = new Byte[] { 1, 2, 3, 4, 5 };  <br>  <br>      // Create the temporary file.  <br>      FileStream fs = new FileStream(&quot;Temp.dat&quot;, FileMode.Create);  <br>      try {  <br>         // Write the bytes to the temporary file.  <br>         fs.Write(bytesToWrite, 0, bytesToWrite.Length);  <br>      }  <br>      finally {  <br>         // Explicitly close the file when finished writing to it.  <br>         if (fs != null)  fs.Dispose();  <br>      }  <br>  <br>      // Delete the temporary file.  <br>      File.Delete(&quot;Temp.dat&quot;);  <br>   }  <br>}<br>
Adding the exception-handling code is the right thing to do, and you must have the diligence <br>to do it. Fortunately, the C# language provides a using statement, which offers a simplified <br>syntax that produces code identical to the code just shown. Here's how the preceding code <br>would be rewritten using C#'s using statement:<br>
using System;  <br>using System.IO;  <br>  <br>public static class Program {  <br>   public static void Main() {  <br>      // Create the bytes to write to the temporary file.  <br>      Byte[] bytesToWrite = new Byte[] { 1, 2, 3, 4, 5 };  <br>  <br>      // Create the temporary file.  <br>      using (FileStream fs = new FileStream(&quot;Temp.dat&quot;, FileMode.Create)) {  <br>         // Write the bytes to the temporary file.  <br>         fs.Write(bytesToWrite, 0, bytesToWrite.Length);  <br>      }  <br>  <br>      // Delete the temporary file.  <br>      File.Delete(&quot;Temp.dat&quot;);  <br>   }  <br>}<br>
In the using statement, you initialize an object and save its reference in a variable. Then you <br>access the variable via code contained inside using's braces. When you compile this code, <br>the compiler automatically emits the try and finally blocks. Inside the finally block, the <br>compiler emits code to cast the object to an IDisposable and calls the Dispose method. <br>Obviously, the compiler al ows the using statement to be used only with types that implement <br>the IDisposable interface.<br>
<hr>
<A name=571></a><IMG src="CLRviaCsharp-571_1.jpg"><br>
<b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>553</b><br>
<b>Note  </b>C#'s using statement supports the capability to initialize multiple variables as long as the <br>variables are all of the same type. It also supports the capability to use just an already initialized <br>variable. For more information about this topic, refer to the "Using Statements" topic in the C# <br>Programmer's Reference.<br>
The using statement also works with value types that implement the IDisposable interface. <br>This allows you to create an extremely efficient and useful mechanism to encapsulate the <br>code necessary to begin and end an operation. For example, let's say that you want to lock <br>a block of code by using a Mutex object. The Mutex class does implement the IDisposable <br>interface, but calling Dispose on it releases the native resource; it has nothing to do with the <br>lock itself. To get simplified syntax to lock and unlock a Mutex, you can define a value type <br>that encapsulates the locking and unlocking of a Mutex object. The MutexLock structure <br>below is an example of this, and the Main method following it demonstrates how to use the <br>MutexLock effectively:<br>
using System;  <br>using System.Threading;  <br>  <br>// This value type encapsulates mutex locking and unlocking <br>internal struct MutexLock : IDisposable {  <br>   private readonly Mutex m_mutex;  <br>  <br>   // This constructor acquires a lock on the mutex  <br>   public MutexLock(Mutex m) {   <br>      m_mutex = m;   <br>      m_mutex.WaitOne();   <br>   }  <br>  <br>   // This Dispose method releases the lock on the mutex  <br>   public void Dispose() {  <br>      m_mutex.ReleaseMutex();  <br>   }  <br>}  <br>  <br>public static class Program {  <br>   // This method demonstrates how to use the MutexLock effectively  <br>   public static void Main() {  <br>      // Construct a mutex object  <br>      Mutex m = new Mutex();  <br>  <br>      // Lock the mutex, do something, and unlock the mutex  <br>      using (new MutexLock(m)) {  <br>         // Perform some thread-safe operation in here...  <br>      }  <br>   }  <br>}<br>
<hr>
<A name=572></a><IMG src="CLRviaCsharp-572_1.jpg"><br>
<b>554 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>An Interesting Dependency Issue</b><br>
The System.IO.FileStream type allows the user to open a file for reading and writing. <br>To improve performance, the type's implementation makes use of a memory buffer. Only <br>when the buffer fills does the type flush the contents of the buffer to the file. A FileStream <br>supports the writing of bytes only. If you want to write characters and strings, you can use a <br>System.IO.StreamWriter, as is demonstrated in the following code:<br>
FileStream fs = new FileStream(&quot;DataFile.dat&quot;, FileMode.Create);  <br>StreamWriter sw = new StreamWriter(fs);  <br>sw.Write(&quot;Hi there&quot;);  <br>  <br>// The following call to Close is what you should do.  <br>sw.Close();     <br>// NOTE: StreamWriter.Close closes the FileStream;  <br>// the FileStream doesn't have to be explicitly closed.<br>
Notice that the StreamWriter's constructor takes a reference to a Stream object as a param-<br>eter, allowing a reference to a FileStream object to be passed as an argument. Internally, <br>the StreamWriter object saves the Stream's reference. When you write to a StreamWriter <br>object, it internally buffers the data in its own memory buffer. When the buffer is full, the <br>StreamWriter object writes the data to the Stream.<br>
When you're finished writing data via the StreamWriter object, you should call Dispose or <br>Close. (Because the StreamWriter type implements the dispose pattern, you can also use <br>it with C#'s using statement.) Both of these methods do exactly the same thing: cause the <br>StreamWriter object to flush its data to the Stream object and close the Stream object. In <br>my example, when the FileStream object is closed, it flushes its buffer to disk just prior to <br>calling the Win32 CloseHandle function.<br>
<b>Note  </b>You don't have to explicitly call Dispose or Close on the FileStream object because <br>the StreamWriter calls it for you. However, if you do call Dispose/Close explicitly, the <br>FileStream will see that the object has already been cleaned up--the methods do nothing and <br>just return.<br>
What do you think would happen if there were no code to explicitly call Dispose or Close? <br>Well, at some point, the garbage collector would correctly detect that the objects were gar-<br>bage and finalize them. But the garbage collector doesn't guarantee the order in which the <br>Finalize methods are called. So if the FileStream object were finalized first, it would close <br>the file. Then when the StreamWriter object was finalized, it would attempt to write data to <br>the closed file, throwing an exception. If, on the other hand, the StreamWriter object were <br>finalized first, the data would be safely written to the file.<br>
How was Microsoft to solve this problem? Making the garbage collector finalize objects in a <br>specific order would have been impossible because objects could contain references to each <br>other, and there would be no way for the garbage collector to correctly guess the order in <br>
<hr>
<A name=573></a><IMG src="CLRviaCsharp-573_1.jpg"><br>
<b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>555</b><br>
which to finalize these objects. Here is Microsoft's solution: the StreamWriter type does <br>not implement a Finalize method, missing the opportunity to flush the data in its buffer <br>to the underlying FileStream object. This means that if you forget to explicitly close the <br>StreamWriter object, data is guaranteed to be lost. Microsoft expects developers to see this <br>consistent loss of data and fix the code by inserting an explicit call to Close/Dispose.<br>
<b>Note  </b>The .NET Framework offers a feature called Managed Debugging Assistants (MDAs). <br>When an MDA is enabled, the .NET Framework looks for certain common programmer errors <br>and fires a corresponding MDA. In the debugger, it looks like an exception has been thrown. <br>There is an MDA available to detect when a StreamWriter object is garbage collected with-<br>out having prior been explicitly closed. To enable this MDA in Microsoft Visual Studio, open <br>your project and select the Debug.Exceptions menu item. In the Exceptions dialog box, expand <br>the Managed Debugging Assistants node and scroll to the bottom. There you will see the <br>StreamWriterBufferredDataLost MDA. Select the Thrown check box to have the Visual Studio  <br>debugger stop whenever a StreamWriter object's data is lost.<br>
<b>Monitoring and Controlling the Lifetime of Objects </b><br>
<b>Manually</b><br>
The CLR provides each AppDomain with a <i>GC handle table</i>. This table allows an application <br>to monitor the lifetime of an object or manually control the lifetime of an object. When an <br>AppDomain is created, the table is empty. Each entry on the table consists of a pointer to <br>an object on the managed heap and a flag indicating how you want to monitor or control <br>the object. An application adds and removes entries from the table via the System.Runtime.<br>InteropServices.GCHandle type shown below. Since the GC handle table is used mostly in <br>scenarios when you are interoperating with unmanaged code, most of GCHandle's members <br>have the [SecurityCritical] attribute applied to them.<br>
// This type is defined in the System.Runtime.InteropServices namespace  <br>public struct GCHandle {  <br>   // Static methods that create an entry in the table  <br>   public static GCHandle Alloc(object value);  <br>   public static GCHandle Alloc(object value, GCHandleType type);  <br>  <br>   // Static methods that convert a GCHandle to an IntPtr  <br>   public static explicit operator IntPtr(GCHandle value);  <br>   public static IntPtr ToIntPtr(GCHandle value);  <br>  <br>   // Static methods that convert an IntPtr to a GCHandle  <br>   public static explicit operator GCHandle(IntPtr value);  <br>   public static GCHandle FromIntPtr(IntPtr value);  <br>  <br>   // Static methods that compare two GCHandles   <br>   public static Boolean operator ==(GCHandle a, GCHandle b);  <br>   public static Boolean operator !=(GCHandle a, GCHandle b);  <br>  <br>
<hr>
<A name=574></a><b>556 </b><br>
<b>Part IV  Core Facilities</b><br>
   // Instance method to free the entry in the table (index is set to 0)  <br>   public void Free();  <br>  <br>   // Instance property to get/set the entry's object reference  <br>   public object Target { get; set; }  <br>  <br>   // Instance property that returns true if index is not 0  <br>   public Boolean IsAllocated { get; }  <br>  <br>   // For a pinned entry, this returns the address of the object  <br>   public IntPtr AddrOfPinnedObject();  <br>  <br>   public override Int32 GetHashCode();  <br>   public override Boolean Equals(object o);  <br>}<br>
Basically, to control or monitor an object's lifetime, you call GCHandle's static Alloc method, <br>passing a reference to the object that you want to monitor/control, and a GCHandleType, <br>which is a flag indicating how you want to monitor/control the object. The GCHandleType <br>type is an enumerated type defined as follows:<br>
public enum GCHandleType {  <br>   Weak = 0,                  // Used for monitoring an object's existence  <br>   WeakTrackResurrection = 1, // Used for monitoring an object's existence  <br>   Normal = 2,                // Used for controlling an object's lifetime  <br>   Pinned = 3                 // Used for controlling an object's lifetime  <br>}<br>
Now, here's what each flag means:<br>
<b>  </b>Weak<b>  </b>This flag allows you to <i>monitor</i> the lifetime of an object. Specifically, you can  <br>
detect when the garbage collector has determined this object to be unreachable from <br>application code. Note that the object's Finalize method may or may not have  <br>executed yet and therefore, the object may still be in memory.<br>
<b>  </b>WeakTrackResurrection<b>  </b>This flag allows you to <i>monitor</i> the lifetime of an object. <br>
Specifically, you can detect when the garbage collector has determined that this object <br>is unreachable from application code. Note that the object's Finalize method (if it  <br>exists) has definitely executed, and the object's memory has been reclaimed.<br>
<b>  </b>Normal<b>  </b>This flag allows you to <i>control</i> the lifetime of an object. Specifically, you are <br>
telling the garbage collector that this object must remain in memory even though <br>there may be no variables (roots) in the application that refer to this object. When  <br>a garbage collection runs, the memory for this object can be compacted (moved).  <br>The Alloc method that doesn't take a GCHandleType flag assumes that <br>GCHandleType.Normal is specified.<br>
<b>  </b>Pinned<b>  </b>This flag allows you to <i>control</i> the lifetime of an object. Specifically, you are <br>
telling the garbage collector that this object must remain in memory even though <br>there might be no variables (roots) in the application that refer to this object. When a <br>
<hr>
<A name=575></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>557</b><br>
garbage collection runs, the memory for this object cannot be compacted (moved). <br>This is typically useful when you want to hand the address of the memory out to  <br>unmanaged code. The unmanaged code can write to this memory in the managed <br>heap knowing that the location of the managed object will not be moved due to a  <br>garbage collection.<br>
When you call GCHandle's static Alloc method, it scans the AppDomain's GC handle table, <br>looking for an available entry where the address of the object you passed to Alloc is stored, <br>and a flag is set to whatever you passed for the GCHandleType argument. Then, Alloc re-<br>turns a GCHandle instance back to you. A GCHandle is a lightweight value type that contains <br>a single instance field, an IntPtr, which refers to the index of the entry in the table. When <br>you want to free this entry in the GC handle table, you take the GCHandle instance and call <br>the Free method (which also invalidates the instance by setting the IntPtr field to zero).<br>
Here's how the garbage collector uses the GC handle table. When a garbage collection <br>occurs:<br>
<b> </b><br>
<b>1.  </b>The garbage collector marks all of the reachable objects (as described at the beginning <br>
of this chapter). Then, the garbage collector scans the GC handle table; all Normal or <br>Pinned objects are considered roots, and these objects are marked as well (including <br>any objects that these objects refer to via their fields).<br>
<b> </b><br>
<b>2.  </b>The garbage collector scans the GC handle table looking for all of the Weak entries. If a <br>
Weak entry refers to an object that isn't marked, the pointer identifies an unreachable <br>object (garbage), and the entry has its pointer value changed to null.<br>
<b> </b><br>
<b>3.  </b>The garbage collector scans the finalization list. If a pointer in the list refers to an un-<br>
marked object, the pointer identifies an unreachable object, and the pointer is moved <br>from the finalization list to the freachable queue. At this point, the object is marked <br>because the object is now considered reachable.<br>
<b> </b><br>
<b>4.  </b>The garbage collector scans the GC handle table looking for all of the <br>
WeakTrackResurrection entries. If a WeakTrackResurrection entry refers to an  <br>object that isn't marked (which now is an object pointed to by an entry in the freach-<br>able queue), the pointer identifies an unreachable object (garbage), and the entry has <br>its pointer value changed to null.<br>
<b> </b><br>
<b>5.  </b>The garbage collector compacts the memory, squeezing out the holes left by the un-<br>
reachable objects. Note that the garbage collector sometimes decides not to compact <br>memory if it determines that the amount of fragmentation isn't worth the time to <br>compact. Pinned objects are not compacted (moved); the garbage collector will move <br>other objects around them.<br>
Now that you have an understanding of the mechanism, let's take a look at when you'd use <br>them. The easiest flags to understand are the Normal and Pinned flags, so let's start with <br>these two. Both of these flags are typically used when interoperating with unmanaged code.<br>
<hr>
<A name=576></a><b>558 </b><br>
<b>Part IV  Core Facilities</b><br>
The Normal flag is used when you need to hand a reference to a managed object to unman-<br>aged code because, at some point in the future, the unmanaged code is going to call back <br>into managed code, passing it the reference. You can't actually pass a pointer to a managed <br>object out to unmanaged code because if a garbage collection occurs, the object could <br>move in memory, invalidating the pointer. So to work around this, you would call GCHandle's <br>Alloc method, passing in a reference to the object and the Normal flag. Then you'd cast the <br>returned GCHandle instance to an IntPtr and pass the IntPtr into the unmanaged code. <br>When the unmanaged code calls back into managed code, the managed code would cast the <br>passed IntPtr back to a GCHandle and then query the Target property to get the reference <br>(or current address) of the managed object. When the unmanaged code no longer needs the <br>reference, you'd call GCHandle's Free method, which will allow a future garbage collection to <br>free the object (assuming no other root exists to this object).<br>
Notice that in this scenario, the unmanaged code is not actually using the managed object <br>itself; the unmanaged code wants a way just to reference the object. In some scenarios, the <br>unmanaged code needs to actually use the managed object. In these scenarios, the managed <br>object must be pinned. Pinning prevents the garbage collector from moving/compacting the <br>object. A common example is when you want to pass a managed String object to a Win32 <br>function. In this case, the String object must be pinned because you can't pass the refer-<br>ence of a managed object to unmanaged code and then have the garbage collector move <br>the object in memory. If the String object were moved, the unmanaged code would either <br>be reading or writing to memory that no longer contained the String object's characters--<br>this will surely cause the application to run unpredictably.<br>
When you use the CLR's P/Invoke mechanism to call a method, the CLR pins the arguments <br>for you automatically and unpins them when the unmanaged method returns. So, in most <br>cases, you never have to use the GCHandle type to explicitly pin any managed objects your-<br>self. You do have to use the GCHandle type explicitly when you need to pass the address of <br>a managed object to unmanaged code and then, the unmanaged function returns, but un-<br>managed code might still need to use the object later. The most common example of this is <br>when performing asynchronous I/O operations.<br>
Let's say that you allocate a byte array that should be filled as data comes in from a socket.  <br>Then, you would call GCHandle's Alloc method, passing in a reference to the array object  <br>and the Pinned flag. Then, using the returned GCHandle instance, you call the <br>AddrOfPinnedObject method. This returns an IntPtr that is the actual address of the <br>pinned object in the managed heap; you'd then pass this address into the unmanaged func-<br>tion, which will return back to managed code immediately. While the data is coming from <br>the socket, this byte array buffer should not move in memory; preventing this buffer from <br>moving is accomplished by using the Pinned flag. When the asynchronous I/O operation has <br>completed, you'd call GCHandle's Free method, which will allow a future garbage collection <br>to move the buffer. Your managed code should still have a reference to the buffer so that <br>you can access the data, and this reference will prevent a garbage collection from freeing the <br>buffer from memory completely.<br>
<hr>
<A name=577></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>559</b><br>
It is also worth mentioning that C# offers a fixed statement that effectively pins an object <br>over a block of code. Here is some code that demonstrates its use:<br>
unsafe public static void Go() { <br>   // Allocate a bunch of objects that immediately become garbage <br>   for (Int32 x = 0; x &lt; 10000; x++) new Object(); <br> <br>   IntPtr  originalMemoryAddress; <br>   Byte[] bytes = new Byte[1000];   // Allocate this array after the garbage objects <br> <br>   // Get the address in memory of the Byte[] <br>   fixed (Byte* pbytes = bytes) { originalMemoryAddress = (IntPtr) pbytes; } <br> <br>   // Force a collection; the garbage objects will go away &amp; the Byte[] might be compacted <br>   GC.Collect();   <br> <br>   // Get the address in memory of the Byte[] now &amp; compare it to the first address <br>   fixed (Byte* pbytes = bytes) { <br>      Console.WriteLine(&quot;The Byte[] did{0} move during the GC&quot;,  <br>         (originalMemoryAddress == (IntPtr) pbytes) ? &quot; not&quot; : null); <br>   } <br>}<br>
Using C#'s fixed statement is more efficient that allocating a pinned GC handle. What <br>happens is that the C# compiler emits a special "pinned" flag on the pbytes local variable. <br>During a garbage collection, the garbage collector examines the contents of this root, and if <br>the root is not null, it knows not to move the object referred to by the variable during the <br>compaction phase. The C# compiler emits IL to initialize the pbytes local variable to the ad-<br>dress of the object at the start of a fixed block, and the compiler emits an IL instruction to <br>set the pbytes local variable back to null at the end of the fixed block so that the variable <br>doesn't refer to any object, allowing the object to move when the next garbage collection <br>occurs.<br>
Now, let's talk about the next two flags, Weak and WeakTrackResurrection. These two flags <br>can be used in scenarios when interoperating with unmanaged code, but they can also be <br>used in scenarios that use only managed code. The Weak flag lets you know when an object <br>has been determined to be garbage but the object's memory is not guaranteed to be  <br>reclaimed yet. The WeakTrackResurrection flag lets you know when an object's memory  <br>has been reclaimed. Of the two flags, the Weak flag is much more commonly used than the  <br>WeakTrackResurrection flag. In fact, I've never seen anyone use the WeakTrackResurrection <br>flag in a real application.<br>
Let's say that Object-A periodically calls a method on Object-B. However, the fact that <br>Object-A has a reference to Object-B forbids Object-B from being garbage collected, and <br>in some rare scenarios, this may not be desired; instead, we might want Object-A to call <br>Object-B's method if Object-B is still alive in the managed heap. To accomplish this scenario, <br>Object-A would call GCHandle's Alloc method, passing in the reference to Object-B and <br>the Weak flag. Object-A would now just save the returned GCHandle instance instead of the <br>reference to Object-B.<br>
<hr>
<A name=578></a><b>560 </b><br>
<b>Part IV  Core Facilities</b><br>
At this point, Object-B can be garbage collected if no other roots are keeping it alive. When <br>Object-A wants to call Object-B's method, it would query GCHandle's read-only Target <br>property. If this property returns a non-null value, then Object-B is still alive. Object-A's <br>code would then cast the returned reference to Object-B's type and call the method. If <br>the Target property returns null, then Object-B has been collected and Object-A would <br>not attempt to call the method. At this point, Object-A's code would probably also call <br>GCHandle's Free method to relinquish the GCHandle instance.<br>
Since working with the GCHandle type can be a bit cumbersome and because it requires <br>elevated security to keep or pin an object in memory, the System namespace includes a <br>WeakReference class to help you. This class is really just an object-oriented wrapper around <br>a GCHandle instance: logically, its constructor calls GCHandle's Alloc, its Target property <br>calls GCHandle's Target property, and its Finalize method calls GCHandle's Free method. <br>In addition, no special permissions are required for code to use the WeakReference class <br>because the class supports only weak references; it doesn't support the behavior provided by <br>GCHandle instances allocated with a GCHandleType of Normal or Pinned.<br>
The downside of the WeakReference class is that its object must be allocated on the heap. <br>So the WeakReference class is a heavier-weight object than a GCHandle instance. Also, the <br>WeakReference class doesn't implement the dispose pattern (which is a bug), so there is no <br>way for you to free the GCHandle table entry explicitly; you have to wait for a garbage  <br>collection to kick in so that its Finalize method is called. The WeakReference class was  <br>introduced in version 1.0 of the .NET Framework; therefore, it is not generic (generics were <br>introduced in version 2.0). So, I have created a little, lightweight structure that I sometimes <br>use to put a compile-time type-safe wrapper around the WeakReference class:<br>
internal struct WeakReference&lt;T&gt; : IDisposable where T : class { <br>   private WeakReference m_weakReference; <br> <br>   public WeakReference(T target) { m_weakReference = new WeakReference(target); } <br>   public T Target { get { return (T)m_weakReference.Target; } } <br>   public void Dispose() { m_weakReference = null; } <br>}<br>
Occasionally, developers ask me if there is a way to create a weak delegate where one object <br>will register a callback delegate with some other object's event but the developer doesn't <br>want the registering of the event to forcibly keep the object alive. For example, let's say that <br>we have a class called DoNotLiveJustForTheEvent. We want to create an instance of this <br>class and have it register a callback method with a Button object's Click event. However, we <br>don't want the Button object's event to keep the DoNotLiveJustForTheEvent object alive. <br>If the DoNotLiveJustForTheEvent object has no other reason to live, then we want it to get <br>garbage collected, and it will just not receive a notification the next time the Button object <br>raises its Click event. Let me show you how you might accomplish this:<br>
First, here is the definition of the DoNotLiveJustForTheEvent class:<br>
<hr>
<A name=579></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>561</b><br>
internal sealed class DoNotLiveJustForTheEvent { <br>   public void Clicked(Object sender, EventArgs e) {  <br>      MessageBox.Show(&quot;Test got notified of button click.&quot;);  <br>   } <br>}<br>
Now, here is the code that creates a Form and two Button controls. The first Button con-<br>trol fills the left half of the Form's client area and the second Button control fills the right <br>half of the Form's client area. Then, on the first Button control, I construct an instance <br>of the DoNotLiveJustForTheEvent class and register this object's Clicked method as <br>the event handler for this Button control's Click event. However, I do this by using my <br>WeakEventHandler class, which turns an EventHandler delegate into a weak version of  <br>itself. I'll show how this class is implemented shortly. On the second Button control's Click <br>event, I register a callback that will force a garbage collection to occur; I click this button to <br>test that everything is working OK. Finally, I add the controls to the form's control collection, <br>resize the form's client area, and then show the form:<br>
public static void Go() { <br>   var form = new Form() {  <br>      Text = &quot;Weak Delegate Test&quot;,  <br>      FormBorderStyle = FormBorderStyle.FixedSingle  <br>   }; <br> <br>   var btnTest = new Button() {  <br>      Text = &quot;Click me&quot;,  <br>      Width = form.Width / 2  <br>   }; <br> <br>   var btnGC = new Button() {  <br>      Text = &quot;Force GC&quot;,  <br>      Left = btnTest.Width,  <br>      Width = btnTest.Width  <br>   }; <br> <br>   // WeakEventHandler turns an EventHandler delegate into a weak version of itself  <br>   btnTest.Click += new WeakEventHandler(new DoNotLiveJustForTheEvent().Clicked) <br>      { RemoveDelegateCode = eh =&gt; btnTest.Click -= eh }; <br> <br>   btnGC.Click += (sender, e) =&gt; { GC.Collect(); MessageBox.Show(&quot;GC complete.&quot;); }; <br> <br>   form.Controls.Add(btnTest); <br>   form.Controls.Add(btnGC); <br>   form.ClientSize = new Size(btnTest.Width * 2, btnTest.Height); <br>   form.ShowDialog(); <br>}<br>
Since I do not store the reference to the DoNotLiveJustForEvent object in a root variable, <br>the object will be considered garbage when the next garbage collection runs. But, until then, <br>I can click the left button multiple times and see that the DoNotLiveJustForEvent object's <br>Clicked method is getting called. However, once I click the right button in the form, the<b> <br></b>DoNotLiveJustForEvent object is garbage collected. Now, when I click the left button, the <br>
<hr>
<A name=580></a><b>562 </b><br>
<b>Part IV  Core Facilities</b><br>
WeakEventHandler object determines that the DoNotLiveJustForEvent object is gone, <br>and it unregisters itself with the Button's Click event so that it never gets called again. Of <br>course, the WeakEventHandler object will have its memory reclaimed during the next gar-<br>bage collection.<br>
To understand my WeakEventHandler class, you need to first understand its base class. <br>WeakEventHandler is derived from my abstract generic WeakDelegate class:<br>
public abstract class WeakDelegate&lt;TDelegate&gt; where TDelegate  <br>   : class /* MulticastDelegate */ { <br>   private WeakReference&lt;TDelegate&gt; m_weakDelegate; <br>   private Action&lt;TDelegate&gt; m_removeDelegateCode; <br> <br>   public WeakDelegate(TDelegate @delegate) { <br>      var md = (MulticastDelegate)(Object)@delegate; <br>      if (md.Target == null)  <br>         throw new ArgumentException( <br>            &quot;There is no reason to make a WeakDelegate to a static method.&quot;); <br> <br>      // Save a WeakReference to the delegate <br>      m_weakDelegate = new WeakReference&lt;TDelegate&gt;(@delegate); <br>   } <br> <br>   public Action&lt;TDelegate&gt; RemoveDelegateCode { <br>      set { <br>         // Save the delegate that refers to code that knows how to remove the  <br>         // WeakDelegate object when the non-weak delegate object is GC'd <br>         m_removeDelegateCode = value; <br>      } <br>   } <br> <br>   protected TDelegate GetRealDelegate() { <br>      // If the real delegate hasn't been GC'd yet, just return it <br>      TDelegate realDelegate = m_weakDelegate.Target; <br>      if (realDelegate != null) return realDelegate; <br> <br>      // The real delegate was GC'd, we don't need our  <br>      // WeakReference to it anymore (it can be GC'd) <br>      m_weakDelegate.Dispose(); <br> <br>      // Remove the delegate from the chain (if the user told us how) <br>      if (m_removeDelegateCode != null) { <br>         m_removeDelegateCode(GetDelegate()); <br>         m_removeDelegateCode = null;  // Let the remove handler delegate be GC'd <br>      } <br>      return null;   // The real delegate was GC'd and can't be called <br>   } <br> <br>   // All derived classes must return a delegate to  <br>   // a private method matching the TDelegate type <br>   public abstract TDelegate GetDelegate(); <br> <br>   // Implicit conversion operator to convert a WeakDelegate object to an actual delegate <br>   public static implicit operator TDelegate(WeakDelegate&lt;TDelegate&gt; @delegate) { <br>
<hr>
<A name=581></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>563</b><br>
     return @delegate.GetDelegate(); <br>   } <br>}<br>
Now, we can look at my WeakEventHandler class:<br>
// This class provides support for the non-generic EventHandler delegate <br>public sealed class WeakEventHandler : WeakDelegate&lt;EventHandler&gt; { <br>   public WeakEventHandler(EventHandler @delegate) : base(@delegate) { } <br> <br>   /// &lt;summary&gt;Returns a reference to the non-generic EventHandler delegate&lt;/summary&gt; <br>   public override EventHandler GetDelegate() { return Callback; } <br> <br>   // This private method must match the desired delegate's signature <br>   private void Callback(Object sender, EventArgs e) { <br>      // If the target hasn't been GC'd invoke it <br>      var eh = base.GetRealDelegate(); <br>      if (eh != null) eh(sender, e); <br>   } <br>}<br>
Solving this weak delegate problem turned out to be much more challenging than I first <br>expected it to be. The CLR and C# have a lot of limitations that I had to work around; this <br>makes the code bigger and more complex than I would have liked. Here are some of the <br>problems:<br>
  I want my WeakDelegate class to have its TDelegate generic argument constrained <br>
to accept only delegate objects that are derived from System.MulticastDelegate. <br>However, C# doesn't allow you to constrain a generic argument to MulticastDelegate <br>or even System.Delegate (the base class of MulticastDelegate). Therefore, the best I <br>can do is constrain TDelegate to class (that is, any reference type).<br>
  I wanted to have a WeakDelegate object automatically remove itself from the delegate <br>
chain that it is a member of when it sees that its target delegate has been garbage  <br>collected. However, a delegate has no way to know what chain it is a member of.<br>
  I also thought about passing an event (like the Button's Click event) to <br>
WeakDelegate's constructor. Then I could have code inside my WeakDelegate class <br>that automatically removes the WeakDelegate object from the event, but there is no <br>way to create a variable that refers to an event. Therefore, the user of a WeakDelegate <br>class can optionally set the RemoveDelegateCode property to some delegate referring <br>to code that knows how to remove the delegate from a delegate chain or an event; at <br>least I can pass the WeakDelegate object's delegate to remove into this code.<br>
  The CLR treats each delegate type as different types and so you can't cast a reference <br>
to one delegate type to another delegate type even if the delegate types have the <br>same signature. For example, I'd like to cast a reference to an EventHandler delegate <br>to an EventHandler&lt;EventArgs&gt; delegate since these delegate signatures are actu-<br>ally identical. But the CLR treats these as different types, and the cast is not allowed. <br>
<hr>
<A name=582></a><IMG src="CLRviaCsharp-582_1.jpg"><br>
<b>564 </b><br>
<b>Part IV  Core Facilities</b><br>
Microsoft's CLR team knows about this delegate limitation and is considering ways to <br>allow delegates with the same signature to be equivalent in a future version of the CLR. <br>Due to this limitation, a different class has to be defined for each delegate's type.<br>
I already showed you the WeakEventHandler type that corresponds to the EventHandler <br>delegate. I also have a WeakEventHandler&lt;TEventArgs&gt; type that corresponds to the <br>EventHandler&lt;TEventArgs&gt;<b> </b>delegate type:<br>
// This WeakDelegate partial class provides support for the  <br>// generic EventHandler&lt;TEventArgs&gt; delegate <br>public sealed class WeakEventHandler&lt;TEventArgs&gt; :  <br>   WeakDelegate&lt;EventHandler&lt;TEventArgs&gt;&gt; where TEventArgs : EventArgs { <br> <br>   public WeakEventHandler(EventHandler&lt;TEventArgs&gt; @delegate) : base(@delegate) { } <br> <br>   /// &lt;summary&gt; <br>   /// Returns a reference to the generic  <br>   /// EventHandler&lt;typeparam name=&quot;TEventArgs&quot;/&gt; delegate <br>   /// &lt;/summary&gt; <br>   public override EventHandler&lt;TEventArgs&gt; GetDelegate() { return Callback; } <br> <br>   private void Callback(Object sender, TEventArgs e) { <br>      // If the target hasn't been GC'd invoke it <br>      var eh = base.GetRealDelegate(); <br>      if (eh != null) eh(sender, e); <br>   } <br>}<br>
If the CLR would treat delegate types that have the same signature as equivalent, I could <br>use my WeakEventHandler&lt;TEventArgs&gt; type for non-generic EventHandler events, and I <br>could delete my WeakEventHandler class entirely.<br>
It would actually be pretty cool if the .NET Framework included a weak reference delegate <br>mechanism, but no such thing exists today. However, it has been discussed by the CLR team <br>at Microsoft, and it is likely that something like that will be part of a future version. If the CLR <br>had first-class support for it, then they could easily work around all the limitations that I had <br>to deal with, which would make the implementation easier to use and more efficient.<br>
<b>Important  </b>When developers start learning about weak references, they immediately start <br>thinking that they are useful in caching scenarios. For example, they think it would be cool <br>to construct a bunch of objects that contain a lot of data and then to create weak references <br>to these objects. When the program needs the data, the program checks the weak reference <br>to see if the object that contains the data is still around, and if it is, the program just uses it; the <br>program experiences high performance. However, if a garbage collection occurred, the objects <br>that contain the data will be destroyed, and when the program has to re-create the data, the <br>program experiences lower performance.<br>
The problem with this technique is the following: Garbage collections do not occur when memory <br>is full or close to full. Instead, garbage collections occur whenever generation 0 is full, which oc-<br>curs approximately after every 256 KB of memory is allocated. So objects are being tossed out of <br>memory much more frequently than desired, and your application's performance suffers greatly.<br>
<hr>
<A name=583></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>565</b><br>
Weak references can be used quite effectively in caching scenarios, but building a good cache <br>algorithm that finds the right balance between memory consumption and speed is very complex. <br>Basically, you want your cache to keep strong references to all of your objects and then, when <br>you see that memory is getting tight, you start turning strong references into weak references. <br>Currently, the CLR offers no mechanism to notify an application that memory is getting tight. But <br>some people have had much success by periodically calling the Win32 GlobalMemoryStatusEx <br>function and checking the returned MEMORYSTATUSEX structure's dwMemoryLoad member. If this <br>member reports a value above 80, memory is getting tight, and you can start converting strong <br>references to weak references based on whether you want a least-recently used algorithm, a <br>most-frequently used algorithm, a time-base algorithm, or whatever.<br>
Developers frequently want to associate a piece of data with another entity. For example, you <br>can associate data with a thread or with an AppDomain. It is also possible to associate data <br>with an individual object by using the System.Runtime.CompilerServices. <br>ConditionalWeakTable&lt;TKey,TValue&gt; class, which looks like this:<br>
public sealed class ConditionalWeakTable&lt;TKey, TValue&gt;  <br>   where TKey : class where TValue : class { <br>   public ConditionalWeakTable(); <br>   public void    Add(TKey key, TValue value); <br>   public TValue  GetValue(TKey key, CreateValueCallback&lt;TKey, TValue&gt; createValueCallback); <br>   public Boolean TryGetValue(TKey key, out TValue value); <br>   public TValue  GetOrCreateValue(TKey key); <br>   public Boolean Remove(TKey key); <br> <br>   public delegate TValue CreateValueCallback(TKey key);  // Nested delegate definition <br>}<br>
If you want to associate some arbitrary data with one or more objects, you would first create <br>an instance of this class. Then, call the Add method passing in a reference to some object for <br>the key parameter and the data you want to associate with the object in the value param-<br>eter. If you attempt to add a reference to the same object more than once, the Add method <br>throws an ArgumentException; to change the value associated with an object, you must <br>remove the key and then add it back in with the new value. Note that this class is thread-safe <br>so multiple threads can use it concurrently, although this means that the performance of the <br>class is not stellar; you should test the performance of this class to see how well it works for <br>your scenario. Also, there is no good reason why TValue is constrained to class (only reference <br>types). In the future, the CLR team might remove the constraint on TValue so that you can <br>associate value type instances with an object without having to box the value types.<br>
Of course, a table object internally stores a WeakReference to the object passed in as the <br>key; this ensures that the table doesn't forcibly keep the object alive. But what makes the <br>ConditionalWeakTable class so special is that it guarantees that the value remains in mem-<br>ory as long as the object identified by the key is in memory. So this is more than a normal <br>WeakReference because if it were, the value could be garbage collected even though the <br>key object continued to live. The ConditionalWeakTable class could be used to implement <br>the dependency property mechanism of Silverlight and Windows Presentation Foundation <br>
<hr>
<A name=584></a><b>566 </b><br>
<b>Part IV  Core Facilities</b><br>
(WPF). It can also be used internally by dynamic languages to dynamically associate data with <br>objects.<br>
Here is some code that demonstrates the use of the ConditionalWeakTable class. It allows <br>you to call the GCWatch extension method on any object passing in some String tag. Then it <br>notifies you via the console window whenever that particular object gets garbage collected:<br>
internal static class ConditionalWeakTableDemo { <br>   public static void Main() { <br>      Object o = new Object().GCWatch(&quot;My Object created at &quot; + DateTime.Now); <br>      GC.Collect();     // We will not see the GC notification here <br>      GC.KeepAlive(o);  // Make sure the object o refers to lives up to here <br>      o = null;         // The object that o refers to can die now <br> <br>      GC.Collect();     // We'll see the GC notification here <br>   } <br>} <br> <br>internal static class GCWatcher { <br>   // NOTE: Be careful with Strings due to interning and MarshalByRefObject proxy objects <br>   private readonly static ConditionalWeakTable&lt;Object, NotifyWhenGCd&lt;String&gt;&gt; s_cwt = <br>      new ConditionalWeakTable&lt;Object, NotifyWhenGCd&lt;String&gt;&gt;(); <br> <br>   private sealed class NotifyWhenGCd&lt;T&gt; { <br>      private readonly T m_value; <br> <br>      internal NotifyWhenGCd(T value) { m_value = value; } <br>      public override string ToString() { return m_value.ToString(); } <br>      ~NotifyWhenGCd() { Console.WriteLine(&quot;GC'd: &quot; + m_value); } <br>   } <br> <br>   public static T GCWatch&lt;T&gt;(this T @object, String tag) where T : class { <br>      s_cwt.Add(@object, new NotifyWhenGCd&lt;String&gt;(tag)); <br>      return @object; <br>   } <br>}<br>
<b>Resurrection</b><br>
When we talked about finalization, you'll recall that when an object requiring finalization <br>is considered dead, the garbage collector forces the object back to life so that its Finalize <br>method can be called. Then, after its Finalize method is called, the object is permanently <br>dead. To summarize: An object requiring finalization dies, lives, and then dies again. Bringing <br>a dead object back to life is called <i>resurrection</i>.<br>
The act of preparing to call an object's Finalize method is a form of resurrection. When <br>the garbage collector places a reference to the object on the freachable queue, the object is <br>now reachable from a root and has come back to life. This is required so that the code in the <br>Finalize method can access the object's fields. Eventually, the object's Finalize method <br>returns, no roots point to the object because it is removed from the freachable queue, and <br>the object is dead forever after.<br>
<hr>
<A name=585></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>567</b><br>
But what if an object's Finalize method executed code that placed a pointer to the object <br>in a static field, as demonstrated in the following code?<br>
internal sealed class SomeType {  <br>   ~SomeType() {  <br>      Program.s_ObjHolder = this;   <br>   }  <br>}  <br>  <br>public static class Program {  <br>   public static Object s_ObjHolder;    // Defaults to null  <br>   ...  <br>}<br>
In this case, when a SomeType object has its Finalize method called, a reference to the <br>object is placed in a root, and the object is reachable from the application's code. This ob-<br>ject is now resurrected, and the garbage collector won't consider the object to be garbage. <br>The application is free to use the object--but you must remember that the object <i>has </i>been <br>finalized, so using it can cause unpredictable results. Also keep in mind that if SomeType con-<br>tained fields that referenced other objects (either directly or indirectly), all objects would be <br>resurrected because they are all reachable from the application's roots. However, be aware <br>that some of these other objects might also have had their Finalize method called.<br>
In general, resurrection is not considered a good thing, and you should avoid writing code <br>that takes advantage of this "feature" of the CLR. The few scenarios in which resurrection <br>can be useful are when an application's architecture requires use of the same object over <br>and over again. When the object is finished being used, a garbage collection will occur. In <br>the object's Finalize method, it assigns its this pointer to another root, preventing the <br>object from dying. But you'll want to tell the garbage collector to call the object's Finalize <br>method again after the next usage. To make this possible, the GC type offers a static method <br>named ReRegisterForFinalize. This method takes a single parameter: a reference to an <br>object. The following code demonstrates how to fix SomeType's Finalize method so that <br>the Finalize method is called after each use of the object:<br>
internal sealed class SomeType {  <br>   ~SomeType() {  <br>      Program.s_ObjHolder = this;   <br>      GC.ReRegisterForFinalize(this);  <br>   }  <br>}<br>
When the Finalize method is called, it resurrects the object by making a root refer to the <br>object. The Finalize method then calls ReRegisterForFinalize, which appends the  <br>address of the specified object (this) to the end of the finalization list. When the garbage <br>collector determines that this object is unreachable (some time in the future when the static <br>field is set to null), it will move the object's pointer from the finalization list to the freachable <br>queue, and the Finalize method will be called again. Again, remember that resurrecting an <br>object resurrects all of the objects it refers to; you may need to call ReRegisterForFinalize <br>
<hr>
<A name=586></a><IMG src="CLRviaCsharp-586_1.jpg"><br>
<b>568 </b><br>
<b>Part IV  Core Facilities</b><br>
for all of these objects, and in many situations, this is impossible because you won't have  <br>access to the private fields of the other objects!<br>
This example shows how to create an object that constantly resurrects itself and never dies--<br>but you don't usually want objects to do this. It's far more common to conditionally set a <br>root to reference the object inside the Finalize method.<br>
<b>Note  </b>Make sure that you call ReRegisterForFinalize no more than once per resurrection,  <br>or the object will have its Finalize method called multiple times. The reason is that each call  <br>to ReRegisterForFinalize appends a new entry to the end of the finalization list. When an <br>object is determined to be garbage, all of these entries move from the finalization list to the <br>freachable queue, making the object's Finalize method called multiple times.<br>
At the end of this chapter's "Generations" section, I present a GCNotification class that uses <br>resurrection in a useful and meaningful way.<br>
<b>Generations</b><br>
As I mentioned near the beginning of the chapter, generations are a mechanism within the <br>CLR garbage collector whose sole reason for being is to improve an application's performance. <br>A <i>generational garbage collector</i> (also known as an <i>ephemeral garbage collector</i>, although I <br>don't use the latter term in this book) makes the following assumptions:<br>
  The newer an object is, the shorter its lifetime will be.<br>
  The older an object is, the longer its lifetime will be.<br>
  Collecting a portion of the heap is faster than collecting the whole heap.<br>
Numerous studies have demonstrated the validity of these assumptions for a very large set <br>of existing applications, and these assumptions have influenced how the garbage collector is <br>implemented. In this section, I'll describe how generations work.<br>
When initialized, the managed heap contains no objects. Objects added to the heap are said <br>to be in generation 0. Stated simply, objects in generation 0 are newly constructed objects <br>that the garbage collector has never examined. Figure 21-8 shows a newly started application <br>with five objects allocated (A through E). After a while, objects C and E become unreachable.<br>
A<br>
B<br>
C<br>
D<br>
E<br>
Generation 0<br>
<b>FIGURE 21-8  </b>A newly initialized heap containing some objects, all in generation 0. No collections have  <br>occurred yet.<br>
<hr>
<A name=587></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>569</b><br>
When the CLR initializes, it selects a budget size for generation 0 of, say, 256 KB. (The exact <br>size is subject to change.) So if allocating a new object causes generation 0 to surpass its <br>budget, a garbage collection must start. Let's say that objects A through E occupy 256 KB. <br>When object F is allocated, a garbage collection must start. The garbage collector will deter-<br>mine that objects C and E are garbage and will compact object D, causing it to be adjacent <br>to object B. Incidentally, generation 0's budget of 256 KB was chosen because it is likely that <br>all of these objects will fit entirely into a CPU's L2 cache so that compacting memory happens <br>incredibly fast. The objects that survive the garbage collection (objects A, B, and D) are said <br>to be in generation 1. Objects in generation 1 have been examined by the garbage collector <br>once. The heap now looks like Figure 21-9.<br>
A<br>
B<br>
D<br>
Gener-<br>
Generation 0<br>
ation 1<br>
<b>FIGURE 21-9  </b>After one collection, generation 0 survivors are promoted to generation 1; generation 0 is <br>empty<br>
After a garbage collection, generation 0 contains no objects. As always, new objects will be <br>allocated in generation 0. Figure 21-10 shows the application running and allocating objects <br>F through K. In addition, while the application was running, objects B, H, and J became un-<br>reachable and should have their memory reclaimed at some point.<br>
A<br>
B<br>
D<br>
F<br>
G H I<br>
J<br>
K<br>
Gener-<br>
Generation 0<br>
ation 1<br>
<b>FIGURE 21-10  </b>New objects are allocated in generation 0; generation 1 has some garbage<br>
Now let's say that attempting to allocate object L would put generation 0 over its 256-KB <br>budget. Because generation 0 has reached its budget, a garbage collection must start.  <br>When starting a garbage collection, the garbage collector must decide which generations to <br>examine. Earlier, I said that when the CLR initializes, it selects a budget for generation 0. Well, <br>it also selects a budget for generation 1. Let's say that the budget selected for generation 1 is <br>2 MB.<br>
When starting a garbage collection, the garbage collector also sees how much memory is <br>occupied by generation 1. In this case, generation 1 occupies much less than 2 MB, so the <br>garbage collector examines only the objects in generation 0. Look again at the assumptions <br>that the generational garbage collector makes. The first assumption is that newly created  <br>objects have a short lifetime. So generation 0 is likely to have a lot of garbage in it, and  <br>collecting generation 0 will therefore reclaim a lot of memory. The garbage collector will just <br>ignore the objects in generation 1, which will speed up the garbage collection process.<br>
<hr>
<A name=588></a><IMG src="CLRviaCsharp-588_1.jpg"><br>
<b>570 </b><br>
<b>Part IV  Core Facilities</b><br>
Obviously, ignoring the objects in generation 1 improves the performance of the garbage <br>collector. However, the garbage collector improves performance more because it doesn't <br>traverse every object in the managed heap. If a root or an object refers to an object in an <br>old generation, the garbage collector can ignore any of the older objects' inner references, <br>decreasing the amount of time required to build the graph of reachable objects. Of course, <br>it's possible that an old object's field refers to a new object. To ensure that the updated fields <br>of these old objects are examined, the garbage collector uses a mechanism internal to the <br>JIT compiler that sets a bit when an object's reference field changes. This support lets the gar-<br>bage collector know which old objects (if any) have been written to since the last collection. <br>Only old objects that have had fields change need to be examined to see whether they refer <br>to any new object in generation 0.2<br>
<b>Note  </b>Microsoft's performance tests show that it takes less than 1 millisecond to perform a <br>garbage collection of generation 0. Microsoft's goal is to have garbage collections take no more <br>time than an ordinary page fault.<br>
A generational garbage collector also assumes that objects that have lived a long time will <br>continue to live. So it's likely that the objects in generation 1 will continue to be reachable <br>from the application. Therefore, if the garbage collector were to examine the objects in gen-<br>eration 1, it probably wouldn't find a lot of garbage. As a result, it wouldn't be able to reclaim <br>much memory. So it is likely that collecting generation 1 is a waste of time. If any garbage <br>happens to be in generation 1, it just stays there. The heap now looks like Figure 21-11.<br>
A<br>
B<br>
D<br>
F<br>
G<br>
I<br>
K<br>
Generation 1<br>
Generation 0<br>
<b>FIGURE 21-11  </b>After two collections, generation 0 survivors are promoted to generation 1 (growing the size of <br>generation 1); generation 0 is empty<br>
As you can see, all of the generation 0 objects that survived the collection are now part of <br>generation 1. Because the garbage collector didn't examine generation 1, object B didn't <br>have its memory reclaimed even though it was unreachable at the time of the last garbage <br>collection. Again, after a collection, generation 0 contains no objects and is where new  <br>objects will be placed. In fact, let's say that the application continues running and allocates <br>
2  For the curious, here are some more details about this. When the JIT compiler produces native code that modifies  <br>
a reference field inside an object, the native code includes a call to a write barrier method. This write barrier meth-<br>od checks if the object whose field is being modified is in generation 1 or 2 and if it is, the write barrier code sets a <br>bit in what is called the card table. The card table has 1 bit for every 128-byte range of data in the heap. When the <br>next GC starts, it scans the card table to know which objects in generations 1 and 2 have had their fields changed <br>since the last GC. If any of these modified objects refer to an object in generation 0, then the generation 0 objects <br>survive the collection. After the GC, the card table is reset to all zeroes. The write barrier code causes a slight per-<br>formance hit when writing to a reference field in an object (as opposed to a local variable or static field) and that <br>performance hit is slightly worse if that object is in generation 1 or 2.<br>
<hr>
<A name=589></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>571</b><br>
objects L through O. And while running, the application stops using objects G, L, and M, <br>making them all unreachable. The heap now looks like Figure 21-12.<br>
A<br>
B<br>
D<br>
F<br>
G<br>
I<br>
K<br>
L M N O<br>
Generation 1<br>
Generation 0<br>
<b>FIGURE 21-12  </b>New objects are allocated in generation 0; generation 1 has more garbage<br>
Let's say that allocating object P causes generation 0 to exceed its budget, causing a garbage <br>collection to occur. Because the memory occupied by all of the objects in generation 1 is less <br>than 2 MB, the garbage collector again decides to collect only generation 0, ignoring the  <br>unreachable objects in generation 1 (objects B and G). After the collection, the heap looks <br>like Figure 21-13.<br>
A<br>
B<br>
D<br>
F<br>
G<br>
I<br>
K<br>
N<br>
O<br>
Generation 1<br>
Generation 0<br>
<b>FIGURE 21-13  </b>After three collections, generation 0 survivors are promoted to generation 1 (growing the size <br>of generation 1 again); generation 0 is empty<br>
In Figure 21-13, you see that generation 1 keeps growing slowly. In fact, let's say that genera-<br>tion 1 has now grown to the point in which all of the objects in it occupy 2 MB of memory. At <br>this point, the application continues running (because a garbage collection just finished) and <br>starts allocating objects P through S, which fill generation 0 up to its budget. The heap now <br>looks like Figure 21-14.<br>
A<br>
B<br>
D<br>
F<br>
G<br>
I<br>
K<br>
N<br>
O P<br>
Q<br>
R<br>
S<br>
Generation 1<br>
Generation 0<br>
<b>FIGURE 21-14  </b>New objects are allocated in generation 0; generation 1 has more garbage<br>
When the application attempts to allocate object T, generation 0 is full, and a garbage collec-<br>tion must start. This time, however, the garbage collector sees that the objects in generation <br>1 are occupying so much memory that generation 1's 2-MB budget has been reached. Over <br>the several generation 0 collections, it's likely that a number of objects in generation 1 have <br>become unreachable (as in our example). So this time, the garbage collector decides to ex-<br>amine all of the objects in generation 1 and generation 0. After both generations have been <br>garbage collected, the heap now looks like Figure 21-15.<br>
<hr>
<A name=590></a><IMG src="CLRviaCsharp-590_1.jpg"><br>
<b>572 </b><br>
<b>Part IV  Core Facilities</b><br>
D<br>
F<br>
I<br>
N<br>
O<br>
Q<br>
S<br>
Generation 2<br>
Gener-<br>
Generation 0<br>
ation 1<br>
<b>FIGURE 21-15  </b>After four collections: generation 1 survivors are promoted to generation 2, generation 0  <br>survivors are promoted to generation 1, and generation 0 is empty<br>
As before, any objects that were in generation 0 that survived the garbage collection are now <br>in generation 1; any objects that were in generation 1 that survived the collection are now in <br>generation 2. As always, generation 0 is empty immediately after a garbage collection and <br>is where new objects will be allocated. Objects in generation 2 are objects that the garbage <br>collector has examined two or more times. There might have been several collections, but <br>the objects in generation 1 are examined only when generation 1 reaches its budget, which <br>usually requires several garbage collections of generation 0.<br>
The managed heap supports only three generations: generation 0, generation 1, and genera-<br>tion 2; there is no generation 3.3 When the CLR initializes, it selects budgets for all three  <br>generations. As I mentioned earlier, the budget for generation 0 is about 256 KB, and the <br>budget for generation 1 is about 2 MB. The budget for generation 2 is around 10 MB. Again, <br>the budget sizes are selected to improve performance. The larger the budget, the less  <br>frequently a garbage collection will occur. And again, the performance improvement comes <br>because of the initial assumptions: new objects have short lifetimes, and older objects are <br>likely to live longer.<br>
The CLR's garbage collector is a self-tuning collector. This means that the garbage collector <br>learns about your application's behavior whenever it performs a garbage collection. For  <br>example, if your application constructs a lot of objects and uses them for a very short period <br>of time, it's possible that garbage collecting generation 0 will reclaim a lot of memory. In fact, <br>it's possible that the memory for all objects in generation 0 can be reclaimed.<br>
If the garbage collector sees that there are very few surviving objects after collecting gen-<br>eration 0, it might decide to reduce the budget of generation 0 from 256 KB to 128 KB. This <br>reduction in the allotted space will mean that garbage collections occur more frequently but <br>will require less work for the garbage collector, so your process's working set will be small. In <br>fact, if all objects in generation 0 are garbage, a garbage collection doesn't have to compact <br>any memory; it can simply set NextObjPtr back to the beginning of generation 0, and then <br>the garbage collection is performed. Wow, this is a fast way to reclaim memory!<br>
<b>Note  </b>The garbage collector works extremely well for applications with threads that sit idle at <br>the top of their stack most of the time. Then, when the thread has something to do, it wakes up, <br>creates a bunch of short-lived objects, returns, and then goes back to sleep. Many applications <br>follow this architecture, including Windows Forms, WPF, ASP.NET Web Forms, and XML Web  <br>service applications.<br>
3  The System.GC class's static MaxGeneration method returns 2.<br>
<hr>
<A name=591></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>573</b><br>
For ASP.NET applications, a client request comes in, a bunch of new objects are constructed, the <br>objects perform work on the client's behalf, and the result is sent back to the client. At this point, <br>all of the objects used to satisfy the client's request are garbage. In other words, each ASP.NET <br>application request causes a lot of garbage to be created. Because these objects are unreachable <br>almost immediately after they're created, each garbage collection reclaims a lot of memory. This <br>keeps the process's working set very low, and the garbage collector's performance is phenomenal.<br>
In fact, most of an application's roots live on the thread's stack in arguments or local variables. <br>If a thread's stack is short, it takes very little time for the garbage collector to examine the roots <br>and mark the reachable objects. In other words, garbage collections go much faster if you avoid <br>deeps stacks. One way to avoid a deep stack is to avoid using recursive methods.<br>
On the other hand, if the garbage collector collects generation 0 and sees that there are a <br>lot of surviving objects, not a lot of memory was reclaimed in the garbage collection. In this <br>case, the garbage collector will grow generation 0's budget to maybe 512 KB. Now, fewer <br>collections will occur, but when they do, a lot more memory should be reclaimed. By the way, <br>if insufficient memory has been reclaimed after a collection, the garbage collector will per-<br>form a full collection before throwing an OutOfMemoryException.<br>
Throughout this discussion, I've been talking about how the garbage collector dynamically <br>modifies generation 0's budget after every collection. But the garbage collector also modi-<br>fies the budgets of generation 1 and generation 2 by using similar heuristics. When these <br>generations are garbage collected, the garbage collector again sees how much memory <br>is reclaimed and how many objects survived. Based on the garbage collector's findings, it <br>might grow or shrink the thresholds of these generations as well to improve the overall per-<br>formance of the application. The end result is that the garbage collector fine-tunes itself  <br>automatically based on the memory load required by your application--this is very cool!<br>
The GCNotification class shown below is similar to the GCBeep program discussed in the <br>"Using Finalization with Managed Resources" section earlier in this chapter. However, the <br>GCNotification class raises an event whenever a generation 0 or generation 2 collection <br>occurs. With these events, you could have the computer beep whenever a collection or you <br>calculate how much time passes between collections, how much memory is allocated be-<br>tween collections, and more. With this class, you could easily instrument your application to <br>get a better understanding of how your application uses memory.<br>
public static class GCNotification { <br>   private static Action&lt;Int32&gt; s_gcDone = null;  // The event's field <br> <br>   public static event Action&lt;Int32&gt; GCDone { <br>      add { <br>         // If there were no registered delegates before, start reporting notifications now <br>         if (s_gcDone == null) { new GenObject(0); new GenObject(2); } <br>         s_gcDone += value; <br>      } <br>      remove { s_gcDone -= value; } <br>   } <br> <br>
<hr>
<A name=592></a><b>574 </b><br>
<b>Part IV  Core Facilities</b><br>
   private sealed class GenObject { <br>      private Int32 m_generation; <br>      public GenObject(Int32 generation) { m_generation = generation; } <br>      ~GenObject() { // This is the Finalize method <br>         // If this object is in the generation we want (or higher),  <br>         // notify the delegates that a GC just completed <br>         if (GC.GetGeneration(this) &gt;= m_generation) { <br>            Action&lt;Int32&gt; temp = Interlocked.CompareExchange(ref s_gcDone, null, null); <br>            if (temp != null) temp(m_generation); <br>         } <br> <br>         // Keep reporting notifications if there is at least one delegated registered, <br>         // the AppDomain isn't unloading, and the process isn't shutting down <br>         if ((s_gcDone != null)  <br>            &amp;&amp; !AppDomain.CurrentDomain.IsFinalizingForUnload()  <br>            &amp;&amp; !Environment.HasShutdownStarted) { <br>            // For Gen 0, create a new object; for Gen 2, resurrect the object &amp; let <br>            // the GC call Finalize again the next time Gen 2 is GC'd <br>            if (m_generation == 0) new GenObject(0); <br>            else GC.ReRegisterForFinalize(this); <br>         } else { /* Let the objects go away */ } <br>      } <br>   } <br>}<br>
<b>Other Garbage Collection Features for Use with Native </b><br>
<b>Resources</b><br>
Sometimes, a native resource consumes a lot of memory, but the managed object wrapping <br>that resource occupies very little memory. The quintessential example of this is the bitmap. <br>A bitmap can occupy several megabytes of native memory, but the managed object is tiny <br>because it contains only an HBITMAP (a 4- or 8-byte value). From the CLR's perspective, a pro-<br>cess could allocate hundreds of bitmaps (using little managed memory) before performing a <br>collection. But if the process is manipulating many bitmaps, the process's memory consump-<br>tion will grow at a phenomenal rate. To fix this situation, the GC class offers the following two <br>static methods:<br>
public static void AddMemoryPressure(Int64 bytesAllocated);   <br>public static void RemoveMemoryPressure(Int64 bytesAllocated);<br>
A class that wraps a potentially large native resource should use these methods to give the <br>garbage collector a hint as to how much memory is really being consumed. Internally, the <br>garbage collector monitors this pressure, and when it gets high, a garbage collection is <br>forced.<br>
There are some native resources that are fixed in number. For example, Windows formerly had <br>a restriction that it could create only five device contexts. There had also been a restriction  <br>on the number of files that an application could open. Again, from the CLR's perspective, a <br>process could allocate hundreds of objects (that use little memory) before performing a  <br>collection. But if the number of these native resources is limited, attempting to use more <br>
<hr>
<A name=593></a><IMG src="CLRviaCsharp-593_1.jpg"><br>
<b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>575</b><br>
than are available will typically result in exceptions being thrown. To fix this situation, the <br>System.Runtime.InteropServices namespace offers the HandleCollector class:<br>
public sealed class HandleCollector {  <br>   public HandleCollector(String name, Int32 initialThreshold);  <br>   public HandleCollector(String name, Int32 initialThreshold,  Int32 maximumThreshold);  <br>   public void Add();  <br>   public void Remove();  <br>  <br>   public Int32 Count { get; }  <br>   public Int32 InitialThreshold { get; }  <br>   public Int32 MaximumThreshold { get; }  <br>   public String Name { get; }  <br>}<br>
A class that wraps a native resource that has a limited quantity available should use an  <br>instance of this class to give the garbage collector a hint as to how many instances of the  <br>resource are really being consumed. Internally, this class object monitors the count, and <br>when it gets high, a garbage collection is forced.<br>
<b>Note  </b>Internally, the GC.AddMemoryPressure and HandleCollector.Add methods call <br>GC.Collect, forcing a garbage collection to start prior to generation 0 reaching its budget. <br>Normally, forcing a garbage collection to start is strongly discouraged because it usually has an <br>adverse effect on your application's performance. However, classes that call these methods are <br>doing so in an effort to keep limited native resources available for the application. If the native <br>resources run out, the application will fail. For most applications, it is better to work with reduced <br>performance than to not be working at all.<br>
Here is some code that demonstrates the use and effect of the memory pressure methods <br>and the HandleCollector class:<br>
using System;  <br>using System.Runtime.InteropServices;  <br>  <br>public static class Program {  <br>   public static void Main() {  <br>      MemoryPressureDemo(0);                 // 0    causes infrequent GCs <br>      MemoryPressureDemo(10 * 1024 * 1024);  // 10MB causes frequent GCs <br> <br>      HandleCollectorDemo();    <br>} <br> <br>   private static void MemoryPressureDemo(Int32 size) {  <br>      Console.WriteLine();  <br>      Console.WriteLine(&quot;MemoryPressureDemo, size={0}&quot;, size);  <br>      // Create a bunch of objects specifying their logical size  <br>      for (Int32 count = 0; count &lt; 15; count++) {  <br>         new BigNativeResource(size);  <br>      }  <br>  <br>      // For demo purposes, force everything to be cleaned-up  <br>      GC.Collect();  <br>
<hr>
<A name=594></a><b>576 </b><br>
<b>Part IV  Core Facilities</b><br>
      GC.WaitForPendingFinalizers();  <br>   }  <br>  <br>   private sealed class BigNativeResource {  <br>      private Int32 m_size;  <br>  <br>      public BigNativeResource(Int32 size) {  <br>         m_size = size;  <br>         if (m_size &gt; 0) {  <br>            // Make the GC think the object is physically bigger  <br>            GC.AddMemoryPressure(m_size);  <br>         }  <br>         Console.WriteLine(&quot;BigNativeResource create.&quot;);  <br>      }  <br>  <br>      ~BigNativeResource() {  <br>         if (m_size &gt; 0) {  <br>            // Make the GC think the object released more memory  <br>            GC.RemoveMemoryPressure(m_size);  <br>         }  <br>         Console.WriteLine(&quot;BigNativeResource destroy.&quot;);  <br>      }  <br>   }  <br>  <br>  <br>   private static void HandleCollectorDemo() {  <br>      Console.WriteLine();  <br>      Console.WriteLine(&quot;HandleCollectorDemo&quot;);  <br>      for (Int32 count = 0; count &lt; 10; count++) {  <br>         new LimitedResource();  <br>      }  <br>  <br>      // For demo purposes, force everything to be cleaned-up  <br>      GC.Collect();  <br>      GC.WaitForPendingFinalizers();  <br>   }  <br>  <br>   private sealed class LimitedResource {  <br>      // Create a HandleCollector telling it that collections should  <br>      // occur when two or more of these objects exist in the heap  <br>      private static HandleCollector s_hc = new HandleCollector(&quot;LimitedResource&quot;, 2);  <br>  <br>      public LimitedResource() {  <br>         // Tell the HandleCollector that 1 more LimitedResource   <br>         // object has been added to the heap  <br>         s_hc.Add();  <br>         Console.WriteLine(&quot;LimitedResource create.  Count={0}&quot;, s_hc.Count);  <br>      }  <br>      ~LimitedResource() {  <br>         // Tell the HandleCollector that 1 less LimitedResource   <br>         // object has been removed from the heap  <br>         s_hc.Remove();  <br>         Console.WriteLine(&quot;LimitedResource destroy. Count={0}&quot;, s_hc.Count);  <br>      }  <br>   }  <br>}<br>
<hr>
<A name=595></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>577</b><br>
If you compile and run the code above, your output will be similar to the following output:<br>
MemoryPressureDemo, size=0  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>  <br>MemoryPressureDemo, size=10485760  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>
<hr>
<A name=596></a><b>578 </b><br>
<b>Part IV  Core Facilities</b><br>
BigNativeResource create.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource create.  <br>BigNativeResource create.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>BigNativeResource destroy.  <br>  <br>HandleCollectorDemo  <br>LimitedResource create.  Count=1  <br>LimitedResource create.  Count=2  <br>LimitedResource create.  Count=3  <br>LimitedResource destroy. Count=3  <br>LimitedResource destroy. Count=2  <br>LimitedResource destroy. Count=1  <br>LimitedResource create.  Count=1  <br>LimitedResource create.  Count=2  <br>LimitedResource destroy. Count=2  <br>LimitedResource create.  Count=2  <br>LimitedResource create.  Count=3  <br>LimitedResource destroy. Count=3  <br>LimitedResource destroy. Count=2  <br>LimitedResource destroy. Count=1  <br>LimitedResource create.  Count=1  <br>LimitedResource create.  Count=2  <br>LimitedResource destroy. Count=2  <br>LimitedResource create.  Count=2  <br>LimitedResource destroy. Count=1  <br>LimitedResource destroy. Count=0<br>
<b>Predicting the Success of an Operation that Requires a </b><br>
<b>Lot of Memory</b><br>
Occasionally you find yourself implementing an algorithm that you know will require a num-<br>ber of objects that together will occupy a good bit of memory. You could start executing the <br>algorithm, and, if you run out of memory, the CLR will throw an OutOfMemoryException. <br>In that case, you have done a lot of work that now must be thrown away. Plus, you need to <br>catch this exception and allow your program to recover gracefully.<br>
In the System.Runtime namespace, there is a MemoryFailPoint class that offers you the <br>ability to check for sufficient memory prior to starting a memory-hungry algorithm. Here is <br>what the class looks like:<br>
public sealed class MemoryFailPoint : CriticalFinalizerObject, IDisposable {  <br>   public MemoryFailPoint(Int32 sizeInMegabytes);  <br>   ~MemoryFailPoint();  <br>   public void Dispose();  <br>}<br>
<hr>
<A name=597></a><IMG src="CLRviaCsharp-597_1.jpg"><br>
<b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>579</b><br>
The way you use this class is pretty simple. First, you construct an instance of it by passing <br>in the number of megabytes that you think your algorithm is going to require (round up if <br>you're not completely sure). Internally, the constructor performs the following checks that <br>trigger actions in consequence:<br>
<b> </b><br>
<b>1.  </b>Is there enough available space in the system's paging file, and is there enough contigu-<br>
ous virtual address space in the process to satisfy the request? Note that the constructor <br>subtracts any amount of memory that has been logically reserved by another call to <br>MemoryFailPoint's constructor.<br>
<b> </b><br>
<b>2.  </b>If there isn't enough space, a garbage collection is forced in an attempt to free up <br>
some space.<br>
<b> </b><br>
<b>3.  </b>If there is still not enough paging file space, an attempt is made to expand the paging  <br>
file. If the paging file cannot grow enough, an InsufficientMemoryException is <br>thrown.<br>
<b> </b><br>
<b>4.  </b>If there still isn't enough contiguous virtual address space, an <br>
InsufficientMemoryException is thrown.<br>
<b> </b><br>
<b>5.  </b>If enough paging file space and virtual address space has been found, the requested <br>
number of megabytes are reserved by adding the number of megabytes to a private <br>static field defined within the MemoryFailPoint class. The addition is done in a thread-<br>safe way so that multiple threads can construct an instance of this class simultaneously <br>and be guaranteed that they have logically reserved the memory they requested as <br>long as no exception is thrown in the constructor.<br>
If MemoryFailPoint's constructor throws an InsufficientMemoryException, your  <br>application can release some resources it is currently using, or it can reduce its performance <br>(perform less caching of data) in order to reduce the chance of the CLR throwing an <br>OutOfMemoryException in the future. By the way, InsufficientMemoryException is  <br>derived from OutOfMemoryException.<br>
<b>Important  </b>If MemoryFailPoint's constructor doesn't throw an exception, you have logically <br>reserved the memory you have requested and you can execute your memory-hungry algorithm.  <br>However, be aware that you have not physically allocated this memory. This means that it <br>is just <i>more likely</i> for your algorithm to run successfully, getting the memory it needs. The <br>MemoryFailPoint class cannot guarantee that your algorithm will get the memory it needs <br>even if the constructor doesn't throw an exception. This class exists to <i>help</i> you make a more  <br>robust application.<br>
When you have completed executing the algorithm, you should call Dispose on the <br>MemoryFailPoint object you constructed. Internally, Dispose just subtracts (in a thread-safe <br>way) the number of megabytes you reserved from the MemoryFailPoint's static field. The <br>code below demonstrates the use of the MemoryFailPoint class:<br>
<hr>
<A name=598></a><b>580 </b><br>
<b>Part IV  Core Facilities</b><br>
using System;  <br>using System.Runtime;  <br>  <br>public static class Program {  <br>   public static void Main() {  <br>      try {  <br>         // Logically reserve 1.5 GB of memory  <br>         using (MemoryFailPoint mfp = new MemoryFailPoint(1500)) {  <br>            // Perform memory-hungry algorithm in here  <br>  <br>         } // Dispose will logically free the 1.5 GB of memory  <br>      }  <br>      catch (InsufficientMemoryException e) {  <br>         // The memory could not be reserved  <br>         Console.WriteLine(e);  <br>      }  <br>   }  <br>}<br>
<b>Programmatic Control of the Garbage Collector</b><br>
The System.GC type allows your application some direct control over the garbage collector. <br>For starters, you can query the maximum generation supported by the managed heap by <br>reading the GC.MaxGeneration property; this property always returns 2.<br>
You can also force the garbage collector to perform a collection by calling one of the follow-<br>ing two static methods:<br>
void GC.Collect(Int32 Generation)  <br>void GC.Collect() <br>void Collect(Int32 generation, GCCollectionMode mode)<br>
The first method allows you to specify which generation(s) to collect. You can pass any integer <br>from 0 to GC.MaxGeneration inclusive. Passing 0 causes generation 0 to be collected, passing <br>1 causes generations 1 and 0 to be collected, and passing 2 causes generations 2, 1, and 0  <br>to be collected. The version of the Collect<i> </i>method that takes no parameters forces a full <br>collection of all generations and is equivalent to calling:<br>
GC.Collect(GC.MaxGeneration);<br>
The third overload of Collect allows you to pass a generation and a GCCollectionMode. <br>Table 21-1 describes the various GC collection mode symbols.<br>
<hr>
<A name=599></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>581</b><br>
<b>TABLE 21-1  Symbols Defined by the </b>GCCollectionMode<b> Enumerated Type</b><br>
<b>Symbol Name</b><br>
<b>Description</b><br>
Default<br>
The same as calling GC.Collect with no flag. Today, this is the same as <br>passing Forced, but this may change in a future version of the CLR.<br>
Forced<br>
Forces a collection to occur immediately for all generations up to and  <br>including the specified generation.<br>
Optimized<br>
The garbage collector will only perform a collection if the collection would <br>be productive either by freeing a lot of memory or by reducing fragmenta-<br>tion. If the garbage collection would not be productive, then the call has no <br>effect.<br>
Under most circumstances, you should avoid calling any of the Collect<i> </i>methods; it's best <br>just to let the garbage collector run on its own accord and fine-tune its generation budgets <br>based on actual application behavior. However, if you're writing a console user interface (CUI) <br>or graphical user interface (GUI) application, your application code owns the process and the <br>CLR in that process. For these application types, you <i>might </i>want to suggest a garbage collec-<br>tion to occur at certain times using a GCCollectionMode of Optimized. Normally, modes of <br>Default and Forced are used for debugging and testing.<br>
For example, you might consider calling the Collect method if some non-recurring event <br>has just occurred that has likely caused a lot of old objects to die. The reason that calling <br>Collect in such a circumstance may not be so bad is that the garbage collector's predictions <br>of the future based on the past are not likely to be accurate for non-recurring events.<br>
For example, it might make sense for your application to force a full garbage collection of <br>all generations after your application initializes or after the user saves a data file. When a <br>Windows Form control is hosted on a Web page, a full collection is performed each time a <br>page is unloaded. Don't explicitly call Collect to try to improve your application's response <br>time; call it to reduce your process's working set.<br>
The GC type also offers a WaitForPendingFinalizers<i> </i>method. This method simply suspends <br>the calling thread until the thread processing the freachable queue has emptied the queue, <br>calling each object's Finalize method. In most applications, it's unlikely that you'll ever have <br>to call this method. Occasionally, though, I've seen code like this:<br>
GC.Collect();  <br>GC.WaitForPendingFinalizers();  <br>GC.Collect();<br>
This code forces a garbage collection. When the collection is complete, the memory for  <br>objects that don't require finalization is reclaimed. But the objects that do require finalization  <br>can't have their memory reclaimed yet. After the first call to Collect returns, the special,  <br>dedicated finalization thread is calling Finalize methods asynchronously. The cal  to <br>WaitForPendingFinalizers puts the application's thread to sleep until all Finalize meth-<br>ods are called. When WaitForPendingFinalizers returns, all of the finalized objects are now <br>
<hr>
<A name=600></a><b>582 </b><br>
<b>Part IV  Core Facilities</b><br>
truly garbage. At this point, the second call to Collect forces another garbage collection, <br>which reclaims all of the memory occupied by the now-finalized objects.<br>
For some applications (especially server applications that tend to keep a lot of objects in <br>memory), the time required for the garbage collector to do a full collection that includes <br>generation 2 can be excessive. In fact, if the collection takes a very long time to complete,  <br>then client requests might time out. To help these kinds of applications, the GC class  <br>offers a RegisterForFullGCNotification method. Using this method and some additional  <br>helper methods (WaitForFullGCApproach, WaitForFullGCComplete, and <br>CancelFullGCNotification), an application can now be notified when the garbage collec-<br>tor is getting close to performing a full collection. The application can then call GC.Collect <br>to force a collection at a more opportune time, or the application could communicate with <br>another server to better load balance the client requests. For more information, examine <br>these methods in the .NET Framework SDK documentation. Note that you should always call <br>the WaitForFullGCApproach and WaitForFullGCComplete methods in pairs because the <br>CLR handles them as pairs internally.<br>
Finally, the GC class offers two static methods to allow you to determine which generation an <br>object is currently in:<br>
Int32 GetGeneration(Object obj)  <br>Int32 GetGeneration(WeakReference wr)<br>
The first version of GetGeneration takes an object reference as a parameter, and the second <br>version takes a WeakReference reference as a parameter. The value returned will be between <br>0 and GC.MaxGeneration inclusively.<br>
The following code will help you understand how generations work. The code also demon-<br>strates the use of the GC methods just discussed.<br>
using System;  <br>  <br>internal sealed class GenObj {  <br>   ~GenObj() {  <br>      Console.WriteLine(&quot;In Finalize method&quot;);  <br>   }  <br>}  <br>  <br>public static class Program {  <br>   public static void Main() {  <br>      Console.WriteLine(&quot;Maximum generations: &quot; + GC.MaxGeneration);  <br>  <br>      // Create a new GenObj in the heap.  <br>      Object o = new GenObj();  <br>  <br>      // Because this object is newly created, it is in generation 0.  <br>      Console.WriteLine(&quot;Gen &quot; + GC.GetGeneration(o)); // 0  <br>  <br>
<hr>
<A name=601></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>583</b><br>
      // Performing a garbage collection promotes the object's generation.  <br>      GC.Collect();  <br>      Console.WriteLine(&quot;Gen &quot; + GC.GetGeneration(o)); // 1  <br>  <br>      GC.Collect();  <br>      Console.WriteLine(&quot;Gen &quot; + GC.GetGeneration(o)); // 2  <br>  <br>      GC.Collect();  <br>      Console.WriteLine(&quot;Gen &quot; + GC.GetGeneration(o)); // 2 (max)  <br>  <br>  <br>      o = null; // Destroy the strong reference to this object.  <br>  <br>      Console.WriteLine(&quot;Collecting Gen 0&quot;);  <br>      GC.Collect(0);                    // Collect generation 0.  <br>      GC.WaitForPendingFinalizers();    // Finalize is NOT called.  <br>  <br>      Console.WriteLine(&quot;Collecting Gens 0, and 1&quot;);  <br>      GC.Collect(1);                    // Collect generations 0 &amp; 1.  <br>      GC.WaitForPendingFinalizers();    // Finalize is NOT called.  <br>  <br>      Console.WriteLine(&quot;Collecting Gens 0, 1, and 2&quot;);  <br>      GC.Collect(2);                    // Same as Collect()  <br>      GC.WaitForPendingFinalizers();    // Finalize IS called.  <br>   }  <br>}<br>
Building and running this code yields the following output:<br>
Maximum generations: 2  <br>Gen 0  <br>Gen 1  <br>Gen 2  <br>Gen 2  <br>Collecting Gen 0  <br>Collecting Gens 0, and 1  <br>Collecting Gens 0, 1, and 2  <br>In Finalize method<br>
<b>Thread Hijacking</b><br>
Earlier in this chapter, I explained the garbage collection algorithm. However, I made a big <br>assumption during that discussion: that only one thread is running. In the real world, it's likely <br>for multiple threads to be accessing the managed heap or at least manipulating objects allo-<br>cated within the managed heap. When one thread sparks a garbage collection, other threads <br>must not access any objects (including object references on its own stack) because the garbage <br>collector is likely to move these objects, changing their memory locations.<br>
So when the garbage collector wants to start a garbage collection, all threads executing <br>managed code must be suspended. The CLR has a few different mechanisms that it uses <br>to safely suspend threads so that a garbage collection can be performed. The reason that <br>
<hr>
<A name=602></a><b>584 </b><br>
<b>Part IV  Core Facilities</b><br>
there are multiple mechanisms is to keep threads running as long as possible and to reduce <br>overhead as much as possible. I don't want to get into all of the details here, but suffice it to <br>say that Microsoft has done a lot of work to reduce the overhead involved with a garbage <br>collection. Microsoft will continue to modify these mechanisms over time to ensure efficient <br>garbage collections in the future.<br>
When the CLR wants to start a garbage collection, it immediately suspends all threads that <br>are executing managed code. The CLR then examines each thread's instruction pointer to <br>determine where the thread is executing. The instruction pointer address is then compared <br>with the JIT compiler­produced tables in an effort to determine what code the thread is <br>executing.<br>
If the thread's instruction pointer is at an offset identified by a table, the thread is said to <br>have reached a <i>safe point</i>. A safe point is a place where it's OK to leave a thread suspended <br>until a garbage collection completes. If the thread's instruction pointer isn't at an offset iden-<br>tified by an internal method table, the thread isn't at a safe point, and the CLR can't perform <br>a garbage collection. In this case, the CLR <i>hijacks </i>the thread: the CLR modifies the thread's <br>stack so that the return address points to a special function implemented inside the CLR. The <br>thread is then resumed. When the currently executing method returns, the special function <br>will execute, suspending the thread.<br>
However, the thread might not return from its method for quite some time. So after the <br>thread resumes execution, the CLR waits about 250 milliseconds for the thread to be hijacked. <br>After this time, the CLR suspends the thread again and checks its instruction pointer. If the <br>thread has reached a safe point, the garbage collection can start. If the thread still hasn't <br>reached a safe point, the CLR checks to see whether another method has been called; if one <br>has, the CLR modifies the stack again so that the thread is hijacked when it returns from the <br>most recently executing method. Then the CLR resumes the thread and waits another few <br>milliseconds before trying again.<br>
When all of the threads have reached a safe point or have been hijacked, garbage collection <br>can begin. When the garbage collection is completed, all threads are resumed, and the ap-<br>plication continues running. The hijacked threads return to the method that originally called <br>them.<br>
This algorithm has one small twist. When the CLR wants to start a garbage collection, it sus-<br>pends all threads that are executing managed code, but it does not suspend threads that are <br>executing unmanaged code. Once all of the threads that are executing managed code are at <br>a safe point or are hijacked, the garbage collection is allowed to start. The threads executing <br>unmanaged code are allowed to continue running because any object that they are using <br>should have been pinned. If a thread currently executing unmanaged code returns to man-<br>aged code, the thread is immediately suspended until the garbage collection has completed.<br>
As it turns out, the CLR uses hijacking most of the time rather than using the JIT compiler­<br>produced tables to determine if the thread is at a safe point. The reason is the JIT compiler­<br>
<hr>
<A name=603></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>585</b><br>
produced tables require a lot of memory and increase the working set, which in turn hurts <br>performance significantly. So, the JIT compiler­produced tables contain information for  <br>sections of code having loops that do not call other methods. If the method has a loop that <br>calls other methods or if there are no loops, the JIT compiler­produced tables do not have <br>much information in them, and hijacking is used to suspend the threads.<br>
<b>Garbage Collection Modes</b><br>
When the CLR starts, it selects a GC mode, and this mode cannot change during the lifetime <br>of the process. There are two basic GC modes:<br>
<b>  Workstation  </b>This mode fine-tunes the garbage collector for client-side applications. <br>
The garbage collector assumes that other applications are running on the machine <br>and does not hog CPU resources. The Workstation mode can have two submodes: <br>Workstation with the concurrent collector and Workstation without the concurrent  <br>collector. I'll describe the concurrent collector feature shortly.<br>
<b>  Server  </b>This mode fine-tunes the garbage collector for server-side applications. The <br>
garbage collector assumes that no other applications (client or server) are running on <br>the machine and it assumes that all the CPUs on the machine are available to do a  <br>garbage collection. This GC mode causes the managed heap to be split into several <br>sections, one per CPU. When a garbage collection is initiated, the garbage collector  <br>has one thread per CPU; each thread collects its own section in parallel with the other <br>threads. Parallel collections work well for server applications in which the worker <br>threads tend to exhibit uniform behavior. This feature requires the application to be <br>running on a computer with multiple CPUs so that the threads can truly be working  <br>simultaneously to attain a performance improvement.<br>
By default, applications run with the Workstation GC mode, and the concurrent collector is <br>turned on. However, a server application (such as ASP.NET or SQL Server) that hosts the CLR <br>can request the CLR to load the Server GC. However, if the server application is running on a <br>uniprocessor machine, then the CLR will load the Workstation GC mode without the concur-<br>rent collector.<br>
An application that self-hosts the CLR can tell the CLR to use the server collector by creat-<br>ing a configuration file (as discussed in Chapter 2, "Building, Packaging, Deploying, and <br>Administering Applications and Types," and Chapter 3, "Shared Assemblies and Strongly <br>Named Assemblies") that contains a gcServer element for the application. Here's an exam-<br>ple of a configuration file:<br>
&lt;configuration&gt;   <br>    &lt;runtime&gt;   <br>        &lt;gcServer enabled=&quot;true&quot;/&gt;   <br>    &lt;/runtime&gt;   <br>&lt;/configuration&gt;<br>
<hr>
<A name=604></a><b>586 </b><br>
<b>Part IV  Core Facilities</b><br>
When an application is running, it can ask the CLR if it is running in the Server GC mode by <br>querying the GCSettings class's IsServerGC read-only Boolean property:<br>
using System;  <br>using System.Runtime; // GCSettings is in this namespace  <br>  <br>public static class Program {  <br>   public static void Main() {  <br>      Console.WriteLine(&quot;Application is running with server GC=&quot; + GCSettings.IsServerGC);  <br>    }  <br>}<br>
The Workstation GC mode can run in concurrent or non-concurrent mode. In concurrent <br>mode, the garbage collector has an additional background thread that collects objects con-<br>currently while the application runs. When a thread allocates an object that pushes genera-<br>tion 0 over its budget, the garbage collector first suspends all threads and then determines <br>which generations to collect. If the garbage collector needs to collect generation 0 or 1, it <br>proceeds as normal. However, if generation 2 needs collecting, the size of generation 0 will <br>be increased beyond its budget to allocate the new object, and then the application's threads <br>are resumed.<br>
While the application's threads are running, the garbage collector has a normal priority <br>background thread that marks unreachable objects. This thread competes for CPU time with <br>the application's threads, causing the application's tasks to execute more slowly. Once the <br>objects are marked, the garbage collector suspends all threads again and decides whether <br>to compact memory. If the garbage collector decides to compact memory, memory is com-<br>pacted, root references are fixed up, and the application's threads are resumed. This garbage <br>collection takes less time than usual because the set of unreachable objects has already been <br>built. However, the garbage collector might decide not to compact memory; in fact, the gar-<br>bage collector favors this approach. If you have a lot of free memory, the garbage collector <br>won't compact the heap; this improves performance but grows your application's working <br>set. When using the concurrent garbage collector, you'll typically find that your application is <br>consuming more memory than it would with the non-concurrent garbage collector.<br>
To summarize: Concurrent collection creates a better interactive experience for users and <br>is therefore best for interactive CUI or GUI applications. For some applications, however, <br>concurrent collection will actually hurt performance and will cause more memory to be <br>used. When testing your application, you should experiment with and without concurrent <br>collection and see which approach gives the best performance and memory usage for your <br>application.<br>
You can tell the CLR not to use the concurrent collector by creating a configuration file for <br>the application (as discussed in Chapters 2 and 3) that contains a gcConcurrent element. <br>Here's an example of a configuration file:<br>
<hr>
<A name=605></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>587</b><br>
&lt;configuration&gt;  <br>   &lt;runtime&gt;  <br>      &lt;gcConcurrent enabled=&quot;false&quot;/&gt;  <br>   &lt;/runtime&gt;  <br>&lt;/configuration&gt;<br>
In addition to the modes just described, the garbage collector supports synchronization-free <br>allocations. On a multiprocessor system, generation 0 of the managed heap is partitioned <br>into multiple memory arenas, one arena per thread. This allows multiple threads to make  <br>allocations simultaneously so that exclusive access to the heap isn't required.<br>
While the GC mode is configured for the process and it cannot change while the process <br>runs, your application can have some control over the garbage collection by using the <br>GCSettings class's GCLatencyMode property. This read/write property can be set to any of <br>the values in the GCLatencyMode enumerated type, as shown in Table 21-2.<br>
<b>TABLE 21-2  Symbols Defined by the </b>GCLatencyMode<b> Enumerated Type</b><br>
<b>Symbol Name</b><br>
<b>Description</b><br>
Batch <br>
In the Workstation GC mode, this latency mode turns off the concurrent GC.<br>
(default for the  <br>
In the Server GC mode, this is the only valid latency mode.<br>
Server GC mode)<br>
Interactive <br>
In the Workstation GC mode, this latency mode turns on the concurrent GC.<br>
(default for the <br>
In the Server GC, this latency mode is not valid.<br>
Workstation GC <br>mode)<br>LowLatency<br>
In the Workstation GC mode, you use this latency mode during short-term, <br>time-sensitive operations (like drawing animations) where a generation 2 <br>collection might be disruptive.<br>In the Server GC, this latency mode is not valid.<br>
The LowLatency mode requires some additional explanation. Typically, you would set this <br>mode, perform a short-term, time-sensitive operation, and then set the mode back to either <br>Batch or Interactive. While the mode is set to LowLatency, the garbage collector will real y <br>avoid doing any generation 2 collections because these could take a long time. Of course, if <br>you call GC.Collect(), then generation 2 still gets collected. Also, the garbage collector will <br>perform a generation 2 collection if Windows tells the CLR that system memory is low (see <br>the "What Causes Finalize Methods to Be Called" section earlier in this chapter).<br>
Under LowLatency mode, it is more likely that your application could get an <br>OutOfMemoryException thrown. Therefore, stay in this mode for as short a time as possible,  <br>avoid allocating many objects, avoid allocating large objects, and set the mode back to <br>Batch or Interactive using a <i>constrained execution region (CER),</i> as discussed in Chapter <br>20, "Exceptions and State Management." Also, remember that the latency mode is a process-<br>wide setting and threads may be running concurrently. These other threads could even <br>change this setting while another thread is using it and so you may want to update some <br>kind of counter (manipulated via Interlocked methods) when you have multiple threads <br>
<hr>
<A name=606></a><b>588 </b><br>
<b>Part IV  Core Facilities</b><br>
manipulating this setting. Here is some code showing how to properly use the LowLatency <br>mode:<br>
private static void LowLatencyDemo() { <br>   GCLatencyMode oldMode = GCSettings.LatencyMode; <br>   System.Runtime.CompilerServices.RuntimeHelpers.PrepareConstrainedRegions(); <br>   try { <br>      GCSettings.LatencyMode = GCLatencyMode.LowLatency; <br>      // Run your code here... <br>   } <br>   finally { <br>      GCSettings.LatencyMode = oldMode; <br>   } <br>}<br>
<b>Large Objects</b><br>
There is one more performance improvement you might want to be aware of. Any objects <br>that are 85,000 bytes or more in size are considered to be <i>large objects</i>. Large objects are al-<br>located from a special large object heap. Objects in this heap are finalized and freed just as <br>the small objects I've been talking about. However, large objects are never compacted be-<br>cause it would waste too much CPU time to shift 85,000-byte blocks of memory down in the <br>heap. However, you should never write code that assumes that large objects do not move in <br>memory because the size of large objects could change from 85,000 bytes to something else <br>in the future. To guarantee that an object doesn't move in memory, pin it as discussed in the <br>"Monitoring and Controlling the Lifetime of Objects Manually" section earlier in this chapter.<br>
Large objects are always considered part of generation 2, so you should create large objects <br>only for resources that you need to keep alive for a long time. Allocating short-lived large <br>objects will cause generation 2 to be collected more frequently, which will hurt performance. <br>The following program proves that large objects are always allocated in generation 2:<br>
using System;  <br>  <br>public static class Program {  <br>   public static void Main() {  <br>      Object o = new Byte[85000];  <br>      Console.WriteLine(GC.GetGeneration(o));  // Displays 2; not 0  <br>   }  <br>}<br>
All of these mechanisms are transparent to your application code. To you, the developer, <br>it appears as if there is just one managed heap; these mechanisms exist simply to improve <br>application performance.<br>
<hr>
<A name=607></a><b> </b><br>
<b>Chapter 21  Automatic Memory Management (Garbage Collection) </b><br>
<b>589</b><br>
<b>Monitoring Garbage Collections</b><br>
Within a process, there are a few methods that you can call to monitor the garbage collector. <br>Specifically, the GC class offers the following static methods, which you can call to see how <br>many collections have occurred of a specific generation or how much memory is currently <br>being used by objects in the managed heap:<br>
Int64 GetTotalMemory(Boolean forceFullCollection);  <br>Int32 CollectionCount(Int32 generation);<br>
To profile a particular code block, I have frequently written code to call these methods before  <br>and after the code block and then calculate the difference. This gives me a very good indica-<br>tion of how my code block has affected my process's working set and indicates how many <br>garbage collections occurred while executing the code block. If the numbers are high, I know <br>to spend more time tuning the algorithms in my code block.<br>
You can also see how much memory is being used by individual AppDomains as opposed to <br>the whole process. For more information about this, see the "AppDomain Monitoring" section <br>in Chapter 22.<br>
When you instal  the .NET Framework, it instal s a set of performance counters that offer a lot <br>of real-time statistics about the CLR's operations. These statistics are visible via the PerfMon.exe <br>tool or the System Monitor ActiveX control that ships with Windows. The easiest way to  <br>access the System Monitor control is to run PerfMon.exe and click the <i>+</i> toolbar button, <br>which causes the Add Counters dialog box shown in Figure 21-16 to appear.<br>
<b>FIGURE 21-16  </b>PerfMon.exe showing the .NET CLR Memory counters<br>
<hr>
<A name=608></a><b>590 </b><br>
<b>Part IV  Core Facilities</b><br>
To monitor the CLR's garbage collector, select the .NET CLR Memory performance object. <br>Then select a specific application from the instance list box. Finally, select the set of counters <br>that you're interested in monitoring, click Add, and then click OK. At this point, the System <br>Monitor will graph the selected real-time statistics. For an explanation of a particular counter, <br>select the desired counter and then select the Show Description check box.<br>
Another great tool for monitoring your application's object allocations is the CLR Profiler. <br>This tool offers call profiling, heap snapshots, and memory-use timelines. There is even an <br>API that can be used from test code to start and stop profiling and inject comments into the <br>logs. Also, the source code for this tool is available so that you can modify the tool for your <br>own needs. The best way to acquire this tool is for you to search the Web for <i>CLR profiler</i>. <br>This tool is invaluable, and I highly recommend it.<br>
Finally, you should look into using the SOS Debugging Extension (SOS.dll), which can often <br>offer great assistance when debugging memory problems and other CLR problems. For <br>memory-related actions, the SOS Debugging Extension allows you to see how much memory <br>is allocated within the process to the managed heap, displays all objects registered for final-<br>ization in the finalization queue, displays the entries in the GCHandle table per AppDomain <br>or for the entire process, shows the roots that are keeping an object alive in the heap, and <br>more.<br>
<hr>
<A name=609></a>Chapter 22<br><b>CLR Hosting and AppDomains</b><br>
<b>In this chapter:<br>CLR Hosting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 592<br>AppDomains  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 594<br>AppDomain Unloading  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 609<br>AppDomain Monitoring. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 610<br>AppDomain First-Chance Exception Notifications  . . . . . . . . . . . . . . . . . . . . . . . . 612<br>How Hosts Use AppDomains. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 612<br>Advanced Host Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 615</b><br>
In this chapter, I'll discuss two main topics that really show off the incredible value provided <br>by the Microsoft .NET Framework: <i>hosting</i> and <i>AppDomains</i>. Hosting allows any application <br>to utilize the features of the common language runtime (CLR). In particular, this allows exist-<br>ing applications to be at least partially written using managed code. Furthermore, hosting <br>allows applications the ability to offer customization and extensibility via programming.<br>
Allowing extensibility means that third-party code will be running inside your process. In <br>Microsoft Windows, loading a third party's DLLs into a process has been fraught with peril. <br>The DLL could easily have code in it that could compromise the application's data structures <br>and code. The DLL could also try to use the security context of the application to gain access <br>to resources that it should not have access to. The CLR's AppDomain feature solves all of <br>these problems. AppDomains allow third-party untrusted code to run in an existing process, <br>and the CLR guarantees that the data structures, code, and security context will not be  <br>exploited or compromised.<br>
Programmers typically use hosting and AppDomains along with assembly loading and reflec-<br>tion. Using these four technologies together makes the CLR an incredibly rich and powerful <br>platform. In this chapter, I'll focus on hosting and AppDomains. In the next chapter, I'll focus <br>on assembly loading and reflection. When you learn and understand all of these technologies, <br>you'll see how your investment in the .NET Framework today will certainly pay off down the <br>line.<br>
<b> </b><br>
<b> </b><br>
<b>591</b><br>
<hr>
<A name=610></a><b>592 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>CLR Hosting</b><br>
The .NET Framework runs on top of Microsoft Windows. This means that the .NET Framework <br>must be built using technologies that Windows can interface with. For starters, all managed <br>module and assembly files must use the Windows portable executable (PE) file format and be <br>either a Windows executable (EXE) file or a DLL.<br>
When developing the CLR, Microsoft implemented it as a COM server contained inside a DLL; <br>that is, Microsoft defined a standard COM interface for the CLR and assigned GUIDs to this <br>interface and the COM server. When you install the .NET Framework, the COM server rep-<br>resenting the CLR is registered in the Windows registry just as any other COM server would. <br>If you want more information about this topic, refer to the MetaHost.h C++ header file that <br>ships with the .NET Framework SDK. This header file defines the GUIDs and the unmanaged <br>ICLRMetaHost interface definition.<br>
Any Windows application can host the CLR. However, you shouldn't create an instance of the <br>CLR COM server by calling CoCreateInstance; instead, your unmanaged host should call <br>the CLRCreateInstance function declared in MetaHost.h. The CLRCreateInstance function <br>is implemented in the MSCorEE.dll file, which is usually found in the C:\Windows\System32 <br>directory. This DLL is affectionately referred to as the <i>shim</i>, and its job is to determine which <br>version of the CLR to create; the shim DLL doesn't contain the CLR COM server itself.<br>
A single machine may have multiple versions of the CLR installed, but there will be only  <br>one version of the MSCorEE.dll file (the shim).1 The version of MSCorEE.dll installed on the <br>machine is the version that shipped with the latest version of the CLR installed on the  <br>machine. Therefore, this version of MSCorEE.dll knows how to find any previous versions  <br>of the CLR that may be installed.<br>
The actual CLR code is contained in a file whose name has changed with different versions <br>of the CLR. For versions 1.0, 1.1, and 2.0, the CLR code is in a file called MSCorWks.dll, and <br>for version 4.0, the CLR code is in a file called Clr.dll. Since you can have multiple versions <br>of the CLR installed on a single machine, these files are installed into different directories as <br>follows.2<br>
  Version 1.0 is in C:\Windows\Microsoft.NET\Framework\v1.0.3705<br>
  Version 1.1 is in C:\Windows\Microsoft.NET\Framework\v1.0.4322<br>
  Version 2.0 is in C:\Windows\Microsoft.NET\Framework\v2.0.50727<br>
  Version 4.0 is in C:\Windows\Microsoft.NET\Framework\v4.0.21006<br>
1  If you are using a 64-bit version of Windows, there are actually two versions of the MSCorEE.dll file installed. One <br>
version is the 32-bit x86 version, which will be in the C:\Windows\SysWOW64 directory. The other version is the <br>64-bit x64 or IA64 version (depending on your computer's CPU architecture), which will be in the C:\Windows <br>\System32 directory.<br>
2  Note that versions 3.0 and 3.5 of the .NET Framework shipped with version 2.0 of the CLR; I do not show the  <br>
directories for .NET Framework versions 3.0 and 3.5 because the CLR DLL loads from the v2.0.50727 directory.<br>
<hr>
<A name=611></a><b> </b><br>
<b>Chapter 22  CLR Hosting and AppDomains </b><br>
<b>593</b><br>
The CLRCreateInstance function can return an ICLRMetaHost interface. A host application  <br>can call this interface's GetRuntime function, specifying the version of the CLR that the <br>host would like to create. The shim then loads the desired version of the CLR into the host's <br>process.<br>
By default, when a managed executable starts, the shim examines the executable file and  <br>extracts the information indicating the version of the CLR that the application was built  <br>and tested with. However, an application can override this default behavior by placing  <br>requiredRuntime and supportedRuntime entries in its XML configuration file (described in <br>Chapter 2, "Building, Packaging, Deploying, and Administering Applications and Types," and <br>Chapter 3, "Shared Assemblies and Strongly Named Assemblies").<br>
The GetRuntime function returns a pointer to the unmanaged ICLRRuntimeInfo interface <br>from which the ICLRRuntimeHost interface is obtained via the GetInterface method. The <br>hosting application can call methods defined by this interface to:<br>
  Set Host managers. Tell the CLR that the host wants to be involved in making decisions <br>
related to memory allocations, thread scheduling/synchronization, assembly loading,  <br>and more. The host can also state that it wants notifications of garbage collection <br>starts and stops and when certain operations time out.<br>
  Get CLR managers. Tell the CLR to prevent the use of some classes/members. In addi-<br>
tion, the host can tell which code can and can't be debugged and which methods in <br>the host should be called when a special event--such as an AppDomain unload, CLR <br>stop, or stack overflow exception--occurs.<br>
  Initialize and start the CLR.<br>
  Load an assembly and execute code in it.<br>
  Stop the CLR, thus preventing any more managed code from running in the Windows <br>
process.<br>
There are many reasons why hosting the CLR is useful. Hosting allows any application to offer  <br>CLR features and a programmability story and to be at least partially written in managed <br>code. Any application that hosts the runtime offers many benefits to developers who are  <br>trying to extend the application. Here are some of the benefits:<br>
  Programming can be done in any programming language.<br>
  Code is just-in-time (JIT)­compiled for speed (versus being interpreted).<br>
  Code uses garbage collection to avoid memory leaks and corruption.<br>
  Code runs in a secure sandbox.<br>
  The host doesn't need to worry about providing a rich development environment.  <br>
The host makes use of existing technologies: languages, compilers, editors, debuggers, <br>profilers, and more.<br>
<hr>
<A name=612></a><IMG src="CLRviaCsharp-612_1.jpg"><br>
<b>594 </b><br>
<b>Part IV  Core Facilities</b><br>
If you are interesting in using the CLR for hosting scenarios, I highly recommend that you <br>get Steven Pratschner's excellent book, <i>Customizing the Microsoft .NET Framework Common <br>Language Runtime</i> (Microsoft Press 2005), even though it focuses on pre-4.0 versions of the <br>CLR.<br>
<b>Note  </b>Of course, a Windows process does not need to load the CLR at all. It needs to be loaded <br>only if you want to execute managed code in a process. Prior to .NET Framework 4.0, the CLR <br>allowed only one instance of itself to reside within a Windows process. That is, a process could <br>contain no CLR, v1.0 of the CLR, v1.1 of the CLR, or v2.0 of the CLR. Allowing only one CLR  <br>version per process is a huge limitation. For example, Microsoft Office Outlook couldn't load  <br>two add-ins that were built and tested against different versions of the .NET Framework.<br>
However, with .NET Framework 4.0, Microsoft now supports the ability to load v2.0 and v4.0 in <br>a single Windows process, allowing components written for .NET Framework versions 2.0 and <br>4.0 to run side by side without experiencing any compatibility problems. This is a fantastic new <br>feature, as it allows .NET Framework components to be used reliably in more scenarios than ever <br>before. You can use the ClrVer.exe tool to see which CLR version(s) are loaded into any given  <br>process.<br>
Once a CLR is loaded into a Windows process, it can never be unloaded; calling the AddRef and <br>Release methods on the ICLRRuntimeHost interface has no effect. The only way for the CLR <br>to be unloaded from a process is for the process to terminate, causing Windows to clean up all <br>resources used by the process.<br>
<b>AppDomains</b><br>
When the CLR COM server initializes, it creates an <i>AppDomain</i>. An AppDomain is a logical <br>container for a set of assemblies. The first AppDomain created when the CLR is initialized is <br>called the <i>default AppDomain</i>; this AppDomain is destroyed only when the Windows process <br>terminates.<br>
In addition to the default AppDomain, a host using either unmanaged COM interface methods <br>or managed type methods can instruct the CLR to create additional AppDomains. The whole <br>purpose of an AppDomain is to provide isolation. Here are the specific features offered by an <br>AppDomain:<br>
<b>  Objects created by code in one AppDomain cannot be accessed directly by code in </b><br>
<b>another AppDomain  </b>When code in an AppDomain creates an object, that object is <br>"owned" by that AppDomain. In other words, the object is not allowed to live beyond <br>the lifetime of the AppDomain whose code constructed it. Code in other AppDomains <br>can access another AppDomain's object only by using marshal-by-reference or  <br>marshal-by-value semantics. This enforces a clean separation and boundary because <br>code in one AppDomain can't have a direct reference to an object created by code in <br>a different AppDomain. This isolation allows AppDomains to be easily unloaded from a <br>process without affecting code running in other AppDomains.<br>
<hr>
<A name=613></a><IMG src="CLRviaCsharp-613_1.jpg"><br>
<b> </b><br>
<b>Chapter 22  CLR Hosting and AppDomains </b><br>
<b>595</b><br>
<b>  AppDomains can be unloaded  </b>The CLR doesn't support the ability to unload a single <br>
assembly from an AppDomain. However, you can tell the CLR to unload an AppDomain, <br>which will cause all of the assemblies currently contained in it to be unloaded as well.<br>
<b>  AppDomains can be individually secured  </b>When created, an AppDomain can have a <br>
permission set applied to it that determines the maximum rights granted to assemblies <br>running in the AppDomain. This allows a host to load some code and be ensured that <br>the code cannot corrupt or read important data structures used by the host itself.<br>
<b>  AppDomains can be individually configured  </b>When created, an AppDomain can have <br>
a bunch of configuration settings associated with it. These settings mostly affect how <br>the CLR loads assemblies into the AppDomain. There are configuration settings related <br>to search paths, version binding redirects, shadow copying, and loader optimizations.<br>
<b>Important  </b>A great feature of Windows is that it runs each application in its own process  <br>address space. This ensures that code in one application cannot access code or data in use by <br>another application. Process isolation prevents security holes, data corruption, and other unpre-<br>dictable behaviors from occurring, making Windows and the applications running on it robust. <br>Unfortunately, creating processes in Windows is very expensive. The Win32 CreateProcess <br>function is very slow, and Windows requires a lot of memory to virtualize a process's address <br>space.<br>
However, if an application consists entirely of managed code that is verifiably safe and doesn't <br>call out into unmanaged code, there are no problems related to running multiple managed  <br>applications in a single Windows process. And AppDomains provide the isolation required to <br>secure, configure, and terminate each of these applications.<br>
Figure 22-1 shows a single Windows process that has one CLR COM server running in it. <br>This CLR is currently managing two AppDomains (although there is no hard-coded limit <br>to the number of AppDomains that could be running in a single Windows process). Each <br>AppDomain has its own loader heap, each of which maintains a record of which types have <br>been accessed since the AppDomain was created. These type objects were discussed in <br>Chapter 4, "Type Fundamentals"; each type object in the loader heap has a method table, <br>and each entry in the method table points to JIT-compiled native code if the method has <br>been executed at least once.<br>
<hr>
<A name=614></a><b>596 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Windows Process</b><br>
<b>AppDomain #1 (Default)</b><br>
<b>AppDomain #2</b><br>
Loader Heap<br>
MyApp.exe<br>
Loader Heap<br>
Wintellect.dll<br>
M1() M2()<br>
Type1<br>
...<br>
TypeLib.dll<br>
M1() M2()<br>
Type1<br>
...<br>
(x86) (x86)<br>
(x86) (x86)<br>
System.dll<br>
M1() M2()<br>
System.dll<br>
Type2<br>
...<br>
M1() M2()<br>
Type2<br>
...<br>
(x86) (x86)<br>
(x86) (x86)<br>
M1() M2()<br>
...<br>
...<br>
M1() M2()<br>
...<br>
...<br>
(x86) (x86)<br>
(x86) (x86)<br>
 <br>
Domain-Neutral Assemblies<br>
Loader Heap<br>
MSCorLib.dll<br>
M1() M2()<br>
Type1<br>
...<br>
(x86) (x86)<br>
M1() M2()<br>
Type2<br>
...<br>
(x86) (x86)<br>
M1() M2()<br>
...<br>
...<br>
(x86) (x86)<br>
Execution Engine<br>
(MSCorEE.dll (shim)          Clr.dll (actual CLR)<br>
<b>FIGURE 22-1  </b>A single Windows process hosting the CLR and two AppDomains<br>
In addition, each AppDomain has some assemblies loaded into it. AppDomain #1 (the default <br>AppDomain) has three assemblies: MyApp.exe, TypeLib.dll, and System.dll. AppDomain #2 <br>has two assemblies loaded into it: Wintellect.dll and System.dll.<br>
You'll notice that the System.dll assembly has been loaded into both AppDomains. If both <br>AppDomains are using a single type from System.dll, both AppDomains will have a type <br>object for the same type allocated in each loader heap; the memory for the type object is <br>not shared by all of the AppDomains. Furthermore, as code in an AppDomain calls methods <br>defined by a type, the method's Intermediate Language (IL) code is JIT-compiled, and the <br>resulting native code is associated with each AppDomain; the code for the method is not <br>shared by all AppDomains that call it.<br>
Not sharing the memory for the type objects or native code is wasteful. However, the whole  <br>purpose of AppDomains is to provide isolation; the CLR needs to be able to unload an  <br>AppDomain and free up all of its resources without adversely affecting any other AppDomain. <br>Replicating the CLR data structures ensures that this is possible. It also ensures that a type <br>used by multiple AppDomains has a set of static fields for each AppDomain.<br>
<hr>
<A name=615></a><b> </b><br>
<b>Chapter 22  CLR Hosting and AppDomains </b><br>
<b>597</b><br>
Some assemblies are expected to be used by several AppDomains. The best example is <br>MSCorLib.dll. This assembly contains System.Object, System.Int32, and all of the other <br>types that are so integral to the .NET Framework. This assembly is automatically loaded when <br>the CLR initializes, and all AppDomains share the types in this assembly. To reduce resource <br>usage, MSCorLib.dll is loaded in an AppDomain-neutral fashion; that is, the CLR maintains <br>a special loader heap for assemblies that are loaded in a domain-neutral fashion. All type <br>objects in this loader heap and all native code for methods of these types are shared by all <br>AppDomains in the process. Unfortunately, the benefit gained by sharing these resources <br>does come with a price: assemblies that are loaded domain-neutral can never be unloaded. <br>The only way to reclaim the resources used by them is to terminate the Windows process to <br>cause Windows to reclaim the resources.<br>
<b>Accessing Objects Across AppDomain Boundaries</b><br>
Code in one AppDomain can communicate with types and objects contained in another <br>AppDomain. However, access to these types and objects is allowed only through well- <br>defined mechanisms. The Ch22-1-AppDomains sample application below demonstrates how <br>to create a new AppDomain, load an assembly into it, and construct an instance of a type <br>defined in that assembly. The code shows the different behaviors when constructing a type <br>that is marshaled by reference, a type that is marshaled by value, and a type that can't be <br>marshaled at all. The code also shows how these differently marshaled objects behave when <br>the AppDomain that created them is unloaded. The Ch22-1-AppDomains sample application <br>has very little code in it, but I have added a lot of comments. After the code listing, I'll walk <br>through the code, explaining what the CLR is doing.<br>
private static void Marshalling() { <br>   // Get a reference to the AppDomain that that calling thread is executing in <br>   AppDomain adCallingThreadDomain = Thread.GetDomain(); <br> <br>   // Every AppDomain is assigned a friendly string name (helpful for debugging) <br>   // Get this AppDomain's friendly string name and display it <br>   String callingDomainName = adCallingThreadDomain.FriendlyName; <br>   Console.WriteLine("Default AppDomain's friendly name={0}", callingDomainName); <br> <br>   // Get &amp; display the assembly in our AppDomain that contains the `Main' method <br>   String exeAssembly = Assembly.GetEntryAssembly().FullName; <br>   Console.WriteLine("Main assembly={0}", exeAssembly); <br> <br>   // Define a local variable that can refer to an AppDomain <br>   AppDomain ad2 = null; <br> <br>   // *** DEMO 1: Cross-AppDomain Communication using Marshal-by-Reference *** <br>   Console.WriteLine("{0}Demo #1", Environment.NewLine); <br> <br>   // Create new AppDomain (security &amp; configuration match current AppDomain) <br>   ad2 = AppDomain.CreateDomain("AD #2", null, null); <br>   MarshalByRefType mbrt = null; <br> <br>
<hr>
<A name=616></a><b>598 </b><br>
<b>Part IV  Core Facilities</b><br>
   // Load our assembly into the new AppDomain, construct an object, marshal  <br>   // it back to our AD (we really get a reference to a proxy) <br>   mbrt = (MarshalByRefType) <br>      ad2.CreateInstanceAndUnwrap(exeAssembly, "MarshalByRefType"); <br> <br>   Console.WriteLine("Type={0}", mbrt.GetType());  // The CLR lies about the type <br> <br>   // Prove that we got a reference to a proxy object <br>   Console.WriteLine("Is proxy={0}", RemotingServices.IsTransparentProxy(mbrt)); <br> <br>   // This looks like we're calling a method on MarshalByRefType but, we're not. <br>   // We're calling a method on the proxy type. The proxy transitions the thread <br>   // to the AppDomain owning the object and calls this method on the real object. <br>   mbrt.SomeMethod(); <br> <br>   // Unload the new AppDomain <br>   AppDomain.Unload(ad2); <br>   // mbrt refers to a valid proxy object; the proxy object refers to an invalid AppDomain <br> <br>   try { <br>      // We're calling a method on the proxy type. The AD is invalid, exception is thrown <br>      mbrt.SomeMethod(); <br>      Console.WriteLine("Successful call."); <br>   } <br>   catch (AppDomainUnloadedException) { <br>      Console.WriteLine("Failed call."); <br>   } <br> <br> <br>   // *** DEMO 2: Cross-AppDomain Communication using Marshal-by-Value *** <br>   Console.WriteLine("{0}Demo #2", Environment.NewLine); <br> <br>   // Create new AppDomain (security &amp; configuration match current AppDomain) <br>   ad2 = AppDomain.CreateDomain("AD #2", null, null); <br> <br>   // Load our assembly into the new AppDomain, construct an object, marshal  <br>   // it back to our AD (we really get a reference to a proxy) <br>   mbrt = (MarshalByRefType) <br>      ad2.CreateInstanceAndUnwrap(exeAssembly, "MarshalByRefType"); <br> <br>   // The object's method returns a COPY of the returned object;  <br>   // the object is marshaled by value (not be reference). <br>   MarshalByValType mbvt = mbrt.MethodWithReturn(); <br> <br>   // Prove that we did NOT get a reference to a proxy object <br>   Console.WriteLine("Is proxy={0}", RemotingServices.IsTransparentProxy(mbvt)); <br> <br>   // This looks like we're calling a method on MarshalByValType and we are. <br>   Console.WriteLine("Returned object created " + mbvt.ToString()); <br> <br>   // Unload the new AppDomain <br>   AppDomain.Unload(ad2); <br>   // mbvt refers to valid object; unloading the AppDomain has no impact. <br> <br>   try { <br>
<hr>
<A name=617></a><b> </b><br>
<b>Chapter 22  CLR Hosting and AppDomains </b><br>
<b>599</b><br>
      // We're calling a method on an object; no exception is thrown <br>      Console.WriteLine("Returned object created " + mbvt.ToString()); <br>      Console.WriteLine("Successful call."); <br>   } <br>   catch (AppDomainUnloadedException) { <br>      Console.WriteLine("Failed call."); <br>   } <br> <br> <br>   // DEMO 3: Cross-AppDomain Communication using non-marshalable type *** <br>   Console.WriteLine("{0}Demo #3", Environment.NewLine); <br> <br>   // Create new AppDomain (security &amp; configuration match current AppDomain) <br>   ad2 = AppDomain.CreateDomain("AD #2", null, null); <br> <br>   // Load our assembly into the new AppDomain, construct an object, marshal  <br>   // it back to our AD (we really get a reference to a proxy) <br>   mbrt = (MarshalByRefType) <br>      ad2.CreateInstanceAndUnwrap(exeAssembly, "MarshalByRefType"); <br> <br>   // The object's method returns an non-marshalable object; exception <br>   NonMarshalableType nmt = mbrt.MethodArgAndReturn(callingDomainName); <br>   // We won't get here... <br>} <br> <br> <br>// Instances can be marshaled-by-reference across AppDomain boundaries <br>public sealed class MarshalByRefType : MarshalByRefObject { <br>   public MarshalByRefType() { <br>      Console.WriteLine("{0} ctor running in {1}", <br>         this.GetType().ToString(), Thread.GetDomain().FriendlyName); <br>   } <br> <br>   public void SomeMethod() { <br>      Console.WriteLine("Executing in " + Thread.GetDomain().FriendlyName); <br>   } <br> <br>   public MarshalByValType MethodWithReturn() { <br>      Console.WriteLine("Executing in " + Thread.GetDomain().FriendlyName); <br>      MarshalByValType t = new MarshalByValType(); <br>      return t; <br>   } <br> <br>   public NonMarshalableType MethodArgAndReturn(String callingDomainName) { <br>      // NOTE: callingDomainName is [Serializable] <br>      Console.WriteLine("Calling from `{0}' to `{1}'.", <br>         callingDomainName, Thread.GetDomain().FriendlyName); <br>      NonMarshalableType t = new NonMarshalableType(); <br>      return t; <br>   } <br>} <br> <br> <br>// Instances can be marshaled-by-value across AppDomain boundaries <br>[Serializable] <br>
<hr>
<A name=618></a><b>600 </b><br>
<b>Part IV  Core Facilities</b><br>
public sealed class MarshalByValType : Object { <br>   private DateTime m_creationTime = DateTime.Now; // NOTE: DateTime is [Serializable] <br> <br>   public MarshalByValType() { <br>      Console.WriteLine("{0} ctor running in {1}, Created on {2:D}", <br>         this.GetType().ToString(), <br>         Thread.GetDomain().FriendlyName, <br>         m_creationTime); <br>   } <br> <br>   public override String ToString() { <br>      return m_creationTime.ToLongDateString(); <br>   } <br>} <br> <br>// Instances cannot be marshaled across AppDomain boundaries <br>// [Serializable] <br>public sealed class NonMarshalableType : Object { <br>   public NonMarshalableType() { <br>      Console.WriteLine("Executing in " + Thread.GetDomain().FriendlyName); <br>   } <br>}<br>
If you build and run the Ch22-1-AppDomains application, you get the following output:<br>
Default AppDomain's friendly name= Ch22-1-AppDomains.exe <br>Main assembly=Ch22-1-AppDomains, Version=0.0.0.0, Culture=neutral, PublicKeyToken=null <br> <br>Demo #1 <br>MarshalByRefType ctor running in AD #2 <br>Type=MarshalByRefType <br>Is proxy=True <br>Executing in AD #2 <br>Failed call. <br> <br>Demo #2 <br>MarshalByRefType ctor running in AD #2 <br>Executing in AD #2 <br>MarshalByValType ctor running in AD #2, Created on Friday, August 07, 2009 <br>Is proxy=False <br>Returned object created Friday, August 07, 2009 <br>Returned object created Friday, August 07, 2009 <br>Successful call. <br> <br>Demo #3 <br>MarshalByRefType ctor running in AD #2 <br>Calling from 'Ch22-1-AppDomains.exe' to 'AD #2'. <br>Executing in AD #2 <br> <br>Unhandled Exception: System.Runtime.Serialization.SerializationException:  <br>Type `NonMarshalableType' in assembly `Ch22-1-AppDomains, Version=0.0.0.0,  <br>Culture=neutral, PublicKeyToken=null' is not marked as serializable. <br>at MarshalByRefType.MethodArgAndReturn(String callingDomainName) <br>at Program.Marshalling() <br>at Program.Main()  <br>is not marked as serializable. <br>
<hr>
<A name=619></a><b> </b><br>
<b>Chapter 22  CLR Hosting and AppDomains </b><br>
<b>601</b><br>
at MarshalByRefType.MethodArgAndReturn(String callingDomainName) <br>   at Program.Marshalling() <br>   at Program.Main()<br>
Now, I will discuss what this code and the CLR are doing.<br>
Inside the Marshalling method, I first get a reference to an AppDomain object that identifies  <br>the AppDomain the calling thread is currently executing in. In Windows, a thread is always <br>created in the context of one process, and the thread lives its entire lifetime in that process. <br>However, a one-to-one correspondence doesn't exist between threads and AppDomains. <br>AppDomains are a CLR feature; Windows knows nothing about AppDomains. Since multiple  <br>AppDomains can be in a single Windows process, a thread can execute code in one <br>AppDomain and then execute code in another AppDomain. From the CLR's perspective, a  <br>thread is executing code in one AppDomain at a time. A thread can ask the CLR what <br>AppDomain it is currently executing in by calling System.Threading.Thread's static <br>GetDomain method. The thread could also query System.AppDomain's static, read-only <br>CurrentDomain property to get the same information.<br>
When an AppDomain is created, it can be assigned a <i>friendly name</i>. A friendly name is just  <br>a String that you can use to identify an AppDomain. This is typically useful in debugging <br>scenarios. Since the CLR creates the default AppDomain before any of our code can run,  <br>the CLR uses the executable file's file name as the default AppDomain's friendly name.  <br>My Marshalling method queries the default AppDomain's friendly name by using  <br>System.AppDomain's read-only FriendlyName property.<br>
Next, my Marshalling method queries the strong-name identity of the assembly (loaded  <br>into the default AppDomain) that defines the entry point method Main that calls <br>Marshalling. This assembly defines several types: Program,<b> </b>MarshalByRefType,<b> </b>MarshalBy <br>ValType, and NonMarshalableType. At this point, we're ready to look at the three demos <br>that are all pretty similar to each other.<br>
<b>Demo #1: Cross-AppDomain Communication that Uses Marshal-by-</b><br>
<b>Reference<br></b>In Demo #1, System.AppDomain's static CreateDomain method is called, instructing the  <br>CLR to create a new AppDomain in the same Windows process. The AppDomain type actually  <br>offers several overloads of the CreateDomain method; I encourage you to study them <br>and select the version that is most appropriate when you are writing code to create a new <br>AppDomain. The version of CreateDomain that I call accepts three arguments:<br>
<b>  A </b>String<b> identifying the friendly name I want assigned to the new AppDomain  </b>I'm <br>
passing in "AD #2" here.<br>
<b>  A </b>System.Security.Policy.Evidence<b> identifying the evidence that the CLR should </b><br>
<b>use to calculate the AppDomain's permission set  </b>I'm passing null here so that the <br>new AppDomain will inherit the same permission set as the AppDomain creating it. <br>
<hr>
<A name=620></a><IMG src="CLRviaCsharp-620_1.jpg"><br>
<b>602 </b><br>
<b>Part IV  Core Facilities</b><br>
Usually, if you want to create a security boundary around code in an AppDomain, you'd <br>construct a System.Security.PermissionSet object, add the desired permission <br>objects to it (instances of types that implement the IPermission interface), and then <br>pass the resulting PermissionSet object reference to the overloaded version of the <br>CreateDomain method that accepts a PermissionSet.<br>
<b>  A </b>System.AppDomainSetup<b> identifying the configuration settings the CLR should use </b><br>
<b>for the new AppDomain  </b>Again, I'm passing null here so that the new AppDomain <br>will inherit the same configuration settings as the AppDomain creating it. If you want <br>the AppDomain to have a special configuration, construct an AppDomainSetup object, <br>set its various properties to whatever you desire such as the name of the configuration <br>file for example, and then pass the resulting AppDomainSetup object reference to the <br>CreateDomain method.<br>
Internally, the CreateDomain method creates a new AppDomain in the process. This <br>AppDomain will be assigned the specified friendly name, security, and configuration settings. <br>The new AppDomain will have its very own loader heap, which will be empty because <br>there are currently no assemblies loading into the new AppDomain. When you create an <br>AppDomain, the CLR does not create any threads in this AppDomain; no code runs in the <br>AppDomain unless you explicitly have a thread call code in the AppDomain.<br>
Now to create an instance of an object in the new AppDomain, we must first load an assembly <br>into the new AppDomain and then construct an instance of a type defined in this assembly. <br>This is precisely what the call to AppDomain's public, instance CreateInstanceAndUnwrap <br>method does. When calling CreateInstanceAndUnwrap, I pass two arguments: a String <br>identifying the assembly I want loaded into the new AppDomain (referenced by the ad2 <br>variable) and another String identifying the name of the type that I want to construct an <br>instance of. Internally, CreateInstanceAndUnwrap causes the calling thread to transition <br>from the current AppDomain into the new AppDomain. Now, the thread (which is inside the <br>call to CreateInstanceAndUnwrap) loads the specified assembly into the new AppDomain <br>and then scans the assembly's type definition metadata table, looking for the specified type <br>("MarshalByRefType"). After the type is found, the thread calls the MarshalByRefType's  <br>parameterless constructor. Now the thread transitions back to the default AppDomain so that <br>CreateInstanceAndUnwrap can return a reference to the newMarshalByRefType object.<br>
<b>Note  </b>There are overloaded versions of CreateInstanceAndUnwrap that allow you to call <br>a type's constructor passing in arguments.<br>
While this sounds all fine and good, there is a problem: the CLR cannot allow a variable <br>(root) living in one AppDomain to reference an object created in another AppDomain. <br>If CreateInstanceAndUnwrap simply returned the reference to the object, isolation <br>would be broken, and isolation is the whole purpose of AppDomains! So just before <br>CreateInstanceAndUnwrap returns the object reference, it performs some additional logic.<br>
<hr>
<A name=621></a><b> </b><br>
<b>Chapter 22  CLR Hosting and AppDomains </b><br>
<b>603</b><br>
You'll notice that the MarshalByRefType type is derived from a very special base class: <br>System.MarshalByRefObject. When CreateInstanceAndUnwrap sees that it is marshalling  <br>an object whose type is derived from MarshalByRefObject, the CLR will marshal the object  <br>by reference across the AppDomain boundaries. Here is what it means to marshal an object  <br>by reference from one AppDomain (the source AppDomain where the object is real y created) <br>to another AppDomain (the destination AppDomain from where CreateInstanceAndUnwrap <br>is called).<br>
When a source AppDomain wants to send or return the reference of an object to a destination <br>AppDomain, the CLR defines a proxy type in the destination AppDomain's loader heap. This <br>proxy type is defined using the original type's metadata, and therefore, it looks exactly like <br>the original type; it has all of the same instance members (properties, events, and methods). <br>The instance fields are not part of the type, but I'll talk more about this in a moment. This <br>new type does have some instance fields defined inside of it, but these fields are not identi-<br>cal to that of the original data type. Instead, these fields indicate which AppDomain "owns" <br>the real object and how to find the real object in the owning AppDomain. (Internally, the <br>proxy object uses a GCHandle instance that refers to the real object. The GCHandle type is <br>discussed in Chapter 21, "Automatic Memory Management (Garbage Collection)."<br>
Once this type is defined in the destination AppDomain, CreateInstanceAndUnwrap creates  <br>an instance of this proxy type, initializes its fields to identify the source AppDomain and the <br>real object, and returns a reference to this proxy object to the destination AppDomain. In my <br>Ch22-1-AppDomains application, the mbrt variable will be set to refer to this proxy. Notice <br>that the object returned from CreateInstanceAndUnwrap is actually not an instance of the  <br>MarshalByRefType type. The CLR will usually not allow you to cast an object of one type to  <br>an incompatible type. However, in this situation, the CLR does allow the cast because this new <br>type has the same instance members as defined on the original type. In fact, if you use the <br>proxy object to call GetType, it actually lies to you and says that it is a MarshalByRefType <br>object.<br>
However, it is possible to prove that the object returned from CreateInstanceAndUnwrap is <br>actually a reference to a proxy object. To do this, my Ch22-1-AppDomains application calls <br>System.Runtime.Remoting.RemotingService's public, static IsTransparentProxy method <br>passing in the reference returned from CreateInstanceAndUnwrap. As you can see from the <br>output, IsTransparentProxy returns true, indicating that the object is a proxy.<br>
Now, my Ch22-1-AppDomains application uses the proxy to call the SomeMethod method. <br>Since the mbrt variable refers to a proxy object, the proxy's implementation of this method <br>is called. The proxy's implementation uses the information fields inside the proxy object to <br>transition the calling thread from the default AppDomain to the new AppDomain. Any actions <br>now performed by this thread run under the new AppDomain's security and configuration <br>settings. Then, the thread uses the proxy object's GCHandle field to find the real object in the <br>new AppDomain, and then it uses the real object to call the real SomeMethod method.<br>
<hr>
<A name=622></a><IMG src="CLRviaCsharp-622_1.jpg"><br>
<b>604 </b><br>
<b>Part IV  Core Facilities</b><br>
There are two ways to prove that the calling thread has transitioned from the default <br>AppDomain to the new AppDomain. First, inside the SomeMethod method, I call  <br>Thread.GetDomain().FriendlyName. This will return "AD #2" (as evidenced by the  <br>output) since the thread is now running in the new AppDomain created by using  <br>AppDomain.CreateDomain with "AD #2" as the friendly name parameter. Second, if you <br>step through the code in a debugger and display the Call Stack window, the [AppDomain <br>Transition] line marks where a thread has transitioned across an AppDomain boundary. See <br>the Call Stack window near the bottom of Figure 22-2.<br>
<b>FIGURE 22-2  </b>The Debugger's Call Stack window showing an AppDomain transition<br>
When the real SomeMethod method returns, it returns to the proxy's SomeMethod method, <br>which transitions the thread back to the default AppDomain, and then the thread continues <br>executing code in the default AppDomain.<br>
<b>Note  </b>When a thread in one AppDomain calls a method in another AppDomain, the thread <br>transitions between the two AppDomains. This means that method calls across AppDomain <br>boundaries are executed synchronously. However, at any given time, a thread is considered to be <br>in just one AppDomain, and it executes code using that AppDomain's security and configuration <br>settings. If you want to execute code in multiple AppDomains concurrently, you should create <br>additional threads and have them execute whatever code you desire in whatever AppDomains <br>you desire.<br>
The next thing that my Ch22-1-AppDomains application does is call AppDomain's public, <br>static Unload method to force the CLR to unload the specified AppDomain including all of <br>the assemblies loaded into it, and a garbage collection is forced to free up any objects that <br>were created by code in the unloading AppDomain. At this point, the default AppDomain's <br>mbrt variable still refers to a valid proxy object; however, the proxy object no longer refers to <br>a valid AppDomain (because it has been unloaded).<br>
<hr>
<A name=623></a><hr>
<A name=624></a><hr>
<A name=625></a><IMG src="CLRviaCsharp-625_1.jpg"><br>
<b> </b><br>
<b>Chapter 22  CLR Hosting and AppDomains </b><br>
<b>607</b><br>
MarshalByValType is not derived from System.MarshalByRefObject, and therefore, the <br>CLR cannot define a proxy type to create an instance from; the object can't be marshaled by <br>reference across the AppDomain boundary.<br>
However, since MarshalByValType is marked with the [Serializable] custom attribute, <br>MethodWithReturn is allowed to marshal the object by value. The next paragraph describes <br>what it means to marshal an object by value from one AppDomain (the source AppDomain) <br>to another AppDomain (the destination AppDomain). For more information about the CLR"s <br>serialization and deserialization mechanisms, see Chapter 24, "Runtime Serialization."<br>
When a source AppDomain wants to send or return a reference to an object to a destination <br>AppDomain, the CLR serializes the object's instance fields into a byte array. This byte array is <br>copied from the source AppDomain to the destination AppDomain. Then, the CLR deserial-<br>izes the byte array in the destination AppDomain. This forces the CLR to load the assembly <br>that defines the type being deserialized into the destination AppDomain if it is not already <br>loaded. Then, the CLR creates an instance of the type and uses the values in the byte array to <br>initialize the object's fields so that they have values identical to those they had in the original <br>object. In other words, the CLR makes an exact duplicate of the source object in the destina-<br>tion's AppDomain. MethodWithReturn then returns a reference to this copy; the object has <br>been marshaled by value across the AppDomain's boundary.<br>
<b>Important  </b>When loading the assembly, the CLR uses the destination AppDomain's policies <br>and configuration settings (for example, the AppDomain can have a different AppBase directory <br>or different version binding redirections). These policy differences might prevent the CLR from <br>locating the assembly. If the assembly cannot be loaded, an exception will be thrown, and the <br>destination will not receive a reference to the object.<br>
At this point, the object in the source AppDomain and the object in the destination <br>AppDomain live separate lifetimes, and their states can change independently of each <br>other. If there are no roots in the source AppDomain keeping the original object alive (as <br>in my Ch22-1-AppDomains application), its memory will be reclaimed at the next garbage <br>collection.<br>
To prove that the object returned from MethodWithReturn is not a reference to a proxy object, <br>my Ch22-1-AppDomains application cal s System.Runtime.Remoting.RemotingService's <br>public, static IsTransparentProxy method passing in the reference returned from <br>MethodWithReturn. As you can see from the output, IsTransparentProxy returns false,  <br>indicating that the object is a real object, not a proxy.<br>
Now, my program uses the real object to call the ToString method. Since the mbvt variable <br>refers to a real object, the real implementation of this method is called, and no AppDomain <br>transition occurs. This can be evidenced by examining the debugger's Call Stack window, <br>which will not show an [Appdomain Transition] line.<br>
<hr>
<A name=626></a><b>608 </b><br>
<b>Part IV  Core Facilities</b><br>
To further prove that no proxy is involved, my Ch22-1-AppDomains application unloads the <br>new AppDomain and then attempts to call the ToString method again. Unlike in Demo #1, <br>the call succeeds this time because unloading the new AppDomain had no impact on objects <br>"owned" by the default AppDomain, and this includes the object that was marshaled by <br>value.<br>
<b>Demo #3: Cross-AppDomain Communication Using Non-Marshalable </b><br>
<b>Types<br></b>Demo #3 starts out very similar to Demos #1 and #2. Just as in Demos #1 and #2, an <br>AppDomain is created. Then, CreateInstanceAndUnwrap is called to load the same assembly <br>into the new AppDomain, create a MarshalByValType object in this new AppDomain, and <br>have the mbrt variable refer to a proxy to this object.<br>
Then, using this proxy, I call MethodArgAndReturn, which accepts an argument. Again, <br>the CLR must maintain AppDomain isolation, so it cannot simply pass the reference <br>to the argument into the new AppDomain. If the type of the object is derived from <br>MarshalByRefObject, the CLR will make a proxy for it and marshal it by reference. If the  <br>object's type is marked as [Serializable], the CLR wil  serialize the object (and its children)  <br>to a byte array, marshal the byte array into the new AppDomain, and then deserialize  <br>the byte array into an object graph, passing the root of the object graph into the <br>MethodArgAndReturn method.<br>
In this particular demo, I am passing a System.String object across AppDomain boundaries. <br>The System.String type is not derived from MarshalByRefObject, so the CLR cannot  <br>create a proxy. Fortunately, System.String is marked as [Serializable], and therefore  <br>the CLR can marshal it by value, which allows the code to work. Note that for String  <br>objects, the CLR performs a special optimization. When marshaling a String object across <br>an AppDomain boundary, the CLR just passes the reference to the String object across <br>the boundary; it does not make a copy of the String object. The CLR can offer this opti-<br>mization because String objects are immutable; therefore, it is impossible for code in one <br>AppDomain to corrupt a String object's characters. For more about String immutability, <br>see Chapter 14, "Chars, Strings, and Working with Text."4<br>
Inside MethodArgAndReturn, I display the string passed into it to show that the <br>string came across the AppDomain boundary, and then I create an instance of the <br>NonMarshalableType type and return a reference to this object to the default AppDomain. <br>Since NonMarshalableType is not derived from System.MarshalByRefObject and is also <br>not marked with the [Serializable] custom attribute, MethodArgAndReturn is not  <br>allowed to marshal the object by reference or by value--the object cannot be marshaled <br>
4  By the way, this is why the System.String class is sealed. If the class were not sealed, then you could define your <br>
own class derived from String and add your own fields. If you did this, there is no way that the CLR could ensure <br>that your "string" class was immutable.<br>
<hr>
<A name=627></a><IMG src="CLRviaCsharp-627_1.jpg"><br>
<b> </b><br>
<b>Chapter 22  CLR Hosting and AppDomains </b><br>
<b>609</b><br>
across an AppDomain boundary at all! To report this, MethodArgAndReturn throws a <br>SerializationException in the default AppDomain. Since my program doesn't catch this <br>exception, the program just dies.<br>
<b>AppDomain Unloading</b><br>
One of the great features of AppDomains is that you can unload them. Unloading an <br>AppDomain causes the CLR to unload all of the assemblies in the AppDomain, and the CLR <br>frees the AppDomain's loader heap as well. To unload an AppDomain, you call AppDomain's <br>Unload static method (as the Ch22-1-AppDomains application does). This call causes the CLR <br>to perform a lot of actions to gracefully unload the specified AppDomain:<br>
<b> </b><br>
<b>1.  </b>The CLR suspends all threads in the process that have ever executed managed code.<br>
<b> </b><br>
<b>2.  </b>The CLR examines all of the threads' stacks to see which threads are currently execut-<br>
ing code in the AppDomain being unloaded or which threads might return at some <br>point to code in the AppDomain that is being unloaded. The CLR forces any threads <br>that have the unloading AppDomain on their stack to throw a ThreadAbortException <br>(resuming the thread's execution). This causes the threads to unwind, executing any <br>finally blocks on their way out so that cleanup code executes. If no code catches the <br>ThreadAbortException, it will eventually become an unhandled exception that the <br>CLR swallows; the thread dies, but the process is allowed to continue running. This is <br>unusual because for all other unhandled exceptions, the CLR kills the process.<br>
<b>Important  </b>The CLR will not immediately abort a thread that is currently executing code <br>in a finally block, catch block, a class constructor, a critical execution region, or in <br>unmanaged code. If the CLR allowed this, cleanup code, error recovery code, type initial-<br>ization code, critical code, or arbitrary code that the CLR knows nothing about would not <br>complete, resulting in the application behaving unpredictably and with potential security <br>holes. An aborting thread is allowed to finish executing these code blocks and then, at the <br>end of the code block, the CLR forces the thread to throw a ThreadAbortException<b>.</b><br>
<b> </b><br>
<b>3.  </b>After all threads discovered in step #2 have left the AppDomain, the CLR then walks <br>
the heap and sets a flag in each proxy object that referred to an object created by the <br>unloaded AppDomain. These proxy objects now know that the real object they referred <br>to is gone. If any code now calls a method on an invalid proxy object, the method will <br>throw an AppDomainUnloadedException.<br>
<b> </b><br>
<b>4.  </b>The CLR forces a garbage collection to occur, reclaiming the memory used by any ob-<br>
jects that were created by the now unloaded AppDomain. The Finalize methods for <br>these objects are called, giving the objects a chance to clean themselves up properly.<br>
<b> </b><br>
<b>5.  </b>The CLR resumes all of the remaining threads. The thread that called AppDomain.<br>
Unload will now continue running; calls to AppDomain.Unload occur synchronously.<br>
<hr>
<A name=628></a><IMG src="CLRviaCsharp-628_1.jpg"><br>
<b>610 </b><br>
<b>Part IV  Core Facilities</b><br>
My Ch22-1-AppDomains application uses just one thread to do all of the work. Whenever my <br>code calls AppDomain.Unload, there are no threads in the unloading AppDomain, and there-<br>fore, the CLR doesn't have to throw any ThreadAbortException exceptions. I'll talk more <br>about ThreadAbortException later in this chapter.<br>
By the way, when a thread calls AppDomain.Unload, the CLR waits 10 seconds for the <br>threads in the unloading AppDomain to leave it. If after 10 seconds, the thread that called <br>AppDomain.Unload doesn't return, it will throw a CannotUnloadAppDomainException, and <br>the AppDomain may or may not be unloaded in the future.<br>
<b>Note  </b>If a thread calling AppDomain.Unload is in the AppDomain being unloaded, the CLR  <br>creates another thread that attempts to unload the AppDomain. The first thread will forcibly <br>throw the ThreadAbortException and unwind. The new thread will wait for the AppDomain to <br>unload, and then the new thread terminates. If the AppDomain fails to unload, the new thread <br>will process a CannotUnloadAppDomainException, but since you did not write the code that <br>this new thread executes, you can't catch this exception.<br>
<b>AppDomain Monitoring</b><br>
A host application can monitor the resources that an AppDomain consumes. Some hosts will <br>use this information to decide when to forcibly unload an AppDomain should its memory <br>or CPU consumption rise above what the host considers reasonable. Monitoring can also be <br>used to compare the resource consumption of different algorithms to determine which uses <br>fewer resources. Because AppDomain monitoring incurs additional overhead, hosts must <br>explicitly turn the monitoring on by setting AppDomain's static MonitoringEnabled property <br>to true. This turns on monitoring for all AppDomains. Once monitoring is turned on, it can-<br>not be turned off; attempting to set the MonitoringEnabled property to false causes an <br>ArgumentException to be thrown.<br>
Once monitoring is turned on, your code can query the following four read-only properties <br>offered by the AppDomain class:<br>
<b>  </b>MonitoringSurvivedProcessMemorySize<b>  </b>This static Int64 property returns the <br>
number of bytes that are currently in use by all AppDomains controlled by the current <br>CLR instance. The number is accurate as of the last garbage collection.<br>
<b>  </b>MonitoringTotalAllocatedMemorySize<b>  </b>This instance Int64 property returns the <br>
number of bytes that have been allocated by a specific AppDomain. The number is ac-<br>curate as of the last garbage collection.<br>
<b>  </b>MonitoringSurvivedMemorySize<b>  </b>This instance Int64 property returns the number <br>
of bytes that are currently in use by a specific AppDomain. The number is accurate as of <br>the last garbage collection.<br>
<hr>
<A name=629></a><b> </b><br>
<b>Chapter 22  CLR Hosting and AppDomains </b><br>
<b>611</b><br>
<b>  </b>MonitoringTotalProcessorTime<b>  </b>This instance TimeSpan property returns the <br>
amount of CPU usage incurred by a specific AppDomain.<br>
The following class shows how to use three of these properties to see what has changed <br>within an AppDomain between two points in time:<br>
private sealed class AppDomainMonitorDelta : IDisposable { <br>   private AppDomain m_appDomain; <br>   private TimeSpan m_thisADCpu; <br>   private Int64 m_thisADMemoryInUse; <br>   private Int64 m_thisADMemoryAllocated; <br> <br>   static AppDomainMonitorDelta() { <br>      // Make sure that AppDomain monitoring is turned on <br>      AppDomain.MonitoringIsEnabled = true; <br>   } <br> <br>   public AppDomainMonitorDelta(AppDomain ad) { <br>      m_appDomain = ad ?? AppDomain.CurrentDomain; <br>      m_thisADCpu = m_appDomain.MonitoringTotalProcessorTime; <br>      m_thisADMemoryInUse = m_appDomain.MonitoringSurvivedMemorySize; <br>      m_thisADMemoryAllocated = m_appDomain.MonitoringTotalAllocatedMemorySize; <br>   } <br> <br>   public void Dispose() { <br>      GC.Collect(); <br>      Console.WriteLine("FriendlyName={0}, CPU={1}ms", m_appDomain.FriendlyName, <br>         (m_appDomain.MonitoringTotalProcessorTime - m_thisADCpu).TotalMilliseconds); <br>      Console.WriteLine("   Allocated {0:N0} bytes of which {1:N0} survived GCs", <br>         m_appDomain.MonitoringTotalAllocatedMemorySize - m_thisADMemoryAllocated, <br>         m_appDomain.MonitoringSurvivedMemorySize - m_thisADMemoryInUse); <br>    } <br>}<br>
The following code shows how to use the AppDomainMonitorDelta class:<br>
private static void AppDomainResourceMonitoring() { <br>    using (new AppDomainMonitorDelta(null)) { <br>       // Allocate about 10 million bytes that will survive collections <br>       var list = new List&lt;Object&gt;(); <br>       for (Int32 x = 0; x &lt; 1000; x++) list.Add(new Byte[10000]); <br> <br>       // Allocate about 20 million bytes that will NOT survive collections <br>       for (Int32 x = 0; x &lt; 2000; x++) new Byte[10000].GetType(); <br> <br>       // Spin the CPU for about 5 seconds <br>       Int64 stop = Environment.TickCount + 5000; <br>       while (Environment.TickCount &lt; stop) ; <br>   } <br>}<br>
When I execute this code, I get the following output:<br>
FriendlyName=03-Ch22-1-AppDomains.exe, CPU=5031.25ms <br>   Allocated 30,159,496 bytes of which 10,085,080 survived GCs<br>
<hr>
<A name=630></a><b>612 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>AppDomain First-Chance Exception Notifications</b><br>
Each AppDomain can have associated with it a series of callback methods that get invoked <br>when the CLR begins looking for catch blocks within an AppDomain. These methods can <br>perform logging, or a host can use this mechanism to monitor exceptions being thrown <br>within an AppDomain. The callbacks cannot handle the exception or swallow it in any way; <br>they are just receiving a notification that the exception has occurred. To register a callback <br>method, just add a delegate to AppDomain's instance FirstChanceException event.<br>
Here is how the CLR processes an exception: When the exception is first thrown, the CLR in-<br>vokes any FirstChanceException callback methods registered with the AppDomain that is <br>throwing the exception. Then, the CLR looks for any catch blocks on the stack that are within <br>the same AppDomain. If a catch block handles the exception, then processing of the excep-<br>tion is complete and execution continues as normal. If the AppDomain has no catch block to <br>handle the exception, then the CLR walks up the stack to the calling AppDomain and throws <br>the same exception object again (after serializing and deserializing it). At this point, it is as <br>if a brand new exception is being thrown, and the CLR invokes any FirstChanceException <br>callback methods registered with the now current AppDomain. This continues until the top of <br>the thread's stack is reached. At that point, if the exception is not handled by any code, the <br>CLR terminates the whole process.<br>
<b>How Hosts Use AppDomains</b><br>
So far, I've talked about hosts and how they load the CLR. I've also talked about how the <br>hosts tell the CLR to create and unload AppDomains. To make the discussion more concrete, <br>I'll describe some common hosting and AppDomain scenarios. In particular, I'll explain how <br>different application types host the CLR and how they manage AppDomains.<br>
<b>Executable Applications</b><br>
Console UI applications, NT Service applications, Windows Forms applications, and Windows <br>Presentation Foundation (WPF) applications are all examples of self-hosted applications <br>that have managed EXE files. When Windows initializes a process using a managed EXE file, <br>Windows loads the shim and the shim examines the CLR header information contained in the <br>application's assembly (the EXE file). The header information indicates the version of the CLR <br>that was used to build and test the application. The shim uses this information to determine <br>which version of the CLR to load into the process. After the CLR loads and initializes, it again <br>examines the assembly's CLR header to determine which method is the application's entry <br>point (Main). The CLR invokes this method, and the application is now up and running.<br>
<hr>
<A name=631></a><IMG src="CLRviaCsharp-631_1.jpg"><br>
<b> </b><br>
<b>Chapter 22  CLR Hosting and AppDomains </b><br>
<b>613</b><br>
As the code runs, it accesses other types. When referencing a type contained in another  <br>assembly, the CLR locates the necessary assembly and loads it into the same AppDomain. <br>Any additionally referenced assemblies also load into the same AppDomain. When the  <br>application's Main method returns, the Windows process terminates (destroying the default <br>AppDomain and all other AppDomains).<br>
<b>Note  </b>By the way, you can call System.Environment's static Exit method if you want to shut <br>down the Windows process including all of its AppDomains. Exit is the most graceful way of <br>terminating a process because it first calls the Finalize methods of all of the objects on the <br>managed heap and then releases all of the unmanaged COM objects held by the CLR. Finally, <br>Exit calls the Win32 ExitProcess function.<br>
It's possible for the application to tell the CLR to create additional AppDomains in the  <br>process's address space. In fact, this is what my Ch22-1-AppDomains application did.<br>
<b>Microsoft Silverlight Rich Internet Applications</b><br>
Microsoft's Silverlight runtime technology uses a special CLR that is different from the normal <br>desktop version of the .NET Framework. Once the Silverlight runtime is installed, navigat-<br>ing to a Web site that uses Silverlight causes the Silverlight CLR (CoreClr.dll) to load in your <br>browser (which may or may not be Windows Internet Explorer--you may not even be using <br>a Windows machine). Each Silverlight control on the page runs in its own AppDomain. When <br>the user closes a tab or navigates to another Web site, any Silverlight controls no longer in <br>use have their AppDomains unloaded. The Silverlight code running in the AppDomain runs in <br>a limited-security sandbox so that it cannot harm the user or the machine in any way.<br>
<b>Microsoft ASP.NET Web Forms and XML Web Services </b><br>
<b>Applications</b><br>
ASP.NET is implemented as an ISAPI DLL (implemented in ASPNet_ISAPI.dll). The first time <br>a client requests a URL handled by the ASP.NET ISAPI DLL, ASP.NET loads the CLR. When a <br>client makes a request of a Web application, ASP.NET determines if this is the first time a re-<br>quest has been made. If it is, ASP.NET tells the CLR to create a new AppDomain for this Web <br>application; each Web application is identified by its virtual root directory. ASP.NET then tells <br>the CLR to load the assembly that contains the type exposed by the Web application into this <br>new AppDomain, creates an instance of this type, and starts calling methods in it to satisfy <br>the client's Web request. If the code references more types, the CLR will load the required <br>assemblies into the Web application's AppDomain.<br>
<hr>
<A name=632></a><b>614 </b><br>
<b>Part IV  Core Facilities</b><br>
When future clients make requests of an already running Web application, ASP.NET doesn't <br>create a new AppDomain; instead, it uses the existing AppDomain, creates a new instance <br>of the Web application's type, and starts calling methods. The methods will already be JIT-<br>compiled into native code, so the performance of processing all subsequent client requests is <br>excellent.<br>
If a client makes a request of a different Web application, ASP.NET tells the CLR to create a <br>new AppDomain. This new AppDomain is typically created inside the same worker process as <br>the other AppDomains. This means that many Web applications run in a single Windows pro-<br>cess, which improves the efficiency of the system overall. Again, the assemblies required by <br>each Web application are loaded into an AppDomain created for the sole purpose of isolat-<br>ing that Web application's code and objects from other Web applications.<br>
A fantastic feature of ASP.NET is that the code for a Web site can be changed on the fly with-<br>out shutting down the Web server. When a Web site's file is changed on the hard disk, ASP.<br>NET detects this, unloads the AppDomain that contains the old version of the files (when <br>the last currently running request finishes), and then creates a new AppDomain, loading into <br>it the new versions of the files. To make this happen, ASP.NET uses an AppDomain feature <br>called <i>shadow copying</i>.<br>
<b>Microsoft SQL Server</b><br>
Microsoft SQL Server is an unmanaged application because most of its code is still written in <br>unmanaged C++. SQL Server allows developers to create stored procedures by using man-<br>aged code. The first time a request comes in to the database to run a stored procedure writ-<br>ten in managed code, SQL Server loads the CLR. Stored procedures run in their own secured <br>AppDomain, prohibiting the stored procedures from adversely affecting the database server.<br>
This functionality is absolutely incredible! It means that developers will be able to write <br>stored procedures in the programming language of their choice. The stored procedure can <br>use strongly typed data objects in its code. The code will also be JIT-compiled into native <br>code when executed instead of being interpreted. And developers can take advantage of any <br>types defined in the Framework Class Library (FCL) or in any other assembly. The result is that <br>our job becomes much easier and our applications perform much better. What more could a <br>developer ask for?!<br>
<b>Your Own Imagination</b><br>
Productivity applications such as word processors and spreadsheets also allow users to write <br>macros in any programming language they choose. These macros will have access to all of <br>the assemblies and types that work with the CLR. They will be compiled, so they will execute <br>fast, and, most important, these macros will run in a secure AppDomain so that users don't <br>get hit with any unwanted surprises. Your own applications can use this ability, too, in any <br>way you want.<br>
<hr>
<A name=633></a><b> </b><br>
<b>Chapter 22  CLR Hosting and AppDomains </b><br>
<b>615</b><br>
<b>Advanced Host Control</b><br>
In this section, I'll mention some more advanced topics related to hosting the CLR. My intent <br>is to give you a taste of what is possible, and this will help you to understand more of what <br>the CLR is capable of. I encourage you to seek out other texts if you find this information par-<br>ticularly interesting.<br>
<b>Managing the CLR by Using Managed Code</b><br>
The System.AppDomainManager class allows a host to override CLR default behavior by us-<br>ing managed code instead of using unmanaged code. Of course, using managed code makes <br>implementing a host easier. All you need to do is define your class and derive it from the <br>System.AppDomainManager class, overriding any virtual methods where you want to take <br>over control. Your class should then be built into its very own assembly and installed into the <br>global assembly cache (GAC) because the assembly needs to be granted full-trust, and all as-<br>semblies in the GAC are always granted full-trust.<br>
Then, you need to tell the CLR to use your AppDomainManager-derived class. In <br>code, the best way to do this is to create an AppDomainSetup object initializing its <br>AppDomainManagerAssembly and AppDomainManagerType properties, both of which <br>are of type String. Set the AppDomainManagerAssembly property to the string identi-<br>fying the strong-name identity of the assembly that defines your AppDomainManager-<br>derived class, and then set the AppDomainManagerType property to the full name of your <br>AppDomainManager-derived class. Alternatively, AppDomainManager can be set in your ap-<br>plication's XML configuration file by using the appDomainManagerAssembly and appDomain-<br>ManagerType elements. In addition, a native host could query for the ICLRControl interface <br>and call this interface's SetAppDomainManagerType function, passing in the identity of the <br>GAC-installed assembly and the name of the AppDomainManager-derived class.5<br>
Now, let's talk about what an AppDomainManager-derived class can do. The purpose of the <br>AppDomainManager-derived class is to allow a host to maintain control even when an add-<br>in tries to create AppDomains of its own. When code in the process tries to create a new <br>AppDomain, the AppDomainManager-derived object in that AppDomain can modify security <br>and configuration settings. It can also decide to fail an AppDomain creation, or it can decide <br>to return a reference to an existing AppDomain instead. When a new AppDomain is created, <br>the CLR creates a new AppDomainManager-derived object in the AppDomain. This object can <br>also modify configuration settings, how execution context is flowed between threads, and <br>permissions granted to an assembly.<br>
5  It is also possible to configure an AppDomainManager by using environment variables and registry settings, but <br>
these mechanisms are more cumbersome than the methods mentioned in the text and should be avoided except <br>for some testing scenarios.<br>
<hr>
<A name=634></a><b>616 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Writing a Robust Host Application</b><br>
A host can tell the CLR what actions to take when a failure occurs in managed code. Here are <br>some examples (listed from least severe to most severe):<br>
  The CLR can abort a thread if the thread is taking too long to execute and return a  <br>
response. (I'll discuss this more in the next section.)<br>
  The CLR can unload an AppDomain. This aborts all of the threads that are in the <br>
AppDomain and causes the problematic code to be unloaded.<br>
  The CLR can be disabled. This stops any more managed code from executing in the <br>
process, but unmanaged code is still allowed to run.<br>
  The CLR can exit the Windows process. This aborts all of the threads and unloads <br>
all of the AppDomains first so that cleanup operations occur, and then the process <br>terminates.<br>
The CLR can abort a thread or AppDomain gracefully or rudely. A graceful abort means  <br>that cleanup code executes. In other words, code in finally blocks runs, and objects have <br>their Finalize methods executed. A rude abort means that cleanup code does not execute.  <br>In other words, code in finally blocks may not run, and objects may not have their <br>Finalize methods executed. A graceful abort cannot abort a thread that is in a catch or <br>finally block. However, a rude abort will abort a thread that is in a catch or finally block. <br>Unfortunately, a thread that is in unmanaged code or in a constrained execution region (CER) <br>cannot be aborted at all.<br>
A host can set what is called an <i>escalation policy</i>, which tells the CLR how to deal with man-<br>aged code failures. For example, SQL Server tells the CLR what to do should an unhandled <br>exception be thrown while the CLR is executing managed code. When a thread experiences <br>an unhandled exception, the CLR first attempts to upgrade the exception to a graceful <br>thread abort. If the thread does not abort in a specified time period, the CLR attempts to  <br>upgrade the graceful thread abort to a rude thread abort.<br>
What I just described is what usually happens. However, if the thread experiencing the un-<br>handled exception is in a <i>critical region</i>, the policy is different. A thread that is in a critical <br>region is a thread that has entered a thread synchronization lock that must be released by <br>the same thread, for example, a thread that has called Monitor.Enter, Mutex's WaitOne, <br>or one of ReaderWriterLock's AcquireReaderLock or AcquireWriterLock methods.6 <br>Successfully waiting for an AutoResetEvent, ManualResetEvent, or Semaphore doesn't <br>cause the thread to be in a critical region because another thread can signal these synchro-<br>nization objects. When a thread is in a critical region, the CLR believes that the thread is <br>
6  All of these locks internally call Thread's BeginCriticalRegion and EndCriticalRegion methods to indicate <br>
when they enter and leave critical regions. Your code can call these methods too if you need to. Normally, this <br>would be necessary only if you are interoperating with unmanaged code.<br>
<hr>
<A name=635></a><b> </b><br>
<b>Chapter 22  CLR Hosting and AppDomains </b><br>
<b>617</b><br>
accessing data that is shared by multiple threads in the same AppDomain. After all, this is <br>probably why the thread took the lock. If the thread is accessing shared data, just terminat-<br>ing the thread isn't good enough because other threads may then try to access the shared <br>data that is now corrupt, causing the AppDomain to run unpredictably or with possible  <br>security vulnerabilities.<br>
So when a thread in a critical region experiences an unhandled exception, the CLR first  <br>attempts to upgrade the exception to a graceful AppDomain unload in an effort to get rid  <br>of all of the threads and data objects that are currently in use. If the AppDomain doesn't  <br>unload in a specified amount of time, the CLR upgrades the graceful AppDomain unload to  <br>a rude AppDomain unload.<br>
<b>How a Host Gets Its Thread Back</b><br>
Normally, a host application wants to stay in control of its threads. Let's take a database <br>server as an example. When a request comes into the database server, a thread picks up the <br>request and then dispatches the request to another thread that is to perform the actual work. <br>This other thread may need to execute code that wasn't created and tested by the team that <br>produced the database server. For example, imagine a request coming into the database <br>server to execute a stored procedure written in managed code by the company running <br>the server. It's great that the database server can run the stored procedure code in its own <br>AppDomain, which is locked down with security. This prevents the stored procedure from  <br>accessing any objects outside of its own AppDomain, and it also prevents the code from  <br>accessing resources that it is not allowed to access, such as disk files or the clipboard.<br>
But what if the code in the stored procedure enters an infinite loop? In this case, the database <br>server has dispatched one of its threads into the stored procedure code, and this thread is <br>never coming back. This puts the server in a precarious position; the future behavior of the <br>server is unknown. For example, the performance might be terrible now because a thread <br>is in an infinite loop. Should the server create more threads? Doing so uses more resources <br>(such as stack space), and these threads could also enter an infinite loop themselves.<br>
To solve these problems, the host can take advantage of thread aborting. Figure 22-3 shows <br>the typical architecture of a host application trying to solve the runaway thread problem. <br>Here's how it works (the numbers correspond to the circled numbers in the figure):<br>
<b> </b><br>
<b>1.  </b>A client sends a request to the server.<br>
<b> </b><br>
<b>2.  </b>A server thread picks up this request and dispatches it to a thread pool thread to  <br>
perform the actual work.<br>
<b> </b><br>
<b>3.  </b>A thread pool thread picks up the client request and executes trusted code written by <br>
the company that built and tested the host application.<br>
<hr>
<A name=636></a><b>618 </b><br>
<b>Part IV  Core Facilities</b><br>
<b> </b><br>
<b>4.  </b>This trusted code then enters a try block, and from within the try block, calls across <br>
an AppDomain boundary (via a type derived from MarshalByRefObject). This <br>AppDomain contains the untrusted code (perhaps a stored procedure) that was not <br>built and tested by the company that produced the host application. At this point, the <br>server has given control of its thread to some untrusted code; the server is feeling  <br>nervous right now.<br>
<b> </b><br>
<b>5.  </b>When the host originally received the client's request, it recorded the time. If the un-<br>
trusted code doesn't respond to the client in some administrator-set amount of time, <br>the host calls Thread's Abort method asking the CLR to stop the thread pool thread, <br>forcing it to throw a ThreadAbortException.<br>
<b> </b><br>
<b>6.  </b>At this point, the thread pool thread starts unwinding, calling finally blocks so <br>
that cleanup code executes. Eventually, the thread pool thread crosses back over <br>the AppDomain boundary. Since the host's stub code called the untrusted code <br>from inside a try block, the host's stub code has a catch block that catches the <br>ThreadAbortException.<br>
<b> </b><br>
<b>7.  </b>In response to catching the ThreadAbortException, the host calls Thread's <br>
ResetAbort method. I'll explain the purpose of this call shortly.<br>
<b> </b><br>
<b>8.  </b>Now that the host's code has caught the ThreadAbortException, the host can return <br>
some sort of failure back to the client and allow the thread pool thread to return to the <br>pool so that it can be used for a future client request.<br>
<b>1</b><br>
Host's<br>
<b>5</b><br>
supervisor code<br>
Thread.Abort()<br>
<b>2</b><br>
AppDomain<br>
Bounda<br>
<b>3</b><br>
<b>4</b><br>
Thread<br>
Host's stub<br>
Add-in Code<br>
Pool<br>
(trusted)<br>
(untrusted)<br>
ry<br>
<b>7</b><br>
<b>6</b><br>
Thread.ResetAbort()<br>
<b>8</b><br>
<b>FIGURE 22-3  </b>How a host application gets its thread back<br>
Let me now clear up a few loose ends about this architecture. First, Thread's Abort method  <br>is asynchronous. When Abort is called, it sets the target thread's AbortRequested flag and <br>returns immediately. When the runtime detects that a thread is to be aborted, the runtime <br>tries to get the thread to a <i>safe place</i>. A thread is in a safe place when the runtime feels that <br>it can stop what the thread is doing without causing disastrous effects. A thread is in a safe <br>
<hr>
<A name=637></a><b> </b><br>
<b>Chapter 22  CLR Hosting and AppDomains </b><br>
<b>619</b><br>
place if it is performing a managed blocking operation such as sleeping or waiting. A thread <br>can be corralled to a safe place by using hijacking (described in Chapter 21). A thread is not <br>in a safe place if it is executing a type's class constructor, code in a catch or finally block, <br>code in a CER, or unmanaged code.<br>
Once the thread reaches a safe place, the runtime will detect that the AbortRequested <br>flag is set for the thread. This causes the thread to throw a ThreadAbortException. If this <br>exception is not caught, the exception will be unhandled, all pending finally blocks will <br>execute, and the thread will kill itself gracefully. Unlike all other exceptions, an unhandled <br>ThreadAbortException does not cause the application to terminate. The runtime silently <br>eats this exception and the thread dies, but the application and all of its remaining threads <br>continue to run just fine.<br>
In my example, the host catches the ThreadAbortException, allowing the host to regain <br>control of the thread and return it to the pool. But there is a problem: What is to stop the un-<br>trusted code from catching the ThreadAbortException itself to keep control of the thread? <br>The answer is that the CLR treats the ThreadAbortException in a very special manner. Even <br>when code catches the ThreadAbortException, the CLR doesn't allow the exception to <br>be swallowed. In other words, at the end of the catch block, the CLR automatically rethrows <br>the ThreadAbortException exception.<br>
This CLR feature raises another question: If the CLR rethrows the ThreadAbortException at <br>the end of a catch block, how can the host catch it to regain control of the thread? Inside <br>the host's catch block, there is a call to Thread's ResetAbort method. Calling this method <br>tells the CLR to stop rethrowing the ThreadAbortException at the end of each catch block.<br>
This raises yet another question: What's to stop the untrusted code from catching the <br>ThreadAbortException and calling Thread's ResetAbort method itself to keep control of <br>the thread? The answer is that Thread's ResetAbort method requires the caller to have the <br>SecurityPermission with the ControlThread flag set to true. When the host creates the <br>AppDomain for the untrusted code, the host will not grant this permission, and now, the  <br>untrusted code cannot keep control of the host's thread.<br>
I should point out that there is still a potential hole in this story: While the thread is unwinding <br>from its ThreadAbortException, the untrusted code can execute catch and finally blocks. <br>Inside these blocks, the untrusted code could enter an infinite loop, preventing the host from <br>regaining control of its thread. A host application fixes this problem by setting an escalation <br>policy (discussed earlier). If an aborting thread doesn't finish in a reasonable amount of time, <br>the CLR can upgrade the thread abort to a rude thread abort, a rude AppDomain unload, <br>disabling of the CLR, or killing of the process. I should also note that the untrusted code <br>could catch the ThreadAbortException and, inside the catch block, throw some other kind <br>of exception. If this other exception is caught, at the end of the catch block, the CLR auto-<br>matically rethrows the ThreadAbortException.<br>
<hr>
<A name=638></a><b>620 </b><br>
<b>Part IV  Core Facilities</b><br>
It should be noted, though, that most untrusted code is not actually intended to be malicious; <br>it is just written in such a way so as to be taking too long by the host's standards. Usually, <br>catch and finally blocks contain very little code, and this code usually executes quickly <br>without any infinite loops or long-running tasks. And so it is very unlikely that the escalation <br>policy will have to go into effect for the host to regain control of its thread.<br>
By the way, the Thread class actually offers two Abort methods: One takes no parameters, <br>and the other takes an Object parameter allowing you to pass anything. When code <br>catches the ThreadAbortException, it can query its read-only ExceptionState property. <br>This property returns the object that was passed to Abort. This allows the thread calling <br>Abort to specify some additional information that can be examined by code catching the <br>ThreadAbortException. The host can use this to let its own handling code know why it is <br>aborting threads.<br>
<hr>
<A name=639></a>Chapter 23<br><b>Assembly Loading and Reflection</b><br>
<b>In this chapter:<br>Assembly Loading . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 621<br>Using Reflection to Build a Dynamically Extensible Application  . . . . . . . . . . . . 626<br>Reflection Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 627<br>Designing an Application That Supports Add-Ins . . . . . . . . . . . . . . . . . . . . . . . . . 634<br>Using Reflection to Discover a Type's Members  . . . . . . . . . . . . . . . . . . . . . . . . . . 637</b><br>
This chapter is all about discovering information about types, creating instances of them, and <br>accessing their members when you didn't know anything about them at compile time. The <br>information in this chapter is typically used to create a dynamically extensible application. <br>This is the kind of application for which one company builds a host application and other <br>companies create add-ins to extend the host application. The host can't be built or tested <br>against the add-ins because the add-ins are created by different companies and are likely  <br>to be created after the host application has already shipped. This is why the host needs to <br>discover the add-ins at runtime.<br>
A dynamically extensible application could take advantage of common language runtime <br>(CLR) hosting and AppDomains as discussed in Chapter 22, "CLR Hosting and AppDomains." <br>The host could run the add-in code in an AppDomain with its own security and configuration <br>settings. The host could also unload the add-in code by unloading the AppDomain. At the <br>end of this chapter, I'll talk a little about how to put all of this stuff together--CLR hosting, <br>AppDomains, assembly loading, type discovery, type instance construction, and reflection--<br>in order to build a robust, secure, dynamically extensible application.<br>
<b>Assembly Loading</b><br>
As you know, when the just-in-time (JIT) compiler compiles the Intermediate Language (IL) <br>for a method, it sees what types are referenced in the IL code. Then at runtime, the JIT  <br>compiler uses the assembly's TypeRef and AssemblyRef metadata tables to determine what <br>assembly defines the type being referenced. The AssemblyRef metadata table entry contains <br>all of the parts that make up the strong name of the assembly. The JIT compiler grabs all of <br>these parts--name (without extension or path), version, culture, and public key token--con-<br>catenates them into a string, and then attempts to load an assembly matching this identity <br>into the AppDomain (assuming that it's not already loaded). If the assembly being loaded is <br>
<b> </b><br>
<b> </b><br>
<b>621</b><br>
<hr>
<A name=640></a><IMG src="CLRviaCsharp-640_1.jpg"><br>
<IMG src="CLRviaCsharp-640_2.jpg"><br>
<b>622 </b><br>
<b>Part IV  Core Facilities</b><br>
weakly named, the identity is just the name of the assembly (no version, culture, or public key <br>token information).<br>
Internal y, the CLR attempts to load this assembly by using the System.Reflection.Assembly <br>class's static Load method. This method is publicly documented, and you can call it to explic-<br>itly load an assembly into your AppDomain. This method is the CLR equivalent of Win32's <br>LoadLibrary function. There are actually several overloaded versions of Assembly's Load <br>method. Here are the prototypes of the more commonly used overloads:<br>
public class Assembly {  <br>   public static Assembly Load(AssemblyName assemblyRef);   <br>   public static Assembly Load(String assemblyString);   <br>   // Less commonly used overloads of Load are not shown  <br>}<br>
Internally, Load causes the CLR to apply a version-binding redirection policy to the assembly <br>and looks for the assembly in the global assembly cache (GAC), followed by the application's <br>base directory, private path subdirectories, and codebase locations. If you call Load passing  <br>a weakly named assembly, Load doesn't apply a version-binding redirection policy to the  <br>assembly, and the CLR won't look in the GAC for the assembly. If Load finds the specified  <br>assembly, it returns a reference to an Assembly object that represents the loaded assembly. If <br>Load fails to find the specified assembly, it throws a System.IO.FileNotFoundException.<br>
<b>Note  </b>In some extremely rare situations, you may want to load an assembly that was built for  <br>a specific CPU architecture. In this case, when specifying an assembly's identity, you can also  <br>include a process architecture part. For example, if my GAC happened to have an IL-neutral <br>and an x86-specific version of an assembly, the CLR would favor the CPU-specific version of <br>the assembly (as discussed in Chapter 3, "Shared Assemblies and Strongly Named Assemblies"). <br>However, I can force the CLR to load the IL-neutral version by passing the following string to <br>Assembly's Load method:<br>
&quot;SomeAssembly, Version=2.0.0.0, Culture=neutral, <br>   PublicKeyToken=01234567890abcde, ProcessorArchitecture=MSIL&quot;<br>
Today, the CLR supports four possible values for ProcessorArchitecture: MSIL (Microsoft IL), x86, <br>IA64, and AMD64.<br>
<b>Important  </b>Some developers notice that System.AppDomain offers a Load method. Unlike <br>Assembly's static Load method, AppDomain's Load method is an instance method that allows <br>you to load an assembly into the specified AppDomain. This method was designed to be called <br>by unmanaged code, and it allows a host to inject an assembly into a specific AppDomain. <br>Managed code developers generally shouldn't call this method because when AppDomain's <br>Load method is called, you pass it a string that identifies an assembly. The method then applies <br>policy and searches the normal places looking for the assembly. Recall that an AppDomain has <br>settings associated with it that tell the CLR how to look for assemblies. To load this assembly, the <br>CLR will use the settings associated with the specified AppDomain, not the calling AppDomain.<br>
<hr>
<A name=641></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>623</b><br>
However, AppDomain's Load method returns a reference to an assembly. Because the  <br>System.Assembly class isn't derived from System.MarshalByRefObject, the assembly  <br>object must be marshaled by value back to the calling AppDomain. But the CLR will now use <br>the calling AppDomain's settings to locate the assembly and load it. If the assembly can't be <br>found using the calling AppDomain's policy and search locations, a FileNotFoundException is <br>thrown. This behavior is usually undesirable and is the reason that you should avoid AppDomain's <br>Load method.<br>
In most dynamically extensible applications, Assembly's Load method is the preferred way <br>of loading an assembly into an AppDomain. However, it does require that you have all of <br>the pieces that make up an assembly's identity. Frequently, developers write tools or utilities <br>(such as ILDasm.exe, PEVerify.exe, CorFlags.exe, GACUtil.exe, SGen.exe, SN.exe, XSD.exe) that <br>perform some kind of processing on an assembly. All of these tools take a command-line  <br>argument that refers to the path name of an assembly file (including file extension). To load <br>an assembly specifying a path name, you call Assembly's LoadFrom method:<br>
public class Assembly {  <br>   public static Assembly LoadFrom(String path);   <br>   // Less commonly used overloads of LoadFrom are not shown  <br>}<br>
Internally, LoadFrom first calls System.Reflection.AssemblyName's static GetAssemblyName <br>method, which opens the specified file, finds the AssemblyDef metadata table's entry, <br>and extracts the assembly identity information and returns it in a System.Reflection.<br>AssemblyName object (the file is also closed). Then, LoadFrom internally calls Assembly's Load <br>method, passing it the AssemblyName object. At this point, the CLR applies version-binding <br>redirection policy and searches the various locations looking for a matching assembly. If Load <br>finds the assembly, it will load it, and an Assembly object that represents the loaded assem-<br>bly will be returned; LoadFrom returns this value. If Load fails to find an assembly, LoadFrom <br>loads the assembly at the path name specified in LoadFrom's argument. Of course, if an  <br>assembly with the same identity is already loaded, LoadFrom simply returns an Assembly  <br>object that represents the already loaded assembly.<br>
By the way, the LoadFrom method allows you to pass a URL as the argument. Here is an <br>example:<br>
Assembly a = Assembly.LoadFrom(@&quot;http://Wintellect.com/SomeAssembly.dll&quot;);<br>
When you pass an Internet location, the CLR downloads the file, installs it into the user's <br>download cache, and loads the file from there. Note that you must be online or an exception <br>will be thrown. However, if the file has been downloaded previously, and if Windows Internet <br>Explorer has been set to work offline (see Internet Explorer's Work Offline menu item in its <br>File menu), the previously downloaded file will be used, and no exception will be thrown. You <br>can also call UnsafeLoadFrom, which can load a Web-downloaded assembly, bypassing some <br>security checks.<br>
<hr>
<A name=642></a><IMG src="CLRviaCsharp-642_1.jpg"><br>
<b>624 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Important  </b>It is possible to have different assemblies on a single machine all with the same <br>identity. Because LoadFrom calls Load internally, it is possible that the CLR will not load the  <br>specified file and instead will load a different file giving you unexpected behavior. It is highly  <br>recommended that each build of your assembly change the version number; this ensures that <br>each version has its own identity, and because of this, LoadFrom will now work as expected.<br>
Microsoft Visual Studio's UI designers and other tools typically use Assembly's LoadFile <br>method. This method can load an assembly from any path and can be used to load an  <br>assembly with the same identity multiple times into a single AppDomain. This can happen  <br>as changes to an application's UI are made in the designer/tool and the user rebuilds the  <br>assembly. When loading an assembly via LoadFile, the CLR will not resolve any dependen-<br>cies automatically; your code must register with AppDomain's AssemblyResolve event and <br>have your event callback method explicitly load any dependent assemblies.<br>
If you are building a tool that simply analyzes an assembly's metadata via reflection (as  <br>discussed later in this chapter), and you want to ensure that none of the code contained  <br>inside the assembly executes, the best way for you to load an assembly is to use Assembly's <br>ReflectionOnlyLoadFrom method, or in some rarer cases, Assembly's ReflectionOnlyLoad <br>method. Here are the prototypes of both methods:<br>
public class Assembly {  <br>   public static Assembly ReflectionOnlyLoadFrom(String assemblyFile);   <br>   public static Assembly ReflectionOnlyLoad(String assemblyString);   <br>   // Less commonly used overload of ReflectionOnlyLoad is not shown  <br>}<br>
The ReflectionOnlyLoadFrom method will load the file specified by the path; the strong-<br>name identity of the file is not obtained, and the file is not searched for in the GAC or else-<br>where. The ReflectionOnlyLoad method will search for the specified assembly looking in <br>the GAC, application base directory, private paths, and codebases. However, unlike the Load <br>method, the ReflectionOnlyLoad method does not apply versioning policies, so you will <br>get the exact version that you specify. If you want to apply versioning policy yourself to an <br>assembly identity, you can pass the string into AppDomain's ApplyPolicy method.<br>
When an assembly is loaded with ReflectionOnlyLoadFrom or ReflectionOnlyLoad, <br>the CLR forbids any code in the assembly from executing; any attempt to execute <br>code in an assembly loaded with either of these methods causes the CLR to throw an <br>InvalidOperationException. These methods allow a tool to load an assembly that was  <br>delay-signed, would normally require security permissions that prevent it from loading, or <br>was created for a different CPU architecture.<br>
Frequently when using reflection to analyze an assembly loaded with one of these <br>two methods, the code will have to register a callback method with AppDomain's <br>ReflectionOnlyAssemblyResolve event to manually load any referenced assemblies  <br>
<hr>
<A name=643></a><IMG src="CLRviaCsharp-643_1.jpg"><br>
<b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>625</b><br>
(calling AppDomain's ApplyPolicy method, if desired); the CLR doesn't do it automatically for  <br>you. When the callback method is invoked, it must cal  Assembly's ReflectionOnlyLoadFrom <br>or ReflectionOnlyLoad method to explicitly load a referenced assembly and return a refer-<br>ence to this assembly.<br>
<b>Note  </b>People often ask about assembly unloading. Unfortunately, the CLR doesn't support the <br>ability to unload individual assemblies. If the CLR allowed it, your application would crash if a <br>thread returned back from a method to code in the unloaded assembly. The CLR is all about  <br>robustness and security, and allowing an application to crash in this way would be counterpro-<br>ductive to its goals. If you want to unload an assembly, you must unload the entire AppDomain <br>that contains it. This was discussed in great detail in Chapter 22.<br>
It would seem that assemblies loaded with either the ReflectionOnlyLoadFrom or the <br>ReflectionOnlyLoad method could be unloaded. After all, code in these assemblies is not  <br>allowed to execute. However, the CLR also doesn't allow assemblies loaded via either of these <br>two methods to be unloaded. The reason is that once an assembly is loaded this way, you can <br>still use reflection to create objects that refer to the metadata defined inside these assemblies. <br>Unloading the assembly would require the objects to be invalidated somehow. Keeping track of <br>this would be too expensive in terms of implementation and execution speed.<br>
Many applications consist of an EXE file that depends on many DLL files. When deploying this <br>application, all the files must be deployed. However, there is a technique that you can use <br>to deploy just a single EXE file. First, identify all the DLL files that your EXE file depends on <br>that do not ship as part of the Microsoft .NET Framework itself. Then add these DLLs to your <br>Visual Studio project. For each DLL file you add, display its properties and change its "Build <br>Action" to "Embedded Resource". This causes the C# compiler to embed the DLL file(s) into <br>your EXE file, and you can deploy this one EXE file.<br>
At runtime, the CLR won't be able to find the dependent DLL assemblies, which is a problem. <br>To fix this, when your application initializes, register a callback method with the AppDomain's <br>ResolveAssembly event. The code should look something like this:<br>
AppDomain.CurrentDomain.AssemblyResolve += (sender, args) =&gt; { <br>   String resourceName = &quot;AssemblyLoadingAndReflection.&quot; + <br>      new AssemblyName(args.Name).Name + &quot;.dll&quot;; <br> <br>   using (var stream =  <br>      Assembly.GetExecutingAssembly().GetManifestResourceStream(resourceName)) { <br>      Byte[] assemblyData = new Byte[stream.Length]; <br>      stream.Read(assemblyData, 0, assemblyData.Length); <br>      return Assembly.Load(assemblyData); <br>   } <br>};<br>
Now, the first time a thread calls a method that references a type in a dependent DLL file,  <br>the AssemblyResolve event will be raised and the callback code shown above will find the <br>embedded DLL resource desired and load it by calling an overload of Assembly's Load meth-<br>od that takes a Byte[] as an argument.<br>
<hr>
<A name=644></a><IMG src="CLRviaCsharp-644_1.jpg"><br>
<b>626 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Using Reflection to Build a Dynamically Extensible </b><br>
<b>Application</b><br>
As you know, metadata is stored in a bunch of tables. When you build an assembly or a <br>module, the compiler that you're using creates a type definition table, a field definition table, <br>a method definition table, and so on. The System.Reflection namespace contains several <br>types that allow you to write code that reflects over (or parses) these metadata tables. In  <br>effect, the types in this namespace offer an object model over the metadata contained in  <br>an assembly or a module.<br>
Using these object model types, you can easily enumerate all of the types in a type definition  <br>metadata table. Then for each type, you can obtain its base type, the interfaces it implements, <br>and the flags that are associated with the type. Additional types in the System.Reflection <br>namespace allow you to query the type's fields, methods, properties, and events by parsing <br>the corresponding metadata tables. You can also discover any custom attributes (covered <br>in Chapter 18, "Custom Attributes") that have been applied to any of the metadata entities. <br>There are even classes that let you determine referenced assemblies and methods that return <br>the IL byte stream for a method. With all of this information, you could easily build a tool <br>very similar to Microsoft's ILDasm.exe.<br>
<b>Note  </b>You should be aware that some of the reflection types and some of the members defined <br>by these types are designed specifically for use by developers who are producing compilers for <br>the CLR. Application developers don't typically use these types and members. The Framework <br>Class Library (FCL) documentation doesn't explicitly point out which of these types and members <br>are for compiler developers rather than application developers, but if you realize that not all  <br>reflection types and their members are for everyone, the documentation can be less confusing.<br>
In reality, very few applications will have the need to use the reflection types. Reflection is <br>typically used by class libraries that need to understand a type's definition in order to provide <br>some rich functionality. For example, the FCL's serialization mechanism (discussed in Chapter <br>24, "Runtime Serialization") uses reflection to determine what fields a type defines. The  <br>serialization formatter can then obtain the values of these fields and write them into a byte <br>stream that is used for sending across the Internet, saving to a file, or copying to the clipboard. <br>Similarly, Visual Studio's designers use reflection to determine which properties should be <br>shown to developers when laying out controls on their Web Forms or Windows Forms at  <br>design time.<br>
Reflection is also used when an application needs to load a specific type from a specific  <br>assembly at runtime to accomplish some task. For example, an application might ask the user <br>to provide the name of an assembly and a type. The application could then explicitly load <br>the assembly, construct an instance of the type, and cal  methods defined in the type. This <br>usage is conceptually similar to calling Win32's LoadLibrary and GetProcAddress functions. <br>
<hr>
<A name=645></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>627</b><br>
Binding to types and calling methods in this way is frequently referred to as <i>late binding</i>. <br>(<i>Early binding </i>is when the types and methods used by an application are determined at  <br>compile time.)<br>
<b>Reflection Performance</b><br>
Reflection is an extremely powerful mechanism because it allows you to discover and use <br>types and members at runtime that you did not know about at compile time. This power <br>does come with two main drawbacks:<br>
  Reflection prevents type safety at compile time. Since reflection uses strings heavily, <br>
you lose type safety at compile time. For example, if you call Type.GetType(&quot;Jef&quot;)<b>;</b> to <br>ask reflection to find a type called "Jef" in an assembly that has a type called "Jeff," the <br>code compiles but produces an error at runtime because you accidentally misspelled <br>the type name passed as the argument.<br>
  Reflection is slow. When using reflection, the names of types and their members are <br>
not known at compile time; you discover them at runtime by using a string name to <br>identify each type and member. This means that reflection is constantly performing <br>string searches as the types in the System.Reflection namespace scan through an <br>assembly's metadata. Often, the string searches are case-insensitive comparisons, which <br>can slow this down even more.<br>
Invoking a member by using reflection will also hurt performance. When using reflection to <br>invoke a method, you must first package the arguments into an array; internally, reflection <br>must unpack these on to the thread's stack. Also, the CLR must check that the arguments are <br>of the correct data type before invoking a method. Finally, the CLR ensures that the caller has <br>the proper security permission to access the member being invoked.<br>
For all of these reasons, it's best to avoid using reflection to access a field or invoke a meth-<br>od/property. If you're writing an application that will dynamically discover and construct type <br>instances, you should take one of the following approaches:<br>
  Have the types derive from a base type that is known at compile time. At runtime,  <br>
construct an instance of the derived type, place the reference in a variable that is of  <br>the base type (by way of a cast), and call virtual methods defined by the base type.<br>
  Have the type implement an interface that is known at compile time. At runtime,  <br>
construct an instance of the type, place the reference in a variable that is of the  <br>interface type (by way of a cast), and call the methods defined by the interface.<br>
I tend to prefer using the interface technique over the base type technique because the base <br>type technique doesn't allow the developer to choose the base type that works best in a  <br>particular situation. Although the base type technique works better in versioning scenarios <br>since you could always add a member to the base type and the derived types just inherit it; <br>
<hr>
<A name=646></a><b>628 </b><br>
<b>Part IV  Core Facilities</b><br>
you can't add a member to an interface without forcing al  types that implement the interface <br>to modify their code and recompile it.<br>
When you use either of these two techniques, I strongly suggest that the interface or base <br>type be defined in its own assembly. This will reduce versioning issues. For more information <br>about how to do this, see the section titled "Designing an Application That Supports Add-Ins" <br>in this chapter.<br>
<b>Discovering Types Defined in an Assembly</b><br>
Reflection is frequently used to determine what types an assembly defines. The FCL offers  <br>many methods to get this information. By far, the most commonly used method is <br>Assembly's GetExportedTypes. Here is an example of code that loads an assembly and <br>shows the names of all of the publicly exported types defined in it:<br>
using System;  <br>using System.Reflection;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      String dataAssembly = &quot;System.Data, version=4.0.0.0, &quot; +  <br>         &quot;culture=neutral, PublicKeyToken=b77a5c561934e089&quot;;  <br>      LoadAssemAndShowPublicTypes(dataAssembly);  <br>   }  <br> <br>   private static void LoadAssemAndShowPublicTypes(String assemId) {  <br>      // Explicitly load an assembly in to this AppDomain  <br>      Assembly a = Assembly.Load(assemId);  <br> <br>      // Execute this loop once for each Type   <br>      // publicly-exported from the loaded assembly   <br>      foreach (Type t in a.GetExportedTypes()) {  <br>         // Display the full name of the type  <br>         Console.WriteLine(t.FullName);  <br>      }  <br>   }  <br>}<br>
<b>What Exactly Is a Type Object?</b><br>
Notice that the previous code iterates over an array of System.Type objects. The  <br>System.Type type is your starting point for doing type and object manipulations.  <br>System.Type is an abstract base type derived from System.Reflection.MemberInfo  <br>(because a Type can be a member of another type). The FCL provides a few types that are <br>derived from System.Type<b>:</b>System.RuntimeType, System.ReflectionOnlyType,  <br>System.Reflection.TypeDelegator, and some types defined in the System.Reflection.<br>Emit namespace (EnumBuilder, GenericTypeParameterBuilder, and TypeBuilder).<br>
<hr>
<A name=647></a><IMG src="CLRviaCsharp-647_1.jpg"><br>
<b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>629</b><br>
<b>Note  </b>The TypeDelegator class allows code to dynamically subclass a Type by encapsulating <br>the Type, al owing you to override some of the functionality while having the original Type handle <br>most of the work. This powerful mechanism allows you to override the way reflection works.<br>
Of all of these types, the System.RuntimeType is by far the most interesting. RuntimeType is <br>a type that is internal to the FCL, which means that you won't find it documented in the FCL <br>documentation. The first time a type is accessed in an AppDomain, the CLR constructs an  <br>instance of a RuntimeType and initializes the object's fields to reflect (pun intended) infor-<br>mation about the type.<br>
Recall that System.Object defines a public, nonvirtual instance method named GetType. <br>When you call this method, the CLR determines the specified object's type and returns a  <br>reference to its RuntimeType object. Because there is only one RuntimeType object per type <br>in an AppDomain, you can use equality and inequality operators to see whether two objects <br>are of the same type:<br>
private static Boolean AreObjectsTheSameType(Object o1, Object o2) {  <br>   return o1.GetType() == o2.GetType();  <br>}<br>
In addition to calling Object's GetType method, the FCL offers several more ways to obtain a <br>Type object:<br>
  The System.Type type offers several overloaded versions of the static GetType method. <br>
All versions of this method take a String. The string must specify the full name of <br>the type (including its namespace). Note that the primitive type names supported by <br>the compiler (such as C#'s int, string, bool, and so on) aren't allowed because these <br>names mean nothing to the CLR. If the string is simply the name of a type, the method <br>checks the calling assembly to see whether it defines a type of the specified name. If it <br>does, a reference to the appropriate RuntimeType object is returned.<br>
If the calling assembly doesn't define the specified type, the types defined by <br>MSCorLib.dll are checked. If a type with a matching name still can't be found, null is <br>returned or a System.TypeLoadException is thrown, depending on which overload of <br>the GetType method you called and what parameters you passed to it. The FCL docu-<br>mentation fully explains this method. <br>
You can pass an assembly-qualified type string, such as "System.Int32, mscorlib, <br>Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089", to GetType. In <br>this case, GetType will look for the type in the specified assembly (loading the assembly <br>if necessary).<br>
  The System.Type type offers a static ReflectionOnlyGetType method. This method <br>
behaves similarly to the GetType method mentioned in the previous bullet, except that <br>the type is loaded so that it can be reflected over but cannot be executed.<br>
<hr>
<A name=648></a><IMG src="CLRviaCsharp-648_1.jpg"><br>
<IMG src="CLRviaCsharp-648_2.jpg"><br>
<b>630 </b><br>
<b>Part IV  Core Facilities</b><br>
  The System.Type type offers the following instance methods: GetNestedType and <br>
GetNestedTypes.<br>
  The System.Reflection.Assembly type offers the following instance methods: <br>
GetType, GetTypes, and GetExportedTypes.<br>
  The System.Reflection.Module type offers the following instance methods: GetType, <br>
GetTypes, and FindTypes.<br>
<b>Note  </b>Microsoft has defined a Backus-Naur Form grammar for type names and assembly- <br>qualified type names that is used for constructing strings that will be passed to reflection  <br>methods. Knowledge of the grammar can come in quite handy when you are using reflection, <br>specifically if you are working with nested types, generic types, generic methods, reference  <br>parameters, or arrays. For the complete grammar, see the FCL documentation or do a <br>Web search for "Backus-Naur Form Grammar for Type Names." You can also look at Type's <br>MakeArrayType, MakeByRefType, MakeGenericType, and MakePointerType methods.<br>
Many programming languages also offer an operator that allows you to obtain a Type  <br>object from a type name that is known at compile time. When possible, you should use this <br>operator to obtain a reference to a Type instead of using any of the methods in the preced-<br>ing list, because the operator generally produces faster code. In C#, the operator is called <br>typeof, and you use this operator typically to compare late-bound type information with <br>early-bound (known at compile time) type information. The following code demonstrates an <br>example of its use:<br>
private static void SomeMethod(Object o) {  <br>   // GetType returns the type of the object at runtime (late-bound)  <br>   // typeof returns the type of the specified class (early-bound)  <br>   if (o.GetType() == typeof(FileInfo))      { ... }  <br>   if (o.GetType() == typeof(DirectoryInfo)) { ... }  <br>}<br>
<b>Note  </b>The first if statement in the code checks if the variable o refers to an object of the <br>FileInfo type; it does not check if o refers to an object that is derived from the FileInfo type. <br>In other words, the code above tests for an exact match, not a compatible match, which is what <br>you would get if you use a cast or C#'s is or as operators.<br>
Once you have a reference to a Type object, you can query many of the type's properties <br>to learn more about it. Most of the properties, such as IsPublic, IsSealed, IsAbstract, <br>IsClass, IsValueType, and so on, indicate flags associated with the type. Other properties, <br>such as Assembly, AssemblyQualifiedName, FullName, Module, and so on, return the name <br>of the type's defining assembly or module and the full name of the type. You can also query <br>the BaseType property to obtain the type's base type, and a slew of methods will give you <br>even more information about the type.<br>
<hr>
<A name=649></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>631</b><br>
The FCL documentation describes all of the methods and properties that Type exposes. Be <br>aware that there are a lot of them. In fact, Type offers about 60 public instance properties. <br>This doesn't even include the methods and fields that Type also defines. I'll be covering some <br>of these methods in the next section.<br>
<b>Building a Hierarchy of Exception-Derived Types</b><br>
The code shown below uses many of the concepts discussed already in this chapter to load a <br>bunch of assemblies into the AppDomain and display all of the classes that are ultimately de-<br>rived from System.Exception. By the way, this is the program I wrote to build the exception <br>hierarchy displayed in the "FCL-Defined Exception Classes" section in Chapter 20, "Exceptions <br>and State Management."<br>
public static void Go() { <br>   // Explicitly load the assemblies that we want to reflect over <br>   LoadAssemblies(); <br> <br>   // Recursively build the class hierarchy as a hyphen-separated string <br>   Func&lt;Type, String&gt; ClassNameAndBase = null; <br>   ClassNameAndBase = t =&gt; &quot;-&quot; + t.FullName + <br>       ((t.BaseType != typeof(Object)) ? ClassNameAndBase(t.BaseType) : String.Empty); <br> <br>   // Define query to find all public Exception-derived types in this AppDomain's assemblies <br>   var exceptionTree = <br>       (from a in AppDomain.CurrentDomain.GetAssemblies() <br>        from t in a.GetExportedTypes() <br>        where t.IsClass &amp;&amp; t.IsPublic &amp;&amp; typeof(Exception).IsAssignableFrom(t) <br>        let typeHierarchyTemp = ClassNameAndBase(t).Split('-').Reverse().ToArray() <br>        let typeHierarchy =  <br>           String.Join(&quot;-&quot;, typeHierarchyTemp, 0, typeHierarchyTemp.Length - 1) <br>        orderby typeHierarchy <br>        select typeHierarchy).ToArray(); <br> <br>   // Display the Exception tree <br>   Console.WriteLine(&quot;{0} Exception types found.&quot;, exceptionTree.Length); <br>   foreach (String s in exceptionTree) { <br>      // For this Exception type, split its base types apart <br>      String[] x = s.Split('-'); <br> <br>      // Indent based on # of base types and show the most-derived type <br>      Console.WriteLine(new String(' ', 3 * (x.Length - 1)) + x[x.Length - 1]); <br>   } <br>} <br> <br> <br>private static void LoadAssemblies() { <br>   String[] assemblies = { <br>      &quot;System,                    PublicKeyToken={0}&quot;, <br>      &quot;System.Core,               PublicKeyToken={0}&quot;, <br>      &quot;System.Data,               PublicKeyToken={0}&quot;, <br>      &quot;System.Design,             PublicKeyToken={1}&quot;, <br>
<hr>
<A name=650></a><b>632 </b><br>
<b>Part IV  Core Facilities</b><br>
      &quot;System.DirectoryServices,  PublicKeyToken={1}&quot;, <br>      &quot;System.Drawing,            PublicKeyToken={1}&quot;, <br>      &quot;System.Drawing.Design,     PublicKeyToken={1}&quot;, <br>      &quot;System.Management,         PublicKeyToken={1}&quot;, <br>      &quot;System.Messaging,          PublicKeyToken={1}&quot;, <br>      &quot;System.Runtime.Remoting,   PublicKeyToken={0}&quot;, <br>      &quot;System.Security,           PublicKeyToken={1}&quot;, <br>      &quot;System.ServiceProcess,     PublicKeyToken={1}&quot;, <br>      &quot;System.Web,                PublicKeyToken={1}&quot;, <br>      &quot;System.Web.RegularExpressions, PublicKeyToken={1}&quot;, <br>      &quot;System.Web.Services,       PublicKeyToken={1}&quot;, <br>      &quot;System.Windows.Forms,      PublicKeyToken={0}&quot;, <br>      &quot;System.Xml,                PublicKeyToken={0}&quot;, <br>   }; <br> <br>   String EcmaPublicKeyToken = &quot;b77a5c561934e089&quot;; <br>   String MSPublicKeyToken = &quot;b03f5f7f11d50a3a&quot;; <br> <br>   // Get the version of the assembly containing System.Object <br>   // We'll assume the same version for all the other assemblies <br>   Version version = typeof(System.Object).Assembly.GetName().Version; <br> <br>   // Explicitly load the assemblies that we want to reflect over <br>   foreach (String a in assemblies) { <br>      String AssemblyIdentity =  <br>         String.Format(a, EcmaPublicKeyToken, MSPublicKeyToken) + <br>            &quot;, Culture=neutral, Version=&quot; + version; <br>      Assembly.Load(AssemblyIdentity); <br>   } <br>}<br>
<b>Constructing an Instance of a Type</b><br>
Once you have a reference to a Type-derived object, you might want to construct an in-<br>stance of this type. The FCL offers several mechanisms to accomplish this:<br>
<b>  </b>System.Activator<b>'s </b>CreateInstance<b> methods  </b>The Activator class offers several <br>
overloads of its static CreateInstance method. When you call this method, you can <br>pass either a reference to a Type object or a String that identifies the type of object <br>you want to create. The versions that take a type are simpler. You get to pass a set of <br>arguments for the type's constructor, and the method returns a reference to the new <br>object.<br>
The versions of this method in which you specify the desired type by using a string <br>are a bit more complex. First, you must also specify a string identifying the assembly <br>that defines the type. Second, these methods allow you to construct a remote object <br>if you have remoting options configured properly. Third, these versions don't return <br>a reference to the new object. Instead, they return a System.Runtime.Remoting.<br>ObjectHandle (which is derived from System.MarshalByRefObject).<br>
<hr>
<A name=651></a><IMG src="CLRviaCsharp-651_1.jpg"><br>
<b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>633</b><br>
An ObjectHandle is a type that allows an object created in one AppDomain to be <br>passed around to other AppDomains without forcing the object to materialize. When <br>you're ready to materialize the object, you call ObjectHandle's Unwrap method. This <br>method loads the assembly that defines the type being materialized in the AppDomain <br>where Unwrap is called. If the object is being marshaled by reference, the proxy <br>type and object are created. If the object is being marshaled by value, the copy is <br>deserialized.<br>
<b>  </b>System.Activator<b>'s </b>CreateInstanceFrom<b> methods  </b>The Activator class also  <br>
offers a set of static CreateInstanceFrom methods. These methods behave just as the <br>CreateInstance method, except that you must always specify the type and its assem-<br>bly via string parameters. The assembly is loaded into the calling AppDomain by using <br>Assembly's LoadFrom method (instead of Load). Because none of these methods takes <br>a Type parameter, all of the CreateInstanceFrom methods return a reference to an <br>ObjectHandle, which must be unwrapped.<br>
<b>  </b>System.AppDomain<b>'s methods  </b>The AppDomain type offers four instance <br>
methods (each with several overloads) that construct an instance of a type: <br>CreateInstance, CreateInstanceAndUnwrap, CreateInstanceFrom, and <br>CreateInstanceFromAndUnwrap. These methods work just as Activator's methods  <br>except that these methods are instance methods, allowing you to specify which <br>AppDomain the object should be constructed in. The methods that end with Unwrap <br>exist for convenience so that you don't have to make an additional method call.<br>
<b>  </b>System.Type<b>'s </b>InvokeMember<b> instance method  </b>Using a reference to a Type object, <br>
you can call the InvokeMember method. This method locates a constructor matching <br>the parameters you pass and constructs the type. The type is always created in the call-<br>ing AppDomain, and a reference to the new object is returned. I'll discuss this method <br>in more detail later in this chapter.<br>
<b>  </b>System.Reflection.ConstructorInfo<b>'s </b>Invoke<b> instance method  </b>Using a refer-<br>
ence to a Type object, you can bind to a particular constructor and obtain a reference <br>to the constructor's ConstructorInfo object. Then you can use the reference to the <br>ConstructorInfo object to call its Invoke method. The type is always created in the <br>calling AppDomain, and a reference to the new object is returned. I'll also discuss this <br>method in more detail later in this chapter.<br>
<b>Note  </b>The CLR doesn't require that value types define any constructors. However, this is a  <br>problem because all of the mechanisms in the preceding list construct an object by calling its <br>constructor. However, Activator's CreateInstance methods will allow you to create an  <br>instance of a value type without calling a constructor. If you want to create an instance of a value <br>type without calling a constructor, you must call the version of the CreateInstance method <br>that takes a single Type parameter or the version that takes Type and Boolean parameters.<br>
<hr>
<A name=652></a><b>634 </b><br>
<b>Part IV  Core Facilities</b><br>
The mechanisms just listed allow you to create an object for all types except for arrays <br>(System.Array-derived types) and delegates (System.MulticastDelegate-derived types). <br>To create an array, you should call Array's static CreateInstance method (several over-<br>loaded versions exist). The first parameter to all versions of CreateInstance is a reference to <br>the Type of elements you want in the array. CreateInstance's other parameters allow you <br>to specify various combinations of dimensions and bounds. To create a delegate, you should <br>call Delegate's static CreateDelegate method (several overloads exist). The first parameter <br>to all versions of CreateDelegate is a reference to the Type of delegate you want to create. <br>CreateDelegate's other parameters allow you to specify which instance method of an object <br>or which static method of a type the delegate should wrap.<br>
To construct an instance for a generic type, first get a reference to the open type, and then <br>call Type's public, instance MakeGenericType method, passing in an array of types that you <br>want to use as the type arguments. Then, take the returned Type object and pass it into one <br>of the various methods listed above. Here is an example:<br>
using System;  <br>using System.Reflection;  <br> <br>internal sealed class Dictionary&lt;TKey, TValue&gt; { }  <br> <br>public static class Program {  <br>   public static void Main() {   <br>      // Get a reference to the generic type's type object  <br>      Type openType = typeof(Dictionary&lt;,&gt;);  <br> <br>      // Close the generic type by using TKey=String, TValue=Int32  <br>      Type closedType = openType.MakeGenericType(typeof(String), typeof(Int32));  <br> <br>      // Construct an instance of the closed type  <br>      Object o = Activator.CreateInstance(closedType);  <br> <br>      // Prove it worked  <br>      Console.WriteLine(o.GetType());  <br>   }  <br>}<br>
If you compile the code shown above and run it, you get the following output:<br>
Dictionary`2[System.String,System.Int32]<br>
<b>Designing an Application That Supports Add-Ins</b><br>
When you're building extensible applications, interfaces should be the centerpiece. You could <br>use a base class instead of an interface, but in general, an interface is preferred because it <br>allows add-in developers to choose their own base class. Suppose, for example, that you're <br>writing an application and you want others to be able to create types that your application <br>can load and use seamlessly. Here's the way to design this application:<br>
<hr>
<A name=653></a><IMG src="CLRviaCsharp-653_1.jpg"><br>
<b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>635</b><br>
  Create a Host SDK assembly that defines an interface whose methods are used as the <br>
communication mechanism between the host application and the add-in components. <br>When defining the parameters and return values for the interface methods, try to use <br>other interfaces or types defined in MSCorLib.dll. If you want to pass and return your <br>own data types, define them in this Host SDK assembly, too. Once you settle on your <br>interface definitions, give this assembly a strong name (discussed in Chapter 3), and <br>then package and deploy it to your partners and users. Once published, you should  <br>really avoid making any kind of breaking changes to the types in this assembly. For  <br>example, do not change the interface in any way. However, if you define any data types, <br>it is OK to add new members. If you make any modifications to the assembly, you'll <br>probably want to deploy it with a publisher policy file (also discussed in Chapter 3).<br>
<b>Note  </b>You can use types defined in MSCorLib.dll because the CLR always loads the version  <br>of MSCorLib.dll that matches the version of the CLR itself. Also, only a single version <br>of MSCorLib.dll is ever loaded into a CLR instance. In other words, different versions of <br>MSCorLib.dll never load side by side (as described in Chapter 3). As a result, you won't have <br>any type version mismatches, and your application will require less memory.<br>
  The add-in developers will, of course, define their own types in their own Add-In  <br>
assembly. Their Add-In assembly will reference the types in your Host SDK assembly. <br>The add-in developers are able to put out a new version of their assembly as often as <br>they'd like, and the host application will be able to consume the add-in types without <br>any problem whatsoever.<br>
  Create a separate Host Application assembly containing your application's types. This <br>
assembly will obviously reference the Host SDK assembly and use the types defined in <br>it. Feel free to modify the code in the Host Application assembly to your heart's desire. <br>Because the add-in developers don't reference the Host Application assembly, you can <br>put out a new version of it every hour if you want to and not affect any of the add-in <br>developers.<br>
This section contains some very important information. When using types across assemblies, <br>you need to be concerned with assembly-versioning issues. Take your time to architect this <br>cleanly by isolating the types that you use for communication across assembly boundaries <br>into their own assembly. Avoid mutating or changing these type definitions. However, if you <br>really need to modify the type definitions, make sure that you change the assembly's version <br>number and create a publisher policy file for the new version.<br>
I'll now walk through a very simple scenario that puts all of this together. First, here is the <br>code for the HostSDK.dll assembly:<br>
<hr>
<A name=654></a><b>636 </b><br>
<b>Part IV  Core Facilities</b><br>
using System;  <br> <br>namespace Wintellect.HostSDK {  <br>   public interface IAddIn {  <br>      String DoSomething(Int32 x);  <br>   }  <br>}<br>
Second, here is the code for an AddInTypes.dll assembly defining two public types that  <br>implement the HostSDK's interface. To build this assembly, the HostSDK.dll assembly must  <br>be referenced:<br>
using System;  <br>using Wintellect.HostSDK;  <br> <br>public sealed class AddIn_A : IAddIn {  <br>   public AddIn_A() {  <br>   }  <br>   public String DoSomething(Int32 x) {  <br>      return &quot;AddIn_A: &quot; + x.ToString();  <br>   }  <br>}  <br> <br>public sealed class AddIn_B : IAddIn {  <br>   public AddIn_B() {  <br>   }  <br>   public String DoSomething(Int32 x) {  <br>      return &quot;AddIn_B: &quot; + (x * 2).ToString();  <br>   }  <br>}<br>
Third, here is the code for a simple Host.exe assembly (a console application). To build this <br>assembly, the HostSDK.dll assembly must be referenced. To discover usable add-in types, this <br>host code assumes that the types are defined in assemblies ending with a .dll file extension  <br>and that these assemblies are deployed into the same directory as the host's EXE file. <br>Microsoft's Managed Extensibility Framework (MEF) is built on top of the various mechanisms <br>that I show here, and it also offers add-in registration and discovery mechanisms. I urge you <br>to check MEF out if you are building a dynamically extensible application, as it can simplify <br>some of the material in this chapter.<br>
using System;  <br>using System.IO;  <br>using System.Reflection;  <br>using System.Collections.Generic;  <br>using Wintellect.HostSDK;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      // Find the directory that contains the Host exe  <br>      String AddInDir = Path.GetDirectoryName(Assembly.GetEntryAssembly().Location);  <br> <br>
<hr>
<A name=655></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>637</b><br>
      // Assume AddIn assemblies are in same directory as host's EXE file  <br>      String[] AddInAssemblies = Directory.GetFiles(AddInDir, &quot;*.dll&quot;);  <br> <br>      // Create a collection of usable add-in Types  <br>      List&lt;Type&gt; AddInTypes = new List&lt;Type&gt;();  <br> <br>      // Load add-in assemblies; discover which types are usable by the host  <br>      foreach (String file in AddInAssemblies) {  <br>         Assembly AddInAssembly = Assembly.LoadFrom(file);  <br> <br>         // Examine each publicly exported type  <br>         foreach (Type t in AddInAssembly.GetExportedTypes()) {  <br>            // If the type is a class that implements the IAddIn   <br>            // interface, then the type is usable by the host  <br>            if (t.IsClass &amp;&amp; typeof(IAddIn).IsAssignableFrom(t)) {  <br>               AddInTypes.Add(t);  <br>            }  <br>         }  <br>      }  <br> <br>      // Initialization complete: the host has discovered the usable add-ins  <br> <br>      // Here's how the host can construct add-in objects and use them  <br>      foreach (Type t in AddInTypes) {  <br>         IAddIn ai = (IAddIn) Activator.CreateInstance(t);  <br>         Console.WriteLine(ai.DoSomething(5));  <br>      }  <br>   }  <br>}<br>
The simple host/add-in scenario just shown doesn't use AppDomains. However, in a real-life <br>scenario, you will likely create each add-in in its own AppDomain with its own security and <br>configuration settings. And of course, each AppDomain could be unloaded if you wanted to <br>remove an add-in from memory. To communicate across the AppDomain boundary, you'd <br>either tell the add-in developers to derive their add-in types from MarshalByRefObject <br>or, more likely, have the host application define its own internal type that is derived from <br>MarshalByRefObject. As each AppDomain is created, the host would create an instance of <br>its own MarshalByRefObject-derived type in the new AppDomain. The host's code (in the <br>default AppDomain) would communicate with its own type (in the other AppDomains) to <br>have it load add-in assemblies and create and use instances of the add-in types.<br>
<b>Using Reflection to Discover a Type's Members</b><br>
So far, this chapter has focused on the parts of reflection--assembly loading, type discovery, <br>and object construction--necessary to build a dynamically extensible application. In order <br>to have good performance and compile-time type safety, you want to avoid using reflection <br>as much as possible. In the dynamically extensible application scenario, once an object is <br>constructed, the host code typically casts the object to an interface type or a base class that <br>is known at compile time; this allows the object's members to be accessed in a high-perfor-<br>mance and compile-time type-safe way.<br>
<hr>
<A name=656></a><b>638 </b><br>
<b>Part IV  Core Facilities</b><br>
In the remainder of this chapter, I'm going to focus on some other aspects of reflection that <br>you can use to discover and then invoke a type's members. The ability to discover and invoke <br>a type's members is typically used to create developer tools and utilities that analyze an  <br>assembly by looking for certain programming patterns or uses of certain members. Examples <br>of tools/utilities that do this are ILDasm.exe, FxCopCmd.exe, and Visual Studio's Windows <br>Forms and Web Forms designers. In addition, some class libraries use the ability to discover <br>and invoke a type's members in order to offer rich functionality as a convenience to devel-<br>opers. Examples of class libraries that do so are serialization/deserialization and simple data <br>binding.<br>
<b>Discovering a Type's Members</b><br>
Fields, constructors, methods, properties, events, and nested types can all be defined as <br>members within a type. The FCL contains a type called System.Reflection.MemberInfo. <br>This class is an abstract base class that encapsulates a bunch of properties common to all <br>type members. Derived from MemberInfo are a bunch of classes; each class encapsulates <br>some more properties related to a specific type member. Figure 23-1 shows the hierarchy of <br>these types.<br>
System.Object<br>
System.Reflection.MemberInfo<br>
A nested type is a member<br>
System.Type<br>
System.Reflection.FieldInfo<br>
System.R<br>
S<br>
eflection.MethodBase<br>
ystem.R<br>
System.Reflection.ContructorInfo<br>
System.Reflection.MethodInfo<br>
System.Reflection.PropertyInfo<br>
System.Reflection.EventInfo<br>
<b>FIGURE 23-1  </b>Hierarchy of the reflection types that encapsulate information about a type's member<br>
The following program demonstrates how to query a type's members and display some  <br>information about them. This code processes all of the public types defined in all assemblies <br>loaded in the calling AppDomain. For each type, the GetMembers method is called and  <br>
<hr>
<A name=657></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>639</b><br>
returns an array of MemberInfo-derived objects; each object refers to a single member  <br>defined within the type. The BindingFlags variable, bf, passed to the GetMembers method <br>tells the method which kinds of members to return. I'll talk about BindingFlags later in this <br>chapter. Then, for each member, its kind (field, constructor, method, property, etc.) and its <br>string value (obtained by calling ToString) is shown.<br>
using System;  <br>using System.Reflection;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      // Loop through all assemblies loaded in this AppDomain  <br>      Assembly[] assemblies = AppDomain.CurrentDomain.GetAssemblies();  <br>      foreach (Assembly a in assemblies) {  <br>         WriteLine(0, &quot;Assembly: {0}&quot;, a);  <br> <br>         // Find Types in the assembly  <br>         foreach (Type t in a.GetExportedTypes()) {  <br>            WriteLine(1, &quot;Type: {0}&quot;, t);  <br> <br>            // Discover the type's members  <br>            const BindingFlags bf = BindingFlags.DeclaredOnly |  <br>               BindingFlags.NonPublic | BindingFlags.Public |  <br>               BindingFlags.Instance | BindingFlags.Static;  <br> <br>            foreach (MemberInfo mi in t.GetMembers(bf)) {  <br>               String typeName = String.Empty;  <br>               if (mi is Type)                 typeName = &quot;(Nested) Type&quot;;  <br>               else if (mi is FieldInfo)       typeName = &quot;FieldInfo&quot;;  <br>               else if (mi is MethodInfo)      typeName = &quot;MethodInfo&quot;;  <br>               else if (mi is ConstructorInfo) typeName = &quot;ConstructoInfo&quot;;  <br>               else if (mi is PropertyInfo)    typeName = &quot;PropertyInfo&quot;;  <br>               else if (mi is EventInfo)       typeName = &quot;EventInfo&quot;;  <br> <br>               WriteLine(2, &quot;{0}: {1}&quot;, typeName, mi);  <br>            }  <br>         }  <br>      }  <br>   }  <br>   private static void WriteLine(Int32 indent, String format, params Object[] args) {  <br>      Console.WriteLine(new String(' ', 3 * indent) + format, args);  <br>   }  <br>}<br>
When you compile and run this code, a ton of output is produced. Here is a small sampling <br>of what it looks like:<br>
Assembly: mscorlib, Version=4.0.0.0, Culture=neutral, PublicKeyToken=b77a5c561934e089 <br>   Type: System.Object <br>      MethodInfo: System.String ToString() <br>      MethodInfo: Boolean Equals(System.Object) <br>      MethodInfo: Boolean Equals(System.Object, System.Object) <br>      MethodInfo: Boolean ReferenceEquals(System.Object, System.Object) <br>
<hr>
<A name=658></a><b>640 </b><br>
<b>Part IV  Core Facilities</b><br>
      MethodInfo: Int32 GetHashCode() <br>      MethodInfo: System.Type GetType() <br>      MethodInfo: Void Finalize() <br>      MethodInfo: System.Object MemberwiseClone() <br>      MethodInfo: Void FieldSetter(System.String, System.String, System.Object) <br>      MethodInfo: Void FieldGetter(System.String, System.String, System.Object ByRef) <br>      MethodInfo: System.Reflection.FieldInfo GetFieldInfo(System.String, System.String) <br>      ConstructoInfo: Void .ctor() <br>   Type: System.Collections.Generic.IComparer`1[T] <br>      MethodInfo: Int32 Compare(T, T) <br>   Type: System.Collections.IEnumerator <br>      MethodInfo: Boolean MoveNext() <br>      MethodInfo: System.Object get_Current() <br>      MethodInfo: Void Reset() <br>      PropertyInfo: System.Object Current <br>   Type: System.IDisposable <br>      MethodInfo: Void Dispose() <br>   Type: System.Collections.Generic.IEnumerator`1[T] <br>      MethodInfo: T get_Current() <br>      PropertyInfo: T Current <br>   Type: System.ArraySegment`1[T] <br>      MethodInfo: T[] get_Array() <br>      MethodInfo: Int32 get_Offset() <br>      MethodInfo: Int32 get_Count() <br>      MethodInfo: Int32 GetHashCode() <br>      MethodInfo: Boolean Equals(System.Object) <br>      MethodInfo: Boolean Equals(System.ArraySegment`1[T]) <br>      MethodInfo: Boolean op_Equality(System.ArraySegment`1[T], System.ArraySegment`1[T]) <br>      MethodInfo: Boolean op_Inequality(System.ArraySegment`1[T], System.ArraySegment`1[T]) <br>      ConstructoInfo: Void .ctor(T[]) <br>      ConstructoInfo: Void .ctor(T[], Int32, Int32) <br>      PropertyInfo: T[] Array <br>      PropertyInfo: Int32 Offset <br>      PropertyInfo: Int32 Count <br>      FieldInfo: T[] _array <br>      FieldInfo: Int32 _offset<br>
Since MemberInfo is the root of the member hierarchy, it makes sense for us to discuss <br>it a bit more. Table 23-1 shows several read-only properties and methods offered by the <br>MemberInfo class. These properties and methods are common to all members of a type. <br>Don't forget that System.Type is derived from MemberInfo, and therefore, Type also offers <br>all of the properties shown in Table 23-1.<br>
<b>TABLE 23-1  Properties and Methods Common to All </b>MemberInfo<b>-Derived Types</b><br>
<b>Member Name</b><br>
<b>Member Type</b><br>
<b>Description</b><br>
Name<br>
String property<br>
Returns the name of the member. <br>In the case of a nested type, Name <br>returns the concatenation of the <br>name of the containing type, <br>followed by `+', followed by the <br>name of the nested type.<br>
<hr>
<A name=659></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>641</b><br>
<b>Member Name</b><br>
<b>Member Type</b><br>
<b>Description</b><br>
MemberType<br>
MemberTypes (enum) property<br>
Returns the kind of member (field, <br>constructor, method, property, <br>event, type (non-nested type or <br>nested type).<br>
DeclaringType<br>
Type property<br>
Returns the Type that declares <br>the member.<br>
ReflectedType<br>
Type property<br>
Returns the Type used to obtain <br>this member.<br>
Module<br>
Module property<br>
Returns the Module that declares <br>the member.<br>
MetadataToken<br>
Int32 property<br>
Returns the metadata token <br>(within the module) that identifies <br>the member.<br>
GetCustomAttributes<br>
Method returning Object[]<br>
Returns an array in which each <br>element identifies an instance of <br>a custom attribute applied to this <br>member. Custom attributes can <br>be applied to any member. Use <br>this method with assemblies that <br>have not been loaded in the  <br>"reflection only" context.<br>
GetCustomAttributesData<br>
Method returning <br>
Returns a collection in which each <br>
IList&lt;CustomAttributeData&gt; element identifies an instance of <br>
a custom attribute applied to this <br>member. Custom attributes can <br>be applied to any member. Even <br>though Assembly does not derive <br>from MemberInfo, it provides the <br>same method that can be used <br>with assemblies.<br>
IsDefined<br>
Method returning Boolean<br>
Returns true if at least one  <br>instance of the specified custom <br>attribute is applied to the member.<br>
Most of the properties mentioned in Table 23-1 are self-explanatory. However, developers <br>frequently confuse the DeclaringType and ReflectedType properties. To fully understand <br>these properties, let's define the following type:<br>
public sealed class MyType {  <br>   public override String ToString() { return null; }  <br>}<br>
What would happen if the following line of code executed?<br>
MemberInfo[] members = typeof(MyType).GetMembers();<br>
<hr>
<A name=660></a><b>642 </b><br>
<b>Part IV  Core Facilities</b><br>
The members variable is a reference to an array in which each element identifies a public <br>member defined by MyType and any of its base types, such as System.Object. If you were to <br>query the DeclaringType property for the MemberInfo element identifying the ToString <br>method, you'd see MyType returned because MyType declares a ToString method. On the <br>other hand, if you were to query the DeclaringType property for the MemberInfo element  <br>identifying the Equals method, you'd see System.Object returned because Equals is <br>declared by System.Object, not by MyType. The ReflectedType property always returns <br>MyType because this was the type specified when GetMembers was called to perform the <br>reflection.<br>
Each element of the array returned by calling GetMembers is a reference to one of the con-<br>crete types in the hierarchy (unless the BindingFlags.DeclaredOnly flag is specified). <br>Although Type's GetMembers method returns all of the type's members, Type also offers <br>methods that return specific member types. For example, Type offers GetNestedTypes, <br>GetFields, GetConstructors, GetMethods, GetProperties, and GetEvents. These methods <br>all return arrays in which each element is a reference to a Type object, FieldInfo object, <br>ConstructorInfo object, MethodInfo object, PropertyInfo object, or EventInfo object, <br>respectively.<br>
Figure 23-2 summarizes the types used by an application to walk reflection's object model. <br>From an AppDomain, you can discover the assemblies loaded into it. From an assembly, you <br>can discover the modules that make it up. From an assembly or a module, you can discover <br>the types that it defines. From a type, you can discover its nested types, fields, constructors, <br>methods, properties, and events. Namespaces are not part of this hierarchy because they are <br>simply syntactical gatherings of types. If you want to list all of the namespaces defined in an <br>assembly, you need to enumerate all of the types in this assembly and take a look at their <br>Namespace property.<br>
From a type, it is also possible to discover the interfaces it implements. (I'll show how <br>to do this a little later.) And from a constructor, method, property accessor method, or <br>event add/remove method, you can call the GetParameters method to obtain an array of <br>ParameterInfo objects, which tells you the types of the member's parameters. You can also <br>query the read-only ReturnParameter property to get a ParameterInfo object for detailed <br>information about a member's return value. For a generic type or method, you can call the <br>GetGenericArguments method to get the set of type parameters. Finally, for any of these <br>items, you can call the GetCustomAttributes method to obtain the set of custom attributes <br>applied to them.<br>
<hr>
<A name=661></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>643</b><br>
FieldInfo #1<br>
AppDomain<br>
FieldInfo #2<br>
Assembly #1<br>
Module #1<br>
Type #1<br>
ConstructorInfo #1<br>
Assembly #2<br>
Module #2<br>
Type #2<br>
ConstructorInfo #2<br>
MethodInfo #1<br>
MethodInfo #2<br>
PropertyInfo #1<br>
PropertyInfo #2<br>
EventInfo #1<br>
EventInfo #2<br>
<b>FIGURE 23-2  </b>Types an application uses to walk reflection's object model<br>
BindingFlags<b>: Filtering the Kinds of Members That Are </b><br>
<b>Returned</b><br>
You query a type's members by calling Type's GetMembers, GetNestedTypes, GetFields, <br>GetConstructors, GetMethods, GetProperties, or GetEvents methods. When you call <br>any of these methods, you can pass in an instance of a System.Reflection.BindingFlags <br>enumerated type. The enumerated type identifies a set of bit flags OR'd together to help you <br>filter the members that are returned from these methods. Table 23-2 shows the relevant  <br>symbols defined by the BindingFlags enumerated type.<br>
All of the methods that return a set of members have an overload that takes no arguments <br>at all. When you don't pass a BindingFlags argument, all of these methods return only the <br>public members. In other words, the default is BindingFlags.Public | BindingFlags.<br>Instance | BindingFlags.Static.<br>
Note that Type also defines GetMember, GetNestedType, GetField, GetConstructor, <br>GetMethod, GetProperty, and GetEvent methods. These methods allow you to pass <br>in a String that identifies a member's name to look up. This is when BindingFlags's <br>IgnoreCase flag comes in handy.<br>
<hr>
<A name=662></a><b>644 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>TABLE 23-2  Search Symbols Defined by the </b>BindingFlags<b> Enumerated Type</b><br>
<b>Symbol</b><br>
<b>Value</b><br>
<b>Description</b><br>
Default<br>
0x00<br>
A placeholder for no flags specified. Use this flag when you <br>don't want to specify any of the flags listed in the remainder <br>of this table.<br>
IgnoreCase<br>
0x01<br>
Return members matching specified string regardless of case.<br>
DeclaredOnly<br>
0x02<br>
Return only members of the reflected type, ignoring inherited <br>members.<br>
Instance<br>
0x04<br>
Return instance members.<br>
Static<br>
0x08<br>
Return static members.<br>
Public<br>
0x10<br>
Return public members.<br>
NonPublic<br>
0x20<br>
Return non-public members.<br>
FlattenHierarchy<br>
0x40<br>
Return static members defined by base types.<br>
<b>Discovering a Type's Interfaces<br></b>To obtain the set of interfaces that a type inherits, you can call Type's FindInterfaces, <br>GetInterface, or GetInterfaces method. All of these methods return Type objects that <br>represent an interface. Note that these methods scan the type's inheritance hierarchy and <br>return all of the interfaces defined on the specified type as well as all of its base types.<br>
Determining which members of a type implement a particular interface is a little complicated  <br>because multiple interface definitions can all define the same method. For example, the  <br>IBookRetailer and IMusicRetailer interfaces might both define a method named <br>Purchase. To get the MethodInfo objects for a specific interface, you call Type's <br>GetInterfaceMap instance method passing the interface type as an argument. This  <br>method returns an instance of a System.Reflection.InterfaceMapping (a value type).  <br>The InterfaceMapping type defines the four public fields listed in Table 23-3.<br>
<b>TABLE 23-3  Public Fields Defined by the </b>InterfaceMapping<b> Type</b><br>
<b>Field Name</b><br>
<b>Data Type</b><br>
<b>Description</b><br>
TargetType<br>
Type<br>
This is the type that was used to call <br>GetInterfaceMapping.<br>
InterfaceType<br>
Type<br>
This is the type of the interface passed to <br>GetInterfaceMapping.<br>
InterfaceMethods<br>
MethodInfo[]<br>
This is an array in which each element exposes  <br>information about an interface's method.<br>
TargetMethods<br>
MethodInfo[]<br>
This is an array in which each element exposes  <br>information about the method that the type defines <br>to implement the corresponding interface's method.<br>
<hr>
<A name=663></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>645</b><br>
The InterfaceMethods and TargetMethods arrays run parallel to each other; that is, <br>InterfaceMethods[0] identifies the interface's MethodInfo, and TargetMethods[0] identi-<br>fies the method defined by the type that implements this interface method. Here is some <br>code that shows how to discover the interfaces and interface methods defined by a type:<br>
using System;  <br>using System.Reflection;  <br> <br>// Define two interfaces for testing  <br>internal interface IBookRetailer : IDisposable {  <br>   void Purchase();  <br>   void ApplyDiscount();  <br>}  <br> <br>internal interface IMusicRetailer {  <br>   void Purchase();  <br>}  <br> <br> <br>// This class implements 2 interfaces defined by this assembly   <br>// and 1 interface defined by another assembly  <br>internal sealed class MyRetailer : IBookRetailer, IMusicRetailer, IDisposable {  <br>   // IBookRetailer methods  <br>   void IBookRetailer.Purchase() { }  <br>   public void ApplyDiscount() { }  <br> <br>   // IMusicRetailer method  <br>   void IMusicRetailer.Purchase() { }  <br> <br>   // IDisposable method  <br>   public void Dispose() { }  <br> <br>   // MyRetailer method (not an interface method)  <br>   public void Purchase() { }  <br>}  <br> <br> <br>public static class Program {  <br>   public static void Main() {  <br>       // Find interfaces implemented by MyRetailer where the interface is  <br>       // defined in our own assembly. This is accomplished using a delegate  <br>       // to a filter method that we pass to FindInterfaces. <br>      Type t = typeof(MyRetailer);  <br>      Type[] interfaces = t.FindInterfaces(TypeFilter,  typeof(Program).Assembly);  <br>      Console.WriteLine( <br>         &quot;MyRetailer implements the following interfaces (defined in this assembly):&quot;);  <br> <br>      // Show information about each interface  <br>      foreach (Type i in interfaces) {  <br>         Console.WriteLine(&quot;\nInterface: &quot; + i);  <br> <br>         // Get the type methods that map to the interface's methods  <br>         InterfaceMapping map = t.GetInterfaceMap(i);  <br> <br>
<hr>
<A name=664></a><b>646 </b><br>
<b>Part IV  Core Facilities</b><br>
         for (Int32 m = 0; m &lt; map.InterfaceMethods.Length; m++) {  <br>            // Display the interface method name and which  <br>            // type method implements the interface method.  <br>            Console.WriteLine(&quot;   {0} is implemented by {1}&quot;, <br>               map.InterfaceMethods[m], map.TargetMethods[m]);  <br>         }  <br>      }  <br>   }  <br> <br> <br>   // Returns true if type matches filter criteria  <br>   private static Boolean TypeFilter(Type t, Object filterCriteria) {  <br>      // Return true if the interface is defined in  assembly identified by filterCriteria  <br>      return t.Assembly == filterCriteria;  <br>   }  <br>}<br>
When you build and run the code above, you get the following output:<br>
MyRetailer implements the following interfaces (defined in this assembly):  <br> <br>Interface: IBookRetailer  <br>   Void Purchase() is implemented by Void IBookRetailer.Purchase()  <br>   Void ApplyDiscount() is implemented by Void ApplyDiscount()  <br> <br>Interface: IMusicRetailer  <br>   Void Purchase() is implemented by Void IMusicRetailer.Purchase()<br>
Note that the IDisposable interface does not appear in the output because this interface is <br>not declared in the EXE file's assembly.<br>
<b>Invoking a Type's Members</b><br>
Now that you know how to discover the members defined by a type, you may want to invoke  <br>one of these members. What <i>invoke</i> means depends on the kind of member being invoked. <br>Invoking a FieldInfo lets you get or set a field's value, invoking a ConstructorInfo <br>lets you create an instance of the type passing arguments to a constructor, invoking a <br>MethodInfo lets you call a method passing arguments and obtaining its return value, invok-<br>ing a PropertyInfo lets you call the property's get or set accessor method, and invoking an <br>EventInfo lets you add or remove an event handler.<br>
Let's discuss how to invoke a method first because this is the most complex member you <br>can invoke. Then we'll discuss how to invoke the other members. The Type class offers an <br>InvokeMember method that lets you invoke a member. There are several overloaded versions <br>of InvokeMember. I'll discuss one of the more common overloads; the other overloads work <br>similarly.<br>
<hr>
<A name=665></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>647</b><br>
public abstract class Type : MemberInfo, ... {  <br>   public Object InvokeMember(  <br>      String name,               // Name of member  <br>      BindingFlags invokeAttr,   // How to look up members  <br>      Binder binder,             // How to match members and arguments  <br>      Object target,             // Object to invoke member on  <br>      Object[] args,             // Arguments to pass to method  <br>      CultureInfo culture);      // Culture used by some binders  <br>   ...  <br>}<br>
When you call InvokeMember, it searches the type's members for a match. If no match is <br>found, a System.MissingMethodException, System.MissingFieldException, or  <br>System.MissingMemberException exception is thrown. If a match is found, InvokeMember <br>invokes the member. If the member returns something, InvokeMember returns it to you. If the <br>member doesn't return anything, InvokeMember returns null. If the member you call throws <br>an exception, InvokeMember catches the exception and throws a new System.Reflection.<br>TargetInvocationException. The TargetInvocationException object's InnerException <br>property will contain the actual exception that the invoked method threw. Personally, I don't <br>like this behavior. I'd prefer it if InvokeMember didn't wrap the exception and just allowed it <br>to come through.<br>
Internally, InvokeMember performs two operations. First, it must select the appropriate  <br>member to be called--this is known as <i>binding</i>. Second, it must actually invoke the member <br>--this is known as <i>invoking</i>. When you call InvokeMember, you pass a string as the name  <br>parameter, indicating the name of the member you want InvokeMember to bind to. However, <br>the type might offer several members with the same name. After all, there might be several  <br>overloaded versions of a method, or a method and a field might have the same name. <br>Of course, InvokeMember must bind to a single member before it can invoke it. All of the <br>parameters passed to InvokeMember (except for the target parameter) are used to help <br>InvokeMember decide which member to bind to. Let's take a closer look at these parameters.<br>
The binder parameter identifies an object whose type is derived from the abstract  <br>System.Reflection.Binder type. A Binder-derived type is a type that encapsulates the  <br>rules for how InvokeMember should select a single member. The Binder base type defines  <br>abstract virtual methods such as BindToField, BindToMethod, ChangeType, <br>ReorderArgumentArray, SelectMethod, and SelectProperty. Internal y, InvokeMember calls <br>these methods by using the Binder object passed via InvokeMember's binder parameter.<br>
Microsoft has defined an internal (undocumented) concrete type, called System.<br>DefaultBinder, which is derived from Binder. This DefaultBinder type ships with the FCL, <br>and Microsoft expects that almost everyone will use this binder. Some compiler vendors will <br>define their own Binder-derived type and ship it in a runtime library used by code emitted <br>by their compiler.1 When you pass null to InvokeMember's binder parameter, it will use a <br>
1  The code that accompanies this book includes the source code for a SimpleBinder class that demonstrates how <br>
to define your own Binder-derived type.<br>
<hr>
<A name=666></a><b>648 </b><br>
<b>Part IV  Core Facilities</b><br>
DefaultBinder object. Type offers a public, static, read-only property, DefaultBinder, that <br>you can query to obtain a reference to a DefaultBinder object should you want one.<br>
When a binder object has its methods called, the methods will be passed parameters to help <br>the binder make a decision. Certainly, the binder is passed the name of the member that is <br>being looked for. In addition, the binder's methods are passed the specified BindingFlags <br>as well as the types of all of the parameters that need to be passed to the member being <br>invoked.<br>
Earlier in this chapter, Table 23-2 described the following BindingFlags: Default, <br>IgnoreCase, DeclaredOnly, Instance, Static, Public, NonPublic, and FlattenHierarchy. <br>The presence of these flags tells the binder which members to include in the search.<br>
In addition to these flags, the binder examines the number of arguments passed via <br>InvokeMember's args parameter. The number of arguments limits the set of possible matches <br>even further. The binder then examines the types of the arguments to limit the set even <br>more. However, when it comes to the argument's types, the binder applies some automatic <br>type conversions to make things a bit more flexible. For example, a type can define a method <br>that takes a single Int64 parameter. If you call InvokeMember, and in the args parameter, <br>pass a reference to an array containing an Int32 value, the DefaultBinder considers this a <br>match. When invoking the method, the Int32 value will be converted to an Int64 value. The <br>DefaultBinder supports the conversions listed in Table 23-4.<br>
<b>TABLE 23-4  Conversions That </b>DefaultBinder<b> Supports</b><br>
<b>Source Type</b><br>
<b>Target Type</b><br>
Any type<br>
Its base type<br>
Any type<br>
The interfaces it implements<br>
Char<br>
UInt16, UInt32, Int32, UInt64, Int64, Single, Double<br>
Byte<br>
Char, UInt16, Int16, UInt32, Int32, UInt64, Int64, Single, <br>Double<br>
SByte<br>
Int16, Int32, Int64, Single, Double<br>
UInt16<br>
UInt32, Int32, UInt64, Int64, Single, Double<br>
Int16<br>
Int32, Int64, Single, Double<br>
UInt32<br>
UInt64, Int64, Single, Double<br>
Int32<br>
Int64, Single, Double<br>
UInt64<br>
Single, Double<br>
Int64<br>
Single, Double<br>
Single<br>
Double<br>
A value type instance<br>
A boxed version of the value type instance<br>
<hr>
<A name=667></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>649</b><br>
There are two more BindingFlags that you can use to fine-tune the DefaultBinder's  <br>behavior. These are described in Table 23-5.<br>
<b>TABLE 23-5  </b>BindingFlags<b> Used with </b>DefaultBinder<br>
<b>Symbol</b><br>
<b>Value</b><br>
<b>Description</b><br>
ExactBinding<br>
0x010000<br>
The binder will look for a member whose formal <br>parameters exactly match the types of the supplied <br>arguments.<br>
OptionalParamBinding<br>
0x040000<br>
The binder will consider any member whose count <br>of parameters matches the number of arguments <br>passed. This flag is useful when there are members <br>whose parameters have default values and for <br>methods that take a variable number of arguments. <br>Only Type's InvokeMember method honors this <br>flag.<br>
InvokeMember's last parameter, culture, could also be used for binding. However, the <br>DefaultBinder type completely ignores this parameter. If you define your own binder, you <br>could use the culture parameter to help with argument type conversions. For example, the <br>caller could pass a String argument with a value of "1,23." The binder could examine this <br>string, parse it using the specified culture, and convert the argument's type to a Single (if <br>the culture is "de-DE") or continue to consider the argument to be a String (if the culture <br>is "en-US").<br>
At this point, I've gone through all InvokeMember's parameters related to binding. The one <br>parameter I haven't discussed yet is target. This parameter is a reference to the object <br>whose member you want to call. If you want to call a type's static member, you should pass <br>null for this parameter.<br>
The InvokeMember method is a very powerful method. It allows you to call a method (as I've <br>been discussing), construct an instance of a type (basically by calling a constructor method), <br>get or set a field, or get or set a property. You tell InvokeMember which of these actions you <br>want to perform by specifying one of the BindingFlags listed in Table 23-6.<br>
For the most part, the flags in Table 23-6 are mutually exclusive--you must pick one <br>and only one when calling InvokeMember. However, you can specify both GetField and <br>GetProperty, in which case InvokeMember searches for a matching field first and then for a <br>matching property if it doesn't find a matching field. Likewise, SetField and SetProperty <br>can both be specified and are matched the same way. The binder uses these flags to narrow  <br>the set of possible matches. If you specify the BindingFlags.CreateInstance flag, the <br>binder knows that it can select only a constructor method.<br>
<hr>
<A name=668></a><IMG src="CLRviaCsharp-668_1.jpg"><br>
<b>650 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>TABLE 23-6  </b>BindingFlags<b> Used with </b>InvokeMember<br>
<b>Symbol</b><br>
<b>Value</b><br>
<b>Description</b><br>
InvokeMethod<br>
0x0100<br>
Tells InvokeMember to call a method<br>
CreateInstance<br>
0x0200<br>
Tells InvokeMember to create a new object and call its <br>constructor<br>
GetField<br>
0x0400<br>
Tells InvokeMember to get a field's value<br>
SetField<br>
0x0800<br>
Tells InvokeMember to set a field's value<br>
GetProperty<br>
0x1000<br>
Tells InvokeMember to call a property's get accessor <br>method<br>
SetProperty<br>
0x2000<br>
Tells InvokeMember to call a property's set accessor <br>method<br>
<b>Important</b>  With what I've told you so far, it would seem that reflection makes it easy to bind to <br>a non-public member and invoke the member allowing application code a way to access private <br>members that a compiler would normally prohibit the code from accessing. However, reflection <br>uses code access security (CAS) to ensure that its power isn't abused or exploited.<br>
When you call a method to bind to a member, the CLR first checks to see whether the member  <br>you're trying to bind to would be visible to you at compile time. If it would be, the bind is  <br>successful. If the member wouldn't normally be accessible to you, the method demands the  <br>System.Security.Permissions.ReflectionPermission permission, checking to see whether <br>the System.Security.Permissions.ReflectionPermissionFlags's TypeInformation  <br>bit is set. If this flag is set, the method will bind to the member. If the demand fails, a  <br>System.Security.SecurityException is thrown.<br>
When you call a method to invoke a member, the method performs the same kind of <br>check that it would when binding to a member. But this time, it checks whether the <br>ReflectionPermission has ReflectionPermissionFlag's MemberAccess bit set. If the  <br>bit is set, the member is invoked; otherwise, a SecurityException is thrown.<br>
Of course, if your assembly has full-trust, security checks are assumed to be successful allowing <br>binding and invoking to just work. However, you should never, ever use reflection to access any <br>of a type's undocumented members because a future version of the assembly may easily break <br>your code.<br>
<b>Bind Once, Invoke Multiple Times</b><br>
Type's InvokeMember method gives you access to all of a type's members. However, you <br>should be aware that every time you call InvokeMember, it must bind to a particular member <br>and then invoke it. Having the binder select the right member each time you want to invoke <br>a member is time-consuming, and if you do it a lot, your application's performance wil  suffer. <br>So if you plan on accessing a member frequently, you're better off binding to the desired <br>member once and then accessing that member as often as you want.<br>
In this chapter, we've already discussed how to bind to a member by calling one of Type's <br>methods: GetFields, GetConstructors, GetMethods, GetProperties, GetEvents, or any <br>
<hr>
<A name=669></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>651</b><br>
similar method. All of these methods return references to objects whose type offers methods <br>to access the specific member directly. Table 23-7 shows which method to call for each kind <br>of member to invoke that member.<br>
<b>TABLE 23-7  How to Invoke a Member After Binding to It</b><br>
<b>Type of Member </b><br>
<b>Method to Invoke Member</b><br>
FieldInfo<br>
Call GetValue to get a field's value.<br>Call SetValue to set a field's value.<br>
ConstructorInfo<br>
Call Invoke to construct an instance of the type and call a constructor.<br>
MethodInfo<br>
Call Invoke to call a method of the type.<br>
PropertyInfo<br>
Call GetValue to call a property's get accessor method.<br>Call SetValue to call a property's set accessor method.<br>
EventInfo<br>
Call AddEventHandler to call an event's add accessor method.<br>Call RemoveEventHandler to call an event's remove accessor method.<br>
The PropertyInfo type represents metadata information about a property (as discussed  <br>in Chapter 10, "Properties"); that is, PropertyInfo offers CanRead, CanWrite, and <br>PropertyType read-only properties. These properties indicate whether a property is read-<br>able or writeable and what data type the property is. PropertyInfo has a GetAccessors <br>method that returns an array of MethodInfo elements: one for the get accessor method (if it <br>exists), and one for the set accessor method (if it exists). Of more value are PropertyInfo's <br>GetGetMethod and GetSetMethod methods, each of which returns just one MethodInfo  <br>object. PropertyInfo's GetValue and SetValue methods exist for convenience; internally, <br>they get the appropriate MethodInfo and call it. To support parameterful properties (C#  <br>indexers), the GetValue and SetValue methods offer an index parameter of Object[] type.<br>
The EventInfo type represents metadata information about an event (as discussed in <br>Chapter 11, "Events"). The EventInfo type offers an EventHandlerType read-only property  <br>that returns the Type of the event's underlying delegate. The EventInfo type also has <br>GetAddMethod and GetRemoveMethod methods, which return the MethodInfo corresponding  <br>to the method that adds or removes a delegate to/from the event. To add or remove a  <br>delegate, you can invoke these MethodInfo objects, or you can call EventInfo's more  <br>convenient AddEventHandler and RemoveEventHandler methods.<br>
When you call one of the methods listed in the right column of Table 23-7, you're not binding <br>to a member; you're just invoking the member. You can call any of these methods multiple <br>times, and because binding isn't necessary, the performance will be pretty good.<br>
You might notice that ConstructorInfo's Invoke, MethodInfo's Invoke, and <br>PropertyInfo's GetValue and SetValue methods offer overloaded versions that take a  <br>reference to a Binder-derived object and some BindingFlags. This would lead you to be-<br>lieve that these methods bind to a member. However, they don't.<br>
<hr>
<A name=670></a><b>652 </b><br>
<b>Part IV  Core Facilities</b><br>
When calling any of these methods, the Binder-derived object is used to perform type <br>conversions on the supplied method parameters, such as converting an Int32 argument <br>to an Int64, so that the already selected method can be called. As for the BindingFlags <br>parameter, the only flag that can be passed here is BindingFlags.SuppressChangeType. <br>However, binders are free to ignore this flag. Fortunately, the DefaultBinder class heeds <br>this flag. When DefaultBinder sees this flag, it won't convert any arguments. If you use <br>this flag and the arguments passed don't match the arguments expected by the method, an <br>ArgumentException will be thrown.<br>
Usually when you use the BindingFlags.ExactBinding flag to bind to a member, you'll <br>specify the BindingFlags.SuppressChangeType flag to invoke the member. If you don't use <br>these two flags in tandem, it's unlikely that invoking the member will be successful unless the <br>arguments you pass happen to be exactly what the method expects. By the way, if you call <br>MemberInfo's InvokeMethod to bind and invoke a member, you'll probably want to specify <br>both or neither of the two binding flags.<br>
The following sample application demonstrates the various ways to use reflection to access <br>a type's members. The SomeType class represents a type that has various members: a private <br>field (m_someField), a public constructor (SomeType) that takes an Int32 argument passed <br>by reference, a public method (ToString), a public property (SomeProp), and a public event <br>(SomeEvent). Having defined the SomeType type, I offer three different methods that use <br>reflection to access SomeType's members. Each method uses reflection in a different way to <br>accomplish the same thing:<br>
  The UseInvokeMemberToBindAndInvokeTheMember method demonstrates how to use <br>
Type's InvokeMember to both bind and invoke a member.<br>
  The BindToMemberThenInvokeTheMember method demonstrates how to bind to a <br>
member and invoke it later. This technique yields faster-performing code if you intend <br>to invoke the same member on different objects multiple times.<br>
  The BindToMemberCreateDelegateToMemberThenInvokeTheMember method demon-<br>
strates how to bind to an object or member, and then it creates a delegate that refers <br>to that object or member. Calling through the delegate is very fast, and this technique <br>yields even faster performance if you intend to invoke the same member on the same <br>object multiple times.<br>
  The UseDynamicToBindAndInvokeTheMember method demonstrates how to use C# <br>
dynamic primitive type (discussed at the end of Chapter 5, "Primitive, Reference, and <br>Value Types") to simplify the syntax for accessing members. In addition, this technique <br>can give reasonably good performance if you intend to invoke the same member on <br>different objects that are all of the same type because the binding will happen once <br>per type and be cached so that it can be invoked multiple times quickly. You can also <br>use this technique to invoke a member on objects of different types.<br>
<hr>
<A name=671></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>653</b><br>
using System;  <br>using System.Reflection;  <br>using Microsoft.CSharp.RuntimeBinder; <br> <br> <br>// This class is used to demonstrate reflection  <br>// It has a field, constructor, method, property, and an event  <br>internal sealed class SomeType {  <br>   private Int32 m_someField;  <br>   public SomeType(ref Int32 x) { x *= 2; }  <br>   public override String ToString() { return m_someField.ToString(); }  <br>   public Int32 SomeProp {  <br>      get { return m_someField; }  <br>set { <br>   if (value &lt; 1)  <br>      throw new ArgumentOutOfRangeException(&quot;value&quot;); <br>   m_someField = value; <br>} <br>   public event EventHandler SomeEvent;  <br>   private void NoCompilerWarnings() { SomeEvent.ToString();}  <br>}  <br> <br>public static class Program {  <br>   private const BindingFlags c_bf = BindingFlags.DeclaredOnly | BindingFlags.Public | <br>      BindingFlags.NonPublic | BindingFlags.Instance;  <br> <br>   public static void Main() {  <br>      Type t = typeof(SomeType); <br>      UseInvokeMemberToBindAndInvokeTheMember(t); <br>      Console.WriteLine(); <br> <br>      BindToMemberThenInvokeTheMember(t); <br>      Console.WriteLine(); <br> <br>      BindToMemberCreateDelegateToMemberThenInvokeTheMember(t); <br>      Console.WriteLine(); <br> <br>      UseDynamicToBindAndInvokeTheMember(t); <br>      Console.WriteLine(); <br>   }  <br> <br> <br>   private static void UseInvokeMemberToBindAndInvokeTheMember(Type t) { <br>      Console.WriteLine(&quot;UseInvokeMemberToBindAndInvokeTheMember&quot;); <br> <br>      // Construct an instance of the Type <br>      Object[] args = new Object[] { 12 };  // Constructor arguments <br>      Console.WriteLine(&quot;x before constructor called: &quot; + args[0]); <br>      Object obj = t.InvokeMember(null, c_bf | BindingFlags.CreateInstance,  <br>         null, null, args); <br>      Console.WriteLine(&quot;Type: &quot; + obj.GetType().ToString()); <br>      Console.WriteLine(&quot;x after constructor returns: &quot; + args[0]); <br> <br>
<hr>
<A name=672></a><b>654 </b><br>
<b>Part IV  Core Facilities</b><br>
      // Read and write to a field <br>      t.InvokeMember(&quot;m_someField&quot;, c_bf | BindingFlags.SetField,  <br>         null, obj, new Object[] { 5 }); <br>      Int32 v = (Int32)t.InvokeMember(&quot;m_someField&quot;, c_bf | BindingFlags.GetField,  <br>         null, obj, null); <br>      Console.WriteLine(&quot;someField: &quot; + v); <br> <br>      // Call a method <br>      String s = (String) <br>         t.InvokeMember(&quot;ToString&quot;, c_bf | BindingFlags.InvokeMethod, null, obj, null); <br>      Console.WriteLine(&quot;ToString: &quot; + s); <br> <br>      // Read and write a property <br>      try { <br>         t.InvokeMember(&quot;SomeProp&quot;, c_bf | BindingFlags.SetProperty,  <br>            null, obj, new Object[] { 0 }); <br>      } <br>      catch (TargetInvocationException e) { <br>         if (e.InnerException.GetType() != typeof(ArgumentOutOfRangeException)) throw; <br>         Console.WriteLine(&quot;Property set catch.&quot;); <br>      } <br>      t.InvokeMember(&quot;SomeProp&quot;, c_bf | BindingFlags.SetProperty,  <br>         null, obj, new Object[] { 2 }); <br>      v = (Int32)t.InvokeMember(&quot;SomeProp&quot;, c_bf | BindingFlags.GetProperty,  <br>         null, obj, null); <br>      Console.WriteLine(&quot;SomeProp: &quot; + v); <br> <br>      // Add and remove a delegate from the event by invoking the event's add/remove methods <br>      EventHandler eh = new EventHandler(EventCallback); <br>      t.InvokeMember(&quot;add_SomeEvent&quot;, c_bf | BindingFlags.InvokeMethod,  <br>         null, obj, new Object[] { eh }); <br>      t.InvokeMember(&quot;remove_SomeEvent&quot;, c_bf | BindingFlags.InvokeMethod,  <br>         null, obj, new Object[] { eh }); <br>   }  <br> <br> <br>   private static void BindToMemberThenInvokeTheMember(Type t) { <br>      Console.WriteLine(&quot;BindToMemberThenInvokeTheMember&quot;); <br> <br>      // Construct an instance <br>      // ConstructorInfo ctor =  <br>      //    t.GetConstructor(new Type[] { Type.GetType(&quot;System.Int32&amp;&quot;) }); <br>      ConstructorInfo ctor = t.GetConstructor(new Type[] { typeof(Int32).MakeByRefType() }); <br>      Object[] args = new Object[] { 12 };  // Constructor arguments <br>      Console.WriteLine(&quot;x before constructor called: &quot; + args[0]); <br>      Object obj = ctor.Invoke(args); <br>      Console.WriteLine(&quot;Type: &quot; + obj.GetType().ToString()); <br>      Console.WriteLine(&quot;x after constructor returns: &quot; + args[0]); <br> <br>      // Read and write to a field <br>      FieldInfo fi = obj.GetType().GetField(&quot;m_someField&quot;, c_bf); <br>      fi.SetValue(obj, 33); <br>      Console.WriteLine(&quot;someField: &quot; + fi.GetValue(obj)); <br> <br>
<hr>
<A name=673></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>655</b><br>
      // Call a method <br>      MethodInfo mi = obj.GetType().GetMethod(&quot;ToString&quot;, c_bf); <br>      String s = (String)mi.Invoke(obj, null); <br>      Console.WriteLine(&quot;ToString: &quot; + s); <br> <br>      // Read and write a property <br>      PropertyInfo pi = obj.GetType().GetProperty(&quot;SomeProp&quot;, typeof(Int32)); <br>      try { <br>         pi.SetValue(obj, 0, null); <br>      } <br>      catch (TargetInvocationException e) { <br>         if (e.InnerException.GetType() != typeof(ArgumentOutOfRangeException)) throw; <br>         Console.WriteLine(&quot;Property set catch.&quot;); <br>      } <br>      pi.SetValue(obj, 2, null); <br>      Console.WriteLine(&quot;SomeProp: &quot; + pi.GetValue(obj, null)); <br> <br>      // Add and remove a delegate from the event <br>      EventInfo ei = obj.GetType().GetEvent(&quot;SomeEvent&quot;, c_bf); <br>      EventHandler ts = new EventHandler(EventCallback); // See ei.EventHandlerType <br>      ei.AddEventHandler(obj, ts); <br>      ei.RemoveEventHandler(obj, ts); <br>   }  <br> <br> <br>   // Callback method added to the event <br>   private static void EventCallback(Object sender, EventArgs e) { } <br> <br> <br>   private static void BindToMemberCreateDelegateToMemberThenInvokeTheMember(Type t) { <br>      Console.WriteLine(&quot;BindToMemberCreateDelegateToMemberThenInvokeTheMember&quot;); <br> <br>      // Construct an instance (You can't create a delegate to a constructor) <br>      Object[] args = new Object[] { 12 };  // Constructor arguments <br>      Console.WriteLine(&quot;x before constructor called: &quot; + args[0]); <br>      Object obj = Activator.CreateInstance(t, args); <br>      Console.WriteLine(&quot;Type: &quot; + obj.GetType().ToString()); <br>      Console.WriteLine(&quot;x after constructor returns: &quot; + args[0]); <br> <br>      // NOTE: You can't create a delegate to a field <br> <br>      // Call a method <br>      MethodInfo mi = obj.GetType().GetMethod(&quot;ToString&quot;, c_bf); <br>      var toString = (Func&lt;String&gt;) Delegate.CreateDelegate(typeof(Func&lt;String&gt;), obj, mi); <br>      String s = toString(); <br>      Console.WriteLine(&quot;ToString: &quot; + s); <br> <br>      // Read and write a property <br>      PropertyInfo pi = obj.GetType().GetProperty(&quot;SomeProp&quot;, typeof(Int32)); <br>      var setSomeProp = (Action&lt;Int32&gt;) <br>         Delegate.CreateDelegate(typeof(Action&lt;Int32&gt;), obj, pi.GetSetMethod()); <br>      try { <br>         setSomeProp(0); <br>      } <br>
<hr>
<A name=674></a><b>656 </b><br>
<b>Part IV  Core Facilities</b><br>
      catch (ArgumentOutOfRangeException) { <br>         Console.WriteLine(&quot;Property set catch.&quot;); <br>      } <br>      setSomeProp(2); <br>      var getSomeProp = (Func&lt;Int32&gt;) <br>         Delegate.CreateDelegate(typeof(Func&lt;Int32&gt;), obj, pi.GetGetMethod()); <br>      Console.WriteLine(&quot;SomeProp: &quot; + getSomeProp()); <br> <br>      // Add and remove a delegate from the event <br>      EventInfo ei = obj.GetType().GetEvent(&quot;SomeEvent&quot;, c_bf); <br>      var addSomeEvent = (Action&lt;EventHandler&gt;) <br>         Delegate.CreateDelegate(typeof(Action&lt;EventHandler&gt;), obj, ei.GetAddMethod()); <br>      addSomeEvent(EventCallback); <br>      var removeSomeEvent = (Action&lt;EventHandler&gt;) <br>         Delegate.CreateDelegate(typeof(Action&lt;EventHandler&gt;), obj, ei.GetRemoveMethod()); <br>      removeSomeEvent(EventCallback); <br>   } <br> <br> <br>   private static void UseDynamicToBindAndInvokeTheMember(Type t) { <br>      Console.WriteLine(&quot;UseDynamicToBindAndInvokeTheMember&quot;); <br> <br>      // Construct an instance (You can't create a delegate to a constructor) <br>      Object[] args = new Object[] { 12 };  // Constructor arguments <br>      Console.WriteLine(&quot;x before constructor called: &quot; + args[0]); <br>      dynamic obj = Activator.CreateInstance(t, args); <br>      Console.WriteLine(&quot;Type: &quot; + obj.GetType().ToString()); <br>      Console.WriteLine(&quot;x after constructor returns: &quot; + args[0]); <br> <br>      // Read and write to a field  <br>      try { <br>         obj.m_someField = 5; <br>         Int32 v = (Int32)obj.m_someField; <br>         Console.WriteLine(&quot;someField: &quot; + v); <br>      } <br>      catch (RuntimeBinderException e) { <br>         // We get here because the field is private <br>         Console.WriteLine(&quot;Failed to access field: &quot; + e.Message); <br>      } <br> <br>      // Call a method <br>      String s = (String)obj.ToString(); <br>      Console.WriteLine(&quot;ToString: &quot; + s); <br> <br>      // Read and write a property <br>      try { <br>         obj.SomeProp = 0; <br>      } <br> <br>      catch (ArgumentOutOfRangeException) { <br>         Console.WriteLine(&quot;Property set catch.&quot;); <br>      } <br>      obj.SomeProp = 2; <br>      Int32 val = (Int32)obj.SomeProp; <br>      Console.WriteLine(&quot;SomeProp: &quot; + val); <br> <br>
<hr>
<A name=675></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>657</b><br>
      // Add and remove a delegate from the event <br>      obj.SomeEvent += new EventHandler(EventCallback); <br>      obj.SomeEvent -= new EventHandler(EventCallback); <br>   } <br>}<br>
If you build and run this code, you'll see the following output:<br>
UseInvokeMemberToBindAndInvokeTheMember <br>x before constructor called: 12 <br>Type: SomeType <br>x after constructor returns: 24 <br>someField: 5 <br>ToString: 5 <br>Property set catch. <br>SomeProp: 2 <br> <br>BindToMemberThenInvokeTheMember <br>x before constructor called: 12 <br>Type: SomeType <br>x after constructor returns: 24 <br>someField: 33 <br>ToString: 33 <br>Property set catch. <br>SomeProp: 2 <br> <br>BindToMemberCreateDelegateToMemberThenInvokeTheMember <br>x before constructor called: 12 <br>Type: SomeType <br>x after constructor returns: 24 <br>ToString: 0 <br>Property set catch. <br>SomeProp: 2 <br> <br>UseDynamicToBindAndInvokeTheMember <br>x before constructor called: 12 <br>Type: SomeType <br>x after constructor returns: 24 <br>Failed to access field: 'SomeType.m_someField' is inaccessible due to its protection level <br>ToString: 0 <br>Property set catch. <br>SomeProp: 2<br>
Notice that SomeType's constructor takes an Int32 by reference as its only parameter.  <br>The previous code shows how to call this constructor and how to examine the modified  <br>Int32 value after the constructor returns. Furthermore, near the top of the <br>BindToMemberThenInvokeTheMember method is a call to Type's GetType method passing  <br>in a string of &quot;System.Int32&amp;&quot;. The ampersand (&amp;) in the string allows me to identify a  <br>parameter passed by reference. This ampersand is part of the Backus-Naur Form grammar <br>for type names, which you can look up in the FCL documentation. That line of code could <br>also have been written like this:<br>
ConstructorInfo ctor = t.GetConstructor(new Type[] { typeof(Int32).MakeByRefType() });<br>
<hr>
<A name=676></a><b>658 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Using Binding Handles to Reduce Your Process's Memory </b><br>
<b>Consumption</b><br>
Many applications bind to a bunch of types (Type objects) or type members (MemberInfo-<br>derived objects) and save these objects in a collection of some sort. Then later, the application <br>searches the collection for a particular object and then invokes this object. This is a fine way <br>of doing things except for one small issue: Type and MemberInfo-derived objects require a <br>lot of memory. So if an application holds on to too many of these objects and invokes them <br>occasionally, the application's memory consumption increases dramatically, having an adverse <br>effect on the application's performance.<br>
Internally, the CLR has a more compact way of representing this information. The CLR creates <br>these objects for our applications only to make things easier for developers. The CLR doesn't <br>need these big objects itself in order to run. Developers who are saving/caching a lot of Type <br>and MemberInfo-derived objects can reduce their working set by using runtime handles <br>instead of objects. The FCL defines three runtime handle types (all defined in the System <br>namespace): RuntimeTypeHandle, RuntimeFieldHandle, and RuntimeMethodHandle. All <br>of these types are value types that contain just one field, an IntPtr; this makes instances <br>of these types extremely cheap (memory-wise). The IntPtr field is a handle that refers to a <br>type, field, or method in an AppDomain's loader heap. So what you need now is an easy and <br>efficient way to convert a heavyweight Type/MemberInfo object to a lightweight runtime <br>handle instance and vice versa. Fortunately, this is easy using the following conversion  <br>methods and properties:<br>
  To convert a Type object to a RuntimeTypeHandle, call Type's static GetTypeHandle <br>
method passing in the reference to the Type object.<br>
  To convert a RuntimeTypeHandle to a Type object, call Type's static <br>
GetTypeFromHandle method passing in the RuntimeTypeHandle.<br>
  To convert a FieldInfo object to a RuntimeFieldHandle, query FieldInfo's instance <br>
read-only FieldHandle property.<br>
  To convert a RuntimeFieldHandle to a FieldInfo object, call FieldInfo's static <br>
GetFieldFromHandle method.<br>
  To convert a MethodInfo object to a RuntimeMethodHandle, query MethodInfo's  <br>
instance read-only MethodHandle property.<br>
  To convert a RuntimeMethodHandle to a MethodInfo object, call MethodInfo's static <br>
GetMethodFromHandle method.<br>
The program sample below acquires a lot of MethodInfo objects, converts them to <br>RuntimeMethodHandle instances, and shows the working set difference:<br>
using System;  <br>using System.Reflection;  <br>using System.Collections.Generic;  <br> <br> <br>
<hr>
<A name=677></a><b> </b><br>
<b>Chapter 23  Assembly Loading and Reflection </b><br>
<b>659</b><br>
public sealed class Program {  <br>   private const BindingFlags c_bf = BindingFlags.FlattenHierarchy | BindingFlags.Instance | <br>      BindingFlags.Static | BindingFlags.Public | BindingFlags.NonPublic;  <br> <br>   public static void Main() {  <br>      // Show size of heap before doing any reflection stuff <br>      Show(&quot;Before doing anything&quot;); <br> <br>      // Build cache of MethodInfo objects for all methods in MSCorlib.dll <br>      List&lt;MethodBase&gt; methodInfos = new List&lt;MethodBase&gt;(); <br>      foreach (Type t in typeof(Object).Assembly.GetExportedTypes()) { <br>         // Skip over any generic types <br>         if (t.IsGenericTypeDefinition) continue; <br> <br>         MethodBase[] mb = t.GetMethods(c_bf); <br>         methodInfos.AddRange(mb); <br>      } <br> <br>      // Show number of methods and size of heap after binding to all methods <br>      Console.WriteLine(&quot;# of methods={0:N0}&quot;, methodInfos.Count); <br>      Show(&quot;After building cache of MethodInfo objects&quot;); <br> <br>      // Build cache of RuntimeMethodHandles for all MethodInfo objects <br>      List&lt;RuntimeMethodHandle&gt; methodHandles =  <br>         methodInfos.ConvertAll&lt;RuntimeMethodHandle&gt;(mb =&gt; mb.MethodHandle); <br> <br>      Show(&quot;Holding MethodInfo and RuntimeMethodHandle cache&quot;); <br>      GC.KeepAlive(methodInfos); // Prevent cache from being GC'd early <br> <br>      methodInfos = null;        // Allow cache to be GC'd now <br>      Show(&quot;After freeing MethodInfo objects&quot;); <br> <br>      methodInfos = methodHandles.ConvertAll&lt;MethodBase&gt;( <br>         rmh=&gt; MethodBase.GetMethodFromHandle(rmh)); <br>      Show(&quot;Size of heap after re-creating MethodInfo objects&quot;); <br>      GC.KeepAlive(methodHandles);  // Prevent cache from being GC'd early <br>      GC.KeepAlive(methodInfos);    // Prevent cache from being GC'd early <br> <br>      methodHandles = null;         // Allow cache to be GC'd now <br>      methodInfos = null;           // Allow cache to be GC'd now <br>      Show(&quot;After freeing MethodInfos and RuntimeMethodHandles&quot;); <br>   } <br>}<br>
When I compiled and executed this program, I got the following output:<br>
Heap size=     85,000 - Before doing anything <br># of methods=48,467 <br>Heap size=   7,065,632 - After building cache of MethodInfo objects <br>Heap size=   7,453,496 - Holding MethodInfo and RuntimeMethodHandle cache <br>Heap size=   6,732,704 - After freeing MethodInfo objects <br>Heap size=   7,372,704 - Size of heap after re-creating MethodInfo objects <br>Heap size=     192,232 - After freeing MethodInfos and RuntimeMethodHandles<br>
<hr>
<A name=678></a><hr>
<A name=679></a>Chapter 24<br><b>Runtime Serialization</b><br>
<b>In this chapter:<br>Serialization/Deserialization Quick Start. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 662<br>Making a Type Serializable  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 667<br>Controlling Serialization and Deserialization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 668<br>How Formatters Serialize Type Instances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 672<br>Controlling the Serialized/Deserialized Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 673<br>Streaming Contexts  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 680<br>Serializing a Type as a Different Type and Deserializing an Object <br>   as a Different Object . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 682<br>Serialization Surrogates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 684<br>Overriding the Assembly and/or Type When Deserializing an Object. . . . . . . . 689</b><br>
<i>Serialization </i>is the process of converting an object or a graph of connected objects into a <br>stream of bytes. <i>Deserialization </i>is the process of converting a stream of bytes back into its <br>graph of connected objects. The ability to convert objects to and from a byte stream is an <br>incredibly useful mechanism. Here are some examples:<br>
  An application's state (object graph) can easily be saved in a disk file or database and <br>
then restored the next time the application is run. ASP.NET saves and restores session <br>state by way of serialization and deserialization.<br>
  A set of objects can easily be copied to the system's clipboard and then pasted into <br>
the same or another application. In fact, Windows Forms and Windows Presentation <br>Foundation (WPF) use this.<br>
  A set of objects can be cloned and set aside as a "backup" while a user manipulates the <br>
"main" set of objects.<br>
  A set of objects can easily be sent over the network to a process running on another <br>
machine. The Microsoft .NET Framework's remoting architecture serializes and de-<br>serializes objects that are marshaled by value. It is also used to send objects across <br>AppDomain boundaries, as discussed in Chapter 22, "CLR Hosting and AppDomains."<br>
In addition to the above, once you have serialized objects in a byte stream in memory, it is <br>quite easy to process the data in more useful ways, such as encrypting and compressing the <br>data.<br>
<b> </b><br>
<b> </b><br>
<b>661</b><br>
<hr>
<A name=680></a><IMG src="CLRviaCsharp-680_1.jpg"><br>
<b>662 </b><br>
<b>Part IV  Core Facilities</b><br>
With serialization being so useful, it is no wonder that many programmers have spent count-<br>less hours developing code to perform these types of actions. Historically, this code is difficult <br>to write and is extremely tedious and error-prone. Some of the difficult issues that developers <br>need to grapple with are communication protocols, client/server data type mismatches (such <br>as little-endian/big-endian issues), error handling, objects that refer to other objects, in and <br>out parameters, arrays of structures, and the list goes on.<br>
Well, you'll be happy to know that the .NET Framework has fantastic support for serialization <br>and deserialization built right into it. This means that all of the difficult issues mentioned <br>above are now handled completely and transparently by the .NET Framework. As a developer, <br>you can work with your objects before serialization and after deserialization and have the <br>.NET Framework handle the stuff in the middle.<br>
In this chapter, I explain how the .NET Framework exposes its serialization and deserialization <br>services. For almost all data types, the default behavior of these services wil  be sufficient, <br>meaning that it is almost no work for you to make your own types serializable. However, there <br>is a small minority of types where the serialization service's default behavior wil  not be suf-<br>ficient. Fortunately, the serialization services are very extensible, and I wil  also explain how to <br>tap into these extensibility mechanisms, allowing you to do some pretty powerful things when <br>serializing or deserializing objects. For example, I'l  demonstrate how to serialize Version 1 of <br>an object out to a disk file and then deserialize it a year later into an object of Version 2.<br>
<b>Note  </b>This chapter focuses on the runtime serialization technology in the common language <br>runtime (CLR), which has a deep understanding of CLR data types and can serialize all the  <br>public, protected, internal, and even private fields of an object to a compressed binary stream for <br>high performance. See the System.Runtime.Serialization.NetDataContractSerializer <br>class if you wish to serialize CLR data types to an XML stream. The .NET Framework also offers  <br>other serialization technologies that are designed more for interoperating between CLR <br>data types and non-CLR data types. These other serialization technologies use the System.<br>Xml.Serialization.XmlSerializer class and the System.Runtime.Serialization.<br>DataContractSerializer class.<br>
<b>Serialization/Deserialization Quick Start</b><br>
Let's start off by looking at some code:<br>
using System; <br>using System.Collections.Generic; <br>using System.IO; <br>using System.Runtime.Serialization.Formatters.Binary; <br> <br>internal static class QuickStart { <br>   public static void Main() { <br>      // Create a graph of objects to serialize them to the stream  <br>      var objectGraph = new List&lt;String&gt; { &quot;Jeff&quot;, &quot;Kristin&quot;, &quot;Aidan&quot;, &quot;Grant&quot; }; <br>      Stream stream = SerializeToMemory(objectGraph); <br> <br>
<hr>
<A name=681></a><IMG src="CLRviaCsharp-681_1.jpg"><br>
<b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>663</b><br>
      // Reset everything for this demo <br>      stream.Position = 0; <br>      objectGraph = null; <br> <br>      // Deserialize the objects and prove it worked <br>      objectGraph = (List&lt;String&gt;) DeserializeFromMemory(stream); <br>      foreach (var s in objectGraph) Console.WriteLine(s); <br>   } <br> <br>   private static MemoryStream SerializeToMemory(Object objectGraph) { <br>      // Construct a stream that is to hold the serialized objects <br>      MemoryStream stream = new MemoryStream(); <br> <br>      // Construct a serialization formatter that does all the hard work <br>      BinaryFormatter formatter = new BinaryFormatter(); <br> <br>      // Tell the formatter to serialize the objects into the stream <br>      formatter.Serialize(stream, objectGraph); <br> <br>      // Return the stream of serialized objects back to the caller <br>      return stream; <br>   } <br> <br>   private static Object DeserializeFromMemory(Stream stream) { <br>      // Construct a serialization formatter that does all the hard work <br>      BinaryFormatter formatter = new BinaryFormatter(); <br> <br>      // Tell the formatter to deserialize the objects from the stream <br>      return formatter.Deserialize(stream); <br>   } <br>}<br>
Wow, look how simple this is! The SerializeToMemory method constructs a System.<br>IO.MemoryStream object. This object identifies where the serialized block of bytes is to be <br>placed. Then the method constructs a BinaryFormatter object (which can be found in the <br>System.Runtime.Serialization.Formatters.Binary namespace). A formatter is a type <br>(implementing the System.Runtime.Serialization.IFormatter interface) that knows <br>how to serialize and deserialize an object graph. The Framework Class Library (FCL) ships with <br>two formatters: the BinaryFormatter (used in this code example) and a SoapFormatter <br>(which can be found in the System.Runtime.Serialization.Formatters.Soap namespace <br>and is implemented in the System.Runtime.Serialization.Formatters.Soap.dll assembly).<br>
<b>Note  </b>As of version 3.5 of the .NET Framework, the SoapFormatter class is obsolete and should <br>not be used in production code. However, it can still be useful for debugging serialization code <br>as it produces XML text which you can read. To use XML serialization and deserialization in  <br>production code, see the XmlSerializer and DataContractSerializer classes.<br>
To serialize a graph of objects, just call the formatter's Serialize method and pass it two <br>things: a reference to a stream object and a reference to the object graph that you wish to <br>
<hr>
<A name=682></a><IMG src="CLRviaCsharp-682_1.jpg"><br>
<b>664 </b><br>
<b>Part IV  Core Facilities</b><br>
serialize. The stream object identifies where the serialized bytes should be placed and can be <br>an object of any type derived from the System.IO.Stream abstract base class. This means <br>that you can serialize an object graph to a MemoryStream, a FileStream, a NetworkStream, <br>and so on.<br>
The second parameter to Serialize is a reference to an object. This object could <br>be anything: an Int32, a String, a DateTime, an Exception, a List&lt;String&gt;, a <br>Dictionary&lt;Int32, DatTime&gt;, and so on. The object referred to by the objectGraph  <br>parameter may refer to other objects. For example, objectGraph may refer to a collection <br>that refers to a set of objects. These objects may also refer to other objects. When the  <br>formatter's Serialize method is called, all objects in the graph are serialized to the stream.<br>
Formatters know how to serialize the complete object graph by referring to the metadata <br>that describes each object's type. The Serialize method uses reflection to see what  <br>instance fields are in each object's type as it is serialized. If any of these fields refer to other <br>objects, then the formatter's Serialize method knows to serialize these objects, too.<br>
Formatters have very intelligent algorithms. They know to serialize each object in the graph <br>no more than once out to the stream. That is, if two objects in the graph refer to each other, <br>then the formatter detects this, serializes each object just once, and avoids entering into an <br>infinite loop.<br>
In my SerializeToMemory method, when the formatter's Serialize method returns, the <br>MemoryStream is simply returned to the caller. The application uses the contents of this flat <br>byte array any way it desires. For example, it could save it in a file, copy it to the clipboard, <br>send it over a wire, or whatever.<br>
The DeserializeFromStream method deserializes a stream back into an object graph. This <br>method is even simpler than serializing an object graph. In this code, a BinaryFormatter is <br>constructed and then its Deserialize method is called. This method takes the stream as a <br>parameter and returns a reference to the root object within the deserialized object graph.<br>
Internally, the formatter's Deserialize method examines the contents of the stream, con-<br>structs instances of all the objects that are in the stream, and initializes the fields in all these <br>objects so that they have the same values they had when the object graph was serialized. <br>Typically, you will cast the object reference returned from the Deserialize method into the <br>type that your application is expecting.<br>
<b>Note  </b>Here's a fun, useful method that uses serialization to make a deep copy, or clone, of an <br>object:<br>
private static Object DeepClone(Object original) { <br>   // Construct a temporary memory stream <br>   using (MemoryStream stream = new MemoryStream()) { <br> <br>
<hr>
<A name=683></a><b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>665</b><br>
      // Construct a serialization formatter that does all the hard work <br>      BinaryFormatter formatter = new BinaryFormatter(); <br> <br>      // This line is explained in this chapter's &quot;Streaming Contexts&quot; section <br>      formatter.Context = new StreamingContext(StreamingContextStates.Clone); <br> <br>      // Serialize the object graph into the memory stream <br>      formatter.Serialize(stream, original); <br> <br>      // Seek back to the start of the memory stream before deserializing <br>      stream.Position = 0; <br> <br>      // Deserialize the graph into a new set of objects and  <br>      // return the root of the graph (deep copy) to the caller <br>      return formatter.Deserialize(stream); <br>   } <br>}<br>
At this point, I'd like to add a few notes to our discussion. First, it is up to you to ensure that <br>your code uses the same formatter for both serialization and deserialization. For example, <br>don't write code that serializes an object graph using the SoapFormatter and then deserial-<br>izes the graph using the BinaryFormatter. If Deserialize can't decipher the contents of <br>the stream, then a System.Runtime.Serialization.SerializationException exception <br>will be thrown.<br>
The second thing I'd like to point out is that it is possible and also quite useful to serialize <br>multiple object graphs out to a single stream. For example, let's say that we have the following <br>two class definitions:<br>
[Serializable] internal sealed class Customer { /* ... */ } <br>[Serializable] internal sealed class Order    { /* ... */ }<br>
And then, in the main class of our application, we define the following static fields:<br>
private static List&lt;Customer&gt; s_customers       = new List&lt;Customer&gt;(); <br>private static List&lt;Order&gt;    s_pendingOrders   = new List&lt;Order&gt;(); <br>private static List&lt;Order&gt;    s_processedOrders = new List&lt;Order&gt;();<br>
We can now serialize our application's state to a single stream with a method that looks like <br>this:<br>
private static void SaveApplicationState(Stream stream) { <br>   // Construct a serialization formatter that does all the hard work <br>   BinaryFormatter formatter = new BinaryFormatter(); <br> <br>   // Serialize our application's entire state <br>   formatter.Serialize(stream, s_customers); <br>   formatter.Serialize(stream, s_pendingOrders); <br>   formatter.Serialize(stream, s_processedOrders); <br>}<br>
<hr>
<A name=684></a><IMG src="CLRviaCsharp-684_1.jpg"><br>
<b>666 </b><br>
<b>Part IV  Core Facilities</b><br>
To reconstruct our application's state, we would deserialize the state with a method that <br>looks like this:<br>
private static void RestoreApplicationState(Stream stream) { <br>   // Construct a serialization formatter that does all the hard work <br>   BinaryFormatter formatter = new BinaryFormatter(); <br> <br>   // Deserialize our application's entire state (same order as serialized) <br>   s_customers       = (List&lt;Customer&gt;) formatter.Deserialize(stream); <br>   s_pendingOrders   = (List&lt;Order&gt;)    formatter.Deserialize(stream); <br>   s_processedOrders = (List&lt;Order&gt;)    formatter.Deserialize(stream); <br>}<br>
The third and last thing I'd like to point out has to do with assemblies. When serializing an <br>object, the full name of the type and the name of the type's defining assembly are written  <br>to the stream. By default, BinaryFormatter outputs the assembly's full identity, which  <br>includes the assembly's file name (without extension), version number, culture, and public  <br>key information. When deserializing an object, the formatter first grabs the assembly identity <br>and ensures that the assembly is loaded into the executing AppDomain by calling  <br>System.Reflection.Assembly's Load method (discussed in Chapter 23, "Assembly Loading <br>and Reflection").<br>
After an assembly has been loaded, the formatter looks in the assembly for a type matching <br>that of the object being deserialized. If the assembly doesn't contain a matching type, an <br>exception is thrown and no more objects can be deserialized. If a matching type is found, <br>an instance of the type is created and its fields are initialized from the values contained in <br>the stream. If the type's fields don't exactly match the names of the fields as read from the <br>stream, then a SerializationException exception is thrown and no more objects can be <br>deserialized. Later in this chapter, I'll discuss some sophisticated mechanisms that allow you <br>to override some of this behavior.<br>
<b>Important  </b>Some extensible applications use Assembly.LoadFrom to load an assembly <br>and then construct objects from types defined in the loaded assembly. These objects can be <br>serialized to a stream without any trouble. However, when deserializing this stream, the format-<br>ter attempts to load the assembly by calling Assembly's Load method instead of calling the <br>LoadFrom method. In most cases, the CLR will not be able to locate the assembly file, causing a <br>SerializationException exception to be thrown. This catches many developers by surprise: <br>Since the objects serialized correctly, they expect that they will deserialize correctly as well.<br>
If your application serializes objects whose types are defined in an assembly that your applica-<br>tion loads using Assembly.LoadFrom, then I recommend that you implement a method whose <br>signature matches the System.ResolveEventHandler delegate and register this method with <br>System.AppDomain's AssemblyResolve event just before calling a formatter's Deserialize <br>method. (Unregister this method with the event after Deserialize returns.) Now, whenever  <br>the formatter fails to load an assembly, the CLR calls your ResolveEventHandler method.  <br>This method is passed the identity of the assembly that failed to load. The method can extract  <br>the assembly file name from the assembly's identity and use this name to construct the <br>path where the application knows the assembly file can be found. Then, the method can call <br>Assembly.LoadFrom to load the assembly and return the resulting Assembly reference back <br>from the ResolveEventHandler method.<br>
<hr>
<A name=685></a><IMG src="CLRviaCsharp-685_1.jpg"><br>
<b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>667</b><br>
This section covered the basics of how to serialize and deserialize object graphs. In the  <br>remaining sections, we'll look at what you must do in order to define your own serializable <br>types, and we'll also look at various mechanisms that allow you to have greater control over <br>serialization and deserialization.<br>
<b>Making a Type Serializable</b><br>
When a type is designed, the developer must make the conscious decision as to whether or <br>not to allow instances of the type to be serializable. By default, types are not serializable. For <br>example, the following code does not perform as expected:<br>
internal struct Point { public Int32 x, y; } <br> <br>private static void OptInSerialization() { <br>   Point pt = new Point { x = 1, y = 2 }; <br>   using (var stream = new MemoryStream()) { <br>      new BinaryFormatter().Serialize(stream, pt); // throws SerializationException <br>   } <br>}<br>
If you were to build and run this code in your program, you'd see that the formatter's <br>Serialize method throws a System.Runtime.Serialization.SerializationException <br>exception. The problem is that the developer of the Point type has not explicitly indicated <br>that Point objects may be serialized. To solve this problem, the developer must apply the <br>System.SerializableAttribute custom attribute to this type as follows. (Note that this <br>attribute is defined in the System namespace, not the System.Runtime.Serialization <br>namespace.)<br>
[Serializable] <br>internal struct Point { public Int32 x, y; }<br>
Now, if we rebuild the application and run it, it does perform as expected and the Point  <br>objects will be serialized to the stream. When serializing an object graph, the formatter <br>checks that every object's type is serializable. If any object in the graph is not serializable, the <br>formatter's Serialize method throws the SerializationException exception.<br>
<b>Note  </b>When serializing a graph of objects, some of the object's types may be serializable while <br>some of the objects may not be serializable. For performance reasons, formatters do not verify <br>that all of the objects in the graph are serializable before serializing the graph. So, when serializ-<br>ing an object graph, it is entirely possible that some objects may be serialized to the stream be-<br>fore the SerializationException is thrown. If this happens, the stream contains corrupt data. <br>If you think you may be serializing an object graph where some objects may not be serializable, <br>your application code should be able to recover gracefully from this situation. One option is to <br>serialize the objects into a MemoryStream first. Then, if all objects are successfully serialized, you <br>can copy the bytes in the MemoryStream to whatever stream (i.e. file, network) you really want <br>the bytes written to.<br>
<hr>
<A name=686></a><IMG src="CLRviaCsharp-686_1.jpg"><br>
<b>668 </b><br>
<b>Part IV  Core Facilities</b><br>
The SerializableAttribute custom attribute may be applied to reference types (class), <br>value types (struct), enumerated types (enum), and delegate types (delegate) only. <br>(Note that enumerated and delegate types are always serializable so there is no need to <br>explicitly apply the SerializableAttribute attribute to these types.) In addition, the <br>SerializableAttribute attribute is not inherited by derived types. So, given the following <br>two type definitions, a Person object can be serialized but an Employee object cannot:<br>
[Serializable] <br>internal class Person { ... } <br> <br>internal class Employee : Person { ... }<br>
To fix this, you would just apply the SerializableAttribute attribute to the Employee type <br>as well:<br>
[Serializable] <br>internal class Person { ... } <br> <br>[Serializable] <br>internal class Employee : Person { ... }<br>
Note that this problem was easy to fix. However, the reverse--defining a type derived from a <br>base type that doesn't have the SerializableAttribute attribute applied to it--is not easy <br>to fix. But, this is by design; if the base type doesn't allow instances of its type to be serial-<br>ized, its fields cannot be serialized since a base object is effectively part of the derived object. <br>This is why System.Object has the SerializableAttribute attribute applied to it.<br>
<b>Note  </b>In general, it is recommended that most types you define be serializable. After all, this <br>grants a lot of flexibility to users of your types. However, you must be aware that serialization <br>reads all of an object's fields regardless of whether the fields are declared as public, protected, <br>internal, or private. You might not want to make a type serializable if it contains sensitive or <br>secure data (like passwords) or if the data would have no meaning or value if transferred.<br>
If you find yourself using a type that was not designed for serialization and you do not have <br>the source code of the type to add serialization support, all is not lost. In the "Overriding the <br>Assembly and/or Type When Deserializing an Object" section later in this chapter, I will explain <br>how you can make any non-serializable type serializable.<br>
<b>Controlling Serialization and Deserialization</b><br>
When you apply the SerializableAttribute custom attribute to a type, all instance fields <br>(public, private, protected, and so on) are serialized.1 However, a type may define some <br>instance fields that should not be serialized. In general, there are two reasons why you would <br>not want some of a type's instance fields to be serialized:<br>
1  Do not use C#'s automatically implemented property feature to define properties inside types marked with the <br>
[Serializable] attribute, because the compiler generates the names of the fields and the generated names can <br>be different each time that you recompile your code, preventing instances of your type from being deserializable.<br>
<hr>
<A name=687></a><b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>669</b><br>
  The field contains information that would not be valid when deserialized. For example, <br>
an object that contains a handle to a Windows kernel object (such as a file, process, <br>thread, mutex, event, semaphore, and so on) would have no meaning when deserialized <br>into another process or machine since Windows kernel handles are process-relative <br>values.<br>
  The field contains information that is easily calculated. In this case, you select which <br>
fields do not need to be serialized, thus improving your application's performance by <br>reducing the amount of data transferred.<br>
The code below uses the System.NonSerializedAttribute custom attribute to indicate <br>which fields of the type should not be serialized. (Note that this attribute is also defined in <br>the System namespace, not the System.Runtime.Serialization namespace.)<br>
[Serializable] <br>internal class Circle { <br>   private Double m_radius; <br> <br>   [NonSerialized] <br>   private Double m_area; <br> <br>   public Circle(Double radius) { <br>      m_radius = radius; <br>      m_area = Math.PI * m_radius * m_radius; <br>   } <br> <br>   ... <br>}<br>
In the code above, objects of Circle may be serialized. However, the formatter will serialize <br>the values in the object's m_radius field only. The value in the m_area field will not be serial-<br>ized because it has the NonSerializedAttribute attribute applied to it. This attribute can <br>be applied only to a type's fields, and it continues to apply to this field when inherited by <br>another type. Of course, you may apply the NonSerializedAttribute attribute to multiple <br>fields within a type.<br>
So, let's say that our code constructs a Circle object as follows:<br>
Circle c = new Circle(10);<br>
Internally, the m_area field is set to a value approximate to 314.159. When this object gets <br>serialized, only the value of the m_radius field (10) gets written to the stream. This is exactly <br>what we want, but now we have a problem when the stream is deserialized back into a <br>Circle object. When deserialized, the Circle object will get its m_radius field set to 10, but <br>its m_area field will be initialized to 0--not 314.159!<br>
<hr>
<A name=688></a><b>670 </b><br>
<b>Part IV  Core Facilities</b><br>
The code shown below demonstrates how to modify the Circle type to fix this problem:<br>
[Serializable] <br>internal class Circle { <br>   private Double m_radius; <br> <br>   [NonSerialized] <br>   private Double m_area; <br> <br>   public Circle(Double radius) { <br>      m_radius = radius; <br>      m_area = Math.PI * m_radius * m_radius; <br>   } <br> <br>   [OnDeserialized] <br>   private void OnDeserialized(StreamingContext context) { <br>      m_area = Math.PI * m_radius * m_radius; <br>   } <br>}<br>
I've changed Circle so that it now contains a method marked with the System.Runtime.<br>Serialization.OnDeserializedAttribute custom attribute.2 Whenever an instance of a <br>type is deserialized, the formatter checks if the type defines a method with this attribute on it <br>and then the formatter invokes this method. When this method is called, all the serializable  <br>fields will be set correctly and they may be accessed to perform any additional work that <br>would be necessary to fully deserialize the object.<br>
In the modified version of Circle above, I made the OnDeserialized method simply  <br>calculate the area of the circle using the m_radius field and place the result in the m_area <br>field. Now, m_area will have the desired value of 314.159.<br>
In addition to the OnDeserializedAttribute custom attribute, the  <br>System.Runtime.Serialization namespace also defines OnSerializingAttribute, <br>OnSerializedAttribute, and OnDeserializingAttribute custom attributes, which you <br>can apply to your type's methods to have even more control over serialization and deserial-<br>ization. Here is a sample class that applies each of these attributes to a method:<br>
[Serializable] <br>public class MyType { <br>   Int32 x, y; [NonSerialized] Int32 sum; <br> <br>   public MyType(Int32 x, Int32 y) { <br>      this.x = x; this.y = y; sum = x + y; <br>   } <br> <br>   [OnDeserializing]  <br>   private void OnDeserializing(StreamingContext context) { <br>
2  Use of the System.Runtime.Serialization.OnDeserialized custom attribute is the preferred way  <br>
of invoking a method when an object is deserialized, as opposed to having a type implement the  <br>System.Runtime.Serialization.IDeserializationCallback interface's OnDeserialization method.<br>
<hr>
<A name=689></a><IMG src="CLRviaCsharp-689_1.jpg"><br>
<b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>671</b><br>
      // Example: Set default values for fields in a new version of this type  <br>   } <br>    <br>   [OnDeserialized]  <br>   private void OnDeserialized(StreamingContext context) { <br>      // Example: Initialize transient state from fields <br>      sum = x + y; <br>   } <br> <br>   [OnSerializing]  <br>   private void OnSerializing(StreamingContext context) { <br>      // Example: Modify any state before serializing <br>   } <br> <br>   [OnSerialized]  <br>   private void OnSerialized(StreamingContext context) { <br>      // Example: Restore any state after serializing <br>   } <br>}<br>
Whenever you use any of these four attributes, the method you define must take a single <br>StreamingContext parameter (discussed in the "Streaming Contexts" section later in this <br>chapter) and return void. The name of the method can be anything you want it to be. Also, <br>you should declare the method as private to prevent it from being called by normal code; <br>the formatters run with enough security that they can call private methods.<br>
<b>Note  </b>When you are serializing a set of objects, the formatter first calls all of the objects' methods <br>that are marked with the OnSerializing attribute. Next it serializes all of the objects' fields, <br>and finally it calls all of the objects' methods marked with the OnSerialized attribute. Similarly, <br>when you deserialize a set of objects, the formatter calls all of the objects' methods that are <br>marked with the OnDeserializing attribute, then it deserializes all of the object's fields, and <br>then it calls all of the objects' methods marked with the OnDeserialized attribute.<br>
Note also that during deserialization, when a formatter sees a type offering a method marked <br>with the OnDeserialized attribute, the formatter adds this object's reference to an internal <br>list. After all the objects have been deserialized, the formatter traverses this list in reverse order <br>and calls each object's OnDeserialized method. When this method is called, all the serializable <br>fields will be set correctly, and they may be accessed to perform any additional work that would <br>be necessary to fully deserialize the object. Invoking these methods in reverse order is important <br>because it allows inner objects to finish their deserialization before the outer objects that contain <br>them finish their deserialization.<br>
For example, imagine a collection object (like Hashtable or Dictionary) that internally uses a <br>hash table to maintain its sets of items. The collection object type would implement a method <br>marked with the OnDeserialized attribute. Even though the collection object would start  <br>being deserialized first (before its items), its OnDeserialized method would be called last (after <br>any of its items' OnDeserialized methods). This allows the items to complete deserialization <br>so that all their fields are initialized properly, allowing a good hash code value to be calculated. <br>Then, the collection object creates its internal buckets and uses the items' hash codes to place <br>the items into the buckets. I show an example of how the Dictionary class uses this in the  <br>upcoming "Controlling the Serialized/Deserialized Data" section of this chapter.<br>
<hr>
<A name=690></a><b>672 </b><br>
<b>Part IV  Core Facilities</b><br>
If you serialize an instance of a type, add a new field to the type, and then try to <br>deserialize the object that did not contain the new field, the formatter throws a <br>SerializationException with a message indicating that the data in the stream being dese-<br>rialized has the wrong number of members. This is very problematic in versioning scenarios <br>where it is common to add new fields to a type in a newer version. Fortunately, you can use <br>the System.Runtime.Serialization.OptionalFieldAttribute attribute to help you.<br>
You apply the OptionalFieldAttribute attribute to each new field you add to a type. Now, <br>when the formatters see this attribute applied to a field, the formatters will not throw the <br>SerializationException if the data in the stream does not contain the field.<br>
<b>How Formatters Serialize Type Instances</b><br>
In this section, I give a bit more insight into how a formatter serializes an object's fields. This <br>knowledge can help you understand the more advanced serialization and deserialization <br>techniques explained in the remainder of this chapter.<br>
To make things easier for a formatter, the FCL offers a FormatterServices type in the <br>System.Runtime.Serialization namespace. This type has only static methods in it, and  <br>no instances of the type may be instantiated. The following steps describe how a formatter <br>automatically serializes an object whose type has the SerializableAttribute attribute  <br>applied to it:<br>
<b> </b><br>
<b>1  </b> The formatter calls FormatterServices's GetSerializableMembers method:<br>
public static MemberInfo[] GetSerializableMembers(Type type, StreamingContext context);<br>
This method uses reflection to get the type's public and private instance fields (exclud-<br>ing any fields marked with the NonSerializedAttribute attribute). The method  <br>returns an array of MemberInfo objects, one for each serializable instance field.<br>
<b> </b><br>
<b>2.  </b>The object being serialized and the array of System.Reflection.MemberInfo objects <br>
are then passed to FormatterServices' static GetObjectData method:<br>
public static Object[] GetObjectData(Object obj, MemberInfo[] members);<br>
This method returns an array of Objects where each element identifies the value of <br>a field in the object being serialized. This Object array and the MemberInfo array are <br>parallel. That is, element 0 in the Object array is the value of the member identified by <br>element 0 in the MemberInfo array.<br>
<b> </b><br>
<b>3.  </b>The formatter writes the assembly's identity and the type's full name to the stream.<br>
<b> </b><br>
<b>4.  </b>The formatter then enumerates over the elements in the two arrays, writing each  <br>
member's name and value to the stream.<br>
The following steps describe how a formatter automatically deserializes an object whose type <br>has the SerializableAttribute attribute applied to it:<br>
<hr>
<A name=691></a><b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>673</b><br>
<b> </b><br>
<b>1.  </b>The formatter reads the assembly's identity and full type name from the stream. If the <br>
assembly is not currently loaded into the AppDomain, it is loaded (as described earlier). <br>If the assembly can't be loaded, a SerializationException exception is thrown and <br>the object cannot be deserialized. If the assembly is loaded, the formatter passes the <br>assembly identity information and the type's full name to FormatterServices' static <br>GetTypeFromAssembly method:<br>
public static Type GetTypeFromAssembly(Assembly assem, String name);<br>
This method returns a System.Type object indicating the type of object that is being <br>deserialized.<br>
<b> </b><br>
<b>2.  </b>The formatter calls FormatterServices's static GetUninitializedObject method:<br>
public static Object GetUninitializedObject(Type type);<br>
This method allocates memory for a new object but does not call a constructor for the <br>object. However, all the object's bytes are initialized to null or 0.<br>
<b> </b><br>
<b>3.  </b>The formatter now constructs and initializes a MemberInfo array as it did before by call-<br>
ing FormatterServices's GetSerializableMembers method. This method returns the <br>set of fields that were serialized and that need to be deserialized.<br>
<b> </b><br>
<b>4.  </b>The formatter creates and initializes an Object array from the data contained in the <br>
stream.<br>
<b> </b><br>
<b>5.  </b>The reference to the newly allocated object, the MemberInfo array, and the <br>
parallel Object array of field values is passed to FormatterServices' static <br>PopulateObjectMembers method:<br>
public static Object PopulateObjectMembers( <br>   Object obj, MemberInfo[] members, Object[] data);<br>
This method enumerates over the arrays, initializing each field to its corresponding <br>value. At this point, the object has been completely deserialized.<br>
<b>Controlling the Serialized/Deserialized Data</b><br>
As discussed earlier in this chapter, the best way to get control over the serialization and <br>deserialization process is to use the OnSerializing, OnSerialized, OnDeserializing, <br>OnDeserialized, NonSerialized, and OptionalField attributes. However, there are some <br>very rare scenarios where these attributes do not give you all the control you need. In  <br>addition, the formatters use reflection internally and reflection is slow, which increases the <br>time it takes to serialize and deserialize objects. To get complete control over what data is <br>serialized/deserialized or to eliminate the use of reflection, your type can implement the <br>System.Runtime.Serialization.ISerializable interface, which is defined as follows:<br>
public interface ISerializable { <br>   void GetObjectData(SerializationInfo info, StreamingContext context); <br>}<br>
<hr>
<A name=692></a><IMG src="CLRviaCsharp-692_1.jpg"><br>
<IMG src="CLRviaCsharp-692_2.jpg"><br>
<IMG src="CLRviaCsharp-692_3.jpg"><br>
<b>674 </b><br>
<b>Part IV  Core Facilities</b><br>
This interface has just one method in it, GetObjectData. But most types that implement this <br>interface will also implement a special constructor that I'll describe shortly.<br>
<b>Important  </b>The big problem with the ISerializable interface is that once a type implements <br>it, all derived types must implement it too, and the derived types must make sure that they  <br>invoke the base class's GetObjectData method and the special constructor. In addition, once <br>a type implements this interface, it can never remove it because it will lose compatibility with <br>the derived types. It is always OK for sealed types to implement the ISerializable interface. <br>Using the custom attributes described earlier in this chapter avoids all of the potential problems <br>associated with the ISerializable interface.<br>
<b>Important  </b>The ISerializable interface and the special constructor are intended to be <br>used by the formatters. However, other code could call GetObjectData, which might then <br>return potentially sensitive information, or other code could construct an object that passes in <br>corrupt data. For this reason, it is recommended that you apply the following attribute to the <br>GetObjectData method and the special constructor:<br>
[SecurityPermissionAttribute(SecurityAction.Demand, SerializationFormatter = true)]<br>
When a formatter serializes an object graph, it looks at each object. If its type implements <br>the ISerializable interface, then the formatter ignores all custom attributes and instead <br>constructs a new System.Runtime.Serialization.SerializationInfo object. This object <br>contains the actual set of values that should be serialized for the object.<br>
When constructing a SerializationInfo, the formatter passes two parameters: Type  <br>and System.Runtime.Serialization.IFormatterConverter<b>.</b> The Type parameter  <br>identifies the object that is being serialized. Two pieces of information are required to <br>uniquely identify a type: the string name of the type and its assembly's identity (which  <br>includes the assembly name, version, culture, and public key). When a SerializationInfo <br>object is constructed, it obtains the type's full name (by internally querying Type's FullName <br>property) and stores this string in a private field. You can obtain the type's full name by <br>querying SerializationInfo's FullTypeName property. Likewise, the constructor obtains <br>the type's defining assembly (by internally querying Type's Module property followed by <br>querying Module's Assembly property followed by querying Assembly's FullName property) <br>and stores this string in a private field. You can obtain the assembly's identity by querying <br>SerializationInfo's AssemblyName property.<br>
<b>Note  </b>While you can set a SerializationInfo's FullTypeName and AssemblyName properties, <br>this is discouraged. If you want to change the type that is being serialized, it is recommended <br>that you call SerializationInfo's SetType method, passing a reference to the desired Type <br>object. Calling SetType ensures that the type's full name and defining assembly are set correctly.  <br>An example of calling SetType is shown in the "Serializing a Type as a Different Type and <br>Deserializing an Object as a Different Object" section later in this chapter.<br>
<hr>
<A name=693></a><b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>675</b><br>
Once the SerializationInfo object is constructed and initialized, the formatter calls the <br>type's GetObjectData method, passing it the reference to the SerializationInfo object. <br>The GetObjectData method is responsible for determining what information is necessary  <br>to serialize the object and adding this information to the SerializationInfo object. <br>GetObjectData indicates what information to serialize by calling one of the many overloaded <br>AddValue methods provided by the SerializationInfo type. AddValue is called once for <br>each piece of data that you wish to add.<br>
The code below shows how the Dictionary&lt;TKey, TValue&gt; type implements the <br>ISerializable and IDeserializationCallback interfaces to take control over the  <br>serialization and deserialization of its objects.<br>
[Serializable] <br>public class Dictionary&lt;TKey, TValue&gt;: ISerializable, IDeserializationCallback { <br>   // Private fields go here (not shown) <br> <br>   private SerializationInfo m_siInfo;  // Only used for deserialization <br> <br>   // Special constructor (required by ISerializable) to control deserialization <br>   [SecurityPermissionAttribute(SecurityAction.Demand, SerializationFormatter = true)] <br>   protected Dictionary(SerializationInfo info, StreamingContext context) { <br>      // During deserialization, save the SerializationInfo for OnDeserialization <br>      m_siInfo = info; <br>   } <br> <br>   // Method to control serialization <br>   [SecurityCritical] <br>   public virtual void GetObjectData(SerializationInfo info, StreamingContext context) { <br>    <br>      info.AddValue(&quot;Version&quot;, m_version); <br>      info.AddValue(&quot;Comparer&quot;, m_comparer, typeof(IEqualityComparer&lt;TKey&gt;)); <br>      info.AddValue(&quot;HashSize&quot;, (m_ buckets == null) ? 0 : m_buckets.Length); <br>      if (m_buckets != null) { <br>         KeyValuePair&lt;TKey, TValue&gt;[] array = new KeyValuePair&lt;TKey, TValue&gt;[Count]; <br>         CopyTo(array, 0); <br>         info.AddValue(&quot;KeyValuePairs&quot;, array, typeof(KeyValuePair&lt;TKey, TValue&gt;[])); <br>      } <br>   } <br> <br>   // Method called after all key/value objects have been deserialized  <br>   public virtual void IDeserializationCallback.OnDeserialization(Object sender) { <br>      if (m_siInfo == null) return; // Never set, return <br> <br>      Int32 num = m_siInfo.GetInt32(&quot;Version&quot;); <br>      Int32 num2 = m_siInfo.GetInt32(&quot;HashSize&quot;); <br>      m_comparer = (IEqualityComparer&lt;TKey&gt;)  <br>         m_siInfo.GetValue(&quot;Comparer&quot;, typeof(IEqualityComparer&lt;TKey&gt;)); <br>      if (num2 != 0) { <br>         m_buckets = new Int32[num2]; <br>         for (Int32 i = 0; i &lt; m_buckets.Length; i++) m_buckets[i] = -1; <br>         m_entries = new Entry&lt;TKey, TValue&gt;[num2]; <br>
<hr>
<A name=694></a><IMG src="CLRviaCsharp-694_1.jpg"><br>
<b>676 </b><br>
<b>Part IV  Core Facilities</b><br>
         m_freeList = -1; <br>         KeyValuePair&lt;TKey, TValue&gt;[] pairArray = (KeyValuePair&lt;TKey, TValue&gt;[])  <br>            m_siInfo.GetValue(&quot;KeyValuePairs&quot;, typeof(KeyValuePair&lt;TKey, TValue&gt;[])); <br>         if (pairArray == null) <br>            ThrowHelper.ThrowSerializationException( <br>               ExceptionResource.Serialization_MissingKeys); <br> <br>         for (Int32 j = 0; j &lt; pairArray.Length; j++) { <br>            if (pairArray[j].Key == null) <br>               ThrowHelper.ThrowSerializationException( <br>                  ExceptionResource.Serialization_NullKey); <br>             <br>            Insert(pairArray[j].Key, pairArray[j].Value, true); <br>         } <br>      } else { m_buckets = null; } <br>      m_version = num; <br>      m_siInfo = null; <br>}<br>
Each AddValue method takes a String name and some data. Usually, the data is of a simple <br>value type like Boolean, Char, Byte, SByte, Int16, UInt16, Int32, UInt32, Int64, UInt64, <br>Single, Double, Decimal, or DateTime. However, you can also call AddValue, passing it a <br>reference to an Object such as a String. After GetObjectData has added al  of the necessary <br>serialization information, it returns to the formatter.<br>
<b>Note  </b>You should <i>always</i> call one of the overloaded AddValue methods to add serialization  <br>information for your type. If a field's type implements the ISerializable interface, don't call <br>the GetObjectData on the field. Instead, call AddValue to add the field; the formatter will see <br>that the field's type implements ISerializable and the formatter will call GetObjectData for <br>you. If you were to call GetObjectData on the field object, the formatter wouldn't know to  <br>create a new object when deserializing the stream.<br>
The formatter now takes all of the values added to the SerializationInfo object and serial-<br>izes each of them out to the stream. You'll notice that the GetObjectData method is passed <br>another parameter: a reference to a System.Runtime.Serialization.StreamingContext <br>object. Most types' GetObjectData methods wil  completely ignore this parameter, so I <br>wil  not discuss it now. Instead, I'll discuss it in the "Streaming Contexts" section later in this <br>chapter.<br>
So now you know how to set all of the information used for serialization. At this point, let's <br>turn our attention to deserialization. As the formatter extracts an object from the stream, <br>it allocates memory for the new object (by calling the System.Runtime.Serialize.<br>FormatterServices type's static GetUninitializedObject method). Initially, all of this <br>object's fields are set to 0 or null. Then, the formatter checks if the type implements the <br>ISerializable interface. If this interface exists, the formatter attempts to call a special  <br>constructor whose parameters are identical to that of the GetObjectData method.<br>
<hr>
<A name=695></a><b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>677</b><br>
If your class is sealed, then it is highly recommended that you declare this special construc-<br>tor to be private. This will prevent any code from accidentally calling increasing security. <br>If not, then you should declare this special constructor as protected so that only derived <br>classes can call it. Note that the formatters are able to call this special constructor no matter <br>how it is declared.<br>
This constructor receives a reference to a SerializationInfo object containing all of the <br>values added to it when the object was serialized. The special constructor can call any of the <br>GetBoolean, GetChar, GetByte, GetSByte, GetInt16, GetUInt16, GetInt32, GetUInt32, <br>GetInt64, GetUInt64, GetSingle, GetDouble, GetDecimal, GetDateTime, GetString, and <br>GetValue methods, passing in a string corresponding to the name used to serialize a value. <br>The value returned from each of these methods is then used to initialize the fields of the new <br>object.<br>
When deserializing an object's fields, you should cal  the Get method that matches the type <br>of value that was passed to the AddValue method when the object was serialized. In other <br>words, if the GetObjectData method called AddValue, passing it an Int32 value, then the <br>GetInt32 method should be called for the same value when deserializing the object. If the <br>value's type in the stream doesn't match the type you're trying to get, then the formatter will <br>attempt to use an IFormatterConvert object to "cast" the stream's value to the desired type.<br>
As I mentioned earlier, when a SerializationInfo object is constructed, it is passed an object <br>whose type implements the IFormatterConverter interface. Since the formatter is responsible <br>for constructing the SerializationInfo object, it chooses whatever IFormatterConverter <br>type it wants. Microsoft's BinaryFormatter and SoapFormatter types always construct an <br>instance of the System.Runtime.Serialization.FormatterConverter type. Microsoft's  <br>formatters don't offer any way for you to select a different IFormatterConverter type.<br>
The FormatterConverter type calls the System.Convert class's static methods to convert  <br>values between the core types, such as converting an Int32 to an Int64. However, to <br>convert a value between other arbitrary types, the FormatterConverter calls Convert's <br>ChangeType method to cast the serialized (or original) type to an IConvertible interface <br>and then calls the appropriate interface method. Therefore, to allow objects of a serializable <br>type to be deserialized as a different type, you may want to consider having your type imple-<br>ment the IConvertible interface. Note that the FormatterConverter object is used only <br>when deserializing objects and when you're calling a Get method whose type doesn't match <br>the type of the value in the stream.<br>
Instead of calling the various Get methods listed above, the special constructor could <br>instead call GetEnumerator, which returns a System.Runtime.Serialization.<br>SerializationInfoEnumerator object that can be used to iterate through all the values <br>contained within the SerializationInfo object. Each value enumerated is a System.<br>Runtime.Serialization.SerializationEntry object.<br>
<hr>
<A name=696></a><IMG src="CLRviaCsharp-696_1.jpg"><br>
<b>678 </b><br>
<b>Part IV  Core Facilities</b><br>
Of course, you are welcome to define a type of your own that derives from a type that <br>implements ISerializable's GetObjectData and special constructor. If your type also <br>implements ISerializable, then your implementation of GetObjectData and your imple-<br>mentation of the special constructor <i>must</i> call the same functions in the base class in order <br>for the object to be serialized and deserialized properly. Do not forget to do this or the  <br>objects will not serialize or deserialize correctly. The next section explains how to properly <br>define an ISerializable type whose base type doesn't implement this interface.<br>
If your derived type doesn't have any additional fields in it and therefore has no special  <br>serialization/deserialization needs, then you do not have to implement ISerializable at all. <br>Like all interface members, GetObjectData is virtual and will be called to properly serialize <br>the object. In addition, the formatter treats the special constructor as "virtualized." That is, <br>during deserialization, the formatter will check the type that it is trying to instantiate. If that <br>type doesn't offer the special constructor, then the formatter will scan base classes until it <br>finds one that implements the special constructor.<br>
<b>Important  </b>The code in the special constructor typically extracts its fields from the <br>SerializationInfo object that is passed to it. As the fields are extracted, you are not  <br>guaranteed that the objects are fully deserialized, so the code in the special constructor should <br>not attempt to manipulate the objects that it extracts.<br>
If your type must access members (such as call methods) on an extracted object, then it is <br>recommended that your type also provide a method that has the OnDeserialized attribute <br>applied to it or have your type implement the IDeserializationCallback interface's <br>OnDeserialization method (as shown in the Dictionary example). When this method is <br>called, all objects have had their fields set. However, there is no guarantee to the order in which <br>multiple objects have their OnDeserialized or OnDeserialization method called. So, while <br>the fields may be initialized, you still don't know if a referenced object is completely deserialized  <br>if that referenced object also provides an OnDeserialized method or implements the <br>IDeserializationCallback interface.<br>
<b>How to Define a Type That Implements </b>ISerializable<b> when </b><br>
<b>the Base Type Doesn't Implement This Interface</b><br>
As mentioned earlier, the ISerializable interface is extremely powerful since it allows a <br>type to take complete control over how instances of the type get serialized and deserialized. <br>However, this power comes at a cost: The type is now responsible for serializing all of its base <br>type's fields as well. Serializing the base type's fields is easy if the base type also implements <br>the ISerializable interface; you just call the base type's GetObjectData method.<br>
However, someday, you may find yourself defining a type that needs to take control of its <br>serialization but whose base type does not implement the ISerializable interface. In this <br>case, your derived class must manually serialize the base type's fields by grabbing their values <br>and adding them to the SerializationInfo collection. Then, in your special constructor, <br>you will also have to get the values out of the collection and somehow set the base class's <br>
<hr>
<A name=697></a><b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>679</b><br>
fields. Doing al  of this is easy (albeit tedious) if the base class's fields are public or protected, <br>but it can be very difficult or impossible to do if the base class's fields are private.<br>
This following code shows how to properly implement ISerializable's GetObjectData <br>method and its implied constructor so that the base type's fields are serialized:<br>
[Serializable] <br>internal class Base { <br>   protected String m_name = &quot;Jeff&quot;; <br>   public Base() { /* Make the type instantiable */ } <br>} <br> <br>[Serializable] <br>internal class Derived : Base, ISerializable { <br>   private DateTime m_date = DateTime.Now; <br>   public Derived() { /* Make the type instantiable*/ } <br> <br>   // If this constructor didn't exist, we'd get a SerializationException <br>   // This constructor should be protected if this class were not sealed <br>   [SecurityPermissionAttribute(SecurityAction.Demand, SerializationFormatter = true)] <br>   private Derived(SerializationInfo info, StreamingContext context) { <br>      // Get the set of serializable members for our class and base classes <br>      Type baseType = this.GetType().BaseType; <br>      MemberInfo[] mi = FormatterServices.GetSerializableMembers(baseType, context); <br> <br>      // Deserialize the base class's fields from the info object <br>      for (Int32 i = 0; i &lt; mi.Length; i++) { <br>         // Get the field and set it to the deserialized value <br>         FieldInfo fi = (FieldInfo)mi[i]; <br>         fi.SetValue(this, info.GetValue(baseType.FullName + &quot;+&quot; + fi.Name, fi.FieldType)); <br>      } <br> <br>      // Deserialize the values that were serialized for this class <br>      m_date = info.GetDateTime(&quot;Date&quot;); <br>   } <br> <br> <br>   [SecurityPermissionAttribute(SecurityAction.Demand, SerializationFormatter = true)] <br>   public virtual void GetObjectData(SerializationInfo info, StreamingContext context) { <br>      // Serialize the desired values for this class <br>      info.AddValue(&quot;Date&quot;, m_date); <br> <br>      // Get the set of serializable members for our class and base classes <br>      Type baseType = this.GetType().BaseType; <br>      MemberInfo[] mi = FormatterServices.GetSerializableMembers(baseType, context); <br> <br>      // Serialize the base class's fields to the info object <br>      for (Int32 i = 0; i &lt; mi.Length; i++) { <br>         // Prefix the field name with the fullname of the base type <br>         info.AddValue(baseType.FullName + &quot;+&quot; + mi[i].Name,  <br>            ((FieldInfo)mi[i]).GetValue(this)); <br>      } <br>   } <br>   public override String ToString() { <br>      return String.Format(&quot;Name={0}, Date={1}&quot;, m_name, m_date); <br>   } <br>}<br>
<hr>
<A name=698></a><b>680 </b><br>
<b>Part IV  Core Facilities</b><br>
In this code, there is a base class, Base, which is marked only with the <br>SerializableAttribute custom attribute. Derived from Base is Derived, which <br>also is marked with the SerializableAttribute attribute and also implements the <br>ISerializable interface. To make the situation more interesting, you'll notice that both <br>classes define a String field called m_name. When calling SerializationInfo's AddValue <br>method, you can't add multiple values with the same name. The code above handles this  <br>situation by identifying each field by its class name prepended to the field's name. For  <br>example, when the GetObjectData method calls AddValue to serialize Base's m_name field, <br>the name of the value is written as "Base+m_name."<br>
<b>Streaming Contexts</b><br>
As mentioned earlier, there are many destinations for a serialized set of objects: same pro-<br>cess, different process on the same machine, different process on a different machine, and <br>so on. In some rare situations, an object might want to know where it is going to be deseri-<br>alized so that it can emit its state differently. For example, an object that wraps a Windows <br>semaphore object might decide to serialize its kernel handle if the object knows that it will <br>be deserialized into the same process, because kernel handles are valid within a process. <br>However, the object might decide to serialize the semaphore's string name if it knows that <br>the object will be deserialized on the same machine but into a different process. Finally, the <br>object might decide to throw an exception if it knows that it will be deserialized in a process <br>running on a different machine because a semaphore is valid only within a single machine.<br>
A number of the methods mentioned earlier in this chapter accept a StreamingContext. A <br>StreamingContext structure is a very simple value type offering just two public read-only <br>properties, as shown in Table 24-1.<br>
<b>TABLE 24-1  </b>StreamingContext<b>'s Public Read-Only Properties</b><br>
<b>Member Name</b><br>
<b>Member Type</b><br>
<b>Description</b><br>
State<br>
StreamingContextStates<br>
A set of bit flags indicating the source  <br>or destination of the objects being  <br>serialized/deserialized<br>
Context<br>
Object<br>
A reference to an object that contains any <br>user-desired context information<br>
A method that receives a StreamingContext structure can examine the State property's  <br>bit flags to determine the source or destination of the objects being serialize/deserialized. <br>Table 24-2 shows the possible bit flag values.<br>
<hr>
<A name=699></a><b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>681</b><br>
<b>TABLE 24-2  </b>StreamingContextStates<b>'s Flags</b><br>
<b>Flag Name</b><br>
<b>Flag Value</b><br>
<b>Description</b><br>
CrossProcess<br>
0x0001<br>
The source or destination is a different process on the <br>same machine.<br>
CrossMachines<br>
0x0002<br>
The source or destination is on a different machine.<br>
File<br>
0x0004<br>
The source or destination is a file. Don't assume that the <br>same process will deserialize the data.<br>
Persistence<br>
0x0008<br>
The source or destination is a store such as a database or <br>a file. Don't assume that the same process will deserialize <br>the data.<br>
Remoting<br>
0x0010<br>
The source or destination is remoting to an unknown loca-<br>tion. The location may be on the same machine but may <br>also be on another machine.<br>
Other<br>
0x0020<br>
The source or destination is unknown.<br>
Clone<br>
0x0040<br>
The object graph is being cloned. The serialization code <br>may assume that the same process will deserialize the <br>data, and it is therefore safe to access handles or other <br>unmanaged resources.<br>
CrossAppDomain<br>
0x0080<br>
The source or destination is a different AppDomain.<br>
All<br>
0x00FF<br>
The source or destination may be any of the above con-<br>texts. This is the default context.<br>
Now that you know how to get this information, let's discuss how you would set this infor-<br>mation. The IFormatter interface (which is implemented by both the BinaryFormatter <br>and the SoapFormatter types) defines a read/write StreamingContext property called <br>Context. When you construct a formatter, the formatter initializes its Context property so <br>that StreamingContextStates is set to All and the reference to the additional state object <br>is set to null.<br>
After the formatter is constructed, you can construct a StreamingContext structure using <br>any of the StreamingContextStates bit flags, and you can optionally pass a reference to an <br>object containing any additional context information you need. Now, all you need to do is <br>set the formatter's Context property with this new StreamingContext object before calling  <br>the formatter's Serialize or Deserialize methods. Code demonstrating how to tell a  <br>formatter that you are serializing/deserialzing an object graph for the sole purpose of  <br>cloning all the objects in the graph is shown in the DeepClone method presented earlier in <br>this chapter.<br>
<hr>
<A name=700></a><b>682 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Serializing a Type as a Different Type and Deserializing </b><br>
<b>an Object as a Different Object</b><br>
The .NET Framework's serialization infrastructure is quite rich, and in this section, we discuss <br>how a developer can design a type that can serialize or deserialize itself into a different type <br>or object. Below are some examples where this is interesting:<br>
  Some types (such as System.DBNull and System.Reflection.Missing) are designed <br>
to have only one instance per AppDomain. These types are frequently called <i>singletons</i>. <br>If you have a reference to a DBNull object, serializing and deserializing it should not <br>cause a new DBNull object to be created in the AppDomain. After deserializing, the  <br>returned reference should refer to the AppDomain's already-existing DBNull object.<br>
  Some types (such as System.Type, System.Reflection.Assembly, and other reflec-<br>
tion types like MemberInfo) have one instance per type, assembly, member, and so on. <br>Imagine you have an array where each element references a MemberInfo object. It's <br>possible that five array elements reference a single MemberInfo object. After serializing  <br>and deserializing this array, the five elements that referred to a single MemberInfo <br>object should all refer to a single MemberInfo object. What's more, these elements <br>should refer to the one MemberInfo object that exists for the specific member in the <br>AppDomain. You could also imagine how this could be useful for polling database  <br>connection objects or any other type of object.<br>
  For remotely controlled objects, the CLR serializes information about the server object <br>
that, when deserialized on the client, causes the CLR to create a proxy object. This type <br>of the proxy object is a different type than the server object, but this is transparent to <br>the client code. When the client calls instance methods on the proxy object, the proxy <br>code internally remotes the call to the server that actually performs the request.<br>
Let's look at some code that shows how to properly serialize and deserialize a singleton type:<br>
// There should be only one instance of this type per AppDomain <br>[Serializable] <br>public sealed class Singleton : ISerializable { <br>   // This is the one instance of this type <br>   private static readonly Singleton theOneObject = new Singleton(); <br> <br>   // Here are the instance fields <br>   public String Name = &quot;Jeff&quot;; <br>   public DateTime Date = DateTime.Now; <br> <br>   // Private constructor allowing this type to construct the singleton <br>   private Singleton() { } <br> <br>   // Method returning a reference to the singleton <br>   public static Singleton GetSingleton() { return theOneObject; } <br> <br>   // Method called when serializing a Singleton <br>   // I recommend using an Explicit Interface Method Impl. Here <br>   [SecurityPermissionAttribute(SecurityAction.Demand, SerializationFormatter = true)] <br>
<hr>
<A name=701></a><b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>683</b><br>
   void ISerializable.GetObjectData(SerializationInfo info, StreamingContext context) { <br>      info.SetType(typeof(SingletonSerializationHelper)); <br>      // No other values need to be added <br>   } <br> <br>   [Serializable] <br>   private sealed class SingletonSerializationHelper : IObjectReference { <br>      // Method called after this object (which has no fields) is deserialized <br>      public Object GetRealObject(StreamingContext context) { <br>         return Singleton.GetSingleton(); <br>      } <br>   } <br> <br>   // NOTE: The special constructor is NOT necessary because it's never called <br>}<br>
The Singleton class represents a type that allows only one instance of itself to exist per <br>AppDomain. The following code tests the Singleton's serialization and deserialization code <br>to ensure that only one instance of the Singleton type ever exists in the AppDomain:<br>
private static void SingletonSerializationTest() { <br>   // Create an array with multiple elements referring to the one Singleton object <br>   Singleton[] a1 = { Singleton.GetSingleton(), Singleton.GetSingleton() }; <br>   Console.WriteLine(&quot;Do both elements refer to the same object? &quot;  <br>      + (a1[0] == a1[1])); // &quot;True&quot; <br> <br>   using (var stream = new MemoryStream()) { <br>      BinaryFormatter formatter = new BinaryFormatter(); <br> <br>      // Serialize and then deserialize the array elements <br>      formatter.Serialize(stream, a1); <br>      stream.Position = 0; <br>      Singleton[] a2 = (Singleton[])formatter.Deserialize(stream); <br> <br>      // Prove that it worked as expected: <br>      Console.WriteLine(&quot;Do both elements refer to the same object? &quot;  <br>         + (a2[0] == a2[1])); // &quot;True&quot; <br>      Console.WriteLine(&quot;Do all  elements refer to the same object? &quot;  <br>         + (a1[0] == a2[0])); // &quot;True&quot; <br>   } <br>}<br>
Now, let's walk through the code to understand what's happening. When the Singleton <br>type is loaded into the AppDomain, the CLR calls its static constructor, which constructs <br>a Singleton object and saves a reference to it in a static field, s_theOneObject. The <br>Singleton class doesn't offer any public constructors, which prevents any other code from <br>constructing any other instances of this class.<br>
In SingletonSerializationTest, an array is created consisting of two elements; each <br>element references the Singleton object. The two elements are initialized by calling <br>Singleton's static GetSingleton method. This method returns a reference to the one <br>Singleton object. The first call to Console's WriteLine method displays "True," verifying <br>that both array elements refer to the same exact object.<br>
<hr>
<A name=702></a><b>684 </b><br>
<b>Part IV  Core Facilities</b><br>
Now, SingletonSerializationTest calls the formatter's Serialize method to  <br>serialize the array and its elements. When serializing the first Singleton, the  <br>formatter detects that the Singleton type implements the ISerializable interface  <br>and calls the GetObjectData method. This method calls SetType, passing in the <br>SingletonSerializationHelper type, which tells the formatter to serialize the Singleton <br>object as a SingletonSerializationHelper object instead. Since AddValue is not called, <br>no additional field information is written to the stream. Since the formatter automatically <br>detected that both array elements refer to a single object, the formatter serializes only one <br>object.<br>
After serializing the array, SingletonSerializationTest calls the formatter's <br>Deserialize method. When deserializing the stream, the formatter tries to deserialize a <br>SingletonSerializationHelper object since this is what the formatter was "tricked" into <br>serializing. (In fact, this is why the Singleton class doesn't provide the special constructor <br>that is usually required when implementing the ISerializable interface.) After constructing <br>the SingletonSerializationHelper object, the formatter sees that this type implements <br>the System.Runtime.Serialization.IObjectReference interface. This interface is defined <br>in the FCL as follows:<br>
public interface IObjectReference { <br>   Object GetRealObject(StreamingContext context); <br>}<br>
When a type implements this interface, the formatter calls the GetRealObject method. This <br>method returns a reference to the object that you really want a reference to now that deseri-<br>alization of the object has completed. In my example, the SingletonSerializationHelper <br>type has GetRealObject return a reference to the Singleton object that already exists <br>in the AppDomain. So, when the formatter's Deserialize method returns, the a2 array <br>contains two elements, both of which refer to the AppDomain's Singleton object. The <br>SingletonSerializationHelper object used to help with the deserialization is immediately <br>unreachable and will be garbage collected in the future.<br>
The second call to WriteLine displays "True," verifying that both of a2's array elements refer <br>to the exact same object. The third and last call to WriteLine also displays "True," proving <br>that the elements in both arrays all refer to the exact same object.<br>
<b>Serialization Surrogates</b><br>
Up to now, I've been discussing how to modify a type's implementation to control how a <br>type serializes and deserializes instances of itself. However, the formatters also allow code <br>that is not part of the type's implementation to override how a type serializes and deserializes <br>its objects. There are two main reasons why application code might want to override a type's <br>behavior:<br>
<hr>
<A name=703></a><b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>685</b><br>
  It allows a developer the ability to serialize a type that was not originally designed to <br>
be serialized.<br>
  It allows a developer to provide a way to map one version of a type to a different  <br>
version of a type.<br>
Basically, to make this mechanism work, you first define a "surrogate type" that takes over the <br>actions required to serialize and deserialize an existing type. Then, you register an instance of <br>your surrogate type with the formatter telling the formatter which existing type your surro-<br>gate type is responsible for acting on. When the formatter detects that it is trying to serialize <br>or deserialize an instance of the existing type, it will call methods defined by your surrogate <br>object. Let's build a sample that demonstrates how all this works.<br>
A serialization surrogate type must implement the System.Runtime.Serialization.<br>ISerializationSurrogate interface, which is defined in the FCL as follows:<br>
public interface ISerializationSurrogate { <br>   void GetObjectData(Object obj, SerializationInfo info, StreamingContext context); <br> <br>   Object SetObjectData(Object obj, SerializationInfo info, StreamingContext context, <br>      ISurrogateSelector selector); <br>}<br>
Now, let's walk through an example that uses this interface. Let's say your program contains <br>some DateTime objects that contain values that are local to the user's computer. What if you <br>want to serialize the DateTime objects to a stream but you want the values to be serialized  <br>in universal time? This would allow you to send the data over a network stream to another  <br>machine in another part of the world and have the DateTime value be correct. While you can't <br>modify the DateTime type that ships with the FCL, you can define your own serialization sur-<br>rogate class that can control how DateTime objects are serialized and deserialized. Here is <br>how to define the surrogate class:<br>
internal sealed class UniversalToLocalTimeSerializationSurrogate : ISerializationSurrogate { <br>   public void GetObjectData(Object obj, SerializationInfo info, StreamingContext context) { <br>      // Convert the DateTime from local to UTC <br>      info.AddValue(&quot;Date&quot;, ((DateTime)obj).ToUniversalTime().ToString(&quot;u&quot;));  <br>   } <br> <br>   public Object SetObjectData(Object obj, SerializationInfo info, StreamingContext context, <br>      ISurrogateSelector selector) { <br>      // Convert the DateTime from UTC to local  <br>      return DateTime.ParseExact(info.GetString(&quot;Date&quot;), &quot;u&quot;, null).ToLocalTime(); <br>   } <br>}<br>
The GetObjectData method here works just like the ISerializable interface's <br>GetObjectData method. The only difference is that ISerializationSurrogate's <br>
<hr>
<A name=704></a><b>686 </b><br>
<b>Part IV  Core Facilities</b><br>
GetObjectData method takes one additional parameter: a reference to the "real" object that <br>is to be serialized. In the GetObjectData method above, this object is cast to DateTime, the <br>value is converted from local time to universal time, and a string (formatted using universal <br>full date/time pattern) is added to the SerializationInfo collection.<br>
The SetObjectData method is called in order to deserialize a DateTime object. When this <br>method is called, it is passed a reference to a SerializationInfo object. SetObjectData <br>gets the string date out of this collection, parses it as a universal full date/time formatted <br>string, and then converts the resulting DateTime object from universal time to the machine's <br>local time.<br>
The Object that is passed for SetObjectData's first parameter is a bit strange. Just before  <br>calling SetObjectData, the formatter allocates (via FormatterServices's static <br>GetUninitializedObject method) an instance of the type that the surrogate is a surrogate <br>for. The instance's fields are all 0/null and no constructor has been called on the object. The <br>code inside SetObjectData can simply initialize the fields of this instance using the  <br>values from the passed-in SerializationInfo object and then have SetObjectData  <br>return null. Alternatively, SetObjectData could create an entirely different object or even  <br>a different type of object and return a reference to this new object, in which case, the for-<br>matter will ignore any changes that may or may not have happened to the object it passed in <br>to SetObjectData.<br>
In my example, my UniversalToLocalTimeSerializationSurrogate class acts as a sur-<br>rogate for the DateTime type which is a value type. And so, the obj parameter refers to a <br>boxed instance of a DateTime. There is no way to change the fields in most value types (as <br>they are supposed to be immutable) and so, my SetObjectData method ignores the obj  <br>parameter and returns a new DateTime object with the desired value in it.<br>
At this point, I'm sure you're all wondering how the formatter knows to use this  <br>ISerializationSurrogate type when it tries to serialize/deserialize a DateTime object. The <br>following code demonstrates how to test the UniversalToLocalTimeSerializationSurrogate  <br>class:<br>
private static void SerializationSurrogateDemo() { <br>   using (var stream = new MemoryStream()) { <br>      // 1. Construct the desired formatter <br>      IFormatter formatter = new SoapFormatter(); <br> <br>      // 2. Construct a SurrogateSelector object <br>      SurrogateSelector ss = new SurrogateSelector(); <br> <br>      // 3. Tell the surrogate selector to use our surrogate for DateTime objects <br>      ss.AddSurrogate(typeof(DateTime), formatter.Context,  <br>         new UniversalToLocalTimeSerializationSurrogate()); <br> <br>
<hr>
<A name=705></a><b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>687</b><br>
      // NOTE: AddSurrogate can be called multiple times to register multiple surrogates <br> <br>      // 4. Tell the formatter to use our surrogate selector <br>      formatter.SurrogateSelector = ss; <br> <br>      // Create a DateTime that represents the local time on the machine &amp; serialize it <br>      DateTime localTimeBeforeSerialize = DateTime.Now; <br>      formatter.Serialize(stream, localTimeBeforeSerialize); <br> <br>      // The stream displays the Universal time as a string to prove it worked <br>      stream.Position = 0; <br>      Console.WriteLine(new StreamReader(stream).ReadToEnd()); <br> <br>      // Deserialize the Universal time string &amp; convert it to a local DateTime <br>      stream.Position = 0; <br>      DateTime localTimeAfterDeserialize = (DateTime)formatter.Deserialize(stream); <br> <br>      // Prove it worked correctly: <br>      Console.WriteLine(&quot;LocalTimeBeforeSerialize ={0}&quot;, localTimeBeforeSerialize); <br>      Console.WriteLine(&quot;LocalTimeAfterDeserialize={0}&quot;, localTimeAfterDeserialize); <br>   } <br>}<br>
After steps 1 through 4 have executed, the formatter is ready to use the registered surrogate  <br>types. When the formatter's Serialize method is called, each object's type is looked <br>up in the set maintained by the SurrogateSelector. If a match is found, then the <br>ISerializationSurrogate object's GetObjectData method is called to get the information <br>that should be written out to the stream.<br>
When the formatter's Deserialize method is called, the type of the object about to be  <br>deserialized is looked up in the formatter's SurrogateSelector and if a match is found, then <br>the ISerializationSurrogate object's SetObjectData method is called to set the fields <br>within the object being deserialized.<br>
Internally, a SurrogateSelector object maintains a private hash table. When <br>AddSurrogate is called, the Type and StreamingContext make up the key and the <br>ISerializationSurrogate object is the key's value. If a key with the same Type/<br>StreamingContext already exists, then AddSurrogate throws an ArgumentException. By <br>including a StreamingContext in the key, you can register one surrogate type object that <br>knows how to serialize/deserialize a DateTime object to a file and register a different surro-<br>gate object that knows how to serialize/deserialize a DateTime object to a different process.<br>
<hr>
<A name=706></a><IMG src="CLRviaCsharp-706_1.jpg"><br>
<b>688 </b><br>
<b>Part IV  Core Facilities</b><br>
<b>Note  </b>The BinaryFormatter class has a bug that prevents a surrogate from serializing  <br>objects with references to each other. To fix this problem, you need to pass a reference  <br>to your ISerializationSurrogate object to FormatterServices's static  <br>GetSurrogateForCyclicalReference method. This method returns an <br>ISerializationSurrogate object, which you can then pass to the SurrogateSelector's <br>AddSurrogate method. However, when you use the GetSurrogateForCyclicalReference <br>method, your surrogate's SetObjectData method must modify the value inside the  <br>object referred to by SetObjectData's obj parameter and ultimately return null or <br>obj to the calling method. The downloadable code that accompanies this book shows <br>how to modify the UniversalToLocalTimeSerializationSurrogate class and the <br>SerializationSurrogateDemo method to support cyclical references.<br>
<b>Surrogate Selector Chains</b><br>
Multiple SurrogateSelector objects can be chained together. For example, you could have <br>a SurrogateSelector that maintains a set of serialization surrogates that are used for serial-<br>izing types into proxies that get remoted across the wire or between AppDomains. You could <br>also have a separate SurrogateSelector object that contains a set of serialization surrogates <br>that are used to convert Version 1 types into Version 2 types.<br>
If you have multiple SurrogateSelector objects that you'd like the formatter to use, you <br>must chain them together into a linked list. The SurrogateSelector type implements the <br>ISurrogateSelector interface, which defines three methods. All three of these methods are <br>related to chaining. Here is how the ISurrogateSelector interface is defined:<br>
public interface ISurrogateSelector { <br>   void ChainSelector(ISurrogateSelector selector); <br>   ISurrogateSelector GetNextSelector(); <br>   ISerializationSurrogate GetSurrogate(Type type, StreamingContext context, <br>      out ISurrogateSelector selector); <br>}<br>
The ChainSelector method inserts an ISurrogateSelector object immediately after <br>the ISurrogateSelector object being operated on (`this' object). The GetNextSelector <br>method returns a reference to the next ISurrogateSelector object in the chain or null if <br>the object being operated on is the end of the chain.<br>
The GetSurrogate method looks up a Type/StreamingContext pair in the <br>ISurrogateSelector object identified by this. If the pair cannot be found, then the next <br>ISurrogateSelector object in the chain is accessed, and so on. If a match is found, then <br>GetSurrogate returns the ISerializationSurrogate object that handles the serialization/ <br>deserialization of the type looked up. In addition, GetSurrogate also returns the <br>ISurrogateSelector object that contained the match; this is usually not needed and is  <br>ignored. If none of the ISurrogateSelector objects in the chain have a match for the  <br>Type/StreamingContext pair, GetSurrogate returns null.<br>
<hr>
<A name=707></a><IMG src="CLRviaCsharp-707_1.jpg"><br>
<b> </b><br>
<b>Chapter 24  Runtime Serialization </b><br>
<b>689</b><br>
<b>Note  </b>The FCL defines an ISurrogateSelector interface and also defines a <br>SurrogateSelector type that implements this interface. However, it is extremely rare that  <br>anyone will ever have to define their own type that implements the ISurrogateSelector  <br>interface. The only reason to define your own type that implements this interface is if you need <br>to have more flexibility over mapping one type to another. For example, you might want to  <br>serialize all types that inherit from a specific base class in a special way. The  <br>System.Runtime.Remoting.Messaging.RemotingSurrogateSelector class is a perfect <br>example. When serializing objects for remoting purposes, the CLR formats the objects using the <br>RemotingSurrogateSelector. This surrogate selector serializes all objects that derive from <br>System.MarshalByRefObject in a special way so that deserialization causes proxy objects to <br>be created on the client side.<br>
<b>Overriding the Assembly and/or Type When Deserializing </b><br>
<b>an Object</b><br>
When serializing an object, formatters output the type's full name and the full name of the <br>type's defining assembly. When deserializing an object, formatters use this information to <br>know exactly what type of object to construct and initialize. The earlier discussion about <br>the ISerializationSurrogate interface showed a mechanism allowing you to take over <br>the serialization and deserialization duties for a specific type. A type that implements the <br>ISerializationSurrogate interface is tied to a specific type in a specific assembly.<br>
However, there are times when the ISerializationSurrogate mechanism doesn't provide <br>enough flexibility. Here are some scenarios when it might be useful to deserialize an object <br>into a different type than it was serialized as:<br>
  A developer might decide to move a type's implementation from one assembly to a <br>
different assembly. For example, the assembly's version number changes making the <br>new assembly different from the original assembly.<br>
  An object on a server that gets serialized into a stream that is sent to a client. When <br>
the client processes the stream, it could deserialize the object to a completely different <br>type whose code knows how to remote method calls to the server's object.<br>
  A developer makes a new version of a type. We want to deserialize any already-serialized <br>
objects into the new version of the type.<br>
The System.Runtime.Serialization.SerializationBinder class makes deserializing an <br>object to a different type very easy. To do this, you first define your own type that derives <br>from the abstract SerializationBinder type. In the code below, assume that version 1.0.0.0 <br>of your assembly defined a class called Ver1 and assume that the new version of your assem-<br>bly defines the Ver1ToVer2SerializationBinder class and also defines a class called Ver2:<br>
<hr>
<A name=708></a><IMG src="CLRviaCsharp-708_1.jpg"><br>
<b>690 </b><br>
<b>Part IV  Core Facilities</b><br>
internal sealed class Ver1ToVer2SerializationBinder : SerializationBinder { <br>   public override Type BindToType(String assemblyName, String typeName) { <br>      // Deserialize any Ver1 object from version 1.0.0.0 into a Ver2 object <br> <br>      // Calculate the assembly name that defined the Ver1 type <br>      AssemblyName assemVer1 = Assembly.GetExecutingAssembly().GetName(); <br>      assemVer1.Version = new Version(1, 0, 0, 0); <br> <br>      // If deserializing the Ver1 object from v1.0.0.0, turn it into a Ver2 object  <br>      if (assemblyName == assemVer1.ToString() &amp;&amp; typeName == &quot;Ver1&quot;)  <br>         return typeof(Ver2); <br> <br>      // Else, just return the same type being requested <br>      return Type.GetType(String.Format(&quot;{0}, {1}&quot;, typeName, assemblyName)); <br>   } <br>}<br>
Now, after you construct a formatter, construct an instance of <br>Ver1ToVer2SerializationBinder and set the formatter's Binder read/write property to <br>refer to the binder object. After setting the Binder property, you can now cal  the formatter's <br>Deserialize method. During deserialization, the formatter sees that a binder has been set. <br>As each object is about to be deserialized, the formatter cal s the binder's BindToType method, <br>passing it the assembly name and type that the formatter wants to deserialize. At this point, <br>BindToType decides what type should actually be constructed and returns this type.<br>
<b>Note  </b>The SerializationBinder class also makes it possible to change the assembly/type  <br>information while serializing an object by overriding its BindToName method, which looks like <br>this:<br>
public virtual void BindToName(Type serializedType, <br>   out string assemblyName, out string typeName)<br>
During serialization, the formatter calls this method, passing you the type it wants to serialize. <br>You can then return (via the two out parameters) the assembly and type that you want to serialize <br>instead. If you return null and null (which is what the default implementation does), then no <br>change is performed.<br>
<hr>
<A name=709></a>Chapter 25<br><b>Thread Basics</b><br>
<b>In this chapter:<br>Why Does Windows Support Threads? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 691<br>Thread Overhead. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 692<br>Stop the Madness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 696<br>CPU Trends . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 699<br>NUMA Architecture Machines  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 700<br>CLR Threads and Windows Threads . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 703<br>Using a Dedicated Thread to Perform an Asynchronous  <br>   Compute-Bound Operation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 704<br>Reasons to Use Threads . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 706<br>Thread Scheduling and Priorities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 708<br>Foreground Threads versus Background Threads . . . . . . . . . . . . . . . . . . . . . . . . . 713<br>What Now?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 715</b><br>
In this chapter, I introduce the basic concepts concerning threads, and I offer a way for  <br>developers to conceptualize about them and their use. I'll explain why Microsoft Windows <br>introduced the concept of threads, CPU trends, the relationship between common language <br>runtime (CLR) threads and Windows threads, the overhead associated with using threads, <br>how Windows schedules threads, the Microsoft .NET Framework classes that expose thread <br>properties, and much more.<br>
The chapters in Part V of this book, "Threading," explain how Windows and the CLR work <br>together to provide a threading architecture. It is my hope that after reading these chapters, <br>you will take away a foundation of knowledge that will allow you to effectively use threads to <br>design and build responsive, reliable, and scalable applications and components.<br>
<b>Why Does Windows Support Threads?</b><br>
Back in the early days of computers, operating systems didn't offer the concept of a thread. <br>In effect, there was just one thread of execution that ran throughout the entire system, which <br>included both operating system code and application code. The problem with having only <br>one thread of execution was that a long-running task would prevent other tasks from execut-<br>ing. For example, in the days of 16-bit Windows, it was very common for an application that <br>was printing a document to stall the entire machine, causing the OS and al  other applications <br>
<b> </b><br>
<b> </b><br>
<b>691</b><br>
<hr>
<A name=710></a><b>692 </b><br>
<b>Part V  Threading</b><br>
to stop responding. And, sometimes applications would have a bug in them, resulting in an <br>infinite loop that also stopped the entire machine from operating.<br>
At this point, the end user would have no choice but to reboot the computer by pressing the <br>reset button or power switch. Of course, end users hated doing this (they still do, in fact)  <br>because all running applications terminated; more importantly, any data that these  <br>applications were processing was thrown out of memory and lost. Microsoft knew that  <br>16-bit Windows would not be a good enough operating system to keep Microsoft relevant <br>as the computer industry progressed, so they set out to build a new OS to address the needs <br>of corporations and individuals. This new OS had to be robust, reliable, scalable, and secure, <br>and it had to improve the many deficiencies of 16-bit Windows. This OS kernel originally <br>shipped in Microsoft Windows NT. Over the years, this kernel has had many tweaks and fea-<br>tures added to it. The latest version of this kernel ships in the latest versions of the Microsoft <br>client and server Windows operating systems.<br>
When Microsoft was designing this OS kernel, they decided to run each instance of an  <br>application in what is called a <i>process</i>. A process is just a collection of resources that is used <br>by a single instance of an application. Each process is given a virtual address space, ensuring <br>that the code and data used by one process is not accessible to another process. This makes <br>application instances robust because one process cannot corrupt code or data being used by <br>another. In addition, the OS's kernel code and data are not accessible to processes; therefore, <br>it's not possible for application code to corrupt operating system code or data. So now,  <br>application code cannot corrupt other applications or the OS itself, and the whole computing <br>experience is much better for end users. In addition, the system is more secure because  <br>application code cannot access user names, passwords, credit card information, or other  <br>sensitive information that is in use by another application or the operating system itself.<br>
This is all well and good, but what about the CPU itself? What if an application enters an  <br>infinite loop? Well, if there is only one CPU in the machine, then it executes the infinite loop <br>and cannot execute anything else, so while the data cannot be corrupted and is more secure, <br>the system could still stop responding to the end user. Microsoft needed to fix this problem, <br>too, and threads were the answer. A <i>thread</i> is a Windows concept whose job is to virtualize <br>the CPU. Windows gives each process its very own thread (which functions similar to a CPU), <br>and if application code enters an infinite loop, the process associated with that code freezes <br>up, but other processes (which have their own threads) are not frozen; they keep running!<br>
<b>Thread Overhead</b><br>
Threads are awesome because they enable Windows to be responsive even when applica-<br>tions are executing long-running tasks. Also, threads allow the user to use one application <br>(like Task Manager) to forcibly kill an application that appears frozen because it is executing a <br>long-running task. But as with every virtualization mechanism, threads have space (memory <br>
<hr>
<A name=711></a><b> </b><br>
<b>Chapter 25  Thread Basics </b><br>
<b>693</b><br>
consumption) and time (runtime execution performance) overhead associated with them. <br>Let's explore this overhead in more detail now. Every thread has one of each of the following:<br>
<b>  Thread kernel object  </b>The OS allocates and initializes one of these data structures for <br>
each thread created in the system. The data structure contains a bunch of properties <br>(discussed later in this chapter) that describe the thread. This data structure also contains <br>what is called the thread's context. The context is a block of memory that contains a set <br>of the CPU's registers. When Windows is running on a machine with an x86 CPU, the <br>thread's context uses about 700 bytes of memory. For x64 and IA64 CPUs, the context <br>is about 1,240 and 2,500 bytes of memory, respectively.<br>
<b>  Thread environment block (TEB)  </b>The TEB is a block of memory allocated and  <br>
initialized in user mode (address space that application code can quickly access). The <br>TEB consumes 1 page of memory (4 KB on x86 and x64 CPUs, 8 KB on an IA64 CPU). <br>The TEB contains the head of the thread's exception-handling chain. Each try block <br>that the thread enters inserts a node in the head of this chain; the node is removed <br>from the chain when the thread exists in the try block. In addition, the TEB contains <br>the thread's thread-local storage data as well as some data structures for use by <br>Graphics Device Interface (GDI) and OpenGL graphics.<br>
<b>  User-mode stack  </b>The user-mode stack is used for local variables and arguments <br>
passed to methods. It also contains the address indicating what the thread should  <br>execute next when the current method returns. By default, Windows allocates 1 MB  <br>of memory for each thread's user-mode stack.1<br>
<b>  Kernel-mode stack  </b>The kernel-mode stack is also used when application code passes <br>
arguments to a kernel-mode function in the operating system. For security reasons, <br>Windows copies any arguments passed from user-mode code to the kernel from the <br>thread's user-mode stack to the thread's kernel-mode stack. Once copied, the kernel <br>can verify the arguments' values, and since the application code can't access the kernel-<br>mode stack, the application can't modify the arguments' values after they have been <br>validated and the OS kernel code begins to operate on them. In addition, the kernel <br>calls methods within itself and uses the kernel-mode stack to pass its own arguments, <br>to store a function's local variables, and to store return addresses. The kernel-mode <br>stack is 12 KB when running on a 32-bit Windows system and 24 KB when running on a <br>64-bit Windows system.<br>
1  For native applications, Windows reserves the 1 MB of address space and sparsely commits physical storage to it <br>
as the thread actually requires it when growing the stack. However, when managed applications create a thread, <br>the CLR forces Windows to reserve and fully commit the stack immediately, so 1 MB of physical storage is fully  <br>allocated as each thread is created. The CLR team did this to make managed code behave more reliably in situations <br>where the system was running low on memory. For example, the CLR and managed applications never have to <br>worry about recovering from insufficient memory when attempting to grow a thread's stack. This was very  <br>important for Microsoft SQL Server when executing stored procedures implemented in managed code.<br>
<hr>
<A name=712></a><b>694 </b><br>
<b>Part V  Threading</b><br>
<b>  DLL thread-attach and thread-detach notifications  </b>Windows has a policy that <br>
whenever a thread is created in a process, all DLLs loaded in that process have their <br>DllMain method called, passing a DLL_THREAD_ATTACH flag. Similarly, whenever a <br>thread dies, all DLLs in the process have their DllMain method called, passing it a <br>DLL_THREAD_DETACH flag. Some DLLs need these notifications to perform some special <br>initialization or cleanup for each thread created/destroyed in the process. For example, <br>the C-Runtime library DLL allocates some thread-local storage state that is required <br>should the thread use functions contained within the C-Runtime library.<br>
In the early days of Windows, many processes had maybe 5 or 6 DLLs loaded into them,  <br>but today, some processes have several hundred DLLs loaded into them. Right now, on my <br>machine, Microsoft Office Outlook has about 250 DLLs loaded into its process address space! <br>This means that whenever a new thread is created in Office Outlook, 250 DLL functions must <br>get called before the thread is allowed to do what it was created to do. And these 250 func-<br>tions must be called again whenever a thread in Outlook dies. Wow--this can seriously affect <br>the performance of creating and destroying threads within a process.2<br>
So now, you see all the space and time overhead that is associated with creating a thread, <br>letting it sit around in the system, and destroying it. But the situation gets even worse--now <br>we're going to start talking about <i>context switching</i>. A computer with only one CPU in it <br>can do only one thing at a time. Therefore, Windows has to share the actual CPU hardware <br>among all the threads (logical CPUs) that are sitting around in the system.<br>
At any given moment in time, Windows assigns one thread to a CPU. That thread is allowed <br>to run for a time-slice (sometimes referred to as a <i>quantum</i>). When the time-slice expires, <br>Windows context switches to another thread. Every context switch requires that Windows <br>performs the following actions:<br>
<b> </b><br>
<b>1.  </b>Save the values in the CPU's registers to the currently running thread's context structure <br>
inside the thread's kernel object.<br>
<b> </b><br>
<b>2.  </b>Select one thread from the set of existing threads to schedule next. If this thread is <br>
owned by another process, then Windows must also switch the virtual address space <br>seen by the CPU before it starts executing any code or touching any data.<br>
<b> </b><br>
<b>3.  </b>Load the values in the selected thread's context structure into the CPU's registers.<br>
After the context switch is complete, the CPU executes the selected thread until its time-slice <br>expires, and then another context switch happens again. Windows performs context switches <br>about every 30 ms. Context switches are pure overhead; that is, there is no memory or  <br>performance benefit that comes from context switches. Windows performs context switching <br>to provide end users with a robust and responsive operating system.<br>
2  DLLs produced by C# and most other managed programming languages do not have a DllMain in them at  <br>
all and so managed DLLs will not receive the DLL_THREAD_ATTACH and DLL_THREAD_DETACH notifications  <br>improving performance. In addition, unmanaged DLLs can opt out of these notifications by calling the Win32  <br>DisableThreadLibraryCalls function. Unfortunately, many unmanaged developers are not aware of this  <br>function, so they don't call it.<br>
<hr>
<A name=713></a><IMG src="CLRviaCsharp-713_1.jpg"><br>
<IMG src="CLRviaCsharp-713_2.jpg"><br>
<b> </b><br>
<b>Chapter 25  Thread Basics </b><br>
<b>695</b><br>
Now, if an application's thread enters into an infinite loop, Windows will periodically preempt <br>that thread, assign a different thread to an actual CPU, and let this other thread run for a <br>while. This other thread could be Task Manager's thread and now, the end user can use Task <br>Manager to kill the process containing the thread that is in an infinite loop. When doing this, <br>the process dies and all the data it was working on is destroyed, too, but all other processes <br>in the system continue to run just fine without losing their data. Of course, the user doesn't <br>have to reset the machine and reboot, so context switches are required to provide end users <br>with a much better overall experience at the cost of performance.<br>
In fact, the performance hit is much worse than you might think. Yes, a performance hit  <br>occurs when Windows context switches to another thread. But the CPU was executing  <br>another thread, and the previously running thread's code and data reside in the CPU's caches <br>so that the CPU doesn't have to access RAM memory as much, which has significant latency <br>associated with it. When Windows context switches to a new thread, this new thread is most <br>likely executing different code and accessing different data that is not in the CPU's cache. The <br>CPU must access RAM memory to populate its cache so it can get back to a good execution <br>speed. But then, about 30 ms later, another context switch occurs.<br>
The time required to perform a context switch varies with different CPU architectures and <br>speed. And the time required to build up a CPU's cache depends on what applications are <br>running in the system, the size of the CPU's caches, and various other factors. So it is impos-<br>sible for me to give you an absolute figure or even an estimate as to what time overhead <br>is incurred for each context switch. Suffice it to say that you want to avoid using context <br>switches as much as possible if you are interested in building high-performing applications <br>and components.<br>
<b>Important  </b>At the end of a time-slice, if Windows decides to schedule the same thread again <br>(rather than switching to another thread), then Windows does not perform a context switch. <br>Instead, the thread is allowed to just continue running. This improves performance significantly, <br>and avoiding context switches is something you want to achieve as often as possible when you <br>design your code.<br>
<b>Important  </b>A thread can voluntarily end its time-slice early, which happens quite frequently  <br>because threads typically wait for I/O operations (keyboard, mouse, file, network, etc.) to  <br>complete. For example, Notepad's thread usually sits idle with nothing to do; this thread is  <br>waiting for input. If the user presses the J key on the keyboard, Windows wakes Notepad's  <br>thread to have it process the J keystroke. It may take Notepad's thread just 5 ms to process the <br>key, and then it calls a Win32 function that tells Windows that it is ready to process the next <br>input event. If there are no more input events, then Windows puts Notepad's thread into a wait <br>state (relinquishing the remainder of its time-slice) so that the thread is not scheduled on any <br>CPU until the next input stimulus occurs. This improves overall system performance since threads <br>that are waiting for I/O operations to complete are not scheduled on a CPU and do not waste <br>CPU time; other threads can be scheduled on the CPU instead.<br>
<hr>
<A name=714></a><b>696 </b><br>
<b>Part V  Threading</b><br>
In addition, when performing a garbage collection, the CLR must suspend all the threads, <br>walk their stacks to find the roots to mark objects in the heap, walk their stacks again  <br>(updating roots to objects that moved during compaction), and then resume all the threads. <br>So avoiding threads will greatly improve the performance of the garbage collector, too. And <br>whenever you are using a debugger, Windows suspends all threads in the application being <br>debugged every time a breakpoint is hit and resumes all the threads when you single-step <br>or run the application. So the more threads you have, the slower your debugging experience <br>will be.<br>
From this discussion, you should conclude that you must avoid using threads as much as  <br>possible because they consume a lot of memory and they require time to create, destroy,  <br>and manage. Time is also wasted when Windows context switches between threads and <br>when garbage collections occur. However, this discussion should also help you realize that <br>threads must be used sometimes because they allow Windows to be robust and responsive.<br>
I should also point out that a computer with multiple CPUs in it can actually run multiple <br>threads simultaneously, increasing <i>scalability</i> (the ability to do more work in less time). <br>Windows will assign one thread to each CPU core, and each core will perform its own  <br>context switching to other threads. Windows makes sure that a single thread is not scheduled <br>on multiple cores at one time because this would wreak havoc. Today, computers that  <br>contain multiple CPUs, hyperthreaded CPUs, or multi-core CPUs are commonplace. But when <br>Windows was originally designed, single-CPU computers were commonplace, and Windows <br>added threads to improve system responsiveness and reliability. Today, threads are also  <br>being used to improve scalability, which can happen only on computers that have multiple <br>cores in them.<br>
The remaining chapters in this book discuss the various Windows and CLR mechanisms that <br>exist so that you can effectively wrestle with the tension of creating as few threads as possible <br>while still keeping your code responsive and allowing it to scale if your code is running on a <br>machine with multiple cores.<br>
<b>Stop the Madness</b><br>
If all we cared about was raw performance, then the optimum number of threads to have <br>on any machine is identical to the number of CPUs on that machine. So a machine with one <br>CPU would have only one thread, a machine with two CPUs would have two threads, and <br>so on. The reason is obvious: If you have more threads than CPUs, then context switching is <br>introduced and performance deteriorates. If each CPU has just one thread, then no context <br>switching exists and the threads run at full speed.<br>
<hr>
<A name=715></a><b> </b><br>
<b>Chapter 25  Thread Basics </b><br>
<b>697</b><br>
However, Microsoft designed Windows to favor reliability and responsiveness as opposed to <br>favoring raw speed and performance. And I commend this decision: I don't think any of us <br>would be using Windows or the .NET Framework today if applications could still stop the OS <br>and other applications. Therefore, Windows gives each process its own thread for improved <br>system reliability and responsiveness. On my machine, for example, when I run Task Manager <br>and select the Performance tab, I see the image shown in Figure 25-1.<br>
<b>FIGURE 25-1  </b>Task Manager showing system performance<br>
It shows that my machine currently has 60 processes running on it, and so we'd expect that <br>there were at least 60 threads on my machine since each process gets at least 1 thread. But <br>Task Manager also shows that my machine currently has 829 threads in it! This means that <br>there is about 829 MB of memory allocated for just the thread stacks, and my machine <br>has only 2 GB of RAM in it. This also means that there is an average of approximately 13.8 <br>threads per process.<br>
Now, look at the CPU Usage reading: It shows that my CPU is busy 0 percent of the time. This <br>means that 100 percent of the time, these 829 threads have literally nothing to do--they are <br>just soaking up memory that is definitely not being used when the threads are not running. <br>You have to ask yourself: Do these applications need all these threads to do nothing 100 per-<br>cent of the time? The answer to this question has to be "No." Now, if you want to see which <br>processes are the most wasteful, click the Processes tab, add the Threads column,3 and sort <br>this column in descending order, as shown in Figure 25-2.<br>
3  You add the column by selecting the View menu's Select Columns menu item.<br>
<hr>
<A name=716></a><b>698 </b><br>
<b>Part V  Threading</b><br>
<b>FIGURE 25-2  </b>Task Manager showing processes<br>
As you can see here, Outlook has created 38 threads and is using 0 percent of the CPU, <br>Microsoft Visual Studio (Devenv.exe) has created 34 threads to use 0 percent of the CPU, <br>Windows Live Messenger (Msnmsgr.exe) has created 34 threads to use 0 percent of the CPU, <br>and so on. What is going on here?<br>
When developers were learning about Windows, they learned that a process in Windows is <br>very, very expensive. Creating a process usually takes several seconds, a lot of memory must <br>be allocated, this memory must be initialized, the EXE and DLL files have to load from disk, <br>and so on. By comparison, creating a thread in Windows is very cheap, so developers decided <br>to stop creating processes and start creating threads instead. So now we have lots of threads. <br>But even though threads are cheaper than processes, they are still very expensive compared <br>to most other system resources, so they should be used sparingly and appropriately.<br>
Well, without a doubt, we can say for sure that all of these applications we've just discussed <br>are using threads inefficiently. There is just no way that all of these threads need to exist in <br>the system. It is one thing to allocate resources inside an application; it's quite another to <br>allocate them and then not use them. This is just wasteful, and allocating all the memory <br>for thread stacks means that there is less memory for more important data, such as a user's <br>document.4<br>
4  I just can't resist sharing with you another demonstration of how bad this situation is. Try this: Open Notepad.exe <br>
and use Task Manager to see how many threads are in it. Then select Notepad's File Open menu item to display <br>the common File Open dialog box. Once the dialog box appears, look at Task Manager to see how many new <br>threads just got created. On my machine, 22 additional threads are created just by displaying this dialog box! In <br>fact, every application that uses the common File Open or File Save dialog box will get many additional threads <br>created inside it that sit idle most of the time. A lot of these threads aren't even destroyed when the dialog box is <br>closed.<br>
<hr>
<A name=717></a><b> </b><br>
<b>Chapter 25  Thread Basics </b><br>
<b>699</b><br>
To make matters worse, what if these were the processes running in a single user's Remote <br>Desktop Services session--and what if there were actually 100 users on this machine? Then <br>there would be 100 instances of Outlook, all creating 38 threads only to do nothing with <br>them. That's 3,800 threads each with its own kernel object, TEB, user-mode stack, kernel-<br>mode stack, etc. That is a lot of wasted resources. This madness has to stop, especially if <br>Microsoft wants to give users a good experience when running Windows on netbook com-<br>puters, many of which have only 1 GB of RAM. Again, the chapters in this part of the book <br>will describe how to properly design an application to use very few threads in an efficient <br>manner.<br>
Now, I will admit that today, most threads in the system are created by native code. <br>Therefore, the thread's user-mode stack is really just reserving address space and most likely, <br>the stack is not fully committed to using storage. However, as more and more applications <br>become managed or have managed components running inside them (which Outlook  <br>supports), then more and more stacks become fully committed, and they are allocating a full <br>1 MB of physical storage. Regardless, all threads still have a kernel object, kernel-mode stack, <br>and other resources allocated to them. This trend of creating threads willy-nilly because they <br>are cheap has to stop; threads are not cheap--rather, they are expensive, so use them wisely.<br>
<b>CPU Trends</b><br>
In the past, CPU speeds used to increase with time, so an application that ran slowly on one <br>machine would typically run faster on a newer machine. However, CPU manufacturers are <br>unable to continue the trend of making CPUs faster. When you run CPUs at high speeds, they <br>produce a lot of heat that has to be dissipated. A few years ago, I acquired a newly released <br>notebook computer from a respected manufacturer. This computer had a bug in its firmware <br>that made it not turn the fan on enough; as a result, after running the computer for a while, <br>the CPU and the motherboard melted. The hardware manufacturer replaced the machine <br>and then "improved" the firmware by making the fan run more frequently. Unfortunately, this <br>had the effect of draining the battery faster, because fans consume a lot of power.<br>
These are the kinds of problems that the hardware vendors face today. Since CPU manufac-<br>turers can't continuously produce higher-speed CPUs, they have instead turned their attention <br>to making transistors smaller so that more of them can reside on a single chip. Today, we can <br>have a single silicon chip that contains two or more CPU cores. The result is that our software <br>only gets faster if we write our software to use the multiple cores. How do we do this? We use <br>threads <i>in an intelligent fashion</i>.<br>
<hr>
<A name=718></a><b>700 </b><br>
<b>Part V  Threading</b><br>
Computers use three kinds of multi-CPU technologies today:<br>
<b>  Multiple CPUs  </b>Some computers just have multiple CPUs in them. That is, the  <br>
motherboard has multiple sockets on it, with each socket containing a CPU. Since  <br>the motherboard must be bigger, the computer case is bigger as well, and sometimes <br>these machines have multiple power supplies in them due to the additional power <br>drain. These kinds of computers have been around for a few decades, but they are not <br>as popular today due to their increased size and cost.<br>
<b>  Hyperthreaded chips  </b>This technology (owned by Intel) allows a single chip to look <br>
like two chips. The chip contains two sets of architectural states, such as CPU registers,  <br>but the chip has only one set of execution resources. To Windows, this looks like <br>there are two CPUs in the machine, so Windows schedules two threads concurrently. <br>However, the chip only executes one of the threads at a time. When one thread pauses <br>due to a cache miss, branch misprediction, or data dependency, the chip switches to <br>the other thread. This all happens in hardware, and Windows doesn't know that it is <br>happening; Windows believes that both threads are running concurrently. Windows <br>does know about hyperthreaded CPUs, and if you have multiple hyperthreaded CPUs <br>in a single machine, Windows will first schedule one thread on each CPU so that the <br>threads are truly running concurrently and then schedule other threads on the already-<br>busy CPUs. Intel claims that a hyperthreaded CPU can improve performance by  <br>10 percent to 30 percent.<br>
<b>  Multi-core chips  </b>A few years ago, single chips containing multiple CPU cores have <br>
entered the scene. As I write this, chips with two, three, and four cores are readily  <br>available. Even my notebook computer has two cores in it; I'm sure it won't be long  <br>before our mobile phones have multiple cores in them too. Intel has even been  <br>working on a single chip with 80 cores on it! Wow, this is a lot of computing power! <br>And Intel even has hyperthreaded multi-core chips.<br>
<b>NUMA Architecture Machines</b><br>
While multi-core CPUs look great on the surface, they lead to a new problem. Now, multiple <br>cores are accessing other system resources concurrently, so these other system resources  <br>become the bottleneck of the system's overall performance. For example, if two cores need <br>to access RAM simultaneously, the memory bandwidth limits overall performance so that  <br>a dual-core system yields only a 30 percent to 70 percent performance improvement  <br>compared to a single-core system. To help mitigate this, computers are now employing what <br>is called a <i>Cache-Coherent Non-Uniform Memory Access</i> architecture, or simply, NUMA.<br>
Figure 25-3 shows the architecture of a NUMA-based computer system. This system has four <br>nodes in it. Each node contains four CPUs, a north bridge, a south bridge, and local memory <br>(RAM). Some nodes also have local devices connected. All of the memory is accessible to any <br>
<hr>
<A name=719></a><b> </b><br>
<b>Chapter 25  Thread Basics </b><br>
<b>701</b><br>
node; however, the time it takes to access the memory is non-uniform. For example, any  <br>CPU on Node 1 can access local memory on Node 1 very quickly. A CPU on Node 1 can <br>also access memory on Nodes 2 and 4, but only with a significant performance hit. A CPU in <br>Node 1 can also access memory on Node 3, but the resulting performance hit is even worse <br>since there is no direct line of communication between Nodes 1 and 3. Even though the  <br>16 CPUs are spread across four different nodes, the hardware ensures that the caches of all <br>CPUs remain coherent and in sync with each other.<br>
The Win32 API offers many functions to unmanaged developers that allow their applications <br>to specifically allocate memory on a particular NUMA node and to force threads to run on a <br>specific NUMA node. Today, the CLR does nothing special to accommodate NUMA systems. <br>In the future, I imagine the CLR will include things like having one garbage-collected heap <br>per NUMA node and perhaps the ability for an application to indicate on which node an  <br>object should be allocated. Or perhaps the CLR will migrate objects from one node to  <br>another, depending on which CPU seems to be accessing the object the most.<br>
Node 2<br>
Node 3<br>
CPU 1<br>
CPU 2<br>
CPU 3<br>
CPU 4<br>
CPU 1<br>
CPU 2<br>
CPU 3<br>
CPU 4<br>
Local<br>
North<br>
North<br>
Local<br>
memory<br>
Bridge<br>
Bridge<br>
memory<br>
South<br>
South<br>
Device 4<br>
Device 5<br>
Bridge<br>
Bridge<br>
Node 1<br>
Node 4<br>
CPU 1<br>
CPU 2<br>
CPU 3<br>
CPU 4<br>
CPU 1<br>
CPU 2<br>
CPU 3<br>
CPU 4<br>
Local<br>
North<br>
North<br>
Local<br>
memory<br>
Bridge<br>
Bridge<br>
memory<br>
South<br>
South<br>
Device 1<br>
Device 2<br>
Device 6<br>
Device 7<br>
Bridge<br>
Bridge<br>
Device 3<br>
Device 8<br>
Device 9<br>
<b>FIGURE 25-3  </b>The architecture of a NUMA computer<br>
Back in the early 1990s, it was hard to imagine that someday there would be computers that <br>had 32 CPUs in them. Therefore, when 32-bit Windows was first created, it was designed to <br>handle machines with up to 32 CPUs. Then, when Microsoft was making 64-bit Windows, <br>
<hr>
<A name=720></a><b>702 </b><br>
<b>Part V  Threading</b><br>
it designed the system to handle up to 64 CPUs in a single machine. At the time, 64 CPUs <br>seemed like a lot, but today it looks like machines are going to get even more CPUs in them <br>in the not-so-far-off future.<br>
Starting with Windows Server 2008 R2, Microsoft has designed Windows to support machines <br>that have up to 256 logical processors in them. Figure 25-4 shows how Windows supports all <br>these logical processors. Here's how to interpret the figure:<br>
  A single machine has 1 or more processor groups where each group contains 1 to 64 <br>
logical processors.<br>
  A processor group has one or more NUMA nodes. Each node contains some logical <br>
processors, cache memory, and local memory (all in proximity to each other).<br>
  Each NUMA node has one or more sockets on it for silicon chips.<br>
  Each socket's chip contains one or more CPU cores.<br>
  Each core contains one or more logical processors. There can be more than one logical <br>
processor if the chip is hyperthreaded.<br>
<b>Group 0</b><br>
<b>Group 1</b><br>
NUMA NODE<br>
NUMA NODE<br>
Socket<br>
Socket<br>
Socket<br>
Socket<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
NUMA NODE<br>
NUMA NODE<br>
Socket<br>
Socket<br>
Socket<br>
Socket<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
Core<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
L<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
P<br>
<b>FIGURE 25-4  </b>Windows uses processor groups to support machines with up to 256 logical processors in them<br>
<hr>
<A name=721></a><b> </b><br>
<b>Chapter 25  Thread Basics </b><br>
<b>703</b><br>
Today, the CLR doesn't take advantage of processor groups and so all of the threads it creates <br>run in processor group 0 (the default) and can only use up to 64 cores when running on  <br>64-bit Windows. Since 32-bit versions of Windows only support processor group 0 and since <br>32-bit versions of Windows only support 32 CPUs, managed applications can use up to 32 <br>cores when running on a 32-bit version of Windows.<br>
<b>CLR Threads and Windows Threads</b><br>
Today, the CLR uses the threading capabilities of Windows, so Part V of this book is really <br>focusing on how the threading capabilities of Windows are exposed to developers who write <br>code by using the CLR. I will explain about how threads in Windows work and how the CLR <br>alters the behavior (if it does). However, if you'd like more information about threads, I  <br>recommend reading some of my earlier writings on the topic, such as my book <i>Windows via <br>C/C++, 5th Edition</i> (Microsoft Press, 2007).<br>
While a CLR thread maps directly to a Windows thread today, the Microsoft CLR team  <br>reserves the right to divorce itself from Windows threads in the future. Someday, the CLR <br>may introduce its own logical thread concept so that a CLR logical thread doesn't necessarily  <br>map to a physical Windows thread. For example, there has been talk of creating logical <br>threads that use much less resources than physical threads, and then you could have many <br>logical threads running on top of a very small number of physical threads. For instance, the <br>CLR could determine that one of your threads is in a wait state and reassign that thread to do <br>a different task. The benefits of this include easier coding, less resources used, and potentially <br>improved performance. Unfortunately, implementing this solution would be a huge amount <br>of work for the CLR team, so I would not expect a feature like this to make it into the CLR <br>anytime soon.<br>
For you, all of this means that your code should make as few assumptions as possible when <br>manipulating threads. For example, you should avoid P/Invoking to native Windows functions <br>since these functions have no knowledge of a CLR thread.5 By avoiding native Windows  <br>functions and sticking with Framework Class Library (FCL) types whenever possible, you're <br>guaranteed that your code will easily take advantage of these performance enhancements as <br>they become available in the future.<br>
5  If you need to P/Invoke out to native code and it is important that the code execute using the current physical  <br>
operating system thread, then you should call System.Threading.Thread's static BeginThreadAffinity  <br>method. When the thread no longer requires running by using the physical operating system thread, it can notify <br>the CLR by calling Thread's static EndThreadAffinity method.<br>
<hr>
<A name=722></a><b>704 </b><br>
<b>Part V  Threading</b><br>
<b>Using a Dedicated Thread to Perform an Asynchronous </b><br>
<b>Compute-Bound Operation</b><br>
In this section, I will show you how to create a thread and have it perform an asynchronous <br>compute-bound operation. While I am going to walk you through this, I highly recommend <br>that you avoid the technique I show you here. Instead, you should use the CLR's thread pool <br>to execute asynchronous compute-bound operations whenever possible, and I go into the <br>details about doing this in Chapter 26, "Compute-Bound Asynchronous Operations."<br>
However, there are some occasions when you might want to explicitly create a thread dedi-<br>cated to executing a particular compute-bound operation. Typically, you'd want to create a <br>dedicated thread if you're going to execute code that requires the thread to be in a particular <br>state that is not normal for a thread pool thread. For example, explicitly create your own <br>thread if any of the following is true:<br>
  You need the thread to run with a non-normal thread priority. All thread pool threads <br>
run at normal priority. While you can change this, it is not recommended, and the  <br>priority change does not persist across thread pool operations.<br>
  You need the thread to behave as a foreground thread, thereby preventing the applica-<br>
tion from dying until the thread has completed its task. For more information, see the <br>"Foreground Threads versus Background Threads" section later in this chapter. Thread <br>pool threads are always background threads, and they may not complete their task if <br>the CLR wants to terminate the process.<br>
  The compute-bound task is extremely long-running; this way, I would not be taxing the <br>
thread pool's logic as it tries to figure out whether to create an additional thread.<br>
  I wanted to start a thread and possibly abort it prematurely by calling Thread's Abort <br>
method (discussed in Chapter 22, "CLR Hosting and AppDomains").<br>
To create a dedicated thread, you construct an instance of the System.Threading.Thread <br>class, passing the name of a method into its constructor. Here is the prototype of Thread's <br>constructor:<br>
public sealed class Thread : CriticalFinalizerObject, ... {  <br>   public Thread(ParameterizedThreadStart start);  <br>   // Less commonly used constructors are not shown here   <br>}<br>
The start parameter identifies the method that the dedicated thread will execute, and this <br>method must match the signature of the ParameterizedThreadStart delegate.6<br>
delegate void ParameterizedThreadStart(Object obj);<br>
6  For the record, Thread also offers a constructor that takes a ThreadStart delegate that accepts no arguments <br>
and returns void. Personally, I recommend that you avoid this constructor and delegate because they are more <br>limiting. If your thread method takes an Object and returns void<b>,</b> then you can invoke your method using a  <br>dedicated thread or invoke it using the thread pool (as shown in Chapter 26).<br>
<hr>
<A name=723></a><b> </b><br>
<b>Chapter 25  Thread Basics </b><br>
<b>705</b><br>
Constructing a Thread object is a relatively lightweight operation because it does not actual y <br>create a physical operating system thread. To actually create the operating system thread <br>and have it start executing the callback method, you must call Thread's Start method, pass-<br>ing into it the object (state) that you want passed as the callback method's argument. The <br>following code demonstrates how to create a dedicated thread and have it call a method <br>asynchronously:<br>
using System;  <br>using System.Threading;  <br>  <br>public static class Program {  <br>   public static void Main() {  <br>      Console.WriteLine(&quot;Main thread: starting a dedicated thread &quot; +  <br>         &quot;to do an asynchronous operation&quot;);  <br>      Thread dedicatedThread = new Thread(ComputeBoundOp);  <br>      dedicatedThread.Start(5);  <br>  <br>      Console.WriteLine(&quot;Main thread: Doing other work here...&quot;);  <br>      Thread.Sleep(10000);     // Simulating other work (10 seconds)  <br>  <br>      dedicatedThread.Join();  // Wait for thread to terminate  <br>      Console.WriteLine(&quot;Hit &lt;Enter&gt; to end this program...&quot;);  <br>      Console.ReadLine();  <br>   }  <br>  <br>   // This method's signature must match the ParameterizedThreadStart delegate  <br>   private static void ComputeBoundOp(Object state) {  <br>      // This method is executed by a dedicated thread   <br>  <br>      Console.WriteLine(&quot;In ComputeBoundOp: state={0}&quot;, state);  <br>      Thread.Sleep(1000);  // Simulates other work (1 second)  <br>  <br>      // When this method returns, the dedicated thread dies  <br>   }  <br>}<br>
When I compile and run this code, I get the following output:<br>
Main thread: starting a dedicated thread to do an asynchronous operation  <br>Main thread: Doing other work here...  <br>In ComputeBoundOp: state=5<br>
Sometimes when I run this code, I get the following output since I can't control how <br>Windows schedules the two threads:<br>
Main thread: starting a dedicated thread to do an asynchronous operation  <br>In ComputeBoundOp: state=5  <br>Main thread: Doing other work here...<br>
Notice that the Main method calls Join. The Join method causes the calling thread to stop <br>executing any code until the thread identified by dedicatedThread has destroyed itself or <br>been terminated. <br>
<hr>
<A name=724></a><b>706 </b><br>
<b>Part V  Threading</b><br>
<b>Reasons to Use Threads</b><br>
There are really three reasons to use threads.<br>
<b>  You can use threads to isolate code from other code.  </b>This can improve your applica-<br>
tion's reliability, and in fact, this is why Windows introduced the concept of threads into <br>the operating system. Windows needs threads for reliability because your application <br>is a third-party component to the operating system and Microsoft doesn't verify the <br>quality of your code before you ship it. However, you should be testing all of your  <br>applications before you ship them, and since you are testing complete applications, you <br>should know that they are robust and of high quality. Because of this, your application's <br>need for robustness is not as high as the operating system's need for robustness, and <br>therefore, your application should not use many threads for the purpose of maintaining <br>robustness. If your application supports the loading of components produced by other <br>parties, then your application's need for robustness increases and using threads can <br>help satisfy this requirement.<br>
<b>  You can use threads to make your coding easier.  </b>Sometimes coding is easier if  <br>
you execute a task via its own thread. But of course, when you do this, you are using <br>additional resources and not writing the code as efficiently as possible. Now, I'm all for <br>having an easier coding process even at the expense of some resources. If I weren't  <br>OK with this, then I'd still be writing in machine language as opposed to being a C#  <br>developer. But sometimes I see people using threads thinking that they are choosing  <br>an easier programming methodology when, in fact, they are complicating their life <br>(and their code) substantially. Usually, when you introduce threads, you introduce  <br>coordination code that may require thread synchronization constructs to know when <br>the other thread has terminated. Once you start handling coordination, you are using <br>even more resources and complicating your code. So make sure that threads are really <br>going to help you before you start using them.<br>
<b>  You can use threads to get concurrent execution.  </b>If and only if you know that your <br>
application is running on a machine with multiple CPUs in it, you can get improved <br>performance by having multiple tasks executing simultaneously. Today, machines with <br>multiple CPUs in them are quite common, so designing your application to use mul-<br>tiple cores makes sense and is the focus of Chapter 26 and Chapter 27, "I/O-Bound <br>Asynchronous Operations."<br>
Now, I'd like to share with you a theory of mine. Every computer has an incredibly powerful <br>resource inside it: the CPU itself. If someone spends money on a computer, then that com-<br>puter should be working all the time. In other words, I believe that all the CPUs in a computer <br>should be running at 100 percent utilization all the time. I will qualify this statement with two <br>caveats. First, you may not want the CPUs running at 100 percent utilization if the computer <br>is on battery power because that may drain the battery too quickly. Second, some data  <br>centers would prefer to have 10 machines running at 50 percent CPU utilization rather than  <br>
<hr>
<A name=725></a><b> </b><br>
<b>Chapter 25  Thread Basics </b><br>
<b>707</b><br>
5 machines running at 100 percent CPU utilization because running CPUs at full power tends <br>to generate heat, which requires cooling systems, and powering a HVAC cooling system can  <br>be more expensive than powering more computers running at reduced capacity. Although <br>data centers find it increasingly expensive to maintain multiple machines because each  <br>machine has to have periodic hardware and software upgrades and monitoring, this has to <br>be weighed against the expense of running a cooling system.<br>
Now, if you agree with my theory, then the next step is to figure out what the CPUs should <br>be doing. Before I give you my ideas here, let me say something else first. In the past, devel-<br>opers and end users always felt that the computer was not powerful enough. Therefore, we <br>developers would never just execute code unless the end users give us permission to do so <br>and indicate that it is OK for the application to consume CPU resources via UI elements such <br>as menu items, buttons, and check boxes.<br>
But now, times have changed. Computers ship with phenomenal amounts of computing <br>power, and even more computing power is being promised in the very near future. Earlier <br>in this chapter, I showed you how Task Manager was reporting that my CPU was busy just 0 <br>percent of the time. If my computer contained a quad-core CPU in it instead of the dual-core <br>CPU that it now has, then Task Manager will report 0 percent more often. When an 80-core <br>processor comes out, the machine will look like it's doing nothing almost all the time. To <br>computer purchasers, it looks like they're spending more money for more powerful CPUs and <br>the computer is doing less work!<br>
This is the reason why the hardware manufacturers are having a hard time selling multi-core <br>computers to users: the software isn't taking advantage of the hardware and users get no <br>benefit from buying machines with additional CPUs. What I'm saying is that we now have an <br>abundance of computing power available and more is on the way, so developers can aggres-<br>sively consume it. That's right--in the past, we would never dream of having our applications <br>perform some computation unless we knew the end user wanted the result of that computa-<br>tion. But now that we have extra computing power, we can dream like this.<br>
Here's an example: When you stop typing in Visual Studio's editor, Visual Studio automati-<br>cally spawns the compiler and compiles your code. This makes developers incredibly produc-<br>tive because they can see warnings and errors in their source code as they type and can fix <br>things immediately. In fact, what developers think of today as the Edit-Build-Debug cycle will <br>become just the Edit-Debug cycle because building (compiling) code will just happen all the <br>time. You, as an end user, won't notice this because there is a lot of CPU power available and <br>other things you're doing will barely be affected by the frequent running of the compiler.  <br>In fact, I would expect that in some future version of Visual Studio, the Build menu item  <br>will disappear completely because building will just become automatic. Not only does the <br>application's UI get simpler, but the application also offers "answers" to the end user, making <br>them more productive.<br>
<hr>
<A name=726></a><b>708 </b><br>
<b>Part V  Threading</b><br>
When we remove UI components like menu items, computers get simpler for end users. <br>There are fewer options for them and fewer concepts for them to read and understand. It is <br>the multi-core revolution that allows us to remove these UI elements, thereby making soft-<br>ware so much simpler for end users that my grandmother might someday feel comfortable <br>using a computer. For developers, removing UI elements usually results in less testing, and <br>offering fewer options to the end user simplifies the code base. And if you currently localize <br>the text in your UI elements and your documentation (like Microsoft does), then removing <br>the UI elements means that you write less documentation and you don't have to localize this <br>documentation anymore. All of this can save your organization a lot of time and money.<br>
Here are some more examples of aggressive CPU consumption: spell checking and grammar  <br>checking of documents, recalculation of spreadsheets, indexing files on your disk for fast <br>searching, and defragmenting your hard disk to improve I/O performance.<br>
I want to live in a world where the UI is reduced and simplified, I have more screen real estate <br>to visualize the data that I'm actually working on, and applications offer me information that <br>helps me get my work done quickly and efficiently instead of me telling the application to go <br>get information for me. I think the hardware has been there for software developers to use <br>for the past few years. It's time for the software to start using the hardware creatively.<br>
<b>Thread Scheduling and Priorities</b><br>
A preemptive operating system must use some kind of algorithm to determine which threads <br>should be scheduled when and for how long. In this section, we'll look at the algorithm <br>Windows uses. Earlier in this chapter, I mentioned how every thread's kernel object contains a <br>context structure. The context structure reflects the state of the thread's CPU registers when <br>the thread last executed. After a time-slice, Windows looks at all the thread kernel objects <br>currently in existence. Of these objects, only the threads that are not waiting for something <br>are considered schedulable. Windows selects one of the schedulable thread kernel objects <br>and context switches to it. Windows actually keeps a record of how many times each thread <br>gets context switched to. You can see this when using a tool such as Microsoft Spy++. Figure <br>25-5 shows the properties for a thread. Notice that this thread has been scheduled 31,768 <br>times.7<br>
7  As a side note, you can also see that the thread has been in the system for more than 25 hours, but it actually used <br>
less than 1 second of CPU time, which wastes a lot of resources.<br>
<hr>
<A name=727></a><IMG src="CLRviaCsharp-727_1.jpg"><br>
<b> </b><br>
<b>Chapter 25  Thread Basics </b><br>
<b>709</b><br>
<b>FIGURE 25-5  </b>Spy++ showing a thread's properties<br>
At this point, the thread is executing code and manipulating data in its process's address <br>space. After another time-slice, Windows performs another context switch. Windows per-<br>forms context switches from the moment the system is booted and continues until the sys-<br>tem is shut down.<br>
Windows is called a preemptive multithreaded operating system because a thread can be <br>stopped at any time and another thread can be scheduled. As you'll see, you have some  <br>control over this, but not much. Just remember that you cannot guarantee that your thread <br>will always be running and that no other thread will be allowed to run.<br>
<b>Note  </b>Developers frequently ask me how they can guarantee that their thread will start running <br>within some time period after some event--for example, how can you ensure that a particular <br>thread will start running within 1 ms of data coming from the serial port? I have an easy answer: <br>You can't.<br>
Real-time operating systems can make these promises, but Windows is not a real-time operating <br>system. A real-time operating system requires intimate knowledge of the hardware it is running <br>on so that it knows the latency associated with its hard disk controllers, keyboards, and other <br>components. Microsoft's goal with Windows is to make it work on a wide variety of hardware: <br>different CPUs, different drives, different networks, and so on. In short, Windows is not designed <br>to be a real-time operating system. Let me also add that the CLR makes managed code behave <br>even less in real time. There are many reasons for this, including just-in-time (JIT) loading of DLLs, <br>JIT compiling of code, and the garbage collector kicking in at unpredictable times.<br>
Every thread is assigned a priority level ranging from 0 (the lowest) to 31 (the highest).  <br>When the system decides which thread to assign to a CPU, it examines the priority 31 threads <br>first and schedules them in a round-robin fashion. If a priority 31 thread is schedulable, it is <br>assigned to a CPU. At the end of this thread's time-slice, the system checks to see whether <br>there is another priority 31 thread that can run; if so, it allows that thread to be assigned to a <br>CPU.<br>
<hr>
<A name=728></a><b>710 </b><br>
<b>Part V  Threading</b><br>
So long as priority 31 threads are schedulable, the system never assigns any thread with <br>a priority of 0 through 30 to a CPU. This condition is called <i>starvation,</i> and it occurs when <br>higher-priority threads use so much CPU time that they prevent lower-priority threads from <br>executing. Starvation is much less likely to occur on a multiprocessor machine because a  <br>priority 31 thread and a priority 30 thread can run simultaneously on such a machine. <br>The system always tries to keep the CPUs busy, and CPUs sit idle only if no threads are <br>schedulable.<br>
Higher-priority threads always preempt lower-priority threads, regardless of what the lower-<br>priority threads are executing. For example, if a priority 5 thread is running and the system <br>determines that a higher-priority thread is ready to run, the system immediately suspends <br>the lower-priority thread (even if it's in the middle of its time-slice) and assigns the CPU to <br>the higher-priority thread, which gets a full time-slice.<br>
By the way, when the system boots, it creates a special thread called the <i>zero page thread. <br></i>This thread is assigned priority 0 and is the only thread in the entire system that runs at  <br>priority 0. The zero page thread is responsible for zeroing any free pages of RAM in the  <br>system when no other threads need to perform work.<br>
Microsoft realized that assigning priority levels to threads was going to be too hard for  <br>developers to rationalize. Should this thread be priority level 10? Should this other thread be <br>priority level 23? To resolve this issue, Windows exposes an abstract layer over the priority <br>level system.<br>
When designing your application, you should decide whether your application needs to be <br>more or less responsive than other applications that may be running on the machine. Then <br>you choose a process priority class to reflect your decision. Windows supports six process <br>priority classes: Idle, Below Normal, Normal, Above Normal, High, and Realtime. Of course, <br>Normal is the default and is therefore the most common priority class by far.<br>
The Idle priority class is perfect for applications (like screen savers) that run when the system <br>is all but doing nothing. A computer that is not being used interactively might still be busy <br>(acting as a file server, for example) and should not have to compete for CPU time with a <br>screen saver. Statistics-tracking applications that periodically update some state about the <br>system usually should not interfere with more critical tasks.<br>
You should use the High priority class only when absolutely necessary. You should avoid using <br>the Realtime priority class if possible. Realtime priority is extremely high and can interfere <br>with operating system tasks, such as preventing required disk I/O and network traffic from <br>occurring. In addition, a Realtime process's threads could prevent keyboard and mouse input <br>from being processed in a timely manner, causing the user to think that the system is com-<br>pletely frozen. Basically, you should have a good reason for using Realtime priority, such as <br>the need to respond to hardware events with short latency or to perform some short-lived <br>task.<br>
<hr>
<A name=729></a><IMG src="CLRviaCsharp-729_1.jpg"><br>
<b> </b><br>
<b>Chapter 25  Thread Basics </b><br>
<b>711</b><br>
<b>Note  </b>To keep the overall system running smoothly, a process cannot run in the Realtime priority  <br>class unless the user has the Increase Scheduling Priority privilege. Any user designated as an <br>administrator or a power user has this privilege by default.<br>
Once you select a priority class, you should stop thinking about how your application relates <br>to other applications and just concentrate on the threads within your application. Windows <br>supports seven relative thread priorities: Idle, Lowest, Below Normal, Normal, Above Normal, <br>Highest, and Time-Critical. These priorities are relative to the process's priority class. Again, <br>Normal relative thread priority is the default, and it is therefore the most common.<br>
So, to summarize, your process is a member of a priority class and within that process you as-<br>sign thread priorities that are relative to each other. You'll notice that I haven't said anything <br>about priority levels 0 through 31. Application developers never work with priority levels  <br>directly. Instead, the system maps the process's priority class and a thread's relative priority <br>to a priority level. Table 25-1 shows how the process's priority class and the thread's relative <br>priority maps to priority levels.<br>
<b>TABLE 25-1  How Process Priority Class and Relative Thread Priorities Map to Priority <br>Levels</b><br>
<b>Relative Thread <br>Priority</b><br>
<b>Process Priority Class</b><br>
<b>Below </b><br>
<b>Above </b><br>
<b>Idle</b><br>
<b>Normal</b><br>
<b>Normal</b><br>
<b>Normal</b><br>
<b>High</b><br>
<b>Realtime</b><br>
<b>Time-Critical</b><br>
15<br>
15<br>
15<br>
15<br>
15<br>
31<br>
<b>Highest</b><br>
6<br>
8<br>
10<br>
12<br>
15<br>
26<br>
<b>Above Normal</b><br>
5<br>
7<br>
9<br>
11<br>
14<br>
25<br>
<b>Normal</b><br>
4<br>
6<br>
8<br>
10<br>
13<br>
24<br>
<b>Below Normal</b><br>
3<br>
5<br>
7<br>
9<br>
12<br>
23<br>
<b>Lowest</b><br>
2<br>
4<br>
6<br>
8<br>
11<br>
22<br>
<b>Idle</b><br>
1<br>
1<br>
1<br>
1<br>
1<br>
16<br>
For example, a Normal thread in a Normal process is assigned a priority level of 8. Because <br>most processes are of the Normal priority class and most threads are of Normal thread  <br>priority, most threads in the system have a priority level of 8.<br>
If you have a Normal thread in a high-priority process, the thread will have a priority level <br>of 13. If you change the process's priority class to Idle, the thread's priority level becomes 4. <br>Remember that thread priorities are relative to the process's priority class. If you change a <br>process's priority class, the thread's relative priority will not change, but its priority number <br>will.<br>
<hr>
<A name=730></a><IMG src="CLRviaCsharp-730_1.jpg"><br>
<IMG src="CLRviaCsharp-730_2.jpg"><br>
<b>712 </b><br>
<b>Part V  Threading</b><br>
Notice that the table does not show any way for a thread to have a priority level of 0. This <br>is because the 0 priority is reserved for the zero page thread and the system does not allow <br>any other thread to have a priority of 0. Also, the following priority levels are not obtainable: <br>17, 18, 19, 20, 21, 27, 28, 29, or 30. If you are writing a device driver that runs in kernel mode, <br>you can obtain these levels; a user-mode application cannot. Also note that a thread in the <br>Realtime priority class can't be below priority level 16. Likewise, a thread in a priority class <br>other than Realtime cannot be above 15.<br>
<b>Note  </b>The concept of a process priority class confuses some people. They think that this some-<br>how means that Windows schedules processes. However, Windows never schedules processes; <br>Windows only schedules threads. The process priority class is an abstract concept that Microsoft <br>created to help you rationalize how your application compares with other running applications; it <br>serves no other purpose.<br>
<b>Important  </b>It is best to lower a thread's priority instead of raising another thread's priority. <br>You would normally lower a thread's priority if that thread was going to execute a long-running <br>compute-bound task like compiling code, spell checking, spreadsheet recalculations, etc. You <br>would raise a thread's priority if the thread needs to respond to something very quickly and then <br>run for a very short period of time and go back to its wait state. High-priority threads should <br>be waiting for something most of their life so that they do not affect the responsiveness of the <br>whole system. The Windows Explorer thread that responds to the user pressing the Windows <br>key on the keyboard is an example of a high-priority thread. When the user presses this key, <br>Windows Explorer preempts other lower-priority threads immediately and displays its menu. As <br>the user navigates the menu, Windows Explorer's thread responds to each keystroke quickly,  <br>updates the menu, and then stops running until the user continues navigating the menu.<br>
Normally, a process is assigned a priority class based on the process that starts it running. <br>And most processes are started by Windows Explorer, which spawns all its child processes <br>in the Normal priority class. Managed applications are not supposed to act as though they <br>own their own processes; they are supposed to act as though they run in an AppDomain, so <br>managed applications are not supposed to change their process's priority class because this <br>would affect all code running in the process. For example, many ASP.NET applications run in <br>a single process, with each application in its own AppDomain. The same is true for Silverlight <br>applications, which run in an Internet browser process, and managed stored procedures, <br>which run inside the Microsoft SQL Server process.<br>
On the other hand, your application can change the relative thread priority of its threads by <br>setting Thread's Priority<b> </b>property, passing it one of the five values (Lowest, BelowNormal, <br>Normal, AboveNormal, or Highest) defined in the ThreadPriority enumerated type. <br>However, just as Windows has reserved the priority level 0 and the real-time range for itself,  <br>the CLR reserves the Idle and Time-Critical priority levels for itself. Today, the CLR has no <br>threads that run at Idle priority level, but this could change in the future. However, the <br>
<hr>
<A name=731></a><IMG src="CLRviaCsharp-731_1.jpg"><br>
<b> </b><br>
<b>Chapter 25  Thread Basics </b><br>
<b>713</b><br>
CLR's finalizer thread, discussed in Chapter 21, "Automatic Memory Management (Garbage <br>Collection)," runs at the Time-Critical priority level. Therefore, as a managed developer, you <br>really only get to use the five highlighted relative thread priorities listed in Table 25-1.<br>
<b>Important  </b>Today, most applications do not take advantage of thread priorities. However, in <br>the world that I envision, where the CPUs are busy 100 percent of the time doing some kind of <br>useful work, using thread priorities becomes critically important so that system responsiveness is <br>unaffected. Unfortunately, end users have been trained to interpret a high-CPU usage number to <br>mean that an application is out of control. In my new world, end users will need to be retrained <br>to understand that high-CPU usage is a good thing--that it actually means that the computer is <br>aggressively processing helpful pieces of information for users. The real problem would be if all <br>the CPUs are busy running threads that are priority level 8 and above, as this would mean that <br>applications are having trouble responding to end user input. Perhaps a future version of Task <br>Manager will take thread priority levels into account when reporting CPU usage; this would be <br>much more helpful in diagnosing a troubled system.<br>
I should point out that the System.Diagnostics namespace contains a Process class and  <br>a ProcessThread class. These classes provide the Windows view of a process and thread,  <br>respectively. These classes are provided for developers wanting to write utility applications  <br>in managed code or for developers who are trying to instrument their code to help them <br>debug it. In fact, this is why the classes are in the System.Diagnostics namespace. <br>Applications need to be running with special security permissions to use these two classes. <br>You would not be able to use these classes from a Silverlight application or an ASP.NET  <br>application, for example.<br>
On the other hand, applications can use the AppDomain and Thread classes, which expose <br>the CLR's view of an AppDomain and thread. For the most part, special security permissions  <br>are not required to use these classes, although some operations are still considered privileged.<br>
<b>Foreground Threads versus Background Threads</b><br>
The CLR considers every thread to be either a foreground thread or a background thread. <br>When all the foreground threads in a process stop running, the CLR forcibly ends any back-<br>ground threads that are still running. These background threads are ended immediately; no <br>exception is thrown.<br>
Therefore, you should use foreground threads to execute tasks that you really want to com-<br>plete, like flushing data from a memory buffer out to disk. And you should use background <br>threads for tasks that are not mission-critical, like recalculating spreadsheet cells or indexing <br>records, because this work can continue again when the application restarts, and there is no <br>need to force the application to stay active if the user wants to terminate it.<br>
<hr>
<A name=732></a><IMG src="CLRviaCsharp-732_1.jpg"><br>
<b>714 </b><br>
<b>Part V  Threading</b><br>
The CLR needed to provide this concept of foreground and background threads to better <br>support AppDomains. You see, each AppDomain could be running a separate application <br>and each of these applications would have its own foreground thread. If one application  <br>exits, causing its foreground thread to terminate, then the CLR still needs to stay up and  <br>running so that other applications continue to run. After all the applications exit and all their <br>foreground threads terminate, the whole process can be destroyed.<br>
The following code demonstrates the difference between foreground and background <br>threads:<br>
using System; <br>using System.Threading; <br> <br>public static class Program { <br>   public static void Main() { <br>      // Create a new thread (defaults to foreground) <br>      Thread t = new Thread(Worker); <br> <br>      // Make the thread a background thread <br>      t.IsBackground = true; <br> <br>      t.Start(); // Start the thread <br>      // If t is a foreground thread, the application won't die for about 10 seconds <br>      // If t is a background thread, the application dies immediately <br>      Console.WriteLine(&quot;Returning from Main&quot;); <br>   } <br> <br>   private static void Worker() { <br>      Thread.Sleep(10000);  // Simulate doing 10 seconds of work <br> <br>      // The line below only gets displayed if this code is executed by a foreground thread <br>      Console.WriteLine(&quot;Returning from Worker&quot;); <br>   } <br>}<br>
It is possible to change a thread from foreground to background and vice versa at any time <br>during its lifetime. An application's primary thread and any threads explicitly created by con-<br>structing a Thread object default to being foreground threads. On the other hand, thread <br>pool threads default to being background threads. Also, any threads created by native code <br>that enter the managed execution environment are marked as background threads.<br>
<b>Important  </b>Try to avoid using foreground threads as much as possible. I was brought into a <br>consulting job once where an application just wouldn't terminate. After I spent several hours <br>researching the problem, it turned out that a UI component was explicitly creating a foreground <br>thread (the default), and that was why the process wouldn't terminate. We changed the compo-<br>nent to use the thread pool to fix the problem, and efficiency improved as well.<br>
<hr>
<A name=733></a><b> </b><br>
<b>Chapter 25  Thread Basics </b><br>
<b>715</b><br>
<b>What Now?</b><br>
In this chapter, I've explained the basics about threads, and I hope I've made it clear to you <br>that threads are very expensive resources that should be used sparingly. The best way to  <br>accomplish this is by using the CLR's thread pool. The thread pool will manage thread  <br>creation and destruction for you automatically. The thread pool creates a set of threads that <br>get reused for various tasks so your application requires just a few threads to accomplish all <br>of its work.<br>
In Chapter 26, I will focus on how to use the CLR's thread pool to perform compute-bound <br>operations. Then, in Chapter 27, I will discuss how to use the thread pool in combination with <br>the CLR's Asynchronous Programming Model to perform I/O-bound operations. In many <br>scenarios, you can perform asynchronous compute-bound and I/O-bound operations in such <br>a way that thread synchronization is not required at all. However, there are some scenarios <br>where thread synchronization is required, and the way that the thread synchronization  <br>constructs work and the difference between these various constructs are discussed in <br>Chapter 28, "Primitive Thread Synchronization Constructs," and Chapter 29, "Hybrid Thread <br>Synchronization Constructs."<br>
Before ending this discussion, I'd like to point out that I have been working extensively with <br>threads since the first beta version of Windows NT 3.1 was available around 1992. And when <br>.NET was in beta, I started producing a library of classes that can simplify asynchronous pro-<br>gramming and thread synchronization. This library is called the <i>Wintellect Power Threading <br>Library,</i> and it is freely downloadable and usable. Versions of the library exist for the desk-<br>top CLR, the Silverlight CLR, and the Compact Framework. The library, documentation, and <br>sample code can be downloaded from <i>http://Wintellect.com/PowerThreading.aspx.</i> This Web <br>site also contains links to a support forum, as well as to videos that show how to use various <br>parts of the library.<br>
<hr>
<A name=734></a><hr>
<A name=735></a>Chapter 26<br><b>Compute-Bound Asynchronous </b><br>
<b>Operations</b><br>
<b>In this chapter:<br>Introducing the CLR's Thread Pool. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 718<br>Performing a Simple Compute-Bound Operation. . . . . . . . . . . . . . . . . . . . . . . . . 719<br>Execution Contexts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 721<br>Cooperative Cancellation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 722<br>Tasks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 726<br></b>Parallel<b>'s Static </b>For<b>, </b>ForEach<b>, and </b>Invoke<b> Methods . . . . . . . . . . . . . . . . . . . . . 739<br>Parallel Language Integrated Query . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 743<br>Performing a Periodic Compute-Bound Operation  . . . . . . . . . . . . . . . . . . . . . . . 747<br>How the Thread Pool Manages Its Threads . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 750<br>Cache Lines and False Sharing. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 752</b><br>
In this chapter, I'll talk about the various ways that you can perform operations asynchro-<br>nously. When performing an asynchronous compute-bound operation, you execute it using <br>other threads. Here are some examples of compute-bound operations: compiling code, spell <br>checking, grammar checking, spreadsheet recalculations, transcoding audio or video data, <br>and producing a thumbnail of an image. Certainly, compute-bound operations are common <br>in financial and engineering applications.<br>
I would say that most applications do not spend the bulk of their time processing in-memory <br>data or performing calculations. You can verify that this is true by opening Task Manager and <br>selecting the Performance tab. If your CPU usage is below 100% (which it tends to be most of <br>the time), then the processes you have running are not using all the processing power made <br>available by your machine's CPU cores. When the CPU usage is less than 100%, then some <br>(if not all) of the threads within their processes are not running at all. Instead, these threads <br>are waiting for some input or output operation to occur. For example, these threads are wait-<br>ing for a timer to come due, waiting for data to be read from or written to a database, Web <br>service, file, network, or other hardware device, or waiting for keystrokes, mouse movement, <br>or mouse button clicks. When performing an I/O-bound operation, the Microsoft Windows <br>device driver has the hardware device do the work for you and the CPU itself doesn't execute <br>any threads that happen to exist in the system. Since threads are not running on a CPU, Task <br>Manager indicates that CPU usage is low.<br>
<b> </b><br>
<b> </b><br>
<b>717</b><br>
<hr>
<A name=736></a><b>718 </b><br>
<b>Part V  Threading</b><br>
However, even in applications that are heavily I/O-bound, these applications perform some <br>computation on data that has been received, and parallelizing this computation can greatly <br>improve the application's throughput. This chapter introduces the common language run-<br>time's (CLR's) thread pool and some basic concepts about how it works and how to use it. <br>This information is critically useful, as the thread pool is the core technology that enables you <br>to design and implement scalable, responsive, and reliable applications and components.  <br>Then this chapter shows the various mechanisms available that allow you to perform com-<br>pute-bound operations via the thread pool. There are two reasons why you would want to <br>execute compute-bound operations asynchronously: to keep the UI responsive in a GUI  <br>application or to scale a time-consuming calculation across multiple CPUs.<br>
<b>Introducing the CLR's Thread Pool</b><br>
As stated in the previous chapter, creating and destroying a thread is an expensive operation <br>in terms of time. In addition, having lots of threads wastes memory resources and also hurts <br>performance due to the operating system having to schedule and context switch between <br>the runnable threads. To improve this situation, the CLR contains code to manage its own <br>thread pool. You can think of a thread pool as being a set of threads that are available for <br>your application's own use. There is one thread pool per CLR; this thread pool is shared by all <br>AppDomains controlled by that CLR. If multiple CLRs load within a single process, then each <br>CLR has its own thread pool.<br>
When the CLR initializes, the thread pool has no threads in it. Internally, the thread pool <br>maintains a queue of operation requests. When your application wants to perform an asyn-<br>chronous operation, you call some method that appends an entry into the thread pool's <br>queue. The thread pool's code will extract entries from this queue and dispatch the entry to <br>a thread pool thread. If there are no threads in the thread pool, a new thread will be created. <br>Creating a thread has a performance hit associated with it (as already discussed). However, <br>when a thread pool thread has completed its task, the thread is not destroyed; instead, the <br>thread is returned to the thread pool, where it sits idle waiting to respond to another request. <br>Since the thread doesn't destroy itself, there is no added performance hit.<br>
If your application makes many requests of the thread pool, the thread pool will try to ser-<br>vice all of the requests using just this one thread. However, if your application is queuing up <br>several requests faster than the thread pool thread can handle them, additional threads will <br>be created. Your application will eventually get to a point at which all of its requests can be <br>handled by a small number of threads, so the thread pool should have no need to create a <br>lot of threads.<br>
If your application stops making requests of the thread pool, the pool may have a lot of <br>threads in it that are doing nothing. This is wasteful of memory resources. So when a thread <br>pool thread has been idle with nothing to do for some period of time (subject to change with <br>different versions of the CLR), the thread wakes itself up and kills itself to free up resources. <br>
<hr>
<A name=737></a><IMG src="CLRviaCsharp-737_1.jpg"><br>
<b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>719</b><br>
As the thread is killing itself, there is a performance hit. However, this probably doesn't matter  <br>since the thread is killing itself because it has been idle, which means that your application <br>isn't performing a lot of work.<br>
The great thing about the thread pool is that it manages the tension between having a few <br>threads, to keep from wasting resources, and having more threads, to take advantage of <br>multiprocessors, hyperthreaded processors, and multi-core processors. And the thread pool <br>is heuristic. If your application needs to perform many tasks and CPUs are available, the <br>thread pool creates more threads. If your application's workload decreases, the thread pool <br>threads kill themselves.<br>
Internally, the thread pool categorizes its threads as either <i>worker threads</i> or <i>I/O threads</i>. <br>Worker threads are used when your application asks the thread pool to perform an asyn-<br>chronous compute-bound operation (which can include initiating an I/O-bound operation). <br>I/O threads are used to notify your code when an asynchronous I/O-bound operation has <br>completed. Specifically, this means that you are using the Asynchronous Programming Model <br>(APM) to make I/O requests such as accessing a file, networked server, database, Web service, <br>or other hardware device.<br>
<b>Performing a Simple Compute-Bound Operation</b><br>
To queue an asynchronous compute-bound operation to the thread pool, you typically call <br>one of the following methods defined by the ThreadPool class:<br>
static Boolean QueueUserWorkItem(WaitCallback callBack);  <br>static Boolean QueueUserWorkItem(WaitCallback callBack, Object state);<br>
These methods queue a "work item" and optional state data to the thread pool's queue, <br>and then all of these methods return immediately. A work item is simply a method identi-<br>fied by the callback parameter that will be called by a thread pool thread. The method can <br>be passed a single parameter specified via the state (the state data) argument. The version <br>of QueueUserWorkItem without the state parameter passes null to the callback method. <br>Eventually, some thread in the pool will process the work item, causing your method to <br>be called. The callback method you write must match the System.Threading.WaitCallback <br>delegate type, which is defined as follows:<br>
delegate void WaitCallback(Object state);<br>
<b>Note  </b>The signatures of the WaitCallback delegate, the TimerCallback delegate (discussed  <br>in this chapter's "Performing a Periodic Compute-Bound Operation" section), and the <br>ParameterizedThreadStart delegate (discussed in Chapter 25, "Thread Basics") are all  <br>identical. If you define a method matching this signature, the method can be invoked by using <br>ThreadPool.QueueUserWorkItem, by using a System.Threading.Timer object, or by using a <br>System.Threading.Thread object.<br>
<hr>
<A name=738></a><IMG src="CLRviaCsharp-738_1.jpg"><br>
<b>720 </b><br>
<b>Part V  Threading</b><br>
The following code demonstrates how to have a thread pool thread call a method <br>asynchronously:<br>
using System;  <br>using System.Threading;  <br> <br>public static class Program {  <br>   public static void Main() {  <br>      Console.WriteLine(&quot;Main thread: queuing an asynchronous operation&quot;);  <br>      ThreadPool.QueueUserWorkItem(ComputeBoundOp, 5);  <br>      Console.WriteLine(&quot;Main thread: Doing other work here...&quot;);  <br>      Thread.Sleep(10000);  // Simulating other work (10 seconds)  <br>      Console.WriteLine(&quot;Hit &lt;Enter&gt; to end this program...&quot;);  <br>      Console.ReadLine();  <br>   }  <br> <br>   // This method's signature must match the WaitCallback delegate  <br>   private static void ComputeBoundOp(Object state) {  <br>      // This method is executed by a thread pool thread  <br> <br>      Console.WriteLine(&quot;In ComputeBoundOp: state={0}&quot;, state);  <br>      Thread.Sleep(1000);  // Simulates other work (1 second)  <br> <br>      // When this method returns, the thread goes back  <br>      // to the pool and waits for another task  <br>   }  <br>}<br>
When I compile and run this code, I get the following output:<br>
Main thread: queuing an asynchronous operation  <br>Main thread: Doing other work here...  <br>In ComputeBoundOp: state=5<br>
And, sometimes when I run this code, I get this output:<br>
Main thread: queuing an asynchronous operation  <br>In ComputeBoundOp: state=5  <br>Main thread: Doing other work here...<br>
The difference in the order of the lines in the output is attributed to the fact that the two <br>methods are running asynchronously with respect to one another. The Windows scheduler <br>determines which thread to schedule first, or it may schedule them both simultaneously if the <br>application is running on a multi-CPU machine.<br>
<b>Note  </b>If the callback method throws an exception that is unhandled, the CLR terminates the pro-<br>cess (unless the host imposes its own policy). Unhandled exceptions are discussed in Chapter 20, <br>"Exceptions and State Management."<br>
<hr>
<A name=739></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>721</b><br>
<b>Execution Contexts</b><br>
Every thread has an execution context data structure associated with it. The ex-<br>ecution context includes things such as security settings (compressed stack, Thread's <br>Principal property, and Windows identity), host settings (see System.Threading.<br>HostExecutionContextManager), and logical call context data (see System.Runtime.<br>Remoting.Messaging.CallContext's LogicalSetData and LogicalGetData methods). <br>When a thread executes code, some operations are affected by the values of the thread's <br>execution context settings. This is certainly true for the security settings. Ideally, whenever a <br>thread uses another (helper) thread to perform tasks, the issuing thread's execution context <br>should flow (be copied) to the helper thread. This ensures that any operations performed <br>by helper thread(s) are executing with the same security settings and host settings. It also <br>ensures that any data stored in the initiating thread's logical call context is available to the <br>helper thread.<br>
By default, the CLR automatically causes the initiating thread's execution context to flow to <br>any helper threads. This transfers context information to the helper thread, but it comes at a <br>performance cost because there is a lot of information in an execution context, and accumu-<br>lating all of this information and then copying it for the helper thread takes a fair amount of <br>time. If the helper thread then employs additional helper threads, then more execution con-<br>text data structures have to be created and initialized as well.<br>
In the System.Threading namespace, there is an ExecutionContext class that allows you to <br>control how a thread's execution context flows from one thread to another. Here is what the <br>class looks like:<br>
public sealed class ExecutionContext : IDisposable, ISerializable { <br>   [SecurityCritical] public static AsyncFlowControl SuppressFlow(); <br>   public static void RestoreFlow(); <br>   public static Boolean IsFlowSuppressed(); <br> <br>   // Less commonly used methods are not shown <br>}<br>
You can use this class to suppress the flowing of an execution context, thereby improv-<br>ing your application's performance. The performance gains can be quite substantial for a <br>server application. There is not much performance benefit for a client application, and the <br>SuppressFlow method is marked with the [SecurityCritical] attribute, making it impos-<br>sible to call in some client applications (like Silverlight). Of course, you should suppress the <br>flowing of execution context only if the helper thread does not need or access the context <br>information. If the initiating thread's execution context does not flow to a helper thread, the <br>helper thread will use whatever execution context it last associated with it. Therefore, the <br>helper thread really shouldn't execute any code that relies on the execution context state <br>(such as a user's Windows identity).<br>
<hr>
<A name=740></a><b>722 </b><br>
<b>Part V  Threading</b><br>
Here is an example showing how suppressing the flow of execution context affects data in a <br>thread's logical call context when queueing a work item to the CLR's thread pool1:<br>
public static void Main() { <br>   // Put some data into the Main thread's logical call context <br>   CallContext.LogicalSetData(&quot;Name&quot;, &quot;Jeffrey&quot;); <br> <br>   // Initiate some work to be done by a thread pool thread <br>   // The thread pool thread can access the logical call context data  <br>   ThreadPool.QueueUserWorkItem( <br>      state =&gt; Console.WriteLine(&quot;Name={0}&quot;, CallContext.LogicalGetData(&quot;Name&quot;))); <br> <br> <br>   // Now, suppress the flowing of the Main thread's execution context <br>   ExecutionContext.SuppressFlow(); <br> <br>   // Initiate some work to be done by a thread pool thread <br>   // The thread pool thread can NOT access the logical call context data <br>   ThreadPool.QueueUserWorkItem( <br>      state =&gt; Console.WriteLine(&quot;Name={0}&quot;, CallContext.LogicalGetData(&quot;Name&quot;))); <br> <br>   // Restore the flowing of the Main thread's execution context in case <br>   // it employs more thread pool threads in the future <br>   ExecutionContext.RestoreFlow(); <br>   ... <br>}<br>
When I compile and run the code above, I get the following output:<br>
Name=Jeffrey <br>Name=<br>
While this discussion has focused on suppressing the flow of execution context when calling <br>ThreadPool.QueueUserWorkItem, this technique is also useful when using Task objects (dis-<br>cussed in the "Tasks" section of this chapter) and is also useful when initiating asynchronous <br>I/O operations (discussed in Chapter 27, "I/O-Bound Asynchronous Operations").<br>
<b>Cooperative Cancellation</b><br>
The Microsoft .NET Framework offers a standard pattern for canceling operations. This  <br>pattern is <i>cooperative,</i> meaning that the operation that you wish to cancel has to explicitly <br>support being canceled. In other words, the code performing the operation that you wish <br>to cancel and the code that attempts to cancel the operation must both use the types men-<br>tioned in this section. It is nice when long-running compute-bound operations offer cancel-<br>lation, so you should consider adding cancellation to your own compute-bound operations. <br>
1  The items that you add to the logical call context must be serializable, as discussed in Chapter 24, "Runtime <br>
Serialization." Flowing an execution context that contains logical call context data items can hurt performance <br>dramatically because capturing the execution context requires serializing and deserializing all the data items.<br>
<hr>
<A name=741></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>723</b><br>
In this section, I'll explain how to accomplish this. But, first, let me explain the two main types <br>provided in the Framework Class Library (FCL) that are part of the standard cooperative  <br>cancellation pattern.<br>
To cancel an operation, you must first create a System.Threading.<br>CancellationTokenSource object. This class looks like this:<br>
public sealed class CancellationTokenSource : IDisposable {  // A reference type <br>   public CancellationTokenSource(); <br>   public void Dispose();  // Frees resources (like the WaitHandle) <br> <br>   public Boolean IsCancellationRequested { get; } <br>   public CancellationToken Token { get; } <br> <br>   public void Cancel();  // Internally, calls Cancel passing false <br>   public void Cancel(Boolean throwOnFirstException); <br>   ... <br>}<br>
This object contains all the state having to do with managing cancellation. After construct-<br>ing a CancellationTokenSource (a reference type), one or more CancellationToken (a <br>value type) instances can be obtained from its Token property and passed around to your <br>operations that allow themselves to be canceled. Here are the most useful members of the <br>CancellationToken value type:<br>
public struct CancellationToken {  // A value type <br>   // IsCancellationRequested is called by non-Task invoked operations <br>   public Boolean    IsCancellationRequested { get; }  <br> <br>   public void       ThrowIfCancellationRequested();  // Called by Task-invoked operations <br> <br>   // WaitHandle is signaled when the CancellationTokenSource is canceled <br>   public WaitHandle WaitHandle { get; }   <br>   // GetHashCode, Equals, operator== and operator!= members are not shown <br> <br>   public static CancellationToken None { get; } <br>   public Boolean CanBeCanceled { get; }  // Rarely used <br> <br>   public CancellationTokenRegistration Register(Action&lt;Object&gt; callback, Object state, <br>      Boolean useSynchronizationContext);  // Simpler overloads not shown <br>}<br>
A CancellationToken instance is a lightweight value type as it contains a single private field: <br>a reference to its CancellationTokenSource object. A compute-bound operation's loop can <br>periodically call CancellationToken's IsCancellationRequested property to know if the <br>loop should terminate early, thereby ending the compute-bound operation. Of course, the <br>benefit here is that CPU time is no longer being wasted on an operation whose result you <br>know you're not interested in. Now, let me put all this together with some sample code:<br>
<hr>
<A name=742></a><IMG src="CLRviaCsharp-742_1.jpg"><br>
<b>724 </b><br>
<b>Part V  Threading</b><br>
internal static class CancellationDemo { <br>   public static void Go() { <br>      CancellationTokenSourcects = new CancellationTokenSource(); <br> <br>      // Pass the CancellationToken and the number-to-count-to into the operation <br>      ThreadPool.QueueUserWorkItem(o =&gt; Count(cts.Token, 1000)); <br> <br>      Console.WriteLine(&quot;Press &lt;Enter&gt; to cancel the operation.&quot;); <br>      Console.ReadLine(); <br>      cts.Cancel();  // If Count returned already, Cancel has no effect on it <br>      // Cancel returns immediately, and the method continues running here... <br>   } <br> <br>   private static void Count(CancellationToken token, Int32 countTo) { <br>      for (Int32 count = 0; count &lt;countTo; count++) { <br>         if (token.IsCancellationRequested) { <br>            Console.WriteLine(&quot;Count is cancelled&quot;); <br>            break; // Exit the loop to stop the operation <br>         } <br> <br>         Console.WriteLine(count); <br>         Thread.Sleep(200);   // For demo, waste some time <br>      } <br>      Console.WriteLine(&quot;Count is done&quot;); <br>   } <br>}<br>
<b>Note  </b>If you want to execute an operation and prevent it from being canceled, you can pass  <br>the operation the CancellationToken returned from calling CancellationToken's static  <br>None property. This property returns a special CancellationToken instance that is not  <br>associated with any CancellationTokenSource object (its private field is null). Since there is <br>no CancellationTokenSource, no code can call Cancel, and the operation that is querying <br>the special CancellationToken's IsCancellationRequested property will always get back <br>false. If you query CancellationToken's CanBeCanceled property using one of these special <br>CancellationToken instances, the property will return false. The property returns true for <br>all other CancellationToken instances obtained by querying a CancellationTokenSource <br>object's Token property.<br>
If you'd like, you can register one or more methods to be invoked when a <br>CancellationTokenSource is canceled. However, you register each callback method using  <br>CancellationToken's Register method. To this method, you pass an Action&lt;Object&gt; <br>delegate, a state value that will be passed to the callback via the delegate, and a <br>Boolean indicating whether or not to invoke the delegate using the calling thread's <br>SynchronizationContext. If you pass false for the useSynchronizationContext  <br>parameter, then the thread that calls Cancel will invoke all the registered methods sequen-<br>tially. If you pass true for the useSynchronizationContext parameter, then the callbacks <br>are sent (as opposed to posted) to the captured SynchronizationContext object which  <br>governs which thread invokes the callback. The SynchronizationContext class is discussed <br>more in the "Applications and Their Threading Models" section in Chapter 27.<br>
<hr>
<A name=743></a><IMG src="CLRviaCsharp-743_1.jpg"><br>
<IMG src="CLRviaCsharp-743_2.jpg"><br>
<b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>725</b><br>
<b>Note  </b>If you register a callback method with a CancellationTokenSource after the <br>CancellationTokenSource has already been canceled, then the thread calling Register  <br>invokes the callback (possible via the calling thread's SynchronizationContext if true is <br>passed for the useSynchronizationContext parameter).<br>
If Register is called multiple times, then multiple callback methods will be invoked. These  <br>callback methods could throw an unhandled exception. If you call <br>CancellationTokenSource's Cancel, passing it true, then the first callback method that <br>throws an unhandled exception stops the other callback methods from executing, and the <br>exception thrown will be thrown from Cancel as well. If you call Cancel passing it false, <br>then all registered callback methods are invoked. Any unhandled exceptions that occur are <br>added to a collection. After all callback methods have executed, if any of them threw an un-<br>handled exception, then Cancel throws an AggregateException with its InnerExceptions <br>property set to the collection of exception objects that were thrown. If no registered callback <br>methods threw an unhandled exception, then Cancel simply returns without throwing any <br>exception at all.<br>
<b>Important  </b>There is no way to correlate an exception object from AggregateException's <br>InnerExceptions collection to a particular operation; you are basically just being told that <br><i>some</i> operation failed and the exception type tells you what the failure was. To track down  <br>the specific location of the failure will require examining the exception object's StackTrace <br>property and manually scanning your source code.<br>
CancellationToken's Register method returns a CancellationTokenRegistration, <br>which looks like this:<br>
public struct CancellationTokenRegistration :  <br>   IEquatable&lt;CancellationTokenRegistration&gt;, IDisposable { <br>   public void Dispose(); <br>   // GetHashCode, Equals, operator== and operator!= members are not shown <br>}<br>
You can call Dispose to remove a registered callback from the CancellationTokenSource <br>that it is associated with so that it does not get invoked when calling Cancel. Here is some <br>code that demonstrates registering two callbacks with a single CancellationTokenSource:<br>
varcts = new CancellationTokenSource(); <br>cts.Token.Register(() =&gt; Console.WriteLine(&quot;Canceled 1&quot;)); <br>cts.Token.Register(() =&gt; Console.WriteLine(&quot;Canceled 2&quot;)); <br> <br>// To test, let's just cancel it now and have the 2 callbacks execute <br>cts.Cancel();<br>
When I run this code, I get the following output as soon as the Cancel method is called:<br>
Canceled 2 <br>Canceled 1<br>
<hr>
<A name=744></a><b>726 </b><br>
<b>Part V  Threading</b><br>
Finally, you can create a new CancellationTokenSource object by linking a bunch of other <br>CancellationTokenSource objects. This new CancellationTokenSource object will be <br>canceled when <i>any</i> of the linked CancellationTokenSource objects are canceled. The  <br>following code demonstrates:<br>
// Create a CancellationTokenSource <br>var cts1 = new CancellationTokenSource(); <br>cts1.Token.Register(() =&gt; Console.WriteLine(&quot;cts1 canceled&quot;)); <br> <br>// Create another CancellationTokenSource <br>var cts2 = new CancellationTokenSource(); <br>cts2.Token.Register(() =&gt; Console.WriteLine(&quot;cts2 canceled&quot;)); <br> <br>// Create a new CancellationTokenSource that is canceled when cts1 or ct2 is canceled <br>var linkedCts = CancellationTokenSource.CreateLinkedTokenSource(cts1.Token, cts2.Token); <br>linkedCts.Token.Register(() =&gt; Console.WriteLine(&quot;linkedCts canceled&quot;)); <br> <br>// Cancel one of the CancellationTokenSource objects (I chose cts2) <br>cts2.Cancel(); <br> <br>// Display which CancellationTokenSource objects are canceled <br>Console.WriteLine(&quot;cts1 canceled={0}, cts2 canceled={1}, linkedCts={2}&quot;, <br>   cts1.IsCancellationRequested, cts2.IsCancellationRequested,  <br>linkedCts.IsCancellationRequested);<br>
When I run the code above, I get the following output:<br>
linkedCts canceled <br>cts2 canceled <br>cts1 canceled=False, cts2 canceled=True, linkedCts=True<br>
<b>Tasks</b><br>
Calling ThreadPool's QueueUserWorkItem method to initiate an asynchronous compute-<br>bound operation is very simple. However, this technique has many limitations. The biggest <br>problem is that there is no built-in way for you to know when the operation has completed, <br>and there is no way to get a return value back when the operation completes. To address <br>these limitations and more, Microsoft introduced the concept of <i>tasks,</i> and you use them via <br>types in the System.Threading.Tasks namespace.<br>
So, instead of calling ThreadPool's QueueUserWorkItem method, you can do the same via <br>tasks:<br>
ThreadPool.QueueUserWorkItem(ComputeBoundOp, 5); // Calling QueueUserWorkItem <br>new Task(ComputeBoundOp, 5).Start();             // Equivalent of above using Task<br>
In the code above, I am creating the Task object and then immediately call Start to schedule <br>the task to run. Naturally, you can create the Task object and then call Start on it later. You <br>could imagine code that creates a Task object and then passes it to some other method that <br>decides when to call Start to schedule the task.<br>
<hr>
<A name=745></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>727</b><br>
When creating a Task, you always call a constructor, passing it an Action or an <br>Action&lt;Object&gt; delegate that indicates the operation that you want performed. If you pass <br>a method that expects an Object, then you must also pass to Task's constructor the argu-<br>ment that you ultimately want passed to the operation. You can also optionally pass to Task's <br>constructor a CancellationToken, which allows the Task to be canceled before it has been <br>scheduled (see the "Cancelling a Task" section later in this chapter).<br>
You can also optionally pass to the constructor some TaskCreationOptions flags that con-<br>trol how the Task executes. TaskCreationOptions is an enumerated type defining a set of <br>flags that you can bitwise-OR together. It is defined as follows:<br>
[Flags, Serializable] <br>public enumTaskCreationOptions { <br>   None             = 0x0000,// The default <br> <br>   // Causes the default TaskScheduler to put the task in the thread pool's <br>   // global queue instead of a worker thread's local queue. <br>   PreferFairness      = 0x0001, <br> <br>   // This flag is a hint to the TaskScheduler and it determines how to interpret this hint. <br>   // Today, the default TaskScheduler creates a thread for the task instead of queuing the <br>   // task to a thread pool thread. This behavior could change in the future. <br>   LongRunning        = 0x0002, <br> <br>   // Always honored: Associates a Task with its parent Task (discussed shortly) <br>   AttachedToParent   = 0x0004, <br>}<br>
Most of these flags are hints that may or may not be honored by the TaskScheduler that is <br>being used to schedule a Task; the AttachedToParent flag is always honored, as it has noth-<br>ing to do with the TaskScheduler itself. TaskScheduler objects are discussed later in the <br>"Task Schedulers" section.<br>
<b>Waiting for a Task to Complete and Getting Its Result</b><br>
With tasks, it is also possible to wait for them to complete and then get their result. Let's say <br>that we have a Sum method that is computationally intensive if n is a large value:<br>
private static Int32 Sum(Int32 n) { <br>   Int32 sum = 0; <br>   for (; n &gt; 0; n--)  <br>      checked { sum += n; }   // in n is large, this will throw System.OverflowException <br>   return sum; <br>}<br>
We can now construct a Task&lt;TResult&gt;object (which is derived from Task), and we pass <br>for the generic TResult argument the compute-bound operation's return type.  Now, after <br>starting the task, we can wait for it to complete and then get its result using the following <br>code:<br>
<hr>
<A name=746></a><IMG src="CLRviaCsharp-746_1.jpg"><br>
<b>728 </b><br>
<b>Part V  Threading</b><br>
// Create a Task (it does not start running now) <br>Task&lt;Int32&gt; t = new Task&lt;Int32&gt;(n =&gt; Sum((Int32)n), 1000000000); <br> <br>// You can start the task sometime later <br>t.Start();  <br> <br>// Optionally, you can explicitly wait for the task to complete <br>t.Wait(); // FYI: Overloads exist accepting timeout/CancellationToken <br> <br>// You can get the result (the Result property internally calls Wait) <br>Console.WriteLine(&quot;The Sum is: &quot; + t.Result); // An Int32 value<br>
<b>Important  </b>When a thread calls the Wait method, the system checks if the Task that the thread <br>is waiting for has started executing. If it has, then the thread calling Wait will block until the <br>Task has completed running. But if the Task has not started executing yet, then the system  <br><i>may</i> (depending on the TaskScheduler) execute the Task using the thread that called Wait. If <br>this happens, then the thread calling Wait does not block; it executes the Task and returns  <br>immediately. This is good in that no thread has blocked, thereby reducing resource usage (by not <br>creating a thread to replace the blocked thread) while improving performance (no time is spent <br>to create a thread and there is no context switching). But it can also be bad if, for example, the <br>thread has taken a thread synchronization lock before calling Wait and then the Task tries to <br>take the same lock, resulting in a deadlocked thread!<br>
If the compute-bound task throws an unhandled exception, the exception will be swallowed, <br>stored in a collection, and the thread pool thread is allowed to return to the thread pool. <br>When the Wait method or the Result property is invoked, these members will throw a <br>System.AggregateException object.<br>
The AggregateException type is used to encapsulate a collection of exception objects <br>(which can happen if a parent task spawns multiple child tasks that throw exceptions). It <br>contains an InnerExceptions property that returns a ReadOnlyCollection&lt;Exception&gt; <br>object. Do not confuse the InnerExceptions property with the InnerException property, <br>which the AggregateException class inherits from the System.Exception base class. For <br>the example above, element 0 of AggregateException's InnerExceptions property would <br>refer to the actual System.OverflowException object thrown by the compute-bound <br>method (Sum).<br>
As a convenience, AggregateException overrides Exception's GetBaseException method. <br>AggregateException's implementation returns the innermost AggregateException that <br>is the root cause of the problem (assuming that there is just one innermost exception in <br>the collection). AggregateException also offers a Flatten method that creates a new <br>AggregateException, whose InnerExceptions property contains a list of exceptions  <br>produced by walking the original AggregateException's inner exception hierarchy. Finally, <br>AggregateException also provides a Handle method that invokes a callback method for <br>each exception contained in the AggregateException. The callback can then decide, for <br>each exception, how to handle the exception; the callback returns true to consider the <br>
<hr>
<A name=747></a><IMG src="CLRviaCsharp-747_1.jpg"><br>
<b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>729</b><br>
exception handled and false if not. If, after calling Handle, at least one exception is not <br>handled, then a new AggregateException object is created containing just the unhandled <br>exceptions and the new AggregateException object is thrown. Later in this chapter, I show <br>examples using the Flatten and Handle methods.<br>
<b>Important  </b>If you never call Wait<b> </b>or<b> </b>Result or query a Task's Exception property, then your <br>code never observes that this exception has occurred. This is not ideal, as your program has ex-<br>perienced an unexpected problem that you are not aware of. So, when a Task object is garbage <br>collected, its Finalize method checks to see if the Task experienced an unobserved exception; <br>if it has, Task's Finalize method throws the AggregateException. Since you cannot catch <br>an exception thrown by the CLR's finalizer thread, your process is terminated immediately. You <br>must fix your code by invoking one of the aforementioned members, ensuring that your code <br>observes the exception and recovers from it.<br>
To help you detect unobserved exceptions, you can register a callback method with <br>TaskScheduler's static UnobservedTaskException event. This event is raised by the CLR's <br>finalizer thread whenever a Task with an unobserved exception is garbage collected.  When <br>raised, your event handler method will be passed an UnobservedTaskExceptionEventArgs <br>object containing the unobserved AggregateException. You can call <br>UnobservedTaskExceptionEventArgs's SetObserved method to indicate that you've pro-<br>cessed the exception, thus preventing the CLR from terminating the process. However, you <br>should not do this as a standard policy. As discussed in Chapter 20, it is better for a process to <br>terminate instead of running with corrupted state.<br>
In addition to waiting for a single task, the Task class also offers two static methods that  <br>allow a thread to wait on an array of Task objects. Task's static WaitAny method blocks the <br>calling thread until any of the Task objects in the array have completed. This method returns <br>an Int32 index into the array indicating which Task object completed, causing the thread <br>to wake and continue running. The method returns -1 if the timeout occurs and throws an <br>OperationCanceledException if WaitAny is canceled via a CancellationToken.<br>
Similarly, the Task class has a static WaitAll method that blocks the calling thread until all <br>the Task objects in the array have completed. The WaitAll method returns true if all the <br>Task objects complete and false if a timeout occurs; an OperationCanceledException is <br>thrown if WaitAll is canceled via a CancellationToken.<br>
<b>Cancelling a Task</b><br>
Of course, you can use a CancellationTokenSource to cancel a Task. First, we must revise <br>our Sum method so that it accepts a CancellationToken:<br>
private static Int32 Sum(CancellationTokenct, Int32 n) { <br>   Int32 sum = 0; <br>   for (; n &gt; 0; n--) { <br> <br>
<hr>
<A name=748></a><b>730 </b><br>
<b>Part V  Threading</b><br>
      // The following line throws OperationCanceledException when Cancel  <br>      // is called on the CancellationTokenSource referred to by the token <br>      ct.ThrowIfCancellationRequested(); <br> <br>      checked { sum += n; }   // in n is large, this will throw System.OverflowException <br>   } <br>   return sum; <br>}<br>
In this code, the compute-bound operation's loop periodically checks to see if the operation  <br>has been canceled by calling CancellationToken's ThrowIfCancellationRequested <br>method. This method is similar to CancellationToken's IsCancellationRequested <br>property shown earlier in the "Cooperative Cancellation" section. However, <br>ThrowIfCancellationRequested throws an OperationCanceledException if the <br>CancellationTokenSource has been canceled. The reason for throwing an exception is <br>because, unlike work items initiated with ThreadPool's QueueUserWorkItem method, tasks <br>have the notion of having completed and a task can even return a value. So, there needs to <br>be a way to distinguish a completed task from a faulting task, and having the task throw an <br>exception lets you know that the task did not run all the way to completion.<br>
Now, we will create the CancellationTokenSource and Task objects as follows:<br>
CancellationTokenSourcects = new CancellationTokenSource(); <br>Task&lt;Int32&gt; t = new Task&lt;Int32&gt;(() =&gt; Sum(cts.Token, 10000), cts.Token); <br> <br>t.Start(); <br> <br>// Sometime later, cancel the CancellationTokenSource to cancel the Task <br>cts.Cancel(); // This is an asynchronous request, the Task may have completed already <br> <br>try { <br>   // If the task got canceled, Result will throw an AggregateException <br>   Console.WriteLine(&quot;The sum is: &quot; + t.Result);   // An Int32 value <br>} <br>catch (AggregateException x) { <br>   // Consider any OperationCanceledException objects as handled.  <br>   // Any other exceptions cause a new AggregateException containing <br>   // only the unhandled exceptions to be thrown <br>   x.Handle(e =&gt; e is OperationCanceledException); <br> <br>   // If all the exceptions were handled, the following executes <br>   Console.WriteLine(&quot;Sum was canceled&quot;); <br>}<br>
When creating a Task, you can associate a CancellationToken with it by passing it to Task's <br>constructor (as shown above). If the CancellationToken gets canceled before the Task is <br>scheduled, the Task gets canceled and never executes at all.2 But if the Task has already <br>been scheduled (by calling the Start method), then the Task's code must explicitly support <br>
2  By the way, if you try to cancel a task before it is even started, an InvalidOperationException is thrown.<br>
<hr>
<A name=749></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>731</b><br>
cancellation if it allows its operation to be canceled while executing. Unfortunately, while a <br>Task object has a CancellationToken associated with it, there is no way to access it, so you <br>must somehow get the <i>same </i>CancellationToken that was used to create the Task object <br>into the Task's code itself. The easiest way to write this code is to use a lambda expression <br>and "pass" the CancellationToken as a closure variable (as I've done in the previous code <br>example).<br>
<b>Starting a New Task Automatically When Another Task </b><br>
<b>Completes</b><br>
In order to write scalable software, you must not have your threads block. This means that <br>calling Wait or querying a task's Result property when the task has not yet finished running <br>will most likely cause the thread pool to create a new thread, which increases resource usage <br>and hurts scalability. Fortunately, there is a better way to find out when a task has completed <br>running. When a task completes, it can start another task. Here is a rewrite of the earlier code <br>that doesn't block any threads:<br>
// Create Task, defer starting it, continue with another task <br>Task&lt;Int32&gt; t = new Task&lt;Int32&gt;(n =&gt; Sum((Int32)n), 1000000000); <br> <br>// You can start the task sometime later <br>t.Start(); <br> <br>// ContinueWith returns a Task but you usually don't care <br>Task cwt = t.ContinueWith(task =&gt; Console.WriteLine(&quot;The sum is: &quot; + task.Result));<br>
Now, when the task executing Sum completes, this task will start another task (also on some <br>thread pool thread) that displays the result. The thread that executes the code above does <br>not block waiting for either of these two tasks to complete; the thread is allowed to execute <br>other code or, if it is a thread pool thread itself, it can return to the pool to perform other <br>operations. Note that the task executing Sum could complete before ContinueWith is called. <br>This will not be a problem because the ContinueWith method will see that the Sum task is <br>complete and it will immediately start the task that displays the result.<br>
Also, note that ContinueWith returns a reference to a new Task object (which my code <br>placed in the cwt variable). Of course, you can invoke various members (like Wait,<b> </b>Result, or <br>even ContinueWith) using this Task object, but usually you will ignore this Task object and <br>will not save a reference to it in a variable.<br>
I should also mention that Task objects internally contain a collection of ContinueWith <br>tasks. So you can actually call ContinueWith several times using a single Task object. <br>When the task completes, all the ContinueWith tasks will be queued to the thread <br>pool. In addition, when calling ContinueWith, you can specify a bitwise OR'd set of <br>TaskContinuationOptions. The first four flags--None, PreferFairness, LongRunning,  <br>
<hr>
<A name=750></a><b>732 </b><br>
<b>Part V  Threading</b><br>
and AttachedToParent--are identical to the flags offered by the TaskCreationOptions <br>enumerated type shown earlier. Here is what the TaskContinuationOptions type looks like:<br>
[Flags, Serializable] <br>public enumTaskContinuationOptions { <br>   None                  = 0x0000,// The default <br> <br>   // Causes the default TaskScheduler to put the task in the thread pool's <br>   // global queue instead of a worker thread's local queue. <br>   PreferFairness        = 0x0001, <br> <br>   // Causes the default TaskScheduler to create a thread for the task instead <br>   // of queuing the task to a thread pool thread <br>   LongRunning           = 0x0002, <br> <br>   // Always honored: Associates a Task with its parent Task (discussed shortly) <br>   AttachedToParent      = 0x0004, <br> <br>   // This flag indicates that you want the thread that executed the first task to also <br>   // execute the ContinueWith task. If the first task has already completed, then the <br>   // thread calling ContinueWith will execute the ContinueWith task. <br>   ExecuteSynchronously  = 0x80000, <br> <br>   // These flags indicate under what circumstances to run the ContinueWith task <br>   NotOnRanToCompletion  = 0x10000, <br>   NotOnFaulted          = 0x20000, <br>   NotOnCanceled         = 0x40000, <br> <br>   // These flags are convenient combinations of the above three flags <br>   OnlyOnCanceled        = NotOnRanToCompletion | NotOnFaulted, <br>   OnlyOnFaulted         = NotOnRanToCompletion | NotOnCanceld, <br>   OnlyOnRanToCompletion = NotOnFaulted         | NotOnCanceled, <br>}<br>
When you call ContinueWith, you can indicate that you want the new task to execute only <br>if the first task is canceled by specifying the TaskContinuationOptions.OnlyOnCanceled <br>flag. Similarly, you have the new task execute only if the first task throws an unhandled  <br>exception using the TaskContinuationOptions.OnlyOnFaulted flag. And, of course, you <br>can use the TaskContinuationOptions.OnlyOnRanToCompletion flag to have the new task <br>execute only if the first task runs all the way to completion without being canceled or throw-<br>ing an unhandled exception. By default, if you do not specify any of these flags, then the new <br>task will run regardless of how the first task completes. When a Task completes, any of its <br>continue-with tasks that do not run are automatically canceled. Here is an example that puts <br>all of this together:<br>
Task&lt;Int32&gt; t = new Task&lt;Int32&gt;(n =&gt; Sum((Int32)n), 10000); <br> <br>// You can start the task sometime later <br>t.Start(); <br> <br>// Each ContinueWith returns a Task but you usually don't care <br>
<hr>
<A name=751></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>733</b><br>
t.ContinueWith(task =&gt; Console.WriteLine(&quot;The sum is: &quot; + task.Result), <br>   TaskContinuationOptions.OnlyOnRanToCompletion); <br> <br>t.ContinueWith(task =&gt; Console.WriteLine(&quot;Sum threw: &quot; + task.Exception),  <br>   TaskContinuationOptions.OnlyOnFaulted); <br> <br>t.ContinueWith(task =&gt; Console.WriteLine(&quot;Sum was canceled&quot;),  <br>   TaskContinuationOptions.OnlyOnCanceled);<br>
<b>A Task May Start Child Tasks</b><br>
Finally, tasks support parent/child relationships, as demonstrated by the following code:<br>
Task&lt;Int32[]&gt; parent = new Task&lt;Int32[]&gt;(() =&gt; { <br>   var results = new Int32[3];   // Create an array for the results <br> <br>   // This tasks creates and starts 3 child tasks <br>   new Task(() =&gt; results[0] = Sum(10000), TaskCreationOptions.AttachedToParent).Start(); <br>   new Task(() =&gt; results[1] = Sum(20000), TaskCreationOptions.AttachedToParent).Start(); <br>   new Task(() =&gt; results[2] = Sum(30000), TaskCreationOptions.AttachedToParent).Start(); <br> <br>   // Returns a reference to the array (even though the elements may not be initialized yet) <br>   return results;  <br>}); <br> <br>// When the parent and its children have run to completion, display the results <br>varcwt = parent.ContinueWith( <br>   parentTask =&gt; Array.ForEach(parentTask.Result, Console.WriteLine)); <br> <br>// Start the parent Task so it can start its children <br>parent.Start();<br>
Here, the parent task creates and starts three Task objects. By default, Task objects created  <br>by another task are top-level tasks that have no relationship to the task that creates them. <br>However, the TaskCreationOptions.AttachedToParent flag associates a Task with the <br>Task that creates it so that the creating task is not considered finished until all its children  <br>(and grandchildren) have finished running. When creating a Task by calling the <br>ContinueWith method, you can make the continue-with task be a child by specifying the <br>TaskContinuationOptions.AttachedToParent flag.<br>
<b>Inside a Task</b><br>
Each Task object has a set of fields that make up the task's state. There is an Int32 ID (see <br>Task's read-only Id property), an Int32 representing the execution state of the Task, a ref-<br>erence to the parent task, a reference to the TaskScheduler specified when the Task was <br>created, a reference to the callback method, a reference to the object that is to be passed <br>to the callback method (queryable via Task's read-only AsyncState property), a reference <br>to an ExecutionContext, and a reference to a ManualResetEventSlim object. In addition, <br>each Task object has a reference to some supplementary state that is created on demand. <br>
<hr>
<A name=752></a><b>734 </b><br>
<b>Part V  Threading</b><br>
The supplementary state includes a CancellationToken, a collection of ContinueWithTask <br>objects, a collection of Task objects for child tasks that have thrown unhandled exceptions, <br>and more. My point is that while tasks provide you a lot of features, there is some cost to <br>tasks because memory must be allocated for all this state. If you don't need the additional <br>features offered by tasks, then your program will use resources more efficiently if you use <br>ThreadPool.QueueUserWorkItem.<br>
The Task and Task&lt;TResult&gt; classes implement the IDisposable interface, allowing you to <br>call Dispose when you are done with the Task object. Today, all the Dispose method does <br>is close the ManualResetEventSlim object. However, it is possible to define classes derived <br>from Task and Task&lt;TResult&gt;, and these classes could allocate their own resources, which <br>would be freed in their override of the Dispose method. Of course, most developers will not <br>explicitly call Dispose on a Task object in their code; instead, they will just let the garbage <br>collector clean up any resources when it determines that they are no longer in use.<br>
You'll notice that each Task object contains an Int32 field representing a Task's unique ID. <br>When you create a Task object, the field is initialized to zero. Then the first time you query <br>Task's read-only Id property, the property assigns a unique Int32 value to this field and  <br>returns it from the property. Task IDs start at 1 and increment by 1 as each ID is assigned. <br>Just looking at a Task object in the Microsoft Visual Studio debugger wil  cause the debugger <br>to display the Task's ID, forcing the Task to be assigned an ID.<br>
The idea behind the ID is that each Task can be identified by a unique value. In fact, Visual <br>Studio shows you these task IDs in its Parallel Tasks and Parallel Stacks windows. But since <br>you don't assign the IDs yourself in your code, it is practically impossible to correlate an ID <br>number with what your code is doing. While running a task's code, you can query Task's <br>static CurrentId property, which returns a nullable Int32 (Int32?). You can also call this <br>from Visual Studio's Watch window or Immediate window while debugging to get the ID for <br>the code that you are currently stepping through. Then you can find your task in the Parallel <br>Tasks/Stacks windows. If you query the CurrentId property while a task is not executing, it <br>returns null.<br>
During a Task object's existence, you can learn where it is in its lifecycle by querying Task's <br>read-only Status property. This property returns a TaskStatus value that is defined as <br>follows:<br>
public enum TaskStatus { <br>   // These flags indicate the state of a Task during its lifetime: <br>   Created,             // Task created explicitly; you can manually Start() this task <br>   WaitingForActivation,// Task created implicitly; it starts automatically <br> <br>   WaitingToRun,  // The task was scheduled but isn't running yet <br>   Running,       // The task is actually running <br> <br>   // The task is waiting for children to complete before it considers itself complete <br>   WaitingForChildrenToComplete, <br> <br>
<hr>
<A name=753></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>735</b><br>
   // A task's final state is one of these: <br>   RanToCompletion, <br>   Canceled, <br>   Faulted <br>}<br>
When you first construct a Task object, its status is Created. Later, when the task is started, <br>its status changes to WaitingToRun. When the Task is actually running on a thread, its status <br>changes to Running. When the task stops running and is waiting for any child tasks, the  <br>status changes to WaitingForChildrenToComplete. When a task is completely finished,  <br>it enters one of three final states: RanToCompletion, Canceled, or Faulted. When a <br>Task&lt;TResult&gt; runs to completion, you can query the task's result viaTask&lt;TResult&gt;'s <br>Result property. When a Task or Task&lt;TResult&gt; faults, you can obtain the unhandled  <br>exception that the task threw by querying Task's Exception property; which always returns <br>an AggregateException object whose collection contains the set of unhandled exceptions.<br>
For convenience, Task offers several read-only, Boolean properties: IsCanceled,  <br>IsFaulted, and IsCompleted. Note that IsCompleted returns true when the Task is in  <br>the RanToCompleted, Canceled, or Faulted state. The easiest way to determine if a Task <br>completed successfully is to use code like this:<br>
if (task.Status == TaskStatus.RanToCompletion) ...<br>
A Task object is in the WaitingForActivation state if that Task is creating by calling one of <br>these functions: ContinueWith, ContinueWhenAll, ContinueWhenAny, or FromAsync.<b> </b>A Task <br>created by constructing a TaskCompletionSource&lt;TResult&gt; object is also created in the <br>WaitingForActivation state. This state means that the Task's scheduling is controlled by <br>the task infrastructure. For example, you cannot explicitly start a Task object that was  <br>created by calling ContinueWith. This Task will start automatically when its antecedent task <br>has finished executing.<br>
<b>Task Factories</b><br>
Occasionally, you might want to create a bunch of Task objects that share the same state.  <br>To keep you from having to pass the same parameters to each Task's constructor  <br>over and over again, you can create a task factory that encapsulates the common state. <br>The System.Threading.Tasks namespace defines a TaskFactory type as well as a <br>TaskFactory&lt;TResult&gt; type. Both of these types are derived from System.Object; that is, <br>they are peers of each other.<br>
If you want to create a bunch of tasks that have no return values, then you will construct <br>a TaskFactory. If you want to create a bunch of tasks that have a specific return value, <br>then you will construct a TaskFactory&lt;TResult&gt; where you pass the task's desired return <br>type for the generic TResult argument. When you create one of these task factory classes, <br>you pass to its constructor the defaults that you want the tasks that the factory creates to <br>
<hr>
<A name=754></a><b>736 </b><br>
<b>Part V  Threading</b><br>
have. Specifically, you pass to the task factory the CancellationToken, TaskScheduler, <br>TaskCreationOptions, and TaskContinuationOptions settings that you want factory-<br>created tasks to have.<br>
Here is some sample code demonstrating the use of a TaskFactory:<br>
Task parent = new Task(() =&gt; { <br>   varcts = new CancellationTokenSource(); <br>   vartf = new TaskFactory&lt;Int32&gt;(cts.Token,  <br>   TaskCreationOptions.AttachedToParent,  <br>   TaskContinuationOptions.ExecuteSynchronously,  <br>   TaskScheduler.Default); <br> <br>   // This tasks creates and starts 3 child tasks <br>   varchildTasks = new[] { <br>   tf.StartNew(() =&gt; Sum(cts.Token, 10000)), <br>   tf.StartNew(() =&gt; Sum(cts.Token, 20000)), <br>   tf.StartNew(() =&gt; Sum(cts.Token, Int32.MaxValue))  // Too big, throws OverflowException <br>   }; <br> <br>   // If any of the child tasks throw, cancel the rest of them <br>   for (Int32 task = 0; task &lt;childTasks.Length; task++) <br>      childTasks[task].ContinueWith( <br>         t =&gt; cts.Cancel(), TaskContinuationOptions.OnlyOnFaulted); <br> <br>   // When all children are done, get the maximum value returned from the  <br>   // non-faulting/canceled tasks. Then pass the maximum value to another  <br>   // task which displays the maximum result <br>   tf.ContinueWhenAll( <br>      childTasks,  <br>      completedTasks =&gt; completedTasks.Where( <br>         t =&gt; !t.IsFaulted &amp;&amp; !t.IsCanceled).Max(t =&gt; t.Result), <br>      CancellationToken.None) <br>      .ContinueWith(t =&gt;Console.WriteLine(&quot;The maximum is: &quot; + t.Result), <br>         TaskContinuationOptions.ExecuteSynchronously); <br>}); <br>
// When the children are done, show any unhandled exceptions too <br>parent.ContinueWith(p =&gt; { <br>   // I put all this text in a StringBuilder and call Console.WriteLine just once  <br>   // because this task could execute concurrently with the task above &amp; I don't  <br>   // want the tasks' output interspersed <br>   StringBuildersb = new StringBuilder( <br>      &quot;The following exception(s) occurred:&quot; + Environment.NewLine); <br> <br>   foreach (var e in p.Exception.Flatten().InnerExceptions)  <br>      sb.AppendLine(&quot;   &quot;+ e.GetType().ToString()); <br>   Console.WriteLine(sb.ToString()); <br>}, TaskContinuationOptions.OnlyOnFaulted);<br>
// Start the parent Task so it can start its children <br>parent.Start();<br>
<hr>
<A name=755></a><IMG src="CLRviaCsharp-755_1.jpg"><br>
<b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>737</b><br>
With this code, I am creating a TaskFactory&lt;Int32&gt; object that I will use to create  <br>three Task objects. I want four things: for each Task object to share the same <br>CancellationTokenSource token, for all three tasks to be considered children of their par-<br>ent, for all continue-with tasks created by the TaskFactory object to execute synchronously, <br>and for all the Task objects created by this TaskFactory to use the default TaskScheduler.<br>
Then I create an array consisting of the three child Task objects, all created by calling <br>TaskFactory's StartNew method. This method conveniently creates and starts each child <br>task. In a loop, I tell each child task that throws an unhandled exception to cancel all the  <br>other child tasks that are still running. Finally, using the TaskFactory, I call <br>ContinueWhenAll, which creates a Task that runs when all the child tasks have completed <br>running. Since this task is created with the TaskFactory, it will also be considered a child <br>of the parent task and it will execute synchronously using the default TaskScheduler. <br>However, I want this task to run even if the other child tasks were canceled, so I override <br>the TaskFactory's CancellationToken by passing in CancellationToken.None, which <br>prevents this task from being cancelable at all. Finally, when the task that processes all the <br>results is complete, I create another task that displays the highest value returned from all the <br>child tasks.<br>
<b>Note  </b>When calling TaskFactory's or TaskFactory&lt;TResult&gt;'s static ContinueWhenAll <br>and ContinueWhenAny methods, the following TaskContinuationOption flags are illegal: <br>NotOnRanToCompletion, NotOnFaulted, and NotOnCanceled. And of course, the convenience <br>flags (OnlyOnCanceled, OnlyOnFaulted, and OnlyOnRanToCompletion) are also illegal. That <br>is, ContinueWhenAll and ContinueWhenAny execute the continue-with task regardless of how <br>the antecedent tasks complete.<br>
<b>Task Schedulers</b><br>
The task infrastructure is very flexible, and TaskScheduler objects are a big part of this flex-<br>ibility. A TaskScheduler object is responsible for executing scheduled tasks and also exposes <br>task information to the Visual Studio debugger. The FCL ships with two TaskScheduler-<br>derived types: the thread pool task scheduler and a synchronization context task scheduler. <br>By default, all applications use the thread pool task scheduler. This task scheduler schedules <br>tasks to the thread pool's worker threads and is discussed in more detail in this chapter's <br>"How the Thread Pool Manages Its Threads" section. You can get a reference to the default <br>task scheduler by querying TaskScheduler's static Default property.<br>
The synchronization context task scheduler is typically used for Windows Forms, Windows <br>Presentation Foundation (WPF), and Silverlight applications. This task scheduler schedules all <br>tasks onto the application's GUI thread so that all the task code can successfully update UI <br>components like buttons, menu items, and so on. The synchronization context task scheduler <br>does not use the thread pool at all. You can get a reference to a synchronization context <br>
<hr>
<A name=756></a><b>738 </b><br>
<b>Part V  Threading</b><br>
task scheduler by querying TaskScheduler's static FromCurrentSynchronizationContext <br>method.<br>
Here is a simple Windows Forms application that demonstrates the use of the synchronization <br>context task scheduler:<br>
internalsealed class MyForm : Form { <br>   public MyForm() { <br>      Text = &quot;Synchronization Context Task Scheduler Demo&quot;; <br>      Visible = true; Width = 400; Height = 100; <br>   } <br> <br>   // Get a reference to a synchronization context task scheduler <br>   private readonly TaskScheduler m_syncContextTaskScheduler = <br>      TaskScheduler.FromCurrentSynchronizationContext(); <br> <br>   private CancellationTokenSource m_cts; <br> <br>   protected override void OnMouseClick(MouseEventArgs e) { <br>      if (m_cts != null) { // An operation is in flight, cancel it <br>         m_cts.Cancel(); <br>         m_cts = null; <br>      } else { // An operation is not in flight, start it <br>         Text = &quot;Operation running&quot;; <br>         m_cts = new CancellationTokenSource(); <br> <br>         // This task uses the default task scheduler and executes on a thread pool thread <br>         var t = new Task&lt;Int32&gt;(() =&gt; Sum(m_cts.Token, 20000), m_cts.Token); <br>         t.Start(); <br> <br>         // These tasks use the sync context task scheduler and execute on the GUI thread <br>         t.ContinueWith(task =&gt; Text = &quot;Result: &quot; + task.Result,  <br>            CancellationToken.None, TaskContinuationOptions.OnlyOnRanToCompletion, <br>            m_syncContextTaskScheduler); <br> <br>         t.ContinueWith(task =&gt; Text = &quot;Operation canceled&quot;,  <br>            CancellationToken.None, TaskContinuationOptions.OnlyOnCanceled, <br>            m_syncContextTaskScheduler); <br> <br>         t.ContinueWith(task =&gt; Text = &quot;Operation faulted&quot;, <br>            CancellationToken.None, TaskContinuationOptions.OnlyOnFaulted, <br>            m_syncContextTaskScheduler); <br>      } <br>      base.OnMouseClick(e); <br>   } <br>}<br>
When you click in the client area of this form, a compute-bound task will start executing  <br>on a thread pool thread. This is good because the GUI thread is not blocked during this <br>time and can therefore respond to other UI operations. However, the code executed <br>by the thread pool thread should not attempt to update UI components or else an <br>InvalidOperationException will be thrown.<br>
<hr>
<A name=757></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>739</b><br>
When the compute-bound task is done, one of the three continue-with tasks will execute. <br>These tasks are all issued against the synchronization context task scheduler corresponding <br>to the GUI thread, and this task scheduler queues the tasks to the GUI thread, allowing the <br>code executed by these tasks to update UI components successfully. All of these tasks update <br>the form's caption via the inherited Text property.<br>
Since the compute-bound work (Sum) is running on a thread pool thread, the user can inter-<br>act with the UI to cancel the operation. In my simple code example, I allow the user to cancel <br>the operation by clicking in the form's client area while an operation is running.<br>
You can, of course, define your own class derived from TaskScheduler if you have special <br>task scheduling needs. Microsoft has provided a bunch of sample code for tasks and includes <br>the source code for a bunch of task schedulers in the Parallel Extensions Extras package, <br>which can be downloaded from here: <i>http://code.msdn.microsoft.com/ParExtSamples</i>. Here <br>are some of the task schedulers included in this package:<br>
  IOTaskScheduler<b>  </b>This task scheduler queues tasks to the thread pool's I/O threads <br>
instead of its worker threads.<br>
  LimitedConcurrencyLevelTaskScheduler<b>  </b>This task scheduler allows no more than <br>
<i>n </i>(a constructor parameter) tasks to execute simultaneously.<br>
  OrderedTaskScheduler<b>  </b>This task scheduler allows only one task to execute at a time. <br>
This class is derived from LimitedConcurrencyLevelTaskScheduler and just passes 1 <br>for <i>n</i>.<br>
  PrioritizingTaskScheduler<b>  </b>This task scheduler queues tasks to the CLR's thread <br>
pool. After this has occurred, you can call Prioritize to indicate that a Task should <br>be processed before all normal tasks (if it hasn't been processed already). You can call <br>Deprioritize to make a Task be processed after all normal tasks.<br>
  ThreadPerTaskScheduler<b>  </b>This task scheduler creates and starts a separate thread <br>
for each task; it does not use the thread pool at all.<br>
Parallel<b>'s Static </b>For<b>, </b>ForEach<b>, and </b>Invoke<b> Methods</b><br>
There are some common programming scenarios that can potentially benefit from the <br>improved performance possible with tasks. To simplify programming, the static System.<br>Threading.Tasks.Parallel class encapsulates these common scenarios while using Task <br>objects internally. For example, instead of processing all the items in a collection like this:<br>
// One thread performs all this work sequentially <br>for (Int32 i = 0; i &lt; 1000; i++) DoWork(i);<br>
you can instead get multiple thread pool threads to assist in performing this work by using <br>the Parallel class's For method:<br>
<hr>
<A name=758></a><b>740 </b><br>
<b>Part V  Threading</b><br>
// The thread pool's threads process the work in parallel <br>Parallel.For(0, 1000, i =&gt; DoWork(i));<br>
Similarly, if you have a collection, instead of doing this:<br>
// One thread performs all this work sequentially <br>foreach (var item in collection) DoWork(item);<br>
you can do this:<br>
// The thread pool's threads process the work in parallel <br>Parallel.ForEach(collection, item =&gt; DoWork(item));<br>
If you can use either For or ForEach in your code, then it is recommended that you use For <br>because it executes faster.<br>
And finally, if you have several methods that you need to execute, you could execute them all <br>sequentially, like this:<br>
// One thread executes all the methods sequentially <br>Method1(); <br>Method2(); <br>Method3();<br>
or you could execute them in parallel, like this:<br>
// The thread pool's threads execute the methods in parallel <br>Parallel.Invoke( <br>   () =&gt; Method1(),  <br>   () =&gt; Method2(),  <br>   () =&gt; Method3());<br>
All of Parallel's methods have the calling thread participate in the processing of the work, <br>which is good in terms of resource usage because we wouldn't want the calling thread to just <br>suspend itself while waiting for thread pool threads to do all the work. However, if the calling  <br>thread finishes its work before the thread pool threads complete their part of the work, <br>then the call thread will suspend itself until all the work is done, which is also good because <br>this gives you the same semantics as you'd have when using a for or foreach loop: The <br>thread doesn't continue running until all the work is done. Also note that if any operation <br>throws an unhandled exception, the Parallel method you called will ultimately throw an <br>AggregateException.<br>
Of course, you should not go through all your source code replacing for loops with calls <br>to Parallel.For and foreach loops with calls to Parallel.ForEach<b>.</b> When calling the <br>Parallel method, there is an assumption that it is OK for the work items to be performed <br>concurrently. Therefore, do not use the Parallel methods if the work must be processed <br>in sequential order. Also, avoid work items that modify any kind of shared data because the <br>
<hr>
<A name=759></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>741</b><br>
data could get corrupted if it is manipulated by multiple threads simultaneously. Normally, <br>you would fix this by adding thread synchronization locks around the data access, but if you <br>do this, then one thread at a time can access the data and you would lose the benefit of  <br>processing multiple items in parallel.<br>
In addition, there is overhead associated with the Parallel methods; delegate objects have <br>to be allocated, and these delegates are invoked once for each work item. If you have lots of <br>work items that can be processed by multiple threads, then you might gain a performance <br>increase. Also, if you have lots of work to do for each item, then the performance hit of call-<br>ing through the delegate is negligible. You will actually hurt your performance if you use <br>the Parallel methods for just a few work items or for work items that are processed very <br>quickly.<br>
I should mention that Parallel's For, ForEach, and Invoke methods all have overloads that <br>accept a ParallelOptions object, which looks like this:<br>
public class ParallelOptions{ <br>   public ParallelOptions(); <br> <br>   // Allows cancellation of the operation <br>   public CancellationTokenCancellationToken { get; set; } // Default=CancellationToken.None <br> <br>   // Allows you to specify the maximum number of work items  <br>   // that can be operated on concurrently <br>   public Int32MaxDegreeOfParallelism { get; set; }     // Default=-1 (# of available CPUs) <br> <br>   // Allows you to specify which TaskScheduler to use <br>   public TaskSchedulerTaskScheduler { get; set; }     // Default=TaskScheduler.Default <br>}<br>
In addition, there are overloads of the For and ForEach methods that let you pass three <br>delegates:<br>
  The task local initialization delegate (localInit) is invoked once for each task partici-<br>
pating in the work. This delegate is invoked before the task is asked to process a work <br>item.<br>
  The body delegate (body<i>) </i>is invoked once for each item being processed by the various <br>
threads participating in the work.<br>
  The task local finally delegate (localFinally) is invoked once for each task participat-<br>
ing in the work. This delegate is invoked after the task has processed all the work items <br>that will be dispatched to it. It is even invoked if the body delegate code experiences an <br>unhandled exception.<br>
Here is some sample code that demonstrates the use of the three delegates by adding up the <br>bytes for all files contained within a directory:<br>
<hr>
<A name=760></a><b>742 </b><br>
<b>Part V  Threading</b><br>
private static Int64 DirectoryBytes(String path, String searchPattern,  <br>   SearchOptionsearchOption) { <br>   var files = Directory.EnumerateFiles(path, searchPattern, searchOption); <br>   Int64 masterTotal = 0; <br> <br>   ParallelLoopResult result = Parallel.ForEach&lt;String, Int64&gt;( <br>      files, <br> <br>      () =&gt; { // localInit: Invoked once per task at start <br>         // Initialize that this task has seen 0 bytes <br>         return 0;   // Set taskLocalTotal initial value to 0 <br>      }, <br> <br>      (file, loopState, index, taskLocalTotal) =&gt; { // body: Invoked once per work item <br>         // Get this file's size and add it to this task's running total <br>         Int64 fileLength = 0; <br>         FileStreamfs = null; <br>         try { <br>            fs = File.OpenRead(file); <br>            fileLength = fs.Length; <br>         }  <br>         catch (IOException) { /* Ignore any files we can't access */ } <br>         finally { if (fs != null) fs.Dispose(); } <br>         return taskLocalTotal + fileLength; <br>      }, <br> <br>      taskLocalTotal =&gt; { // localFinally: Invoked once per task at end <br>         // Atomically add this task's total to the &quot;master&quot; total <br>         Interlocked.Add(ref masterTotal, taskLocalTotal); <br>      }); <br> <br>   return masterTotal; <br>}<br>
Each task maintains its own running total (in the taskLocalTotal variable) for the files <br>that it is given. As each task completes its work, the master total is updated in a thread-safe <br>way by calling the Interlocked.Add method (discussed in Chapter 28, "Primitive Thread <br>Synchronization Constructs"). Since each task has its own running total, no thread synchroni-<br>zation is required during the processing of the item. Since thread synchronization would hurt <br>performance, not requiring thread synchronization is good. It's only after each task returns <br>that masterTotal has to be updated in a thread-safe way, so the performance hit of calling <br>Interlocked.Add occurs only once per task instead of once per work item.<br>
You'll notice that the body delegate is passed a ParallelLoopState object, which looks like <br>this:<br>
public class ParallelLoopState{ <br>   public void Stop(); <br>   public BooleanIsStopped { get; } <br> <br>   public void Break(); <br>   public Int64? LowestBreakIteration{ get; } <br> <br>
<hr>
<A name=761></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>743</b><br>
   public BooleanIsExceptional { get; } <br>   public BooleanShouldExitCurrentIteration { get; } <br>}<br>
Each task participating in the work gets its own ParallelLoopState object, and it can use <br>this object to interact with the other task participating in the work. The Stop method tells the <br>loop to stop processing any more work, and future querying of the IsStopped property will <br>return true. The Break method tells the loop to stop processing any items that are beyond <br>the current item. For example, let's say that ForEach is told to process 100 items and Break <br>is called while processing the fifth item, then the loop will make sure that the first five items <br>are processed before ForEach returns. Note, however, that additional items may have been <br>processed. The LowestBreakIteration property returns the lowest item number whose <br>processing called the Break method. The LowestBreakIteration property returns null if <br>Break was never called.<br>
The IsException property returns true if the processing of any item resulted in an un-<br>handled exception. If the processing of an item takes a long time, your code can query the <br>ShouldExitCurrentIteration property to see if it should exit prematurely. This property <br>returns true if Stop was called, Break was called, the CancellationTokenSource (referred <br>to by the ParallelOption's CancellationToken property) is canceled, or if the processing <br>of an item resulted in an unhandled exception.<br>
Parallel's For and ForEach methods both return a ParallelLoopResult instance, which <br>looks like this:<br>
publicstructParallelLoopResult{ <br>   // Returns false if the operation was ended prematurely <br>   public Boolean IsCompleted { get; } <br>   public Int64? LowestBreakIteration{ get; } <br>}<br>
You can examine the properties to determine the result of the loop. If IsCompleted returns <br>true, then the loop ran to completion and all the items were processed. If IsCompleted <br>is false and LowestBreakIteration is null, then some thread participating in the work <br>called the Stop method. If IsCompleted is false and LowestBreakIteration is not null, <br>then some thread participating in the work called the Break method and the Int64 value <br>returned from LowestBreakIteration indicates the index of the lowest item guaranteed to <br>have been processed.<br>
<b>Parallel Language Integrated Query</b><br>
Microsoft's Language Integrated Query (LINQ) feature offers a convenient syntax for per-<br>forming queries over collections of data. Using LINQ, you can easily filter items, sort items, <br>return a projected set of items, and much more. When you use LINQ to Objects, only one <br>thread processes all the items in your data collection sequentially; we call this a <i>sequential </i><br>
<hr>
<A name=762></a><b>744 </b><br>
<b>Part V  Threading</b><br>
<i>query</i>. You can potentially improve the performance of this processing by using Parallel <br>LINQ, which can turn your sequential query into a <i>parallel query, </i>which internally uses tasks <br>(queued to the default TaskScheduler) to spread the processing of the collection's items <br>across multiple CPUs so that multiple items are processed concurrently. Like Parallel's <br>methods, you will get the most benefit from Parallel LINQ if you have many items to process <br>or if the processing of each item is a lengthy compute-bound operation.<br>
The static System.Linq.ParallelEnumerable class (defined in System.Core.dll) implements <br>all of the Parallel LINQ functionality, and so you must import the System.Linq namespace <br>into your source code via C#'s using directive. In particular, this class exposes parallel ver-<br>sions of all the standard LINQ operators such as Where, Select, SelectMany, GroupBy, Join, <br>OrderBy, Skip, Take, and so on. All of these methods are extension methods that extend <br>the System.Linq.ParallelQuery&lt;T&gt; type. To have your LINQ to Objects query invoke <br>the parallel versions of these methods, you must convert your sequential query (based <br>on IEnumerable or IEnumerable&lt;T&gt;) to a parallel query (based on ParallelQuery or <br>ParallelQuery&lt;T&gt;) using ParallelEnumerable's AsParallel extension method, which <br>looks like this3:<br>
public static ParallelQuery&lt;TSource&gt;AsParallel&lt;TSource&gt;(this IEnumerable&lt;TSource&gt; source) <br>public static ParallelQueryAsParallel(this IEnumerablesource)<br>
Here is an example of a sequential query that has been converted to a parallel query. This <br>query returns all the obsolete methods defined within an assembly:<br>
private static void ObsoleteMethods(Assembly assembly) { <br>var query = <br>      from type in assembly.GetExportedTypes().AsParallel() <br> <br>      from method in type.GetMethods(BindingFlags.Public |  <br>         BindingFlags.Instance | BindingFlags.Static) <br> <br>      let obsoleteAttrType = typeof(ObsoleteAttribute) <br> <br>      where Attribute.IsDefined(method, obsoleteAttrType) <br> <br>      orderbytype.FullName <br> <br>      let obsoleteAttrObj = (ObsoleteAttribute)  <br>         Attribute.GetCustomAttribute(method, obsoleteAttrType) <br> <br>         select String.Format(&quot;Type={0}\nMethod={1}\nMessage={2}\n&quot;, <br>            type.FullName, method.ToString(), obsoleteAttrObj.Message); <br> <br>   // Display the results <br>   foreach (var result in query) Console.WriteLine(result); <br>}<br>
3  The ParallelQuery&lt;T&gt; class is derived from the ParallelQuery class.<br>
<hr>
<A name=763></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>745</b><br>
While uncommon, within a query you can switch from performing parallel operations back to <br>performing sequential operations by calling ParallelEnumerable's AsSequential method:<br>
public static IEnumerable&lt;TSource&gt; AsSequential&lt;TSource&gt;(this ParallelQuery&lt;TSource&gt; source)<br>
This method basically turns a ParallelQuery&lt;T&gt; back to an IEnumerable&lt;T&gt; so that opera-<br>tions performed after calling AsSequential are performed by just one thread.<br>
Normally, the resulting data produced by a LINQ query is evaluated by having some thread <br>execute a foreach statement (as shown earlier). This means that just one thread iterates over <br>all the query's results. If you want to have the query's results processed in parallel, then you <br>should process the resulting query by using ParallelEnumerable's ForAll method:<br>
static void ForAll&lt;TSource&gt;(this ParallelQuery&lt;TSource&gt; source, Action&lt;TSource&gt; action)<br>
This method allows multiple threads to process the results simultaneously. I could modify my <br>code earlier to use this method as follows:<br>
// Display the results <br>query.ForAll(Console.WriteLine);<br>
However, having multiple threads call Console.WriteLine simultaneously actually hurts <br>performance since the Console class internally synchronizes threads, ensuring that only one <br>at a time can access the console window. This prevents text from multiple threads from being <br>interspersed, making the output unintelligible. Use the ForAll method when you intend to <br>perform calculations on each result.<br>
Since Parallel LINQ processes items using multiple threads, the items are processed concur-<br>rently and the results are returned in an unordered fashion. If you need to have Parallel LINQ <br>preserve the order of items as they are processed, then you can call ParallelEnumerable's <br>AsOrdered method. When you call this method, threads will process items in groups and <br>then the groups are merged back together, preserving the order; this will hurt performance. <br>The following operators produce unordered operations: Distinct, Except, Intersect, <br>Union, Join, GroupBy, GroupJoin, and ToLookup. If you wish to enforce ordering again after <br>one of these operators, just call the AsOrdered method.<br>
The following operators produce ordered operations: OrderBy, OrderByDescending, ThenBy, <br>and ThenByDescending. If you wish to go back to unordered processing again to improve <br>performance after one of these operators, just call the AsUnordered method.<br>
Parallel LINQ offers some additional ParallelEnumerable methods that you can call to  <br>control how the query is processed:<br>
<hr>
<A name=764></a><b>746 </b><br>
<b>Part V  Threading</b><br>
public static ParallelQuery&lt;TSource&gt; WithCancellation&lt;TSource&gt;( <br>   this ParallelQuery&lt;TSource&gt; source, CancellationTokencancellationToken) <br> <br>public static ParallelQuery&lt;TSource&gt; WithDegreeOfParallelism&lt;TSource&gt;( <br>   this ParallelQuery&lt;TSource&gt; source, Int32degreeOfParallelism) <br> <br>public static ParallelQuery&lt;TSource&gt; WithExecutionMode&lt;TSource&gt;( <br>   this ParallelQuery&lt;TSource&gt; source, ParallelExecutionModeexecutionMode) <br> <br>public static ParallelQuery&lt;TSource&gt; WithMergeOptions&lt;TSource&gt;( <br>   this ParallelQuery&lt;TSource&gt; source, ParallelMergeOptionsmergeOptions)<br>
Obviously, the WithCancellation method allows you to pass a CancellationToken so that <br>the query processing can be stopped prematurely. The WithDegreeOfParallelism method <br>specifies the maximum number of threads allowed to process the query; it does not force the <br>threads to be created if not all of them are necessary. Usually you will not call this method, <br>and, by default, the query will execute using one thread per core. However, you could call <br>WIthDegreeOfParallelism, passing a number that is smaller than the number of available <br>cores if you want to keep some cores available for doing other work. You could also pass a <br>number that is greater than the number of cores if the query performs synchronous I/O  <br>operations because threads will be blocking during these operations. This wastes more <br>threads but can produce the final result in less time. You might consider doing this in a client <br>application, but I'd highly recommend against performing synchronous I/O operations in a <br>server application.<br>
Parallel LINQ analyzes a query and then decides how to best process it. Sometimes process-<br>ing a query sequentially yields better performance. This is usually true when using any of <br>these operations: Concat, ElementAt(OrDefault), First(OrDefault), Last(OrDefault), <br>Skip(While), Take(While), or Zip. It is also true when using overloads of Select(Many) or <br>Where that pass a position index into your selector or predicate delegate. However, you <br>can force a query to be processed in parallel by calling WithExecutionMode, passing it one <br>of the ParallelExecutionMode flags:<br>
public enum ParallelExecutionMode { <br>   Default = 0,         // Let Parallel LINQ decide to best process the query <br>   ForceParallelism = 1 // Force the query to be processed in parallel <br>}<br>
As mentioned before, Parallel LINQ has multiple threads processing items, and then the <br>results must be merged back together. You can control how the items are buffered and <br>merged by calling WithMergeOptions, passing it one of the ParallelMergeOptions flags:<br>
public enum ParallelMergeOptions { <br>   Default       = 0,    // Same as AutoBuffered today (could change in the future) <br>   NotBuffered   = 1,    // Results are processed as ready <br>   AutoBuffered  = 2,    // Each thread buffers some results before processed <br>   FullyBuffered = 3     // Each thread buffers all results before processed <br>}<br>
<hr>
<A name=765></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>747</b><br>
These options basically give you some control over speed versus memory consumption. <br>NotBuffered saves memory but processes items slower. FullyBuffered consumes more <br>memory while running fastest. AutoBuffered is the compromise in between NotBuffered <br>and FullyBuffered. Really, the best way to know which of these to pick for any given query <br>is to try them all and compare their performance results, or just accept the default, which <br>tends to work pretty well for many queries. See the following blog posts for more informa-<br>tion about how Parallel LINQ partitions work across CPU cores:<br>
  <i>http://blogs.msdn.com/pfxteam/archive/2009/05/28/9648672.aspx</i><br>
  <i>http://blogs.msdn.com/pfxteam/archive/2009/06/13/9741072.aspx</i><br>
<b>Performing a Periodic Compute-Bound Operation</b><br>
The System.Threading namespace defines a Timer class, which you can use to have a <br>thread pool thread call a method periodically. When you construct an instance of the Timer <br>class, you are telling the thread pool that you want a method of yours called back at a future <br>time that you specify. The Timer class offers several constructors, all quite similar to each <br>other:<br>
public sealed class Timer : MarshalByRefObject, IDisposable {  <br>   public Timer(TimerCallback callback, Object state, Int32    dueTime, Int32    period);    <br>   public Timer(TimerCallback callback, Object state, UInt32   dueTime, UInt32   period);  <br>   public Timer(TimerCallback callback, Object state, Int64    dueTime, Int64    period);   <br>   public Timer(TimerCallback callback, Object state, Timespan dueTime, TimeSpan period);  <br>}<br>
All four constructors construct a Timer object identically. The callback parameter identi-<br>fies the method that you want called back by a thread pool thread. Of course, the callback <br>method that you write must match the System.Threading.TimerCallback delegate type, <br>which is defined as follows:<br>
delegate void TimerCallback(Object state);<br>
The constructor's state parameter allows you to pass state data to the callback method  <br>each time it is invoked; you can pass null if you have no state data to pass. You use the  <br>dueTime parameter to tell the CLR how many milliseconds to wait before calling your call-<br>back method for the very first time. You can specify the number of milliseconds by using a <br>signed or unsigned 32-bit value, a signed 64-bit value, or a TimeSpan value. If you want the <br>callback method called immediately, specify 0 for the dueTime parameter. The last parameter, <br>period, allows you to specify how long, in milliseconds, to wait before each successive call <br>to the callback method. If you pass Timeout.Infinite (-1) for this parameter, a thread pool <br>thread will call the callback method just once.<br>
<hr>
<A name=766></a><IMG src="CLRviaCsharp-766_1.jpg"><br>
<b>748 </b><br>
<b>Part V  Threading</b><br>
Internally, the thread pool has just one thread that it uses for all Timer objects. This thread <br>knows when the next Timer object's time is due. When the next Timer object is due, the <br>thread wakes up, and internally calls ThreadPool's QueueUserWorkItem to enter an entry <br>into the thread pool's queue, causing your callback method to get called. If your callback <br>method takes a long time to execute, the timer could go off again. This could cause multiple <br>thread pool threads to be executing your callback method simultaneously. To work around <br>this problem, I recommend the following: Construct the Timer specifying Timeout.Infinite <br>for the period parameter. Now, the timer will fire only once. Then, in your callback method, <br>call the Change method specifying a new due time and again specify Timeout.Infinite for <br>the period parameter. Here is what the Change method overloads look like:<br>
public sealed class Timer : MarshalByRefObject, IDisposable {  <br>   public Boolean Change(Int32    dueTime, Int32    period);  <br>   public Boolean Change(UInt32   dueTime, UInt32   period);  <br>   public Boolean Change(Int64    dueTime, Int64    period);  <br>   public Boolean Change(TimeSpan dueTime, TimeSpan period);   <br>}<br>
The Timer class also offers a Dispose method which allows you to cancel the timer altogether <br>and optionally signal the kernel object identified by the notifyObject parameter when all <br>pending callbacks for the time have completed. Here is what the Dispose method overloads <br>look like:<br>
public sealed class Timer : MarshalByRefObject, IDisposable {  <br>   public Boolean Dispose();  <br>   public Boolean Dispose(WaitHandle notifyObject);   <br>}<br>
<b>Important  </b>When a Timer object is garbage collected, its finalization code tells the thread pool <br>to cancel the timer so that it no longer goes off. So when using a Timer object, make sure that a <br>variable is keeping the Timer object alive or else your callback method will stop getting called. <br>This is discussed and demonstrated in the "Garbage Collections and Debugging" section in <br>Chapter 21, "Automatic Memory Management (Garbage Collection)."<br>
The following code demonstrates how to have a thread pool thread call a method starting <br>immediately and then every 2 seconds thereafter:<br>
internal static class TimerDemo { <br>   private static Timer s_timer; <br> <br>   public static void Go() { <br>      Console.WriteLine(&quot;Main thread: starting a timer&quot;); <br>      using (s_timer = new Timer(ComputeBoundOp, 5, 0, Timeout.Infinite)) { <br>         Console.WriteLine(&quot;Main thread: Doing other work here...&quot;); <br>         Thread.Sleep(10000);  // Simulating other work (10 seconds) <br>      } // Calls Dispose to cancel the timer now <br>   } <br> <br>
<hr>
<A name=767></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>749</b><br>
   // This method's signature must match the TimerCallback delegate <br>   private static void ComputeBoundOp(Object state) { <br>      // This method is executed by a thread pool thread <br>      Console.WriteLine(&quot;In ComputeBoundOp: state={0}&quot;, state); <br>      Thread.Sleep(1000);  // Simulates other work (1 second) <br> <br>      // Have the Timer call this method again in 2 seconds <br>      s_timer.Change(2000, Timeout.Infinite); <br> <br>      // When this method returns, the thread goes back <br>      // to the pool and waits for another work item <br>   } <br>}<br>
<b>So Many Timers, So Little Time</b><br>
Unfortunately, the FCL actually ships with several timers, and it is not clear to most program-<br>mers what makes each timer unique. Let me attempt to explain:<br>
  System.Threading<b>'s </b>Timer <b>class  </b>This is the timer discussed in the previous section, <br>
and it is the best timer to use when you want to perform periodic background tasks on <br>a thread pool thread.<br>
  System.Windows.Forms<b>'s </b>Timer <b>class  </b>Constructing an instance of this class tells <br>
Windows to associate a timer with the calling thread (see the Win32 SetTimer  <br>function). When this timer goes off, Windows injects a timer message (WM_TIMER) into <br>the thread's message queue. The thread must execute a message pump that extracts <br>these messages and dispatches them to the desired callback method. Notice that all of <br>the work is done by just one thread--the thread that sets the timer is guaranteed to be <br>the thread that executes the callback method. This also means that your timer method <br>will not be executed by multiple threads concurrently.<br>
  System.Windows.Threading<b>'s </b>DispatcherTimer<b> class  </b>This class is the  equivalent of <br>
the System.Windows.Forms's Timer class for Silverlight and WPF applications<i>.</i><br>
  System.Timers<b>'s </b>Timer<b> class  </b>This timer is basically a wrapper around System.<br>
Threading's Timer class that causes the CLR to queue events into the thread pool <br>when the timer comes due. The System.Timers.Timer class is derived from System.<br>ComponentModel's Component class, which allows these timer objects to be placed on <br>a design surface in Visual Studio. Also, it exposes properties and events, allowing it to <br>be used more easily from Visual Studio's designer. This class was added to the FCL years <br>ago while Microsoft was still sorting out the threading and timer stuff. This class  <br>probably should have been removed so that everyone would be using the System.<br>Threading.Timer class instead. In fact, I never use the System.Timers.Timer class, <br>and I'd discourage you from using it, too, unless you really want a timer on a design <br>surface.<br>
<hr>
<A name=768></a><b>750 </b><br>
<b>Part V  Threading</b><br>
<b>How the Thread Pool Manages Its Threads</b><br>
Now I'd like to talk about how the thread pool code manages worker and I/O threads. <br>However, I don't want to go into a lot of detail because the internal implementation has <br>changed greatly over the years with each version of the CLR, and it will continue changing <br>with future versions. It is best to think of the thread pool as a black box. The black box is not <br>perfect for any one application, as it is a general-purpose thread scheduling technology  <br>designed to work with a large myriad of applications; it will work better for some applications <br>than for others. It works very well today, and I highly recommend that you trust it because <br>it would be very hard for you to produce a thread pool that works better than the one ship-<br>ping in the CLR. And, over time, most applications should improve as the thread pool code <br>internally changes how it manages threads.<br>
<b>Setting Thread Pool Limits</b><br>
The CLR allows developers to set a maximum number of threads that the thread pool will <br>create. However, it turns out that thread pools should never place an upper limit on the <br>number of threads in the pool because starvation or deadlock might occur. Imagine queuing <br>1,000 work items that all block on an event that is signaled by the 1,001st item. If you've set <br>a maximum of 1,000 threads, the 1,001st work item won't be executed, and all 1,000 threads <br>will be blocked forever, forcing end users to terminate the application and lose all their work. <br>Also, it is very unusual for developers to artificially limit the resources that they have available <br>to their application. For example, would you ever start your application and tell the system <br>you'd like to restrict the amount of memory that the application can use or limit the amount <br>of network bandwidth that your application can use? Yet, for some reason, developers feel <br>compelled to limit the number of threads that the thread pool can have.<br>
Because customers have had starvation and deadlock issues, the CLR team has steadily  <br>increased the default maximum number of threads that the thread pool can have. The  <br>default maximum is now about 1,000 threads, which is effectively limitless since a 32-bit  <br>process has at most 2 GB of usable address space within it. After a bunch of Win32 DLLs load, <br>the CLR DLLs load, the native heap and the managed heap is allocated, there is approximate-<br>ly 1.5 GB of address space left over. Since each thread requires more than 1 MB of memory <br>for its user-mode stack and thread environment block (TEB), the most threads you can get in <br>a 32-bit process is about 1,360. Attempting to create more threads than this will result in an <br>OutOfMemoryException being thrown. Of course, a 64-bit process offers 8 terabytes of  <br>address space, so you could theoretically create hundreds of thousands of threads. But  <br>allocating anywhere near this number of threads is really just a waste of resources, especially <br>when the ideal number of threads to have is equal to the number of CPUs in the machine. <br>What the CLR team should do is remove the limits entirely, but they can't do this now  <br>because doing so might break some applications that expect thread pool limits to exist.<br>
<hr>
<A name=769></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>751</b><br>
The System.Threading.ThreadPool class offers several static methods that you can call <br>to manipulate the number of threads in the thread pool: GetMaxThreads, SetMaxThreads, <br>GetMinThreads, SetMinThreads, and GetAvailableThreads. I highly recommend that you <br>do not call any of these methods. Playing with thread pool limits usually results in making an <br>application perform worse, not better. If you think that your application needs hundreds or <br>thousands of threads, there is something seriously wrong with the architecture of your  <br>application and the way that it's using threads. This chapter and Chapter 27 demonstrate the <br>proper way to use threads.<br>
<b>How Worker Threads Are Managed</b><br>
Figure 26-1 shows the various data structures that make up the worker threads part of the <br>thread pool. The ThreadPool.QueueUserWorkItem method and the Timer class always <br>queue work items to the global queue. Worker threads pull items from this queue using a <br>first-in-first-out (FIFO) algorithm and process them. Since multiple worker threads can be  <br>removing items from the global queue simultaneously, all worker threads contend on a <br>thread synchronization lock to ensure that two or more threads don't take the same work <br>item. This thread synchronization lock can become a bottleneck in some applications, thereby <br>limiting scalability and performance to some degree.<br>
The CLR's Thread Pool<br>
Local<br>
Local<br>
Global<br>
Queue<br>
Queue<br>
Queue<br>
1<br>
n<br>
Worker<br>
Worker<br>
Thread 1<br>
Thread n<br>
Non-Worker<br>
Thread<br>
<b>FIGURE 26-1  </b>The CLR's thread pool<br>
Now let's talk about Task objects scheduled using the default TaskScheduler (obtained by <br>querying TaskScheduler's static Default property).4 When a non-worker thread schedules  <br>a Task, the Task is added to the global queue. But, each worker thread has its own local <br>queue and when a worker thread schedules a Task, the Task is added to calling the thread's  <br>local queue.<br>
4  Other TaskScheduler-derived objects may exhibit behavior different from what I describe here.<br>
<hr>
<A name=770></a><IMG src="CLRviaCsharp-770_1.jpg"><br>
<b>752 </b><br>
<b>Part V  Threading</b><br>
When a worker thread is ready to process an item, it always checks its local queue for a Task <br>first. If a Task exists, the worker thread removes the Task from its local queue and processes <br>the item. Note that a worker thread pulls tasks from its local queue using a last-in-first-out <br>(LIFO) algorithm. Since a worker thread is the only thread allowed to access the head of its <br>own local queue, no thread synchronization lock is required and adding and removing Tasks <br>from the queue is very fast. A side effect of this behavior is that Tasks are executed in the <br>reverse order that they were queued.<br>
<b>Important  </b>Thread pools have never guaranteed the order in which queued items are processed, <br>especially since multiple threads could be processing items simultaneously. However, this side <br>effect exacerbates the problem. You must make sure that your application has no expectations <br>about the order in which queued work items or Tasks execute.<br>
If a worker thread sees that its local queue is empty, then the worker thread will attempt to <br>steal a Task from another worker thread's local queue. Tasks are stolen from the tail of a  <br>local queue and require that a thread synchronization lock be taken, which hurts performance <br>a little bit. Of course, the hope is that stealing rarely occurs, so this lock is taken rarely. If <br>all the local queues are empty, then the worker thread will extract an item from the global <br>queue (taking its lock) using the FIFO algorithm. If the global queue is empty, then the worker <br>thread puts itself to sleep waiting for something to show up. If it sleeps for a long time, then <br>it will wake itself up and destroy itself, allowing the system to reclaim the resources (kernel <br>object, stacks, TEB) that were used by the thread.<br>
The thread pool will quickly create worker threads so that the number of worker threads <br>is equal to the value pass to ThreadPool's SetMinThreads method. If you never call this <br>method (and it's recommended that you never call this method), then the default value is <br>equal to the number of CPUs that your process is allowed to use as determined by your pro-<br>cess's affinity mask. Usually your process is allowed to use all the CPUs on the machine,5 so <br>the thread pool will quickly create worker threads up to the number of CPUs on the machine. <br>After this many threads have been created, the thread pool monitors the completion rate <br>of work items and if items are taking a long time to complete (the meaning of which is not <br>documented), it creates more worker threads. If items start completing quickly, then worker <br>threads will be destroyed.<br>
<b>Cache Lines and False Sharing</b><br>
To improve the performance of repeatedly accessing memory, today's CPUs have on-chip <br>cache memory. Accessing this memory is extremely fast, especially when compared to the <br>speed of the CPU accessing motherboard memory. The first time that a thread reads some <br>value in memory, the CPU fetches the desired value from the motherboard's memory and <br>
5  However, as of CLR version 4, 64 CPUs are used at most when running in a 64-bit process, and 32 CPUs are used at <br>
most when running in a 32-bit process.<br>
<hr>
<A name=771></a><b> </b><br>
<b>Chapter 26  Compute-Bound Asynchronous Operations </b><br>
<b>753</b><br>
stores it in the CPU's on-chip cache. In fact, to improve performance more, the CPU logically <br>divides all memory into what is called a <i>cache line</i>. For the CPU in my computer, a cache line <br>consists of 64 bytes, so the CPU fetches and stores 64-byte blocks from RAM.6 Therefore, if <br>your application needs to read an Int32 value, the 64 bytes that contain the Int32 will be <br>fetched. Fetching more bytes than required usually results in a performance improvement <br>because most applications tend to access data that is stored around other data the application <br>is already accessing. This neighboring data will now be in the CPU's cache, avoiding RAM <br>access.<br>
However, if two or more cores access bytes in the same cache line, then the cores must <br>communicate with each other and effectively pass the cache line from core to core so that <br>multiple cores are not manipulating adjacent bytes at the same time. This can have an awful <br>impact on the performance of your compute-bound operation. Let me demonstrate this with <br>some code:<br>
internal static class FalseSharing { <br>   private class Data { <br>      // These two fields are adjacent and (most likely) in the same cache line <br>      public Int32 field1; <br>      public Int32 field2; <br>   } <br> <br>   private const Int32 iterations = 100000000; // 100 million <br>   private static Int32 s_operations = 2; <br>   private static Int64 s_startTime; <br> <br>   public static void Main() { <br>      // Allocate an object and record the start time <br>      Data data = new Data(); <br>      s_startTime = Stopwatch.GetTimestamp(); <br> <br>      // Have 2 threads access their own fields within the structure <br>      ThreadPool.QueueUserWorkItem(o =&gt; AccessData(data, 0)); <br>      ThreadPool.QueueUserWorkItem(o =&gt; AccessData(data, 1)); <br> <br>      // For testing, block the Main thread <br>      Console.ReadLine(); <br>   } <br> <br>   private static void AccessData(Data data, Int32 field) { <br>      // The threads in here each access their own field within the Data object <br>      for (Int32 x = 0; x &lt; iterations; x++) <br>         if (field == 0) data.field1++; else data.field2++; <br> <br>      // Whichever thread finishes last, shows the time it took <br>      if (Interlocked.Decrement(ref s_operations) == 0) <br>         Console.WriteLine(&quot;Access time: {0:N0}&quot;, Stopwatch.GetTimestamp() - s_startTime); <br>   } <br>}<br>
6  You can determine the number of bytes in a CPU's cache line by calling Win32's GetProcessorInformation <br>
function. My Power Threading library contains a managed wrapper over this function, making it easy to call from <br>managed code.<br>
<hr>
<A name=772></a><b>754 </b><br>
<b>Part V  Threading</b><br>
In this code, a Data object is constructed containing two fields. Most likely, these two <br>fields will reside in the same cache line. Then, two thread pool threads go and execute the <br>AccessData method. One thread will add 1 to Data's field1 field 100,000,000 times, and <br>the other thread will do the same to the field2 field. As each thread finishes, it decrements <br>the value in the s_Operations field; whichever thread decrements the field to 0 is the last <br>thread to finish, and this thread shows how long it took for both threads to complete their <br>work. When I run this on my machine, I get a result of 15,856,074 milliseconds.<br>
Now, let's change the Data class so it looks like this:<br>
[StructLayout(LayoutKind.Explicit)] <br>private class Data { <br>   // These two fields are separated now and no longer in the same cache line <br>   [FieldOffset(0)]  public Int32 field1; <br>   [FieldOffset(64)] public Int32 field2; <br>}<br>
What I have done here is separate the two fields by a cache line (64 bytes). Now, when I run <br>the program, I get a result of 3,415,703 milliseconds. The first version is four times slower <br>because the two fields were part of the same cache line and the CPUs had to keep handing <br>the bytes back and forth to each other! From the program's point of view, the two threads <br>were manipulating different data; but, from the CPU's cache line point of view, the CPUs were <br>manipulating the same data. This is called <i>false sharing</i>. If the CPUs are on different Non-<br>Uniform Memory Access (NUMA) nodes, then the performance impact can be substantially <br>worse. In the second version, the fields were on different cache lines, so the CPUs could each <br>work independently; nothing was shared.<br>
I bring up this discussion to show you that cache lines and false sharing can have an  <br>enormous impact on the performance of an application when adjacent data is accessed by <br>multiple threads simultaneously. This is something you should be aware of in performance-<br>conscience scenarios and, if you detect it, you can usually devise a way to avoid it (like my <br>use of the FieldOffset attribute).<br>
Be aware that arrays maintain their length at the beginning of the array's memory, which is <br>right next to the first few array elements. When you access any array element, the CLR verifies <br>that the index you are using is within the array's length. This means that accessing an array's <br>element always involves accessing the array's length, too. Therefore, to avoid additional false <br>sharing, you should avoid having one thread write to the first few elements in the array while <br>other threads are accessing other elements in the array.<br>
<hr>
<A name=773></a>Chapter 27<br><b>I/O-Bound Asynchronous Operations</b><br>
<b>In this chapter:<br>How Windows Performs I/O Operations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 755<br>The CLR's Asynchronous Programming Model (APM) . . . . . . . . . . . . . . . . . . . . . 761<br>The </b>AsyncEnumerator<b> Class  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 765<br>The APM and Exceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 769<br>Applications and Their Threading Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 770<br>Implementing a Server Asynchronously . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 773<br>The APM and Compute-Bound Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 774<br>APM Considerations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 776<br>I/O Request Priorities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 780<br>Converting the </b>IAsyncResult<b> APM to a Task . . . . . . . . . . . . . . . . . . . . . . . . . . . . 783<br>The Event-Based Asynchronous Pattern . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 784<br>Programming Model Soup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 788</b><br>
The previous chapter focused on ways to perform compute-bound operations asynchronously, <br>allowing the thread pool to schedule the tasks onto multiple cores so that multiple threads <br>can work concurrently, which increases throughput while using system resources efficiently. <br>In this chapter, we'll focus on performing I/O-bound operations asynchronously, allowing <br>hardware devices to handle the tasks so that threads and the CPU are not used at all. This, of <br>course, uses system resources very efficiently because system resources are not required at <br>all. However, the thread pool still plays an important role because, as you'll see, the thread <br>pool threads will process the results of the various I/O operations.<br>
<b>How Windows Performs I/O Operations</b><br>
Let's begin by discussing how Microsoft Windows performs synchronous I/O operations. <br>Figure 27-1 represents a computer system with several hardware devices connected to it. <br>Each of these hardware devices has its own circuit board, each of which contains a small,  <br>special-purpose computer that knows how to control its hardware device. For example, the <br>hard disk drive has a circuit board that knows how to spin up the drive, seek the head to  <br>the right track, read or write data from or to the disk, and transfer the data to or from your <br>computer's memory.<br>
<b> </b><br>
<b> </b><br>
<b>755</b><br>
<hr>
<A name=774></a><b>756 </b><br>
<b>Part V  Threading</b><br>
<b>How Windows does Synchronous I/O</b><br>
.NET<br>
FileStream fs = new FileStream(...);<br>Int32 bytesRead = fs.Read(...);<br>
<b>1</b><br>
<b>9</b><br>
Win32<br>
ReadFile(...);<br>
User-Mode<br>
<b>3</b><br>
<b>IRP</b><br>
<b>8</b><br>
<b>2</b><br>
Windows<br>
Your thread blocks here!<br>
(Windows I/O Subsystem Dispatcher code)<br>
Kernel-Mode<br>
Hardward does I/O; <b>6</b><br>
No threads involved!<br>
<b>4</b><br>
<b>7</b><br>
<b>NTFS Driver</b><br>
<b>Network</b><br>
<b>DVD-ROM</b><br>
<b>RS-232</b><br>
<b>IRP </b><br>
<b>5</b><br>
<b>Queue</b><br>
<b>FIGURE 27-1  </b>How Windows performs a synchronous I/O operation<br>
In your program, you open a disk file by constructing a FileStream object. Then you call <br>the Read method to read data from the file. When you call FileStream's Read method, your <br>thread transitions from managed code to native/user-mode code and Read internally calls <br>the Win32 ReadFile function (#1). ReadFile then allocates a small data structure called an <br>I/O Request Packet (IRP) (#2). The IRP structure is initialized to contain the handle to the file, <br>an offset within the file where bytes will start to be read from, the address of a Byte[] that <br>should be filled with the bytes being read, the number of bytes to transfer, and some other <br>less interesting stuff.<br>
ReadFile then calls into the Windows kernel by having your thread transition from native/<br>user-mode code to native/kernel-mode code, passing the IRP data structure to the kernel <br>(#3). From the device handle in the IRP, the Windows kernel knows which hardware device <br>the I/O operation is destined for, and Windows delivers the IRP to the appropriate device <br>driver's IRP queue (#4). Each device driver maintains its own IRP queue that contains I/O  <br>requests from all processes running on the machine. As IRP packets show up, the device  <br>driver passes the IRP information to the circuit board associated with the actual hardware <br>device. The hardware device now performs the requested I/O operation (#5).<br>
<hr>
<A name=775></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>757</b><br>
But here is the important part: While the hardware device is performing the I/O operation, <br>your thread that issued the I/O request has nothing to do, so Windows puts your thread to <br>sleep so that it is not wasting CPU time (#6). This is great, but while your thread is not wast-<br>ing time, it is wasting space (memory), as its user-mode stack, kernel-mode stack, thread <br>environment block (TEB), and other data structures are sitting in memory but are not being <br>accessed at all. This is bad.<br>
Ultimately, the hardware device will complete the I/O operation, and then Windows will wake <br>up your thread, schedule it to a CPU, and let it return from kernel mode to user mode, and <br>then back to managed code (#7, #8, and #9). FileStream's Read method now returns an <br>Int32, indicating the actual number of bytes read from the file so that you know how many <br>bytes you can examine in the Byte[] that you passed to Read.<br>
Let's imagine that you are implementing a Web application and as each client request comes <br>in to your server, you need to make a database request. When a client request comes in, a <br>thread pool thread will call into your code. If you now issue a database request synchronously, <br>the thread will block for an indefinite amount of time waiting for the database to respond <br>with the result. If during this time another client request comes in, the thread pool will have <br>to create another thread and again this thread will block when it makes another database <br>request. As more and more client requests come in, more and more threads are created, and <br>all these threads block waiting for the database to respond. The result is that your Web server <br>is allocating lots of system resources (threads and their memory) that are barely even used!<br>
And to make matters worse, when the database does reply with the various results, threads <br>become unblocked and they all start executing. But since you might have lots of threads run-<br>ning and relatively few CPU cores, Windows has to perform frequent context switches, which <br>hurts performance even more. This is no way to implement a scalable application.<br>
Now, let's discuss how Windows performs asynchronous I/O operations. In Figure 27-2, I <br>have removed all the hardware devices except the hard disk from the picture, I introduce the <br>common language runtime's (CLR's) thread pool, and I've modified the code slightly. I still <br>open the disk file by constructing a FileStream object, but now I pass in the FileOptions.<br>Asynchronous flag. This flag tells Windows that I want my read and write operations against <br>the file to be performed asynchronously.<br>
<hr>
<A name=776></a><IMG src="CLRviaCsharp-776_1.jpg"><br>
<b>758 </b><br>
<b>Part V  Threading</b><br>
<b>How Windows does Asynchronous I/O</b><br>
.NET<br>
FileStream fs = new FileStream(..., FileOptions.Asynchronous);<br>fs.BeginRead(..., CallbackMethod, ...);<br>
<b>1</b><br>
<b>7</b><br>
void CallbackMethod(...) { ... }<br>
Win32<br>
<b>c</b><br>
ReadFile(...);<br>
User-Mode<br>
<b>3</b><br>
<b>IRP</b><br>
<b>6</b><br>
Windows<br>
<b>2</b><br>
Your thread doesn't <br>
(Windows I/O Subsystem Dispatcher code)<br>
Kernel-<br>
block here; it <br>
Mode<br>
keeps running! <b>5</b><br>
<b>4</b><br>
<b>5</b><br>
<b>NTFS Driver</b><br>
<b>The CLR's Thread Pool</b><br>
<b>IRP </b><br>
<b>a</b><br>
<b>Queue</b><br>
<b>Threads can extract</b><br>
<b>completed IRP's</b><br>
<b>from here</b><br>
<b>b</b><br>
<b>FIGURE 27-2  </b>How Windows performs an asynchronous I/O operation<br>
To read data from the file, I now call BeginRead instead of Read. Like Read, BeginRead calls <br>Win32's ReadFile function (#1). ReadFile allocates its IRP, initializes it just like it did in the <br>synchronous scenario (#2), and then passes it down to the Windows kernel (#3). Windows <br>adds the IRP to the hard disk driver's IRP queue (#4), but now, instead of blocking your <br>thread, your thread is allowed to return to your code; your thread immediately returns from <br>its call to BeginRead (#5, #6, and #7). Now, of course, the IRP has not necessarily been pro-<br>cessed yet, so you cannot have code after BeginRead that attempts to access the bytes in the <br>passed-in Byte[].<br>
Now you might ask, when and how do you process the data that will ultimately be read? <br>Well, when you call BeginRead, you pass it the name of a callback method as an argument <br>(CallbackMethod in my example). The delegate referring to your callback method is effec-<br>tively passed inside the IRP all the way down to the device driver. When the hardware device <br>completes processing the IRP (a), it will queue the IRP's delegate into the CLR's thread pool <br>(b). Sometime in the future, a thread pool thread will extract the completed IRP and invoke <br>your callback method (c).1 So now you know when the operation has completed, and inside <br>this method, you can safely access the data inside the Byte[].<br>
1  Completed IRPs are extracted from the thread pool using a first-in-first-out (FIFO) algorithm.<br>
<hr>
<A name=777></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>759</b><br>
Now that you understand the basics, let's put it all into perspective. Let's say that a client <br>request comes in, and our server makes an asynchronous database request. As a result, our <br>thread won't block, and it will be allowed to return to the thread pool so that it can handle <br>more incoming client requests. So now we have just <i>one</i> thread handling <i>all </i>incoming client <br>requests. When the database server responds, its response is also queued into the thread <br>pool, so our thread pool thread will just process it at some point and ultimately send the <br>necessary data back to the client. At this point, we have just one thread processing all client <br>requests and all database responses. Our server is using very few system resources and it is <br>still running as fast as it can, especially since there are no context switches!<br>
If items appear in the thread pool quicker than our one thread can process them all, then the <br>thread pool might create additional threads. The thread pool will quickly create one thread <br>per CPU on the machine. So on a quad-processor machine, four client requests/database  <br>responses (in any combination) are running on four threads without any context switching.2<br>
However, if any of these threads voluntarily block (by invoking a synchronous I/O operation, <br>calling Thread.Sleep, or waiting to acquire a thread synchronization lock), then Windows <br>notifies the thread pool that one of its threads has stopped running. The thread pool now <br>realizes that the CPUs are undersaturated and creates a new thread to replace the blocked <br>thread. This, of course, is not ideal because creating a new thread is very expensive in terms <br>of both time and memory.<br>
What's worse is that the blocked thread might wake up and now the CPUs are oversaturated <br>again and context switching must occur, decreasing performance. However, the thread pool <br>is smart here. As threads complete their processing and return to the pool, the thread pool <br>won't let them process new work items until the CPUs become exactly saturated again,  <br>thereby reducing context switches and improving performance. And if the thread pool later <br>determines that it has more threads in it than it needs, it lets the extra threads kill themselves, <br>thereby reclaiming the resources that these threads were using.<br>
Internally, the CLR's thread pool uses a Windows resource called an <i>I/O Completion Port</i> to <br>elicit the behavior that I've just described. The CLR creates an I/O Completion Port when <br>it initializes and, as you open hardware devices, these devices can be bound to the I/O <br>Completion Port so that device drivers know where to queue the completed IRPs. If you want <br>to understand more about this mechanism, I recommend my book <i>Windows via C/C++, 5th <br>Edition</i> (Microsoft Press, 2007).<br>
2  This is assuming that other threads are not running on the computer, which is true most of the time since most <br>
computers are running at far less than 100% CPU usage. And CPU usage can be at 100% and this will still work as <br>explained if the running threads have lower priorities. If other threads are running, then context switching does <br>occur. This is bad for performance reasons, but it is good for reliability reasons. Remember that Windows gives <br>each process at least one thread and performs context switches to ensure that an application whose thread is an <br>infinite loop doesn't stop other applications' threads from running.<br>
<hr>
<A name=778></a><b>760 </b><br>
<b>Part V  Threading</b><br>
In addition to minimal resource usage and reduced context switches, we get many other <br>benefits when performing I/O operations asynchronously. Whenever a garbage collection <br>starts, the CLR must suspend all the threads in the process. Therefore, the fewer threads we <br>have, the faster the garbage collector runs. In addition, when a garbage collection occurs, the <br>CLR must walk all the threads' stacks looking for roots. Again, the fewer threads there are, the <br>fewer stacks there are, and this also makes the garbage collection faster. But, in addition, if <br>our threads don't block while processing work items, the threads tend to spend most of their <br>time waiting in the thread pool. So when a garbage collection occurs, the threads are at the <br>top of their stack, and walking each thread's stack for roots takes very little time.<br>
Also, when you debug an application, Windows suspends all threads in the debuggee when <br>you hit a breakpoint. Then, when you continue executing the debuggee, Windows has to  <br>resume all its threads, so if you have a lot of threads in an application, single-stepping <br>through the code in a debugger can be excruciatingly slow. Using asynchronous I/O allows <br>you to have just a few threads, improving your debugging performance.<br>
And, here's yet another benefit: Let's say that your application wants to download 10 images <br>from various Web sites, and that it takes 5 seconds to download each image. If you perform <br>this work synchronously (downloading one image after another), then it takes you 50 seconds <br>to get the 10 images. However, if you use just one thread to initiate 10 asynchronous down-<br>load operations, then all 10 are being performed concurrently and all 10 images will come <br>back in just 5 seconds! That is, when performing multiple synchronous I/O operations, the <br>time it takes to get all the results is the sum of the times required for each individual result. <br>However, when performing multiple asynchronous I/O operations, the time it takes to get all <br>the results is the time required to get the single worst-performing operation.<br>
For GUI applications, asynchronous operations offer yet another advantage: The application's <br>user interface doesn't hang and remains responsive to the end user. In fact, if you are building <br>a Silverlight application, you must perform all I/O operations asynchronously because the <br>Silverlight version of the Framework Class Library (FCL) doesn't even offer methods that per-<br>form synchronous I/O operations. This was done purposely because Silverlight runs in a Web <br>browser, like Windows Internet Explorer, and a thread issuing a synchronous I/O operation <br>could block waiting for a Web server to reply. If this happens, the entire Web browser would <br>be frozen. The user might not even be able to switch to another tab to work with a different  <br>Web site. In fact, this is a big reason why Windows Internet Explorer 8 creates a different <br>process for each tab. Now one tab (not running Silverlight code) could stop responding, but <br>other tabs still respond. But creating a separate process per tab is very resource-intensive, all <br>in the name of keeping the UI responsive.3<br>
3  For the record, there is also a security advantage to having each tab run in its own process.<br>
<hr>
<A name=779></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>761</b><br>
<b>The CLR's Asynchronous Programming Model (APM)</b><br>
Performing asynchronous operations is the key to building high-performance, scalable  <br>applications that allow you to use very few threads to execute a lot of operations. And when <br>coupled with the thread pool, asynchronous operations allow you to take advantage of all <br>of the CPUs that are in the machine. Realizing the enormous potential here, Microsoft's CLR <br>team designed a pattern that would make it easy for developers to take advantage of this <br>capability. This pattern is called the Asynchronous Programming Model (APM).<br>
Personally, I love the APM because it is relatively easy to learn, simple to use, and is supported <br>by many types in the FCL. Here are some examples:<br>
  All System.IO.Stream-derived classes that communicate with hardware devices  <br>
(including FileStream and NetworkStream) offer BeginRead and BeginWrite  <br>methods. Note that Stream-derived classes that do not communicate with hardware <br>devices (including BufferedStream, MemoryStream, and CryptoStream) also offer <br>BeginRead and BeginWrite methods to fit into the APM. However, the code in these <br>methods performs compute-bound operations, not I/O-bound operations, and there-<br>fore a thread is required to execute these operations.<br>
  The System.Net.Dns class offers BeginGetHostAddresses, BeginGetHostByName, <br>
BeginGetHostEntry, and BeginResolve methods.<br>
  The System.Net.Sockets.Socket class offers BeginAccept, BeginConnect, <br>
BeginDisconnect, BeginReceive, BeginReceiveFrom, BeginReceiveMessageFrom, <br>BeginSend, BeginSendFile, and BeginSendTo methods.<br>
  All System.Net.WebRequest-derived classes (including FileWebRequest, <br>
FtpWebRequest, and HttpWebRequest) offer BeginGetRequestStream and <br>BeginGetResponse methods.<br>
  The System.IO.Ports.SerialPort class has a read-only BaseStream property that <br>
returns a Stream, which, as you know, offers BeginRead and BeginWrite methods.<br>
  The System.Data.SqlClient.SqlCommand class offers BeginExecuteNonQuery, <br>
BeginExecuteReader, and BeginExecuteXmlReader methods.<br>
Furthermore, all delegate types define a BeginInvoke method for use with the APM. And <br>finally, tools (such as WSDL.exe and SvcUtil.exe) that produce Web service proxy types also <br>generate BeginXxx methods for use with the APM. By the way, there is a corresponding <br>EndXxx method for each and every BeginXxx method. As you can see, support for the APM <br>is pervasive throughout the FCL.<br>
To synchronously read bytes from a FileStream, you'd call its Read method, which is proto-<br>typed as follows:<br>
public Int32 Read(Byte[] array, Int32 offset, Int32 count)<br>
<hr>
<A name=780></a><b>762 </b><br>
<b>Part V  Threading</b><br>
Calling a function that internally performs synchronous I/O puts your application in an  <br>unpredictable state as you have no idea when (or even if) the method will return. What if the <br>file you opened was on a network server and just before calling Read, the server lost power? <br>Now when will Read return?<br>
And so, if you are interested in writing responsive, robust, and scalable software, you should <br>not call methods that perform synchronous I/O; you should instead cal  methods that perform <br>asynchronous I/O. To asynchronously perform an I/O operation, you would call a BeginXxx <br>method like FileStream's BeginRead method:<br>
IAsyncResult BeginRead(Byte[] array, Int32 offset, Int32 numBytes,   <br>   AsyncCallback userCallback, Object stateObject)<br>
Notice that BeginRead's first three parameters are identical to those of Read. And, in fact,  <br>every BeginXxx method has the same parameters as its synchronous counterpart method. <br>But, every BeginXxx method has two additional parameters: userCallback and  <br>stateObject. The userCallback parameter is of the AsyncCallback delegate type:<br>
public delegate void AsyncCallback(IAsyncResult ar);<br>
For this parameter, you pass the name of a method (or lambda expression) representing code <br>that you want to be executed by a thread pool thread when the asynchronous I/O operation <br>completes. The last parameter to a BeginXxx method, stateObject, is a reference to any <br>object you'd like forwarded on to your callback method. Inside your callback method, you <br>access your objectState by querying the IAsyncResult interface's read-only AsyncState <br>property.<br>
All BeginXxx methods return an object that implements the System.IAsyncResult interface. <br>When you call a BeginXxx method, it constructs an object that uniquely identifies your I/O <br>request, queues up the request to the Windows device driver, and returns to you a refer-<br>ence to the IAsyncResult object. You can think of this object as your receipt. You can actu-<br>ally ignore the object reference returned from BeginXxx because the CLR internally holds <br>a reference to the IAsyncResult object as well. When the operation completes, a thread <br>pool thread will invoke your callback method, passing to it a reference to the internally held <br>IAsyncResult object.<br>
Inside your method, you'll call the corresponding EndXxx method, passing it the <br>IAsyncResult object. The EndXxx method returns the same result that you would have  <br>gotten if you had called the synchronous method. For example, FileStream's Read method  <br>returns an Int32 that indicates the number of bytes actually read from the stream. <br>FileStream's EndRead method's return value has the same meaning:<br>
Int32 EndRead(IAsyncResult result);  // Returns number of bytes read from the stream<br>
Below is the code for a named-pipe server class, PipeServer, which is implemented using <br>the APM:<br>
<hr>
<A name=781></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>763</b><br>
internal sealed class PipeServer { <br>   // Each server object performs asynchronous operations on this pipe <br>   private readonly NamedPipeServerStream m_pipe = new NamedPipeServerStream( <br>      &quot;Echo&quot;, PipeDirection.InOut, -1, PipeTransmissionMode.Message, <br>      PipeOptions.Asynchronous | PipeOptions.WriteThrough); <br> <br>   public PipeServer() { <br>      // Asynchronously accept a client connection <br>      m_pipe.BeginWaitForConnection(ClientConnected, null); <br>   } <br> <br>   private void ClientConnected(IAsyncResult result) { <br>      // A client connected, let's accept another client <br>      new PipeServer(); // Accept another client <br> <br>      // Accept the client connection <br>      m_pipe.EndWaitForConnection(result); <br> <br>      // Asynchronously read a request from the client <br>      Byte[] data = new Byte[1000]; <br>      m_pipe.BeginRead(data, 0, data.Length, GotRequest, data); <br>   } <br> <br>   private void GotRequest(IAsyncResult result) { <br>      // The client sent us a request, process it.  <br>      Int32 bytesRead = m_pipe.EndRead(result); <br>      Byte[] data = (Byte[])result.AsyncState; <br> <br>      // My sample server just changes all the characters to uppercase <br>      // But, you can replace this code with any compute-bound operation <br>      data = Encoding.UTF8.GetBytes( <br>         Encoding.UTF8.GetString(data, 0, bytesRead).ToUpper().ToCharArray()); <br> <br>      // Asynchronously send the response back to the client <br>      m_pipe.BeginWrite(data, 0, data.Length, WriteDone, null); <br>   } <br> <br>   private void WriteDone(IAsyncResult result) { <br>      // The response was sent to the client, close our side of the connection <br>      m_pipe.EndWrite(result); <br>      m_pipe.Close(); <br>   } <br>}<br>
An instance of this class must be created <i>before</i> a client connects to the server because it is <br>the constructor's call to BeginWaitForConnection that allows a client to connect. Once a <br>client connects, the ClientConnect method will be called by a thread pool thread and a new <br>instance of the PipeServer class is created so that additional clients can connect. Meanwhile, <br>the ClientConnected method will call BeginRead, telling the network device driver to listen <br>for incoming data from this client and put that data into the specified Byte[].<br>
When the client sends the data, some thread pool thread will call the GotRequest method. <br>This method will gain access to the Byte[] (by querying the AsyncState property) and then <br>process the data. In my example, I use a UTF-8 encoder to convert the Byte[] into a String, <br>
<hr>
<A name=782></a><b>764 </b><br>
<b>Part V  Threading</b><br>
uppercase the characters in the String, and then convert the String back to a Byte[].<b> <br></b>However, you can replace this code with your own compute-bound operation so that the <br>server does whatever you need it to do. Then GotRequest sends the output data back to the <br>client by calling BeginWrite. When the device driver has finished sending the data to the cli-<br>ent, some thread pool thread will call WriteDone, which then closes the pipe and terminates <br>the connection.<br>
Notice that all the methods follow the same pattern: They end with a call to a BeginXxx <br>method (except the last method, WriteDone) and they start with a call to an EndXxx method <br>(except the constructor). Between the EndXxx and BeginXxx methods, I perform only  <br>compute-bound work; the I/O operations are at the "borders" of the methods, so now, <br>threads never block. After each method, the threads return back to the thread pool where <br>they can handle incoming client requests or incoming network responses. And if the thread <br>pool gets busy with work, then it will automatically create multiple threads to handle the <br>workload--my server scales automatically based on workload and based on the number of <br>CPUs in the machine!<br>
I created my server application as a console application and it initializes itself like this:<br>
public static void Main() { <br>   // Start 1 server per CPU <br>   for (Int32 n = 0; n &lt; Environment.ProcessorCount; n++) <br>       new PipeServer(); <br> <br>   Console.WriteLine(&quot;Press &lt;Enter&gt; to terminate this server application.&quot;); <br>   Console.ReadLine(); <br>}<br>
Now, let me show you the code for a named-pipe client class that is also implemented using <br>the APM. Notice that the PipeClient class is structured identically to the PipeServer class.<br>
internal sealed class PipeClient { <br>   // Each client object performs asynchronous operations on this pipe <br>   private readonly NamedPipeClientStream m_pipe; <br> <br>   public PipeClient(String serverName, String message) { <br>      m_pipe = new NamedPipeClientStream(serverName, &quot;Echo&quot;,  <br>         PipeDirection.InOut, PipeOptions.Asynchronous | PipeOptions.WriteThrough); <br>      m_pipe.Connect(); // Must Connect before setting ReadMode <br>      m_pipe.ReadMode = PipeTransmissionMode.Message; <br> <br>      // Asynchronously send data to the server <br>      Byte[] output = Encoding.UTF8.GetBytes(message); <br>      m_pipe.BeginWrite(output, 0, output.Length, WriteDone, null); <br>   } <br> <br>   private void WriteDone(IAsyncResult result) { <br>      // The data was sent to the server <br>      m_pipe.EndWrite(result); <br> <br>
<hr>
<A name=783></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>765</b><br>
      // Asynchronously read the server's response <br>      Byte[] data = new Byte[1000]; <br>      m_pipe.BeginRead(data, 0, data.Length, GotResponse, data); <br>   } <br> <br>   private void GotResponse(IAsyncResult result) { <br>      // The server responded, display the response and close out connection <br>      Int32 bytesRead = m_pipe.EndRead(result); <br> <br>      Byte[] data = (Byte[])result.AsyncState; <br>      Console.WriteLine(&quot;Server response: &quot; + Encoding.UTF8.GetString(data, 0, bytesRead)); <br>      m_pipe.Close(); <br>   } <br>}<br>
And, my client console application makes one hundred calls into the server using this code:<br>
public static void Main() { <br>   // Now make 100 client requests against the server <br>   for (Int32 n = 0; n &lt; 100; n++) <br>      new PipeClient(&quot;localhost&quot;, &quot;Request #&quot; + n); <br> <br>   // Since all the requests are issued asynchronously, the constructors are likely <br>   // to return before all the requests are complete. The call below stops the  <br>   // application from terminating until we see all the responses displayed. <br>   Console.ReadLine(); <br>}<br>
Frequently, developers implement servers to use one thread per client request. However, a <br>32-bit process can create no more than about 1,360 threads before running out of virtual <br>address space. This means that a server using the one-thread-per-client model can't operate <br>on more than 1,360 clients simultaneously. However, I modified my program to construct a <br>bunch of PipeServer objects, and in a 32-bit process, I was able to create over 4 million of <br>them before running out of memory. So the asynchronous model allows many more concur-<br>rent clients, uses fewer resources, processes clients faster (due to reduced context switches), <br>improves garbage collection time, and improves debugging performance, too! What else <br>could you ask for?<br>
<b>The </b>AsyncEnumerator<b> Class</b><br>
Well, one thing you could ask for is an easier way to do asynchronous programming. The <br>APM's programming model is cumbersome, which is the main reason why a lot of developers <br>don't use it. Here are some of the problems with it:<br>
  You must split your code up into many callback methods.<br>
  You have to avoid using argument and local variables because these variables are  <br>
allocated on a thread's stack and can't be accessed by another thread or by another <br>method.<br>
<hr>
<A name=784></a><b>766 </b><br>
<b>Part V  Threading</b><br>
  Many C# language constructs, like try/catch/finally, using, for, do, while, and <br>
foreach, can't be used if you want to start the construct as one method and end it in <br>another method. For example, in my Server class, I'd like to use C#'s using statement <br>to open the pipe and then have it automatically be closed in a finally block. However, <br>I can't use using because I open the pipe in Server's constructor and I close it in a  <br>different method, WriteDone.<br>
  It's hard to implement other features that many developers typically need such as  <br>
coordinating multiple concurrent operations, supporting cancellation and timeout, and <br>marshaling work to the GUI thread to update controls.<br>
These are the main reasons why many developers avoid the APM. However, I have created <br>a class, AsyncEnumerator, which simplifies all of this and fixes all the problems mentioned <br>above. In a nutshell, my AsyncEnumerator class allows you to perform asynchronous  <br>operations using a synchronous programming model by leveraging C#'s iterator language <br>feature. The class is part of my Power Threading library and is completely free to use. <br>Versions of this library exist for the desktop CLR, Silverlight, and the Microsoft .NET Compact <br>Framework. You can download the latest version of the library and sample code from  <br><i>http://Wintellect.com/PowerThreading.aspx.</i> This Web page contains links to my <i>Concurrent <br>Affairs</i> column in <i>MSDN Magazine</i>, where I explain how my AsyncEnumerator class works. <br>There are also links to some videos I did showing how to use it, and a link to a newsgroup <br>where I offer free technical support.<br>
For now, let me just share some of the features that the AsyncEnumerator class offers:<br>
  It implements the APM itself so it easily integrates with all the Microsoft .NET <br>
Framework technologies, such as ASP.NET and Windows Communication <br>Foundation (WCF). This also allows composition of asynchronous subroutines, as one <br>AsyncEnumerator can invoke another.<br>
  It coordinates multiple concurrent asynchronous operations. That is, you can issue <br>
many asynchronous operations, and the AsyncEnumerator can notify you after all of <br>them have completed or notify you as each one completes.<br>
  It supports discard groups, which allow you to issue a set of asynchronous operations <br>
and have the AsyncEnumerator object automatically throw away the results as they <br>complete. For example, you could request the temperature of London from three dif-<br>ferent Web servers within a single discard group. Whichever server responds the fastest <br>gives your application the information it needs to continue processing. Then you can <br>cancel the remaining operations that are part of that discard group.<br>
  It allows you to cancel a set of asynchronous operations automatically by calling each <br>
operation's EndXxx methods (and swallowing exceptions) for you if you don't care <br>about the results. This is particularly good for GUI applications because it allows users <br>to cancel the operations if they get tired of waiting for the results. In addition, you can <br>have the cancel occur automatically after a timeout interval that you specify. This is <br>particularly good for server applications that want to respond to the client within a  <br>certain period of time with whatever information the server has.<br>
<hr>
<A name=785></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>767</b><br>
  It frees you from having to worry about your application's threading model (as  <br>
discussed in the "Applications and their Threading Models" section later in this chapter). <br>For example, in a GUI application, the AsyncEnumerator invokes your code on the GUI <br>thread by default so you can update UI controls. For an ASP.NET Web Form or XML <br>Web Service application, the AsyncEnumerator automatically ensures that your code is  <br>running under the client's culture and identity.<br>
  It has rich error-handling support. If your iterator returns and an asynchronous opera-<br>
tion later completes, the AsyncEnumerator class throws an exception notifying you <br>that there is no way for the EndXxx method to be called and therefore your application <br>is leaking resources.<br>
  It has rich debugging support. Typically, an application will have many <br>
AsyncEnumerator objects in memory. This is especially true of server applications. In a <br>debugger, you can query the AsyncEnumerator's static GetInProgressList method, <br>which returns a list of all the AsyncEnumerator objects currently in existence. This list is <br>sorted with the object that has been waiting the longest for an operation to complete <br>at the top. If your application appears to be hung, looking at the item at the top of the <br>list will usually take you right to the line in your code that is waiting for an operation to <br>complete. In addition, when you look at an individual AsyncEnumerator object in the <br>debugger, it displays a user-definable tag identifying the operation, the timestamp of <br>the last asynchronous operation it performed, which operations have completed, and <br>which operations have not completed yet. It also shows you the source code file and <br>line within that file where the asynchronous operations were initiated.<br>
Here is what the pipe server code looks like when implemented for use with my <br>AsyncEnumerator class4:<br>
private static IEnumerator&lt;Int32&gt; PipeServerAsyncEnumerator(AsyncEnumerator ae) { <br>   // Each server object performs asynchronous operations on this pipe <br>   using (var pipe = new NamedPipeServerStream( <br>      &quot;Echo&quot;, PipeDirection.InOut, -1, PipeTransmissionMode.Message, <br>      PipeOptions.Asynchronous | PipeOptions.WriteThrough)) { <br> <br>      // Asynchronously accept a client connection <br>      pipe.BeginWaitForConnection(ae.End(), null); <br>      yield return 1; <br> <br>      // A client connected, let's accept another client <br>      var aeNewClient = new AsyncEnumerator(); <br>      aeNewClient.BeginExecute(PipeServerAsyncEnumerator(aeNewClient),  <br>         aeNewClient.EndExecute); <br> <br>      // Accept the client connection <br>      pipe.EndWaitForConnection(ae.DequeueAsyncResult()); <br> <br>      // Asynchronously read a request from the client <br>      Byte[] data = new Byte[1000]; <br>
4  The sample code for this book contains the pipe client code re-implemented to use AsyncEnumerator. This  <br>
version of the code follows the same structure shown here.<br>
<hr>
<A name=786></a><b>768 </b><br>
<b>Part V  Threading</b><br>
      pipe.BeginRead(data, 0, data.Length, ae.End(), null); <br>      yield return 1; <br> <br>      // The client sent us a request, process it.  <br>      Int32 bytesRead = pipe.EndRead(ae.DequeueAsyncResult()); <br> <br>      // My sample server just changes all the characters to uppercase <br>      // But, you can replace this code with any compute-bound operation <br>      data = Encoding.UTF8.GetBytes( <br>         Encoding.UTF8.GetString(data, 0, bytesRead).ToUpper().ToCharArray()); <br> <br>      // Asynchronously send the response back to the client <br>      pipe.BeginWrite(data, 0, data.Length, ae.End(), null); <br>      yield return 1; <br> <br>      // The response was sent to the client, close our side of the connection <br>      pipe.EndWrite(ae.DequeueAsyncResult()); <br>   } // Close happens in a finally block now! <br>}<br>
There are several things to notice about this new version of the code:<br>
  All the code is in one method as opposed to lots of methods spread out within a class. <br>
Since there is no class, there are no fields; all the variables are local variables.<br>
  Where I would have had a method separation, I now have a yield return 1 statement. <br>
This allows the thread to return to where it came from so that it can do more work.<br>
  To every BeginXxx method, I pass ae.End(); this method returns a delegate referring <br>
to a method inside the AsyncEnumerator object. When the operation completes, the <br>thread pool thread notifies the AsyncEnumerator object, which in turn continues  <br>executing your iterator method after the yield return 1 statement.<br>
  I always pass null as the last argument to every BeginXxx method. Therefore, I never <br>
need to call IAsyncResult's AsyncState property and cast its return value to the right <br>type; I just use the local variables directly.<br>
  To every EndXxx method, I pass the result of calling ae.DequeueAsyncResult(). This <br>
method returns the IAsyncResult object that was passed to the AsyncEnumerator <br>object by the thread pool thread when the asynchronous operation completed.<br>
  And last, but not least, notice that now I can use C#'s using statement to control  <br>
the lifetime of the NamedPipeServerStream. This also means that the <br>NamedPipeServerStream object will be closed within a finally block should any <br>other code throw an unhandled exception.<br>
This gives you a good introduction as to what the AsyncEnumerator class can do for you and <br>how it simplifies asynchronous programming. The code above doesn't even show some of <br>the more exciting features. If you're interested in learning more about it, I encourage you to <br>visit the Wintellect Web site mentioned earlier.<br>
<hr>
<A name=787></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>769</b><br>
<b>The APM and Exceptions</b><br>
Whenever you call a BeginXxx method, it could throw an exception, of course. If this hap-<br>pens, you can assume that the asynchronous operation has not been queued, and therefore <br>a thread pool thread will not invoke any callback method that you may have passed to the <br>BeginXxx method.<br>
When a Windows device driver is processing an asynchronous I/O request, it is possible <br>for something to go wrong, and Windows will need to inform your application of this. For <br>example, while sending bytes or waiting for bytes to come in over the network, a timeout <br>could expire. If the data does not come in time, the device driver will want to tell you that <br>the asynchronous operation completed with an error. To accomplish this, the device driver <br>posts the completed IRP to the CLR's thread pool and effectively puts an error code in the <br>IAsyncResult object that represents the asynchronous operation. A thread pool thread will <br>then invoke your callback method, passing it the IAsyncResult object. Your callback method <br>will then pass the IAsyncResult object to the appropriate EndXxx method, which will see <br>the error code, convert it to an appropriate Exception-derived object, and then throw this <br>exception object.<br>
The result of all this is that exceptions work the same with asynchronous programming as <br>they do with synchronous programming. However, you usually don't care about exceptions <br>thrown from a BeginXxx call, and you usually do care about exceptions thrown from an <br>EndXxx call. The following code demonstrates the use of exception handling and the APM:<br>
internal static class ApmExceptionHandling { <br>   public static void Main() { <br>      // Try to access an invalid IP address <br>      WebRequest webRequest = WebRequest.Create(&quot;http://0.0.0.0/&quot;); <br>      webRequest.BeginGetResponse(ProcessWebResponse, webRequest); <br>      Console.ReadLine(); <br>   } <br> <br>   private static void ProcessWebResponse(IAsyncResult result) { <br>      WebRequest webRequest = (WebRequest)result.AsyncState; <br> <br>      WebResponse webResponse = null; <br>      try { <br>         webResponse = webRequest.EndGetResponse(result); <br>         Console.WriteLine(&quot;Content length: &quot; + webResponse.ContentLength); <br>      } <br>      catch (WebException we) { <br>         Console.WriteLine(we.GetType() + &quot;: &quot; + we.Message); <br>      } <br>      finally { <br>         if (webResponse != null) webResponse.Close(); <br>      } <br>   } <br>}<br>
<hr>
<A name=788></a><IMG src="CLRviaCsharp-788_1.jpg"><br>
<b>770 </b><br>
<b>Part V  Threading</b><br>
When I run the above program, I get the following output:<br>
System.Net.WebException: Unable to connect to the remote server<br>
<b>Note  </b>A common problem exists when performing multiple asynchronous Hypertext Transfer <br>Protocol (HTTP) requests that catches many developers by surprise. The HTTP (RFC 2616) states <br>that a client application should not have more than two simultaneous connections to a single <br>server. The classes in the FCL actually enforce this rule, and any thread trying to create additional <br>connections to a particular server is blocked until one of the two existing connections is closed. <br>You should either design your application to have no more than two outstanding connections to <br>a single server at any one time or increase the maximum number of concurrent connections by <br>setting System.Net.ServicePointManager's static DefaultConnectionLimit property to <br>whatever number your application needs.<br>
<b>Applications and Their Threading Models</b><br>
The .NET Framework supports several different kinds of application models, and each ap-<br>plication model might impose its own threading model. Console applications and Windows <br>Services (which are really console applications; you just don't see the console) do not impose <br>any kind of threading model; that is, any thread can do whatever it wants when it wants.<br>
However, GUI applications, including Windows Forms, Windows Presentation Foundation <br>(WPF), and Silverlight, impose a threading model where the thread that created the window is <br>the only thread allowed to update that window. It is common for the GUI thread to spawn off <br>an asynchronous operation so that the GUI thread doesn't block and stop responding to user <br>input like mouse, keystroke, pen, and touch events. However, when the asynchronous opera-<br>tion completes, it completes using a thread pool thread which cannot update the UI showing <br>the results. Somehow, the thread pool thread must have the GUI thread update the UI.<br>
Like console applications, ASP.NET Web Form and XML Web Service applications allow <br>any thread to do whatever it wants. When a thread pool thread starts to process a client's <br>request, it can assume the client's culture (System.Globalization.CultureInfo), allow-<br>ing the Web server to return culture-specific formatting for numbers, dates, and times.5 In <br>addition, the Web server can assume the client's identity (System.Security.Principal.<br>IPrincipal) so that the server can access only the resources that the client is allowed to  <br>access. When a thread pool thread spawns an asynchronous operation, it will be completed <br>by another thread pool thread, which will be processing the result of an asynchronous opera-<br>tion. While this work is being performed on behalf of the original client request, the culture <br>and identity information doesn't flow to the new thread pool thread by default so any  <br>additional work done on behalf of the client is now not using the client's culture and identity <br>information. Ideally, we want the culture and identity information to flow to the other thread <br>pool threads that are still doing work on behalf of the same client.<br>
5  For more information, see <i>http://msdn.microsoft.com/en-us/library/bz9tc508.aspx.</i><br>
<hr>
<A name=789></a><IMG src="CLRviaCsharp-789_1.jpg"><br>
<b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>771</b><br>
Fortunately, the FCL defines a base class, called System.Threading.<br>SynchronizationContext, which solves all these problems. Simply stated, a <br>SynchronizationContext-derived object connects an application model to its threading <br>model. The FCL defines several classes derived from SynchronizationContext, but usually <br>you will not deal directly with these classes; in fact, many of them are not publicly exposed <br>or documented. Here is what the SynchronizationContext class looks like (I show only the <br>members relevant to this discussion):<br>
public class SynchronizationContext { <br>   public static SynchronizationContext Current { get; } <br>   public virtual void Post(SendOrPostCallback d, object state); // Call asynchronously <br>   public virtual void Send(SendOrPostCallback d, object state); // Call synchronously <br>} <br> <br>// SendOrPostCallback is a delegate defined like this: <br>public delegate void SendOrPostCallback(Object state);<br>
For Windows Forms applications, WPF applications, and Silverlight applications, the GUI <br>thread will have a SynchronizationContext-derived class associated with it. You can get a <br>reference to this object by having the GUI thread query SynchronizationContext's static <br>Current property. You would then save a reference to this object in some shared variable <br>(like a static field of your own class). Then, whenever a thread pool thread needs to have <br>the GUI thread update the UI, you would have the thread pool thread reference the saved <br>SynchronizationContext-derived object and call its Post method, passing in the method <br>(matching the SendOrPostCallback delegate's signature) that should be invoked by the GUI <br>thread and an argument that should be passed to this method.<br>
I recommend calling the Post method, as it queues up the callback to the GUI thread and <br>allows the thread pool thread to return immediately. Send, on the other hand, queues up the <br>callback to the GUI thread and then blocks the thread pool thread until the GUI thread has <br>completed calling the callback. Blocking the thread pool thread will most likely cause the <br>thread pool to create a new thread, increasing resource consumption while decreasing  <br>performance. This is why I always avoid calling the Send method.<br>
<b>Note  </b>For the curious, here is how the various SynchronizationContext-derived classes get <br>the GUI thread to invoke the SendOrPostCallback method. For Windows Forms, the System.<br>Windows.Forms.WindowsFormsSynchronizationContext class's Post method internally <br>calls System.Windows.Forms.Control's BeginInvoke method, and its Send method internally <br>calls Control's Invoke method. For WPF and Silverlight, the System.Windows.Threading.<br>DispatcherSynchronizationContext class's Post method internally calls System.Windows.<br>Threading.Dispatcher's BeginInvoke method, and its Send method internally calls <br>Dispatcher's Invoke method.<br>
<hr>
<A name=790></a><b>772 </b><br>
<b>Part V  Threading</b><br>
For ASP.NET Web Form and XML Web Service applications, the thread pool thread that <br>starts running due to an incoming client request will have a SynchronizationContext-<br>derived class associated with it. This object contains within it the client's culture and identity <br>information. You can get a reference to this object by having the thread pool thread query <br>SynchronizationContext's static Current property. You would then save a reference to <br>this object in some field that is a member of the object that is processing the client's request. <br>When another thread pool thread calls back into a method of the class, you would have the <br>thread pool thread reference the saved SynchronizationContext-derived object and call its <br>Post method, passing in the method (matching the SendOrPostCallback delegate's signa-<br>ture) that should be invoked using the client's culture and identity information. This method <br>will be executed by the same thread pool thread that called Post. For ASP.NET applications, <br>the SynchronizationContext-derived type's Post and Send methods perform identically.<br>
For a console or Windows Service application, there will not be a SynchronizationContext-<br>derived object associated with the thread; querying SynchronizationContext's static <br>Current property will return null.<br>
At first, all of this can be very confusing, so I wrote a little method that simplifies things <br>greatly:<br>
private static AsyncCallback SyncContextCallback(AsyncCallback callback) { <br>   // Capture the calling thread's SynchronizationContext-derived object <br>   SynchronizationContext sc = SynchronizationContext.Current; <br> <br>   // If there is no SC, just return what was passed in <br>   if (sc == null) return callback; <br> <br>   // Return a delegate that, when invoked, posts to the captured SC a method that  <br>   // calls the original AsyncCallback passing it the IAsyncResult argument <br>   return asyncResult =&gt; sc.Post(result =&gt; callback((IAsyncResult)result), asyncResult); <br>}<br>
This method turns a normal AsyncCallback method into an AsyncCallback method that <br>is invoked via the calling thread's SynchronizationContext-derived object, ensuring that <br>the right threading model is used no matter what application model I'm using.6 Here is a <br>Windows Forms example that uses the APM and my SyncContextCallback method to  <br>ensure that everything works correctly:<br>
internal sealed class MyWindowsForm : Form { <br>   public MyWindowsForm() { <br>      Text = &quot;Click in the window to start a Web request&quot;; <br>      Width = 400; Height = 100; <br>   } <br> <br>
6  You might wonder why the .NET Framework doesn't just automatically provide what my SyncContextCallback <br>
method does. It wasn't until after .NET Framework version 1.0 shipped that everyone realized how big a problem  <br>this whole "application models have their own threading models" thing was. To address these problems, the <br>SynchronizationContext class was added in .NET Framework version 2.0. To make this the default behavior now <br>could have potentially broken existing applications, and this is why the "right" behavior isn't the default behavior.<br>
<hr>
<A name=791></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>773</b><br>
   protected override void OnMouseClick(MouseEventArgs e) { <br>      // The GUI thread initiates the asynchronous Web request  <br>      Text = &quot;Web request initiated&quot;; <br>      var webRequest = WebRequest.Create(&quot;http://Wintellect.com/&quot;); <br>      webRequest.BeginGetResponse(SyncContextCallback(ProcessWebResponse), webRequest); <br>      base.OnMouseClick(e); <br>   } <br> <br>   private void ProcessWebResponse(IAsyncResult result) { <br>      // If we get here, this must be the GUI thread, it's OK to update the UI <br>      var webRequest = (WebRequest)result.AsyncState; <br>      using (var webResponse = webRequest.EndGetResponse(result)) { <br>         Text = &quot;Content length: &quot; + webResponse.ContentLength; <br>      } <br>   } <br>}<br>
Now, see how similar the WPF version is7:<br>
private sealed class MyWpfWindow : System.Windows.Window { <br>   public MyWpfWindow() { <br>      Title = &quot;Click in the window to start a Web request&quot;; <br>      Width = 400; Height = 100; <br>   } <br> <br>   protected override void OnMouseDown(MouseButtonEventArgs e) { <br>      // The GUI thread initiates the asynchronous Web request  <br>      Title = &quot;Web request initiated&quot;; <br>      var webRequest = WebRequest.Create(&quot;http://Wintellect.com/&quot;); <br>      webRequest.BeginGetResponse(SyncContextCallback(ProcessWebResponse), webRequest); <br>      base.OnMouseDown(e); <br>   } <br> <br>   private void ProcessWebResponse(IAsyncResult result) { <br>      // If we get here, this must be the GUI thread, it's OK to update the UI <br>      var webRequest = (WebRequest)result.AsyncState; <br>      using (var webResponse = webRequest.EndGetResponse(result)) { <br>         Title = &quot;Content length: &quot; + webResponse.ContentLength; <br>      } <br>   } <br>}<br>
<b>Implementing a Server Asynchronously</b><br>
Earlier in this chapter, I showed my pipe server, which is implemented as a console applica-<br>tion, and I implemented it taking advantage of the APM. Other servers using different  <br>application models can also be implemented using the APM. However, I have run into a lot  <br>of people who don't know that this is even possible. So, in this section, I just want to <br>make you aware that you can implement all kinds of servers asynchronously. See the .NET <br>Framework SDK documentation for more details.<br>
7  By the way, the Silverlight version is practically identical to this. The differences are all related to setting the title <br>
and detecting the mouse click; the code related to the APM is absolutely identical to the WPF version.<br>
<hr>
<A name=792></a><b>774 </b><br>
<b>Part V  Threading</b><br>
To implement an ASP.NET Web Form page asynchronously, open your .aspx file <br>and add "Async=true" to your Page directive. Then, inside your code, call the <br>AddOnPreRenderCompleteAsync method (your class inherits this method from System.Web.<br>UI.Page), passing it the names of BeginXxx and EndXxx methods that you write yourself. In <br>your BeginXxx method, start your asynchronous operation and let the thread pool thread <br>return to the pool. Note that even though the thread is returning, the page is <i>not</i> sent back <br>to the client. When the asynchronous operation completes, your EndXxx method will be <br>called. Grab the data, update the page's controls, and now the page will be sent back to the <br>client.<br>
To implement an ASP.NET Web Service asynchronously, just implement your Web method as <br>two methods, a BeginXxx method and an EndXxx method, following the pattern described <br>in this chapter. Mark both methods with the [WebMethod] attribute.<br>
To implement a Windows Communication Foundation Web Service asynchronously, define <br>BeginXxx and EndXxx methods in your contracts following the pattern described in this <br>chapter. Then, mark the BeginXxx method with the [OperationContract(AsyncPattern= <br>true)] attribute.<br>
Let me point out that my AsyncEnumerator class can really simplify your coding when you <br>want to implement a server asynchronously.<br>
<b>The APM and Compute-Bound Operations</b><br>
Chapter 26, "Compute-Bound Asynchronous Operations," showed how to perform compute-<br>bound operations by calling ThreadPool's QueueUserWorkItem method and also by using <br>the System.Threading.Tasks.Task class. Well, in this section, I'll show you how to perform <br>a compute-bound operation using the APM. It's unfortunate that the .NET Framework offers <br>so many different programming models for accomplishing the same thing, as it is confusing <br>to developers which one to use when. And since the multi-core revolution is still in its infan-<br>cy, I suspect that even more programming models will show up in the future. This is just the <br>way of the world. Eventually, many years from now, I'm sure things will get simpler; but for <br>today and the near future, things will get more complicated. In this chapter's "Programming <br>Model Soup" section, I attempt to compare and contrast the various APMs offered today by <br>the .NET Framework.<br>
You can call any method by using the APM, but first, you need to use a delegate that has the <br>same signature as the method you want to cal . For example, let's say you want to cal  a meth-<br>od that sums up the numbers from 1 to n. This computational y intensive task (which performs <br>no I/O) could take a long time to execute if n is a large value.8 Here is the Sum method:<br>
8  Yes, I know that a sum can be calculated quickly for any value of n using this formula: n * (n + 1) / 2. For this <br>
example, let's just forget that this formula exists and do it the old-fashioned way: manually adding up the num-<br>bers so that it takes a long time.<br>
<hr>
<A name=793></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>775</b><br>
private static UInt64 Sum(UInt64 n) {  <br>   UInt64 sum = 0;  <br>   for (UInt64 i = 1; i &lt;= n; i++) {  <br>      checked {     <br>         // I use checked code so that an OverflowException gets   <br>         // thrown if the sum doesn't fit in a UInt64.  <br>         sum += i;  <br>      }  <br>   }  <br>   return sum;  <br>}<br>
If n is large, Sum could take a long time to execute. To keep the UI of my application respon-<br>sive or to take advantage of other CPUs in the computer, I'd like to execute this method asyn-<br>chronously. To do this, I use the generic System.Func&lt;T, TResult&gt; delegate that accepts <br>two type parameters; one for the argument and one for the return type:<br>
public delegate TResult Func&lt;T, TResult&gt;(T arg);<br>
You'll recall from the delegate discussion in Chapter 17, "Delegates," that the C# compiler <br>compiles this line of code into a class definition that logically looks like this:<br>
public sealed class Func&lt;T, TResult&gt; : MulticastDelegate {  <br>   public Func(Object object, IntPtr method);  <br>   public TResult Invoke(T arg);  <br>   public IAsyncResult BeginInvoke(T arg, AsyncCallback callback, Object object);  <br>   public TResult EndInvoke(IAsyncResult result);  <br>}<br>
When you define a delegate in C# source code, the compiler always produces a class that has <br>BeginInvoke and EndInvoke methods. The BeginInvoke method has the same parameters <br>as the delegate definition, with two additional parameters at the end: AsyncCallback and <br>Object. All BeginInvoke methods return an IAsyncResult. The EndInvoke method has one <br>parameter, an IAsyncResult, and the EndInvoke method returns whatever data type the <br>delegate's signature returns.<br>
Now that you understand all of this, using a delegate to execute a compute-bound operation <br>is trivial because it follows the APM pattern we've been talking about. Here is some code that <br>shows how to call Sum asynchronously:<br>
public static void Main() {  <br>   // Initialize a delegate variable to refer to the method we want to call asynchronously  <br>   Func&lt;UInt64, UInt64&gt; sumDelegate = Sum;  <br> <br>   // Call the method using a thread pool thread  <br>   sumDelegate.BeginInvoke(1000000000, SumIsDone, sumDelegate);  <br> <br>   // Executing some other code here would be useful...  <br> <br>   // For this demo, I'll just suspend the primary thread  <br>   Console.ReadLine();  <br>}<br>
<hr>
<A name=794></a><b>776 </b><br>
<b>Part V  Threading</b><br>
The sumDelegate variable is first initialized to refer to the method you want to call asyn-<br>chronously. Then BeginInvoke is called to initiate the asynchronous calling of the method. <br>Internally, the CLR constructs an IAsyncResult object to identify the asynchronous opera-<br>tion. As you know, I/O operations are queued to a Windows device driver; however, a  <br>delegate's BeginInvoke method queues compute-bound operations to the CLR's thread <br>pool by internally calling ThreadPool's QueueUserWorkItem. Finally, BeginInvoke returns <br>the IAsyncResult object to its caller (which usually ignores it). <br>
Since BeginInvoke queued the operation to the CLR's thread pool, a thread pool thread will <br>wake, dequeue the work item, and call the compute-bound method (Sum, in this example). <br>Normally, when a thread pool thread returns from executing a method, the thread returns <br>back to the pool. However, in my example, BeginInvoke was called, passing in the name of a <br>method (SumIsDone) for the second-to-last parameter. Because of this, when Sum returns, the <br>thread pool thread does not return back to the pool; instead, it now calls SumIsDone. In other <br>words, the callback is called when the compute-bound operation has completed, just as it <br>would be called when an I/O-bound operation has completed. Here is what my SumIsDone <br>method looks like:<br>
private static void SumIsDone(IAsyncResult ar) {  <br>   // Extract the sumDelegate (state) from the IAsyncResult object  <br>   var sumDelegate = (Func&lt;UInt64, UInt64&gt;) ar.AsyncState;  <br> <br>   try { <br>      // Get the result and display it <br>      Console.WriteLine(&quot;Sum's result: &quot; + sumDelegate.EndInvoke(result)); <br>   } <br>   catch (OverflowException) { <br>      Console.WriteLine(&quot;Sum's result is too large to calculate&quot;); <br>   } <br>}<br>
<b>APM Considerations</b><br>
All in all, I am a huge fan of the APM, but I must admit that it does have some shortcomings, <br>and it would be nice if Microsoft solved some of these, or at least provided some guidance <br>for developers. Let's discuss these issues.<br>
<b>Using the APM Without the Thread Pool</b><br>
In this chapter, I have discussed how to use the APM and have thread pool threads invoke <br>your callback methods with the asynchronous operations completed. What I have shown you <br>is the preferred way to use the APM, as it uses little resources and offers excellent perfor-<br>mance. However, the APM offers three other ways to know when the asynchronous operation <br>has completed.<br>
<hr>
<A name=795></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>777</b><br>
All BeginXxx methods return a reference to an object that implements the IAsyncResult <br>interface:<br>
public interface IAsyncResult { <br>   Object     AsyncState             { get; } <br>   WaitHandle AsyncWaitHandle        { get; } // Avoid using this <br>   Boolean    IsCompleted            { get; } // Avoid using this <br>   Boolean    CompletedSynchronously { get; } // true if the op completed synchronously <br>}<br>
First, if a thread calls EndXxx, passing in this IAsyncResult object before the operation <br>is complete, the calling thread will block waiting for it to complete and the thread will <br>wake with the result returned from EndXxx. Second, a thread can also block, waiting for <br>the operation to complete, by calling WaitOne (discussed in Chapter 28, "Primitive Thread <br>Synchronization Constructs") on the WaitHandle returned from querying IAsyncResult's <br>AsyncWaitHandle property. These first two techniques should be avoided, however, because <br>they block a thread, potentially causing the thread pool to allocate another thread.<br>
Third, a thread could continuously query IAsyncResult's IsCompleted property in a loop <br>to know when the operation is complete. This technique should also be avoided because it <br>wastes CPU time while pol ing. If you pol  waiting for a compute-bound operation to complete, <br>then you steal CPU time away from the compute-bound operation, making it take longer to <br>complete. Frequently, to reduce continuous polling, programmers call Thread.Sleep within <br>each iteration of the polling loop. If you do this, now you are blocking threads and polling!<br>
<b>Always Call the </b>EndXxx<b> Method, and Call It Only Once</b><br>
You must call EndXxx or else you will leak resources. Some developers have written code to <br>call BeginXxx to write some data to a device, and there is no processing that needs to be <br>done after the data has been written, so they don't care about calling EndXxx. However, call-<br>ing EndXxx is required for two reasons. First, the CLR allocates some internal resources when <br>you initiate an asynchronous operation. When the operation completes, the CLR will hold <br>onto these resources until EndXxx is called. If EndXxx is never called, these resources remain <br>allocated and will be reclaimed only when the process terminates. Second, when you initiate <br>an asynchronous operation, you don't actually know if the operation eventually succeeded or <br>failed. The only way you can discover this is by calling EndXxx and checking the return value <br>or seeing if it throws an exception.<br>
You should not call EndXxx more than once for any given asynchronous operation. When you <br>call EndXxx, it could access some internal resources and then release them. If you call EndXxx <br>again, the resources will have been released already, and the results will be unpredictable. In <br>reality, cal ing EndXxx multiple times for a single operation may or may not work; it depends on <br>how the class that implements the IAsyncResult interface has been written. Since Microsoft <br>never told developers how this should behave, different developers implemented it in differ-<br>ent ways. The only thing you can count on is that calling EndXxx just once will work.<br>
<hr>
<A name=796></a><b>778 </b><br>
<b>Part V  Threading</b><br>
<b>Always Use the Same Object When Calling the </b>EndXxx<b> Method</b><br>
Whatever object you use when calling BeginXxx should be the same object that you use to <br>call EndXxx. For example, don't construct a delegate and call its BeginInvoke method and <br>then construct another delegate (of the same type referring to the same object/method) and <br>use it to call its EndInvoke method. While this seems as if it should work (since both delegate <br>objects are identical in every way), it doesn't work because the IAsyncResult object internal y <br>keeps a reference to the original object used when calling BeginInvoke, and if they don't <br>match, EndInvoke throws an InvalidOperationException with a string message of &quot;The <br>IAsyncResult object provided does not match this delegate.&quot; Again, using one <br>object to call BeginInvoke and another object to call EndInvoke may work for some object <br>types depending on how they were implemented.<br>
<b>Using </b>ref<b>, </b>out<b>, and </b>params<b> Arguments with </b>BeginXxx<b> and <br></b>EndXxx<b> Methods</b><br>
The parameters of BeginXxx and EndXxx methods will deviate slightly from the patterns I've <br>described in this chapter if the non-asynchronous version of the method uses any out/ref <br>parameters or if it has a parameter marked with the params keyword. Since this is very rare, <br>I won't show an example, but you should be aware of it. You'll easily figure out how to call <br>the methods correctly when you need to.<br>
<b>You Can't Cancel an Asynchronous I/O-Bound Operation</b><br>
There is currently no way to cancel an outstanding asynchronous I/O-bound operation. This <br>is a feature that many developers would like, but it is actually quite hard to implement. After <br>all, if you request 1,000 bytes from a server and then you decide you don't want those bytes <br>anymore, there really is no way to tell the server to forget about your request. The way to <br>deal with this is just to let the bytes come back to you and then throw them away. In addition, <br>there is a race condition here: Your request to cancel the request could come just as the last <br>byte is being read. Now what should your application do? You'd need to handle this potential <br>race condition occurring in your own code and decide whether to throw the data away or act <br>on it. Some BeginXxx methods might return an object that implements the IAsyncResult <br>interface, as well as offering some kind of cancel method. In this case, you could cancel the <br>operation. You'd have to check the documentation for the BeginXxx method or the class it <br>returns to see whether cancellation is supported.<br>
<b>Memory Consumption</b><br>
Whenever you call a BeginXxx method, it constructs an instance of a type that implements <br>the IAsyncResult interface. This means that an object is created for every asynchronous <br>operation that you want to perform. This adds more overhead and creates more objects on <br>
<hr>
<A name=797></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>779</b><br>
the heap, which causes more garbage collections to occur. The result: poorer application per-<br>formance. So if you know for a fact that your I/O operations are going to execute extremely <br>quickly, it may make more sense to perform them synchronously. Many developers (including <br>myself) wish that the APM returned value types instead or had some other lightweight way  <br>of identifying a queued asynchronous operation; maybe Microsoft will improve the CLR <br>someday by supporting this.<br>
<b>Some I/O Operations Must Be Done Synchronously</b><br>
The Win32 API offers many functions that execute I/O operations. Unfortunately, some of <br>these methods do not let you perform the I/O asynchronously. For example, the Win32 <br>CreateFile method (called by FileStream's constructor) always executes synchronously. If <br>you're trying to create or open a file on a network server, it could take several seconds before <br>CreateFile returns--the calling thread is idle all the while. An application designed for  <br>optimum performance and scalability would ideally call a Win32 function that lets you create <br>or open a file asynchronously so that your thread is not sitting and waiting for the server to <br>reply. Unfortunately, Win32 has no CreateFile-like function to let you do this, and therefore <br>the FCL cannot offer an efficient way to open a file asynchronously.<br>
Here is an example where this is a real problem. Imagine writing a simple UI control that al-<br>lows the user to type a file path and provides automatic completion (similar to the common <br>File Open dialog box). The control must use separate threads to enumerate directories looking <br>for files because Windows doesn't offer any functions to enumerate files asynchronously. As <br>the user continues to type in the UI control, you have to use more threads and ignore the <br>results from any previously spawned threads. With Windows Vista, Microsoft introduced a <br>new Win32 function called CancelSynchronousIO. This function allows one thread to cancel <br>a synchronous I/O operation that is being performed by another thread. This function is not <br>exposed by the FCL, but you can also P/Invoke to it if you want to take advantage of it from <br>managed code. I show the P/Invoke signature for it in the next section of this chapter.<br>
The point I want you to take away though is that many people think that synchronous APIs <br>are easier to work with, and in many cases this is true. But in some cases, synchronous APIs <br>can make things much harder. Microsoft's Windows team is looking at the synchronous-only <br>APIs and deciding which function needs to be exposed with asynchronous APIs in future  <br>versions of Windows. Once they do this, the FCL will expose this functionality, too.<br>
You can always call any method asynchronously via a delegate's BeginInvoke method, but <br>when you do this, you are using a thread, so you are losing some efficiency. And actually, you <br>can't use a delegate to call a constructor. So the only way to construct a FileStream object <br>asynchronously is to call some other method asynchronously and have this other method <br>construct the FileStream object. Windows doesn't offer functions to asynchronously access <br>the registry, access the event log, get a directory's files/subdirectories, or change a file's/ <br>directory's attributes, to name just a few.<br>
<hr>
<A name=798></a><b>780 </b><br>
<b>Part V  Threading</b><br>
FileStream<b>-Specific Issues</b><br>
When you create a FileStream object, you get to specify whether you want to communicate <br>using synchronous or asynchronous operations via the FileOptions.Asynchronous flag <br>(which is equivalent to calling the Win32 CreateFile function and passing into it the  <br>FILE_FLAG_OVERLAPPED flag). If you do not specify this flag, Windows performs all opera-<br>tions against the file synchronously. Of course, you can still call FileStream's BeginRead <br>method, and to your application, it looks as if the operation is being performed asynchro-<br>nously, but internally, the FileStream class uses another thread to emulate asynchronous <br>behavior. This additional thread is wasteful and hurts performance.<br>
On the other hand, you can create a FileStream object by specifying the FileOptions.<br>Asynchronous flag. Then you can call FileStream's Read method to perform a synchronous <br>operation. Internally, the FileStream class emulates this behavior by starting an asynchro-<br>nous operation and then immediately puts the calling thread to sleep until the operation is <br>complete. This is also inefficient, but it is not as inefficient as calling BeginRead by using a <br>FileStream constructed without the FileOptions.Asynchronous flag.<br>
So, to summarize: When working with a FileStream, you must decide up front whether you <br>intend to perform synchronous or asynchronous I/O against the file and indicate your choice <br>by specifying the FileOptions.Asynchronous flag (or not). If you specify this flag, always call <br>BeginRead. If you do not specify this flag, always call Read. This wil  give you the best perfor-<br>mance. If you intend to make some synchronous and some asynchronous operations against <br>the FileStream, it is more efficient to construct it using the FileOptions.Asynchronous <br>flag. Alternatively, you can create two FileStream objects over the same file; open one <br>FileStream for asynchronous I/O and open the other FileStream for synchronous I/O.<br>
You should also be aware that the NTFS file system device driver performs some operations <br>synchronously no matter how you open the file. For more information about this, see  <br><i>http://support.microsoft.com/default.aspx?scid=kb%3Ben-us%3B156932.</i><br>
<b>I/O Request Priorities</b><br>
In Chapter 25, "Thread Basics," I showed how setting thread priorities affects how threads are <br>scheduled. However, threads also perform I/O requests to read and write data from various <br>hardware devices. If a low-priority thread gets CPU time, it could easily queue hundreds or <br>thousands of I/O requests in a very short time. Because I/O requests typically require time to <br>process, it is possible that a low-priority thread could significantly affect the responsiveness <br>of the system by suspending high-priority threads, which prevents them from getting their <br>work done. Because of this, you can see a machine become less responsive when executing <br>long-running low-priority services such as disk defragmenters, virus scanners, content index-<br>ers, and so on.9<br>
9  The Windows SuperFetch feature takes advantage of low-priority I/O requests.<br>
<hr>
<A name=799></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>781</b><br>
Starting with Windows Vista, it is now possible for a thread to specify a priority when  <br>making I/O requests. For more details about I/O priorities, refer to the white paper at  <br><i>http://www.microsoft.com/whdc/driver/priorityio.mspx. </i>Unfortunately, the FCL does not  <br>include this functionality yet; hopefully, it will be added in a future version. However, you can <br>still take advantage of this feature by P/Invoking out to native Win32 functions. Here is the  <br>P/Invoke code:<br>
internal static class ThreadIO { <br>   public static BackgroundProcessingDisposer BeginBackgroundProcessing( <br>      Boolean process = false) { <br> <br>      ChangeBackgroundProcessing(process, true); <br>      return new BackgroundProcessingDisposer(process); <br>   } <br> <br>   public static void EndBackgroundProcessing(Boolean process = false) { <br>      ChangeBackgroundProcessing(process, false); <br>   } <br> <br>   private static void ChangeBackgroundProcessing(Boolean process, Boolean start) { <br>      Boolean ok = process <br>         ? SetPriorityClass(GetCurrentWin32ProcessHandle(),  <br>               start ? ProcessBackgroundMode.Start : ProcessBackgroundMode.End) <br>         : SetThreadPriority(GetCurrentWin32ThreadHandle(),  <br>               start ? ThreadBackgroundgMode.Start : ThreadBackgroundgMode.End); <br>      if (!ok) throw new Win32Exception(); <br>   } <br> <br>   // This struct lets C#'s using statement end the background processing mode <br>   public struct BackgroundProcessingDisposer : IDisposable { <br>      private readonly Boolean m_process; <br>      public BackgroundProcessingDisposer(Boolean process) { m_process = process; } <br>      public void Dispose() { EndBackgroundProcessing(m_process); } <br>   } <br> <br> <br>   // See Win32's THREAD_MODE_BACKGROUND_BEGIN and THREAD_MODE_BACKGROUND_END <br>   private enum ThreadBackgroundgMode { Start = 0x10000, End = 0x20000 } <br> <br>   // See Win32's PROCESS_MODE_BACKGROUND_BEGIN and PROCESS_MODE_BACKGROUND_END <br>   private enum ProcessBackgroundMode { Start = 0x100000, End = 0x200000 } <br> <br>   [DllImport(&quot;Kernel32&quot;, EntryPoint = &quot;GetCurrentProcess&quot;, ExactSpelling = true)] <br>   private static extern SafeWaitHandle GetCurrentWin32ProcessHandle(); <br> <br>   [DllImport(&quot;Kernel32&quot;, ExactSpelling = true, SetLastError = true)] <br>   [return: MarshalAs(UnmanagedType.Bool)] <br>   private static extern Boolean SetPriorityClass( <br>      SafeWaitHandle hprocess, ProcessBackgroundMode mode); <br> <br>   [DllImport(&quot;Kernel32&quot;, EntryPoint = &quot;GetCurrentThread&quot;, ExactSpelling = true)] <br>   private static extern SafeWaitHandle GetCurrentWin32ThreadHandle(); <br> <br>
<hr>
<A name=800></a><IMG src="CLRviaCsharp-800_1.jpg"><br>
<b>782 </b><br>
<b>Part V  Threading</b><br>
   [DllImport(&quot;Kernel32&quot;, ExactSpelling = true, SetLastError = true)] <br>   [return: MarshalAs(UnmanagedType.Bool)] <br>   private static extern Boolean SetThreadPriority( <br>      SafeWaitHandle hthread, ThreadBackgroundgMode mode); <br> <br>   // http://msdn.microsoft.com/en-us/library/aa480216.aspx <br>   [DllImport(&quot;Kernel32&quot;, SetLastError = true, EntryPoint = &quot;CancelSynchronousIo&quot;)] <br>   [return: MarshalAs(UnmanagedType.Bool)] <br>   private static extern Boolean CancelSynchronousIO(SafeWaitHandle hThread); <br>}<br>
And here is code showing how to use it:<br>
public static void Main () { <br>   using (ThreadIO.BeginBackgroundProcessing()) { <br>      // Issue low-priority I/O requests in here (eg: calls to BeginRead/BeginWrite) <br>   } <br>}<br>
You tell Windows that you want your thread to issue low-priority I/O requests by calling <br>ThreadIO's BeginBackgroundProcessing method. Note that this also lowers the CPU sched-<br>uling priority of the thread. You can return the thread to making normal-priority I/O requests <br>(and normal CPU scheduling priority) by calling EndBackgroundProcessing or by calling <br>Dispose on the value returned by BeginBackgroundProcessing (as shown above via C#'s <br>using statement). A thread can only affect its own background processing mode; Windows <br>doesn't allow a thread to change the background processing mode of another thread.<br>
If you want all threads in a process to make low-priority I/O requests and have low CPU <br>scheduling, you can call BeginBackgroundProcessing, passing in true for the process  <br>parameter. A process can only affect its own background processing mode; Windows doesn't <br>allow a thread to change the background processing mode of another process.<br>
<b>Important  </b>As a developer, it is your responsibility to use these new background priorities to <br>allow the foreground applications to be more responsive, taking care to avoid <i>priority inversion.</i> <br>In the presence of intense normal-priority I/Os, a thread running at background priority can <br>be delayed for <i>seconds </i>before getting the result of its I/O requests. If a low-priority thread has <br>grabbed a thread synchronization lock for which the normal-priority thread is waiting, the  <br>normal-priority threads might end up waiting for the background-priority thread until the <br>low-priority I/O requests are completed. Your background-priority thread does not even have <br>to submit I/Os for the problem to happen. So using shared synchronization objects between <br>normal- and background-priority threads should be minimized (or eliminated if possible) to <br>avoid these priority inversions where normal-priority threads are blocked on locks owned by <br>background-priority threads.<br>
<hr>
<A name=801></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>783</b><br>
<b>Converting the </b>IAsyncResult<b> APM to a Task</b><br>
In "The APM and Compute-Bound Operations" section earlier in this chapter, I showed how <br>to use the APM to perform a compute-bound operation. In this section, I show how to do the <br>opposite: use a Task to perform an I/O-bound operation.<br>
In the System.Threading.Tasks namespace, there is a class called TaskFactory. This class <br>was discussed in Chapter 26. However, this class offers a FromAsync method, which I did not <br>discuss in Chapter 26. This method accepts four arguments and returns a reference to a Task <br>object. The four arguments are a BeginXxx method, an EndXxx method, an Object state, <br>and an optional TaskCreationOptions10 value. So instead of initiating an asynchronous op-<br>eration like this:<br>
WebRequest webRequest = WebRequest.Create(&quot;http://Wintellect.com/&quot;); <br>webRequest.BeginGetResponse(result =&gt; { <br>   WebResponse webResponse = null; <br>   try { <br>      webResponse = webRequest.EndGetResponse(result); <br>      Console.WriteLine(&quot;Content length: &quot; + webResponse.ContentLength); <br>   } <br>   catch (WebException we) { <br>      Console.WriteLine(&quot;Failed: &quot; + we.GetBaseException().Message); <br>   } <br>   finally { if (webResponse != null) webResponse.Close(); } <br>}, null);<br>
you can turn it into a Task, and then use it with the rest of the Task infrastructure like this:<br>
WebRequest webRequest = WebRequest.Create(&quot;http://Wintellect.com/&quot;); <br>Task.Factory.FromAsync&lt;WebResponse&gt;( <br>   webRequest.BeginGetResponse, webRequest.EndGetResponse, null, TaskCreationOptions.None) <br>   .ContinueWith(task =&gt; {  <br>   WebResponse webResponse = null; <br>   try {  <br>      webResponse = task.Result;  <br>      Console.WriteLine(&quot;Content length: &quot; + webResponse.ContentLength);  <br>   } <br>   catch (AggregateException ae) { <br>      if (ae.GetBaseException() is WebException) <br>         Console.WriteLine(&quot;Failed: &quot; + ae.GetBaseException().Message); <br>      else throw; <br>   } <br>   finally { if (webResponse != null) webResponse.Close(); } <br>});<br>
10 The FromAsync method has additional overloads that allow you to pass up to three parameters to a BeginXxx <br>
method. If you need to call a BeginXxx method that takes more than three parameters, then there is a FromAsync <br>overload that accepts an IAsyncResult parameter; you call the BeginXxx method yourself and its return value <br>here. Avoid this overload if you can because it is less efficient than the overloads of FromAsync that do not take an <br>IAsyncResult.<br>
<hr>
<A name=802></a><b>784 </b><br>
<b>Part V  Threading</b><br>
By the way, the Task class implements the IAsyncResult interface, so tasks support the <br>APM to some extent. Task's AsyncState property is the IAsyncResult AsyncState prop-<br>erty, and this returns whatever state was passed in to TaskFactory's state parameter. Since <br>the Task is going to internally call the EndXxx method for you, the other IAsyncResult <br>interface members that are potentially interesting are AsyncWaitHandle, IsCompleted, and <br>maybe CompletedSynchronously. Well, as discussed earlier in this chapter in the "Using the <br>APM Without the Thread Pool" section, the AsyncWaitHandle and IsCompleted properties <br>should always be avoided, and the CompletedSynchronously property is more informative <br>than actionable.<br>
<b>The Event-Based Asynchronous Pattern</b><br>
When the .NET Framework was introduced, the only APM it offered is the one based on the <br>IAsyncResult interface that I've been discussing this whole chapter. Microsoft's Windows <br>Forms team felt that the IAsyncResult APM was too difficult for many Windows Form  <br>developers, so they created a new Event-based Asynchronous Pattern (EAP).11 The main  <br>benefit of the EAP is that it integrates with the Microsoft Visual Studio UI designers. That is, <br>you can drag most classes that implement the EAP to a Visual Studio design surface and then <br>double-click event names and have Visual Studio automatically produce the event callback <br>methods and wire the method up to the events themselves.<br>
Many people, including me, believe that the EAP should never have been introduced into <br>the .NET Framework. We believe that it adds more complication than it solves. For example, <br>should classes that want to offer asynchronous behavior now implement both patterns? Or <br>will two classes now be exposed that basically offer the same functionality, only differing by <br>asynchronous pattern? How would users of a class choose which pattern to use and why? <br>There are also some other technical problems that exist with this pattern, which I describe at <br>the end of this section.<br>
In fact, I'm often asked about the following MSDN Web page: <i>http://msdn2.microsoft.com <br>/en-gb/library/ms228966.aspx.</i> This Web page actual y instructs class developers to expose <br>their asynchronous behavior using the EAP, not the APM. It also says, "It is rare for the <br>IAsyncResult pattern to be implemented without the event-based pattern also being  <br>implemented." This Web page was produced by people on the Windows Forms team. <br>There are very few people at Microsoft who actually agree with this Web page. And, in fact, <br>Microsoft ships only three classes that actually implement both patterns and adhere to what <br>this Web page says. Since I'm not a fan of this pattern and I discourage its use, I do not want <br>to spend a lot of time on it. However, I know that some people do like and use the pattern, <br>so I do want to spend some time on it.<br>
11 Many people from Microsoft's Windows Forms moved to Microsoft's WPF team, so WPF and Silverlight have also <br>
adopted this EAP.<br>
<hr>
<A name=803></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>785</b><br>
Since the EAP was created for Windows Forms developers, let me show you some Windows <br>Forms code that uses the pattern:<br>
internal static class Eap { <br>   public static void Main() { <br>      // Create the form and show it <br>      Application.Run(new MyForm()); <br>   } <br> <br>   private sealed class MyForm : Form { <br>      protected override void OnClick(EventArgs e) { <br>         // The System.Net.WebClient class supports the Event-based Asynchronous Pattern <br>         WebClient wc = new WebClient(); <br> <br>         // When a string completes downloading, the WebClient object raises the  <br>         // DownloadStringCompleted event which will invoke our ProcessString method <br>         wc.DownloadStringCompleted += ProcessString; <br> <br>         // Start the asynchronous operation (this is like calling a BeginXxx method) <br>         wc.DownloadStringAsync(new Uri(&quot;http://Wintellect.com&quot;)); <br>         base.OnClick(e); <br>      } <br> <br>      // This method is guaranteed to be called via the GUI thread <br>      private void ProcessString(Object sender, DownloadStringCompletedEventArgs e) { <br>         // If an error occurred, display it; else display the downloaded string <br>         MessageBox.Show((e.Error != null) ? e.Error.Message : e.Result); <br>      } <br>   } <br>}<br>
In this sample, I manually wrote all the code, but I could have used Visual Studio to drag a <br>WebClient control to my form. Then Visual Studio could have emitted the ProcessString <br>method with no code in it and emitted the code to register this method with WebClient's <br>DownloadStringCompleted event. The EAP also guarantees that the event is raised on the <br>application's GUI thread, allowing code in the event handler method to update UI controls. <br>In addition to Visual Studio designer support, this is another big feature of the EAP. That is, <br>classes that support the EAP automatically map the application model to its threading model; <br>the EAP classes use the SynchronizationContext class internally. In addition, some of the <br>EAP classes offer cancellation and progress reporting.<br>
In the whole FCL, there are just 17 types that implement the EAP pattern. Some of these <br>classes are derived from System.ComponentModel.Component, which allows them to be <br>dragged and dropped onto a Visual Studio design surface, but most of the classes derive  <br>directly from System.Object. Here is the list of classes that support the EAP:<br>
System.ComponentModel.Component-derived types  <br>   System.ComponentModel.BackgroundWorker <br>   System.Media.SoundPlayer <br>   System.Net.WebClient <br>   System.Net.NetworkInformation.Ping <br>   System.Windows.Forms.PictureBox (derived from Control)<br>
<hr>
<A name=804></a><b>786 </b><br>
<b>Part V  Threading</b><br>
System.Object-derived types <br>   System.Net.Mail.SmtpClient <br>   System.Deployment.Application.ApplicationDeployment <br>   System.Deployment.Application.InPlaceHostingManager <br>   System.Activities.WorkflowInvoker <br>   System.ServiceModel.Activities.WorkflowControlClient <br>   System.Net.PeerToPeer.PeerNameResolver <br>   System.Net.PeerToPeer.Collaboration.ContactManager <br>   System.Net.PeerToPeer.Collaboration.Peer <br>   System.Net.PeerToPeer.Collaboration.PeerContact <br>   System.Net.PeerToPeer.Collaboration.PeerNearMe <br>   System.ServiceModel.Discovery.AnnouncementClient <br>   System.ServiceModel.Discovery.DiscoveryClient<br>
The FCL ships 60 classes that implement the IAsyncResult pattern, including the following <br>classes for which there is no equivalent class available that implements the EAP: the various  <br>Stream-derived classes (FileStream, IsolatedStorageFileStream, DeflateStream, <br>GZipStream, and PipeStream), SqlCommand, and more.<br>
I should also point out that tools that produce Web service proxy classes, like WSDL.exe and <br>SvcUtil.exe, can produce proxy classes that support both the APM and the EAP.<br>
If you look at the 17 classes listed above, they are all related to performing I/O-bound <br>work except for one: BackgroundWorker. The BackgroundWorker class is designed for <br>doing asynchronous compute-bound work, but unfortunately, a lot of developers use <br>BackgroundWorker to perform synchronous I/O-bound work, which blocks a thread. I/O-<br>bound work should be performed using one of the other 16 EAP classes or any of the classes <br>that support the APM. The BackgroundWorker class offers the following three events:<br>
<b>  </b>DoWork  The method that you register with this event should contain the compute-<br>
bound code. This event is raised by a thread pool thread.<br>
<b>  </b>ProgressChanged  The method that you register with this event should contain  <br>
the code that updates the UI with progress information. This event is always <br>raised on the GUI thread. The DoWork event handler method must periodically call <br>BackgroundWorker's ReportProgress method to raise the ProgressChanged event.<br>
<b>  </b>RunWorkerCompleted  The method that you register with this event should contain <br>
the code that updates the UI with the result of the compute-bound operation. This <br>event is always raised on the GUI thread. The DoWork event handler method is passed a <br>reference to a DoWorkEventArgs object. This object's Result property must be set to <br>the value that the compute-bound operation wishes to return.<br>
<b>Converting the EAP to a </b>Task<br>
In the "Converting the IAsyncResult APM to a Task" section earlier in this chapter, I showed <br>how to use the IAsyncResult APM to turn an asynchronous operation into a Task so that it <br>could be used with the rest of the Task infrastructure. Well, it is also possible to turn an asyn-<br>chronous operation using the EAP into a Task. The System.Threading.Tasks namespace <br>defines a TaskCompletionSource class that looks like this:<br>
<hr>
<A name=805></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>787</b><br>
public class TaskCompletionSource&lt;TResult&gt; { <br>   public TaskCompletionSource(); <br>   public TaskCompletionSource(Object state, TaskCreationOptions creationOptions); <br> <br>   public void SetCanceled(); <br>   public void SetException(IEnumerable&lt;Exception&gt; exceptions); <br>   public void SetResult(TResult result); <br> <br>   public Task&lt;TResult&gt; Task { get; } <br> <br>   // Less important methods not shown <br>}<br>
Constructing a TaskCompletionSource object also causes the creation of a Task that you <br>can refer to by querying TaskCompletionSource's Task property. Then, when an asynchro-<br>nous operation completes, it uses the TaskCompletionSource object to set the reason for its <br>completion: cancel ation, unhandled exception, or its result. Cal ing one of the SetXxx methods <br>sets the state of the underlying Task object. Here is code showing how to turn the EAP into a <br>Task:<br>
internal sealed class MyFormTask : Form { <br>   protected override void OnClick(EventArgs e) { <br>      // The System.Net.WebClient class supports the Event-based Asynchronous Pattern <br>      WebClient wc = new WebClient(); <br> <br>      // Create the TaskCompletionSource and its underlying Task object <br>      var tcs = new TaskCompletionSource&lt;String&gt;(); <br> <br>      // When a string completes downloading, the WebClient object raises the  <br>      // DownloadStringCompleted event which will invoke our ProcessString method <br>      wc.DownloadStringCompleted += (sender, ea) =&gt; { <br>         // This code always executes on the GUI thread; set the Task's state  <br>         if (ea.Cancelled) tcs.SetCanceled(); <br>         else if (ea.Error != null) tcs.SetException(ea.Error); <br>         else tcs.SetResult(ea.Result); <br>      }; <br> <br>      // Have the Task continue with this Task that shows the result in a message box <br>      // NOTE: The ExecuteSynchronously flag is required to have this code run on the  <br>      // GUI thread; without the flag, the code runs on a thread pool thread  <br>      tcs.Task.ContinueWith(t =&gt; { <br>         try { <br>            MessageBox.Show(t.Result); <br>         } <br>         catch (AggregateException ae) { <br>            MessageBox.Show(ae.GetBaseException().Message); <br>         }}, TaskContinuationOptions.ExecuteSynchronously);   <br> <br>      // Start the asynchronous operation (this is like calling a BeginXxx method) <br>      wc.DownloadStringAsync(new Uri(&quot;http://Wintellect.com&quot;)); <br>      base.OnClick(e); <br>   } <br>}<br>
<hr>
<A name=806></a><b>788 </b><br>
<b>Part V  Threading</b><br>
<b>Comparing the APM and the EAP</b><br>
In this section, I compare the APM to the EPM. The biggest benefit of the EPM over the APM <br>is that it can be used with the Visual Studio offering a design-time approach to invoke asyn-<br>chronous operations. In addition, the EAP was introduced in the FCL at the same time as the <br>SynchronizationContext class, and therefore it has built into it the ability to understand an <br>application's threading model to ensure that, for GUI applications, the event handler method <br>is invoked on the GUI thread.<br>
However, the APM is closer to the metal and the EAP classes are typically implemented  <br>internally using the APM. This means that EAP classes tend to use more memory and perform  <br>slower than their APM equivalents. In fact, the EAP must allocate EventArg-derived objects  <br>for all progress reporting and completion events that are raised. Several EPM classes <br>also contain a collection of UserState objects identifying separate operations and an <br>AsyncOperation object, too. In a typical GUI application, these additional memory alloca-<br>tions (which cause additional garbage collections) are probably insignificant. However, the <br>EPM would be an inappropriate choice for building a high-performance server application.<br>
For simple scenarios, the EPM is easy to use and a fine choice. However, there are some <br>scenarios where the EPM will actually be more complicated to use. If you call the XxxAsync <br>method before registering the event handler method, it is possible that the asynchronous <br>operation could complete before registering the event handler method and then the event <br>handler method will not be invoked. Also, events are cumulative, and so you must unregister <br>a method from the event and register a new method with the event if you want your next <br>asynchronous operation to invoke a different method. Furthermore, static methods and <br>singleton classes cannot offer the EPM for the same reason: different parts of an application <br>may all register events at once, and all event handlers would be invoked when an operation <br>completes regardless of which part of the application issued the asynchronous operation.<br>
Error handling with the EAP is incongruous with the rest of the system. First, exceptions aren't <br>thrown; in your event handler, you must query the AsyncCompletedEventArgs's Exception <br>property to see if it is null or not. If it is not null, then you have to use if statements to <br>determine the type of the Exception-derived object instead of using catch blocks. And, if <br>your code ignores the error, then no unhandled exception occurs, errors go undetected, and <br>your application continues running with unpredictable results.<br>
<b>Programming Model Soup</b><br>
Over the years, the .NET Framework has amassed a number of asynchronous programming <br>models, each with its pros and cons, and I'm sure that new programming models will appear <br>in the future. In an effort to help you, I have produced Table 27-1, which summarizes the <br>various models that currently exist. For each model, I show what's its intended primary use is <br>(compute-bound or I/O-bound operations), how it can emulate the other kind of operation, <br>
<hr>
<A name=807></a><b> </b><br>
<b>Chapter 27  I/O-Bound Asynchronous Operations </b><br>
<b>789</b><br>
if the model supports parent/child relationships, if the model natively supports progress re-<br>porting, cancellation, blocking a thread until the operation completes (a feature you should <br>avoid), notifying you when a timeout expires, and if you can get the result (or exception) of <br>the operation when it completes. Here are some additional notes about Table 27-1:<br>
  Tasks offer improved performance over ThreadPool.QueueUserWorkItem or a  <br>
delegate's BeginInvoke if many tasks are being issued due to the work-stealing <br>queues.<br>
  You can use the PreFairness flag to get the same thread pool behavior as <br>
ThreadPool.QueueUserWorkItem or a delegate's BeginInvoke.<br>
  You can use a customized TaskScheduler, allowing you to change scheduling  <br>
algorithms without changing the code or programming model.<br>
  Task objects consume more memory than just cal ing ThreadPool.QueueUserWorkItem <br>
or a delegate's BeginInvoke. Calling a delegate's BeginInvoke method has known <br>performance issues, and while Task objects require more memory, tasks run faster and <br>are probably a better choice than calling a delegate's BeginInvoke method.<br>
  The IAsyncResult APM offers four rendezvous techniques, which complicates the <br>
model; however, if you mentally restrict yourself to the callback method technique (as I <br>do), then the model is simplified.<br>
  The IAsyncResult APM is generally faster and uses fewer resources than the EAP.<br>
  Some of the classes that support the EAP support cancellation.<br>
  The IAsyncResult APM doesn't support cancellation at all; however, you can always <br>
obtain cancellation behavior by setting a flag and throwing away the result when it <br>does complete. Wrapping the IAsyncResult pattern in a Task and setting the proper <br>ContinueWith callbacks can help you here.<br>
  The EAP is event-based, so that you can easily use it from within Visual Studio's <br>
Windows Forms, WPF, and Silverlight forms designers, and the notifying methods are <br>called in the right UI thread.<br>
<hr>
<A name=808></a><b>790 </b><br>
<b>Part V  Threading</b><br>
<b>n</b><br>
<b>/<br> <br>n</b><br>
<b>t<br>i<br>o</b><br>
<b>t<br>ur</b><br>
<b>c<br>e<br>p</b><br>
s<br>
s<br>
s<br>
s<br>
<b>Re</b><br>
<b>Ex</b><br>
No<br>
No<br>
No<br>
Ye<br>
Ye<br>
Ye<br>
Ye<br>
<b>t<br>u<br>o<br>me</b><br>
s<br>!<br>
s<br>
s<br>
s<br>
<b>Ti</b><br>
No<br>
Ye<br>
Ye<br>
Ye<br>
No<br>
No<br>
Ye<br>
<b>i<br>t</b><br>
s<br>
s<br>
<b>Wa</b><br>
No<br>
No<br>
No<br>
Ye<br>
Ye<br>
No<br>
No<br>
 <br>
 <br>f <br>
-<br>
e<br>s <br>
r i<br>
 <br>
h<br>e <br>
u<br>t<br>e<br>: <br>
Task<br>
u<br>p<br>
t <br>
i<br>s<br>c<br>a<br>r<br>d <br>
y<br>p<br>
<b>c<br>el</b><br>
p<br>
r<br>e <br>
 s<br>
e t<br>
<b>e<br>l<br>s</b><br>
<b>n</b><br>
Dispose<br>
m<br>
r<br>t<br>s i<br>
: D<br>
m<br>
s<br>
<b>d</b><br>
i<br>a <br>
i<br>a <br>
o<br>
e<br>f<br>o<br>
o<br>
O<br>
s<br>u<br>l<br>t<br>
i<br>s<br>c<br>a<br>r<br>d t<br>
s<br>u<br>l<br>t<br>.<br>
<b>o</b><br>
<b>Ca</b><br>
No<br>
V<br>
V<br>
Unregister<br>
C<br>
B<br>
s<br>t<br>a<br>r<br>t<br>s o<br>
Task<br>
p<br>
I/<br>
re<br>
No<br>
S<br>o<br>
d<br>
re<br>
Ye<br>
<b>g</b><br>
<b>g M<br>i<br>n</b><br>
<b>e<br>s<br>s </b><br>
<b>r<br>tin</b><br>
<b>m</b><br>
<b>gr</b><br>
<b>o</b><br>
e<br>
<b>o</b><br>
<b>p</b><br>
m<br>
<b>Pr</b><br>
<b>Re</b><br>
No<br>
No<br>
No<br>
No<br>
No<br>
So<br>
No<br>
<b>r<br>a<br>m<br>g<br>r<br>o</b><br>
<b>t<br> </b><br>
<b>s P</b><br>
<b>r<br>e<br>n</b><br>
<b>il<br>d</b><br>
<b>u</b><br>
<b>h</b><br>
s<br>
<b>o</b><br>
<b>Pa</b><br>
<b>/<br>C</b><br>
No<br>
No<br>
No<br>
Ye<br>
No<br>
No<br>
No<br>
<b>n</b><br>
 <br>
<b>r<br>o<br>c<br>h</b><br>
<b> </b><br>
'<br>s <br>
<b>s<br>y<br>n</b><br>
<b>a<br>r<br>y <br>d<br>n</b><br>
<b>'<br>s A</b><br>
r<br> <br>
<b>r<br>k</b><br>
<b>e<br>c<br>o</b><br>
 o<br>
'<br>s <br>
'<br>s <br>
<b>o</b><br>
<b>a<br>t<br>?</b><br>
<b>e<br>w</b><br>
<b>l<br>a<br>t<br>e S</b><br>
<b>h</b><br>
<b>u</b><br>
TaskScheduler<br>
<b>r<br>a<br>m</b><br>
<b>E<br>m</b><br>
<b>v<br>i<br>a W</b><br>
Sync I/O<br>
Sync I/O<br>
Sync I/O<br>
Sync I/O<br>
TaskCompletionSource<br>
a<br>n<br>d <br>
FromAsync<br>
Delegate<br>
BeginInvoke<br>
BackgroundWorker<br>
Delegate<br>
BeginInvoke<br>
<b>E<br>T F<br>N</b><br>
u<br>t<br>e<br>
u<br>t<br>e<br>
u<br>t<br>e<br>
u<br>t<br>e<br>
<b>e .</b><br>
<b>a<br>r<br>y<br> </b><br>
p<br>
p<br>
p<br>
p<br>
<b>h</b><br>
<b>i<br>m</b><br>
<b>e</b><br>
m<br>
m<br>
m<br>
m<br>
O<br>
O<br>
O<br>
<b>g t</b><br>
<b>Pr</b><br>
<b>Us</b><br>
Co<br>
Co<br>
Co<br>
Co<br>
I/<br>
I/<br>
I/<br>
<b>a<br>r<br>i<br>n</b><br>
 <br>
<b>p<br>m<br>o</b><br>
 <br>
<b> <br>C</b><br>
<b>7<br>-<br>1</b><br>
<b>e<br>l</b><br>
<b>L<br>E<br> 2</b><br>
<b>d<br>Mo</b><br>
<b>T<br>AB</b><br>
QueueUser<br>
   WorkItem<br>
Timer<br>
RegisterWaitFor<br>
   SingleObject<br>
Tasks<br>
IAsyncResult APM<br>
Event-based PM<br>
AsyncEnumerator<br>
<hr>
<A name=809></a>Chapter 28<br><b>Primitive Thread Synchronization </b><br>
<b>Constructs</b><br>
<b>In this chapter:<br>Class Libraries and Thread Safety . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 793<br>Primitive User-Mode and Kernel-Mode Constructs . . . . . . . . . . . . . . . . . . . . . . . 794<br>User-Mode Constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 796<br>Kernel-Mode Constructs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 813</b><br>
When a thread pool thread blocks, the thread pool creates additional threads, and the time <br>and memory resources required to create, destroy, and schedule threads is very expensive. <br>And when many developers see that they have threads in their program that are not do-<br>ing anything useful, they tend to create more threads in hopes that the new threads will do <br>something useful. The key to building scalable and responsive applications is to not block the <br>threads you have so that they can be used and reused to execute other tasks. Chapter 26, <br>"Compute-Bound Asynchronous Operations," focused on how to use existing threads to per-<br>form compute-bound operations, and Chapter 27, "I/O-Bound Asynchronous Operations," <br>focused on how to use threads when performing I/O-bound operations.<br>
In this chapter, I focus on thread synchronization. Thread synchronization is used to prevent <br>corruption when multiple threads access shared data <i>at the same time</i>. I emphasize <i>at the <br>same time</i> because thread synchronization is all about timing. If you have some data that is <br>accessed by two threads and those threads cannot possibly touch the data simultaneously, <br>then thread synchronization is not required at all. In Chapter 27, I showed some code that <br>implements a named-pipe server. In the ClientConnected method, a thread allocates a <br>Byte[] that will be filled with the data being sent from the client. When the client sends the <br>data, a different thread pool thread will execute the GotRequest method, and this method <br>will process the data in the Byte[]. Here we have two different threads accessing the same <br>data. But the application is architected in such a way that it is impossible for two threads to <br>access this same Byte[] at the same time. Therefore, no thread synchronization is used in <br>the named-pipe application at all.<br>
This is ideal because thread synchronization has many problems associated with it. First, it <br>is tedious and extremely error-prone. In your code, you must identify all data that could <br>potentially be touched by multiple threads at the same time. Then you must surround this <br>code with additional code that acquires and releases a thread synchronization lock. The lock <br>ensures that only one thread at a time can access the resource. If you forget to surround just <br>
<b> </b><br>
<b> </b><br>
<b>791</b><br>
<hr>
<A name=810></a><b>792 </b><br>
<b>Part V  Threading</b><br>
one block of code with a lock, then the data will become corrupted. Also, there is no way to <br>prove that you have added all your locking code correctly. You just have to run your applica-<br>tion, stress-test it a lot, and hope that nothing goes wrong. In fact, you should test your  <br>application on a machine that has as many CPUs as possible because the more CPUs you <br>have, the better chance that two or more threads will attempt to access the resource at the <br>same time, making it more likely you'll detect a problem.<br>
The second problem with locks is that they hurt performance. It takes time to acquire and <br>release a lock because there are additional method calls and because the CPUs must coordi-<br>nate with each other to determine which thread will acquire the lock first. Having the CPUs in <br>the machine communicate with each other this way hurts performance. For example, let's say <br>that you have code that adds a node to the head of a linked list:<br>
// This class is used by the LinkedList class <br>public class Node {  <br>   internal Node m_next;  <br>   // Other members not shown <br>} <br> <br>public sealed class LinkedList { <br>   private Node m_head; <br> <br>   public void Add(Node newNode) { <br>      // The two lines below perform very fast reference assignments <br>      newNode.m_next = m_head; <br>      m_head = newNode; <br>   } <br>}<br>
This Add method simply performs two reference assignments that can execute extremely fast. <br>Now, if we want to make Add thread safe so that multiple threads can call it simultaneously <br>without corrupting the linked list, then we need to have the Add method acquire and release <br>a lock:<br>
public sealed class LinkedList { <br>   private SomeKindOfLock m_lock = new SomeKindOfLock(); <br>   private Node m_head; <br> <br>   public void Add(Node newNode) { <br>      m_lock.Acquire(); <br>      // The two lines below perform very fast reference assignments <br>      newNode.m_next = m_head; <br>      m_head = newNode; <br>      m_lock.Release(); <br>   } <br>}<br>
While Add is now thread safe, it has also become substantially slower. How much slower <br>depends on the kind of lock chosen; I will compare the performance of various locks in this <br>chapter and in Chapter 29, "Hybrid Thread Synchronization Constructs." But even the fastest <br>
<hr>
<A name=811></a><b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>793</b><br>
lock could make the Add method several times slower than the version of it that didn't have <br>any lock code in it at all. Of course, the performance becomes significantly worse if the code <br>calls Add in a loop to insert several nodes into the linked list.<br>
The third problem with thread synchronization locks is that they allow only one thread to <br>access the resource at a time. This is the lock's whole reason for existing, but it is also a <br>problem because blocking a thread causes more threads to be created. So, for example, if a <br>thread pool thread attempts to acquire a lock that it cannot have, it is likely that the thread <br>pool will create a new thread to keep the CPUs saturated with work. As discussed in Chapter <br>25, "Thread Basics," creating a thread is very expensive in terms of both memory and perfor-<br>mance. And to make matters even worse, when the blocked threads gets to run again, it will <br>run with this new thread pool thread; Windows is now scheduling more threads than there <br>are CPUs, and this increases context switching, which also hurts performance.<br>
The summary of all of this is that thread synchronization is bad, so you should try to design <br>your applications to avoid as much of it as possible. To that end, you should avoid shared <br>data such as static fields. When a thread uses the new operator to construct an object, the <br>new operator returns a reference to the new object. At this point in time, only the thread <br>that constructs the object has a reference to it; no other thread can access that object. If you <br>avoid passing this reference to another thread that might use the object at the same time as <br>the creating thread, then there is no need to synchronize access to the object.<br>
Try to use value types because they are always copied, so each thread operates on its own <br>copy. Finally, it is OK to have multiple threads accessing shared data simultaneously if that <br>access is read-only. For example, many applications create some data structures during their <br>initialization. Once initialized, the application can create as many threads as it wants; if all <br>these threads just query the data, then all the threads can do this simultaneously without  <br>acquiring or releasing any locks. The String type is an example of this: Once a String object <br>is created, it is immutable, so many threads can access a single String object at the same <br>time without any chance of the String object becoming corrupted.<br>
<b>Class Libraries and Thread Safety</b><br>
Now, I'd like to say a quick word about class libraries and thread synchronization. Microsoft's <br>Framework Class Library (FCL) guarantees that all static methods are thread safe. This means <br>that if two threads call a static method at the same time, no data will get corrupted. The FCL <br>had to do this internally because there is no way that multiple companies producing different  <br>assemblies could coordinate on a single lock for arbitrating access to the resource. The <br>Console class contains a static field, inside which many of its methods acquire and release <br>to ensure that only one thread at a time is accessing the console.<br>
For the record, making a method thread safe does not mean that it internally takes a thread <br>synchronization lock. A thread-safe method means that data doesn't get corrupted if two <br>
<hr>
<A name=812></a><b>794 </b><br>
<b>Part V  Threading</b><br>
threads attempt to access the data at the same time. The System.Math class has a static <br>Max method implemented as follows:<br>
public static Int32 Max(Int32 val1, Int32 val2) { <br>   return (val1 &lt; val2) ? val2 : val1; <br>}<br>
This method is thread safe even though it doesn't take any lock. Since Int32 is a value type, <br>the two Int32 values passed to Max are copied into it and multiple threads could be calling  <br>Max simultaneously, but each thread is working on its own data, isolated from any other <br>thread.<br>
On the other hand, the FCL does not guarantee that instance methods are thread safe  <br>because adding all the locking code would hurt performance too much. And, in fact, if every <br>instance method acquires and releases a lock, then you ultimately end up having just one <br>thread running in your application at any given time, which hurts performance even more.  <br>As mentioned earlier, when a thread constructs an object, only this thread has a reference  <br>to the object, no other thread can access that object, and no thread synchronization is  <br>required when invoking instance methods. However, if the thread then exposes the reference <br>to the object--by placing it in a static field, passing as the state argument to ThreadPool.<br>QueueUserWorkItem or to a Task, and so on--then thread synchronization is required if the <br>threads could attempt simultaneous non­read-only access.<br>
It is recommended that your own class libraries follow this pattern; that is, make all your <br>static methods thread safe and make all your instance methods not thread-safe. There is one <br>caveat to this pattern: if the purpose of the instance method is to coordinate threads, then <br>the instance method should be thread safe. For example, one thread can cancel an opera-<br>tion by calling CancellationTokenSource's Cancel method, and another thread detects <br>that it should stop what it's doing by querying the corresponding CancellationToken's <br>IsCancellationRequested property. These two instance members have some special <br>thread synchronization code inside them to ensure that the coordination of the two threads <br>goes as expected.1<br>
<b>Primitive User-Mode and Kernel-Mode Constructs</b><br>
In this chapter, I explain the <i>primitive</i> thread synchronization constructs. By <i>primitive</i>, I mean <br>the simplest constructs that are available to use in your code. There are two kinds of primitive <br>constructs: user-mode and kernel-mode. Whenever possible, you should use the primitive <br>user-mode constructs because they are significantly faster than the kernel-mode constructs <br>as they use special CPU instructions to coordinate threads. This means that the coordination <br>is occurring in hardware (which is what makes it fast). But this also means that the Microsoft <br>
1  Specifically, the field that both members access is marked as volatile, a concept that will be discussed later in <br>
this chapter.<br>
<hr>
<A name=813></a><b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>795</b><br>
Windows operating system never detects that a thread is blocked on a primitive user-mode <br>construct. Since a thread pool thread blocked on a user-mode primitive construct is never <br>considered blocked, the thread pool will not create a new thread to replace the temporarily <br>blocked thread. In addition, these CPU instructions block the thread for an incredibly short <br>period of time.<br>
Wow! All of this sounds great, doesn't it? And it is great, which is why I recommend using <br>these constructs as much as possible. However, there is a downside: Only the Windows  <br>operating system kernel can stop a thread from running so that it is not wasting CPU time.  <br>A thread running in user mode can be preempted by the system, but the thread will be <br>scheduled again as soon as possible. So a thread that wants to acquire some resource but <br>can't get it spins in user mode. This potentially wastes a lot of CPU time, which would be  <br>better spent performing other work or even just letting the CPU go idle to conserve power.<br>
This brings us to the primitive kernel-mode constructs. The kernel-mode constructs are  <br>provided by the Windows operating system itself. As such, they require that your application's <br>threads call functions implemented in the operating system kernel. Having threads transition <br>from user mode to kernel mode and back incurs a big performance hit, which is why kernel-<br>mode constructs should be avoided.2 However, they do have a positive feature: When a <br>thread uses a kernel-mode construct to acquire a resource that another thread has, Windows <br>blocks the thread so that it is no longer wasting CPU time. Then, when the resource becomes <br>available, Windows resumes the thread, allowing it to access the resource.<br>
A thread waiting on a construct might block forever if the thread currently holding the con-<br>struct never releases it. If the construct is a user-mode construct, the thread is running on a <br>CPU forever, and we call this a <i>livelock</i>. If the construct is a kernel-mode construct, the thread <br>is blocked forever, and we call this a <i>deadlock</i>. Both of these are bad, but of the two, a dead-<br>lock is always preferable to a livelock because a livelock wastes both CPU time and memory <br>(the thread's stack, etc.), while a deadlock wastes only memory.3<br>
In an ideal world, we'd like to have constructs that take the best of both worlds. That is, we'd <br>like a construct that is fast and non-blocking (like the user-mode constructs) when there is no <br>contention. But when there is contention for the construct, we'd like it to be blocked by the <br>operating system kernel. Constructs that work like this do exist; I call them <i>hybrid constructs,</i> <br>and I will discuss them in Chapter 29. It is very common for applications to use the hybrid <br>constructs because in most applications, it is rare for two or more threads to attempt to  <br>access the same data at the same time. A hybrid construct keeps your application running <br>fast most of the time, and occasionally it runs slowly to block the thread. The slowness usually <br>doesn't matter at this point because your thread is going to be blocked anyway.<br>
2  I'll show a program that measures the performance later in this chapter.<br>3  I say that the memory allocated for the thread is wasted because the memory is not being used in a productive <br>
manner if the thread is not making forward progress.<br>
<hr>
<A name=814></a><b>796 </b><br>
<b>Part V  Threading</b><br>
Many of the CLR's thread synchronization constructs are really just object-oriented class <br>wrappers around Win32 thread synchronization constructs. After all, CLR threads are <br>Windows threads, which means that Windows schedules and controls the synchronization of <br>threads. Windows thread synchronization constructs have been around since 1992, and a ton <br>of material has been written about them.4 Therefore, I give them only cursory treatment in <br>this chapter.<br>
<b>User-Mode Constructs</b><br>
There are two kinds of primitive user-mode thread synchronization constructs:<br>
  Volatile constructs, which perform an atomic read <i>or</i> write operation on a variable  <br>
containing a simple data type<br>
  Interlocked constructs, which perform an atomic read <i>and</i> write operation on a variable <br>
containing a simple data type<br>
All the volatile and interlocked constructs require you to pass a reference (memory address) <br>to a variable containing a simple data type. Some CPU architectures require that this memory <br>address be properly aligned or else the constructs will throw a DataMisalignedException.<br>
This means that a variable containing a 1-byte, 2-byte, and 4-byte value must be located at a <br>memory address that is a multiple of 1, 2, or 4, respectively, and that a variable containing  <br>an 8-byte value is located at a memory address that allows the value to be manipulated <br>atomically by the underlying hardware (a multiple of 4 or 8). Specifically, this means (S)Byte <br>variables are on a 1-byte boundary, (U)Int16 variables are on a 2-byte boundary, (U)Int32 <br>and Single variables are on a 4-byte boundary, and (U)Int64 and Double variables are on <br>a 4-byte or an 8-byte boundary. All reference variables and (U)IntPtr variables are 4 bytes <br>wide in a 32-bit process and 8 bytes wide in a 64-bit process, so these variables are always <br>aligned on 4-byte or 8-byte boundaries, depending on the type of process.<br>
Fortunately, the CLR ensures that fields are properly aligned automatically unless the  <br>enclosing type has the [StructLayout(LayoutKind.Explicit)] attribute applied to it and <br>[FieldOffset(...)] attributes applied to individual fields, forcing fields to be misaligned. If <br>you avoid using these attributes, then you should have no trouble when using these user-<br>mode constructs.<br>
Accessing any properly aligned variable of the types mentioned above is always atomic.  <br>This means that all bytes within that variable are read from or written to all at once. So, for <br>example, if you have the following class:<br>
4  In fact, my own book, <i>Windows via C/C++, 5th Edition</i> (Microsoft Press, 2007), has several chapters devoted to this <br>
subject.<br>
<hr>
<A name=815></a><b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>797</b><br>
internal static class SomeType { <br>   public static Int32 x = 0; <br>}<br>
then, if some thread executes this line of code:<br>
SomeType.x = 0x01234567;<br>
the x variable will change from 0x00000000 to 0x01234567 all at once (atomically). Another <br>thread cannot possibly see the value in an intermediate state. For example, it is impossible <br>for some other read to query SomeType.x and get a value of 0x01230000. However, while <br>the reads and writes to a properly aligned variable are guaranteed to happen all at once, you <br>are not guaranteed <i>when</i> they happen due to compiler and CPU optimizations. The volatile <br>constructs ensure that the read or write operation is atomic and, more importantly, they also <br>control the timing of these atomic operations. The interlocked constructs can perform opera-<br>tions that are slightly more complex than simple read and write operations, and they also <br>control the timing of these operations.<br>
Suppose that the x field in the SomeType class above is an Int64 that is not properly aligned. <br>If a thread executes this line of code:<br>
SomeType.x = 0x0123456789abcdef;<br>
it is possible that another thread could query x and get a value of 0x0123456700000000 or <br>0x0000000089abcdef since the read and write operations are not atomic. This is called a <i>torn <br>read</i>.<br>
<b>Volatile Constructs</b><br>
Back in the early days of computing, software was written using assembly language. <br>Assembly language is very tedious because programmers must explicitly state everything: <br>Use this CPU register for this, branch to that, call indirect through this other thing, and so <br>on. To simplify programming, higher-level languages were introduced. These higher-level <br>languages introduced common useful constructs, like if/else, switch/case, various <br>loops, local variables, arguments, virtual method calls, operator overloads, and much more. <br>Ultimately, these language compilers must convert the high-level constructs down to the <br>low-level constructs so that the computer can actually do what you want it to do.<br>
In other words, the C# compiler translates your C# constructs into Intermediate Language <br>(IL), which is then converted by the just-in-time (JIT) compiler into native CPU instructions, <br>which must then be processed by the CPU itself. In addition, the C# compiler, the JIT com-<br>piler, and even the CPU itself can optimize your code. For example, the following ridiculous <br>method can ultimately be compiled into nothing:<br>
<hr>
<A name=816></a><b>798 </b><br>
<b>Part V  Threading</b><br>
private static void OptimizedAway() { <br>   // Constant expression is computed at compile time resulting in zero <br>   Int32 value = (1 * 100) ­ (50 * 2); <br> <br>   // If value is 0, the loop never executes <br>   for (Int32 x = 0; x &lt; value; x++) { <br>       // There is no need to compile the code in the loop since it can never execute <br>      Console.WriteLine(&quot;Jeff&quot;); <br>   } <br>}<br>
In this code, the compiler can see that value will always be 0;<b> </b>therefore, the loop will <br>never execute and consequently, there is no need to compile the code inside the loop. <br>This method could be compiled down to nothing. In fact, when JITting a method that calls <br>OptimizedAway, the JITter will try to inline the OptimizedAway method's code. Since there is <br>no code, the JITter will even remove the code that tries to call OptimizedAway. We love this <br>feature of compilers. As developers, we get to write the code in the way that makes the most <br>sense to us. The code should be easy to write, read, and maintain. Then compilers translate <br>our intentions into machine-understandable code. We want our compilers to do the best job <br>possible for us.<br>
When the C# compiler, JIT compiler, and CPU optimize our code, they guarantee us that the <br>intention of the code is preserved. That is, from a single-threaded perspective, the method <br>does what we want it to do, although it may not do it exactly the way we described in our <br>source code. However, the intention might not be preserved from a multithreaded perspec-<br>tive. Here is an example where the optimizations make the program not work as expected:<br>
internal static class StrangeBehavior { <br>   // As you'll see later, mark this field as volatile to fix the problem <br>   private static Boolean s_stopWorker = false; <br> <br>   public static void Main() { <br>      Console.WriteLine(&quot;Main: letting worker run for 5 seconds&quot;); <br>      Thread t = new Thread(Worker); <br>      t.Start(); <br>      Thread.Sleep(5000); <br>      s_stopWorker = true; <br>      Console.WriteLine(&quot;Main: waiting for worker to stop&quot;); <br>      t.Join(); <br>   } <br> <br>   private static void Worker(Object o) { <br>      Int32 x = 0; <br>      while (!s_stopWorker) x++; <br>      Console.WriteLine(&quot;Worker: stopped when x={0}&quot;, x); <br>   } <br>}<br>
In this code, the Main method creates a new thread that executes the Worker method. This <br>Worker method counts as high as it can before being told to stop. The Main method allows  <br>the Worker thread to run for 5 seconds before telling it to stop by setting the static <br>
<hr>
<A name=817></a><b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>799</b><br>
Boolean field to true. At this point, the Worker thread should display what it counted up to, <br>and then the thread will terminate. The Main thread waits for the Worker thread to terminate <br>by calling Join, and then the Main thread returns, causing the whole process to terminate.<br>
Looks simple enough, right? Well, the program has a potential problem due to all the  <br>optimizations that could happen to it. You see, when the Worker method is compiled, the <br>compiler sees that s_stopWorker is either true or false, and it also sees that this value  <br>never changes inside the Worker method itself. So the compiler could produce code that <br>checks s_stopWorker first. If s_stopWorker is true, then "Worker: stopped when x=0" <br>will be displayed. If s_stopWorker is false, then the compiler produces code that enters <br>an infinite loop that increments x forever. You see, the optimizations cause the loop to run <br>very fast because checking s_stopWorker only occurs once before the loop; it does not get <br>checked with each iteration of the loop.<br>
If you actually want to see this in action, put this code in a .cs file and compile the code using <br>C#'s /platform:x86 and /optimize+ switches. Then run the resulting EXE file, and you'll see <br>that the program runs forever. Note that you have to compile for x86 ensuring that the x86 <br>JIT compiler is used at runtime. The x86 JIT compiler is more mature than the x64 or IA64 JIT <br>compilers, so it performs more aggressive optimizations. The other JIT compilers do not per-<br>form this particular optimization, and therefore the program runs to completion with these <br>other JIT compilers. This highlights another interesting point about all of this. Whether your <br>program behaves as expected depends on a lot of factors, such as which compiler version <br>and compiler switches are used, which JIT compiler is used, and which CPU your code is run-<br>ning on. In addition, to see the program above run forever, you must not run the program <br>under a debugger because the debugger causes the JIT compiler to produce unoptimized <br>code that is easier to step through.<br>
Let's look at another example, which has two threads that are both accessing two fields:<br>
internal sealed class ThreadsSharingData {  <br>   private Int32 m_flag = 0;  <br>   private Int32 m_value = 0;  <br>  <br>   // This method is executed by one thread  <br>   public void Thread1() {  <br>      // Note: These could execute in reverse order <br>      m_value = 5;  <br>      m_flag  = 1;  <br>   }  <br>  <br>   // This method is executed by another thread  <br>   public void Thread2() {  <br>      // Note: m_value could be read before m_flag <br>      if (m_flag == 1)  <br>         Console.WriteLine(m_value);  <br>   }  <br>}<br>
<hr>
<A name=818></a><b>800 </b><br>
<b>Part V  Threading</b><br>
The problem with this code is that the compilers/CPU could translate the code in such a way <br>as to reverse the two lines of code in the Thread1 method. After all, reversing the two lines <br>of code does not change the intention of the method. The method needs to get a 5 in  <br>m_value and a 1 in m_flag. From a single-threaded application's perspective, the order of <br>executing this code is unimportant. If these two lines do execute in reverse order, then  <br>another thread executing the Thread2 method <i>could</i> see that m_flag is 1 and then display 0.<br>
Let's look at this code another way. Let's say that the code in the Thread1 method executes <br>in <i>program order</i> (the way it was written). When compiling the code in the Thread2 method, <br>the compiler must generate code to read m_flag and m_value from RAM into CPU registers. <br>It is possible that RAM will deliver the value of m_value first, which would contain a 0. Then <br>the Thread1 method could execute, changing m_value to 5 and m_flag to 1. But Thread2's <br>CPU register doesn't see that m_value has been changed to 5 by this other thread, and then <br>the value in m_flag could be read from RAM into a CPU register and the value of m_flag <br>becomes 1 now, causing Thread2 to again display 0.<br>
This is all very exciting stuff and is more likely to cause problems in a release build of your <br>program than in a debug build of your program, making it particularly tricky to detect these <br>problems and correct your code. Now, let's talk about how to correct your code.<br>
The System.Threading.Thread class offers three static methods that look like this5:<br>
public sealed class Thread { <br>   public static void  VolatileWrite(ref Int32 address, Int32 value);  <br>   public static Int32 VolatileRead(ref Int32 address);  <br>   public static void  MemoryBarrier(); <br>}<br>
These methods are special. In effect, these methods disable some optimizations usually <br>performed by the C# compiler, the JIT compiler, and the CPU itself. Here's how the methods <br>work:<br>
  The VolatileWrite method forces the value in address to be written to at the point <br>
of the call. In addition, any <i>earlier</i> program-order loads and stores must occur <i>before</i> <br>the call to VolatileWrite.<br>
  The VolatileRead method forces the value in address to be read from at the point of <br>
the call. In addition, any <i>later</i> program-order loads and stores must occur <i>after</i> the call <br>to VolatileRead.<br>
  The MemoryBarrier method doesn't access memory but it forces any <i>earlier</i> program-<br>
order loads and stores to be completed <i>before</i> the call to MemoryBarrier. And it also <br>forces any <i>later</i> program-order loads and stores to be completed <i>after</i> the call to <br>MemoryBarrier. MemoryBarrier is much less useful than the other two methods.<br>
5  There are also overloads of VolatileRead and VolatileWrite that operate on the following types: (S)Byte, <br>
(U)Int16, UInt32, (U)Int64, (U)IntPtr, Single, Double, and Object.<br>
<hr>
<A name=819></a><IMG src="CLRviaCsharp-819_1.jpg"><br>
<b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>801</b><br>
<b>Important  </b>I know that this can be very confusing, so let me summarize it as a simple rule: <br>When threads are communicating with each other via shared memory, write the last value by <br>calling VolatileWrite and read the first value by calling VolatileRead.<br>
So now we can fix the ThreadsSharingData class using these methods:<br>
internal sealed class ThreadsSharingData { <br>    private Int32 m_flag = 0; <br>    private Int32 m_value = 0; <br> <br>    // This method is executed by one thread  <br>    public void Thread1() { <br>        // Note: 5 must be written to m_value before 1 is written to m_flag <br>        m_value = 5; <br>        Thread.VolatileWrite(ref m_flag, 1); <br>    } <br> <br>    // This method is executed by another thread  <br>    public void Thread2() { <br>        // Note: m_value must be read after m_flag is read  <br>        if (Thread.VolatileRead(ref m_flag) == 1)  <br>            Console.WriteLine(m_value); <br>    } <br>}<br>
First, notice that we are following the rule. The Thread1 method writes two values out to <br>fields that are shared by multiple threads. The last value that we want written (setting m_flag <br>to <b>1</b>) is performed by calling VolatileWrite. The Thread2 method reads two values from <br>fields shared by multiple threads, and the first value being read (m_flag) is performed by <br>calling VolatileRead.<br>
But what is really happening here? Well, for the Thread1 method, the VolatileWrite <br>call ensures that all the writes above it are completed before a 1 is written to m_flag. <br>Since m_value = 5 is before the call to VolatileWrite, it must complete first. In fact, if <br>there were many variables being modified before the call to VolatileWrite, they would <br>all have to complete before 1 is written to m_flag. Note that the writes before the call to <br>VolatileWrite can be optimized to execute in any order; it's just that all the writes have to <br>complete before the call to VolatileWrite.<br>
For the Thread2 method, the VolatileRead call ensures that all variable reads after it <br>start after the value in m_flag has been read. Since reading m_value is after the call to <br>VolatileRead, the value must be read after having read the value in m_flag. If there were <br>many reads after the call to VolatileRead, they would all have to start after the value in <br>m_flag has been read. Note that the reads after the call to VolatileRead can be optimized <br>to execute in any order; it's just that the reads can't start happening until after the call to <br>VolatileRead.<br>
<hr>
<A name=820></a><b>802 </b><br>
<b>Part V  Threading</b><br>
<b>C#'s Support for Volatile Fields<br></b>Making sure that programmers call the VolatileRead and VolatileWrite methods cor-<br>rectly is a lot to ask. It's hard for programmers to keep all of this in their minds and to start <br>imagining what other threads might be doing to shared data in the background. To simplify <br>this, the C# compiler has the volatile keyword, which can be applied to static or instance <br>fields of any of these types: Byte, SByte, Int16, UInt16, Int32, UInt32, Char, Single, or <br>Boolean. You can also apply the volatile keyword to reference types and any enum field so <br>long as the enumerated type has an underlying type of Byte, SByte, Int16, UInt16, Int32, <br>UInt32, Single, or Boolean. The JIT compiler ensures that all accesses to a volatile field are <br>performed as volatile reads and writes so that it is not necessary to explicitly call Thread's <br>static VolatileRead or VolatileWrite methods. Furthermore, the volatile keyword tells <br>the C# and JIT compilers not to cache the field in a CPU register, ensuring that all reads to <br>and from the field actually cause the value to be read from memory.<br>
Using the volatile keyword, we can rewrite the ThreadsSharingData class as follows:<br>
internal sealed class ThreadsSharingData { <br>   private volatile Int32 m_flag = 0; <br>   private          Int32 m_value = 0; <br> <br>   // This method is executed by one thread  <br>   public void Thread1() { <br>      // Note: 5 must be written to m_value before 1 is written to m_flag <br>      m_value = 5; <br>      m_flag = 1; <br>   } <br> <br>   // This method is executed by another thread  <br>   public void Thread2() { <br>      // Note: m_value must be read after m_flag is read  <br>      if (m_flag == 1) <br>         Console.WriteLine(m_value); <br>   } <br>}<br>
There are some developers (and I am one of them) who do not like C#'s volatile keyword, <br>and they think that the language should not provide it. Our thinking is that most algorithms <br>require few volatile read or write accesses to a field and that most other accesses to the field <br>can occur normally, improving performance; seldom is it required that all accesses to a field <br>be volatile. For example, it is difficult to interpret how to apply volatile read operations to <br>algorithms like this one:<br>
m_amount = m_amount + m_amount; // Assume m_amount is a volatile field defined in a class<br>
Normally, an integer number can be doubled simply by shifting all bits left by 1 bit, and <br>many compilers can examine the code above and perform this optimization. However, if  <br>m_amount is a volatile field, then this optimization is not allowed. The compiler must pro-<br>duce code to read m_amount into a register and then read it again into another register, add <br>
<hr>
<A name=821></a><b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>803</b><br>
the two registers together, and then write the result back out to the m_amount field. The un-<br>optimized code is certainly bigger and slower; it would be unfortunate if it were contained <br>inside a loop.<br>
Furthermore, C# does not support passing a volatile field by reference to a method. For <br>example, if m_amount is defined as a volatile Int32, attempting to call Int32's TryParse <br>method causes the compiler to generate a warning as shown here:<br>
Boolean success = Int32.TryParse(&quot;123&quot;, out m_amount);  <br>// The above line causes the C# compiler to generate a warning:  <br>// CS0420: a reference to a volatile field will not be treated as volatile<br>
<b>Interlocked Constructs</b><br>
Thread's VolatileRead method performs an atomic read operation, and its VolatileWrite <br>method performs an atomic write operation. That is, each method performs either an atomic <br>read operation <i>or</i> an atomic write operation. In this section, we look at the static System.<br>Threading.Interlocked class's methods. Each of the methods in the Interlocked class <br>performs an atomic read <i>and</i> write operation. In addition, all the Interlocked methods are <br>full memory fences. That is, any variable writes before the call to an Interlocked method <br>execute before the Interlocked method, and any variable reads after the call execute after <br>the call.<br>
The static methods that operate on Int32 variables are by far the most commonly used <br>methods. I show them here:<br>
public static class Interlocked {  <br>   // return (++location)  <br>   public static Int32 Increment(ref Int32 location);  <br>  <br>   // return (--location)  <br>   public static Int32 Decrement(ref Int32 location);  <br>  <br>   // return (location1 += value)  <br>   // Note: value can be a negative number allowing subtraction  <br>   public static Int32 Add(ref Int32 location1, Int32 value);  <br>  <br>   // Int32 old = location1; location1 = value; return old;  <br>   public static Int32 Exchange(ref Int32 location1, Int32 value);  <br>  <br>   // Int32 old = location1;  <br>   // if (location1 == comparand) location1 = value; <br>   // return old;  <br>   public static Int32 CompareExchange(ref Int32 location1,   <br>      Int32 value, Int32 comparand);  <br>   ...  <br>}<br>
<hr>
<A name=822></a><b>804 </b><br>
<b>Part V  Threading</b><br>
There are also overloads of the above methods that operate on Int64 values. Furthermore, <br>the Interlocked class offers Exchange and CompareExchange methods that take Object, <br>IntPtr, Single, and Double, and there is also a generic version in which the generic type is <br>constrained to class (any reference type).<br>
Personally, I love the Interlocked methods because they are relatively fast and you can do <br>so much with them. Let me show you some code that uses the Interlocked methods to <br>asynchronously query several Web servers for data. This code is pretty short, never blocks <br>any threads, and uses thread pool threads to scale automatically, consuming up to the  <br>number of CPUs available if its workload could benefit from it. In addition, the code, as is, <br>supports accessing up to 2,147,483,647 (Int32.MaxValue) Web servers. In other words, this <br>code is a great model to follow for your own scenarios.<br>
internal sealed class MultiWebRequests { <br>   // This helper class coordinates all the asynchronous operations <br>   private AsyncCoordinator m_ac = new AsyncCoordinator(); <br> <br>   // This is the set of Web servers we want to query <br>   private WebRequest[] m_requests = new WebRequest[] { <br>      WebRequest.Create(&quot;http://Wintellect.com/&quot;), <br>      WebRequest.Create(&quot;http://Microsoft.com/&quot;) <br>   }; <br> <br>   // Create the response array: one response for each request <br>   private WebResponse[] m_results = new WebResponse[2];  <br> <br>   public MultiWebRequests(Int32 timeout = Timeout.Infinite) { <br>      // Asynchronously initiate all the requests all at once <br>      for (Int32 n = 0; n &lt; m_requests.Length; n++) { <br>          m_ac.AboutToBegin(1); <br>          m_requests[n].BeginGetResponse(EndGetResponse, n); <br>      } <br> <br>      // Tell the helper class that all operations have been initiated <br>      // and to call AllDone when all operations complete, Cancel is  <br>      // called, or the timeout occurs <br>      m_ac.AllBegun(AllDone, timeout); <br>   } <br> <br>   // Calling this method indicates that the results don't matter anymore <br>   public void Cancel() { m_ac.Cancel(); } <br> <br>   // As each Web server responds, this method is called <br>   private void EndGetResponse(IAsyncResult result) { <br>      // Get the index corresponding to the request <br>      Int32 n = (Int32)result.AsyncState; <br> <br>      // Store the response in the same index as the request <br>      m_results[n] = m_requests[n].EndGetResponse(result); <br> <br>      // Tell the helper class that a Web server responded <br>      m_ac.JustEnded(); <br>   } <br> <br>
<hr>
<A name=823></a><b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>805</b><br>
   // This method is called after all Web servers respond,  <br>   // Cancel is called, or the timeout occurs <br>   private void AllDone(CoordinationStatus status) { <br>      switch (status) { <br>         case CoordinationStatus.Cancel: <br>            Console.WriteLine(&quot;The operation was canceled&quot;); break; <br> <br>         case CoordinationStatus.Timeout: <br>            Console.WriteLine(&quot;The operation timed-out&quot;); break; <br> <br>         case CoordinationStatus.AllDone: <br>            Console.WriteLine(&quot;Here are the results from all the Web servers&quot;); <br>            for (Int32 n = 0; n &lt; m_requests.Length; n++) { <br>               Console.WriteLine(&quot;{0} returned {1} bytes.&quot;, <br>                  m_results[n].ResponseUri, m_results[n].ContentLength); <br>            } <br>            break; <br>      } <br>   } <br>}<br>
OK, the code above doesn't actually use any Interlocked methods directly because I  <br>encapsulated all the coordination code in a reusable class called AsyncCoordinator, which <br>I'll explain shortly. Let me first explain what this class is doing. When the MultiWebRequest <br>class is constructed, it initializes an AsyncCoordinator, the array of WebRequest objects, <br>and the array of WebResponse objects. It then issues all the Web requests asynchronously by <br>calling BeginGetResponse. Just before issuing each request, it calls the AsyncCoordinator's <br>AboutToBegin method, passing it the number of requests about to be issued.6<br>
After all the Web servers' requests have been made, AsyncCoordinator's AllBegun method <br>is called, passing it the name of the method that should execute when all the operations <br>complete (AllDone) and a timeout value. As each Web server responds, various thread pool <br>threads will call MultiWebRequests's EndGetResponse method. This method determines <br>which request it is processing (by examining the IAsyncResult's AsyncState property) <br>and then saves the WebResponse object in the m_results array. After storing each result, <br>AsyncCoordinator's JustEnded method is called to let the AsyncCoordinator object know <br>that an operation completed.<br>
If all the operations have completed, then the AsyncCoordinator will invoke the AllDone <br>method to process the results from all the Web servers. The code executing the AllDone <br>method will be the thread pool thread that just happened to get the last Web server  <br>response. If timeout or cancellation occurs, then AllDone will be invoked via whatever thread <br>pool thread notifies the AsyncCoordinator of timeout or using whatever thread happened <br>to call the Cancel method. There is also a chance that the thread issuing the Web server  <br>requests could invoke AllDone itself if the last request completes before AllBegin is called.<br>
6  The code would still work correctly if it was rewritten calling m_ac.AboutToBeging(m_requests.Length<b>)</b> just <br>
once before the for loop instead of calling AboutToBegin inside the loop.<br>
<hr>
<A name=824></a><b>806 </b><br>
<b>Part V  Threading</b><br>
Note that there is a race because it is possible that all Web server requests complete, <br>AllBegun is called, timeout occurs, and Cancel is called all at the exact same time. If this <br>happens, then the AsyncCoordinator will select a winner and three losers, ensuring  <br>that the AllDone method is never called more than once. The winner is identified by the <br>status argument passed into AllDone, which can be one of the symbols defined by the <br>CoordinationStatus type:<br>
internal enum CoordinationStatus { AllDone, Timeout, Cancel };<br>
Now that you get a sense of what happens, let's take a look at how it works. The <br>AsyncCoordinator class encapsulates all the thread coordination logic in it. It uses <br>Interlocked methods for everything to ensure that the code runs extremely fast and that <br>no threads ever block. Here is the code for this class:<br>
internal sealed class AsyncCoordinator { <br>   private Int32 m_opCount = 1;        // Decremented by AllBegun <br>   private Int32 m_statusReported = 0; // 0=false, 1=true <br>   private Action&lt;CoordinationStatus&gt; m_callback; <br>   private Timer m_timer; <br> <br>   // This method MUST be called BEFORE calling a BeginXxx method <br>   public void AboutToBegin(Int32 opsToAdd = 1) {  <br>      Interlocked.Add(ref m_opCount, opsToAdd);  <br>   } <br> <br>   // This method MUST be called AFTER calling an EndXxx method <br>   public void JustEnded() { <br>      if (Interlocked.Decrement(ref m_opCount) == 0)  <br>         ReportStatus(CoordinationStatus.AllDone); <br>   } <br> <br>   // This method MUST be called AFTER calling ALL BeginXxx methods <br>   public void AllBegun(Action&lt;CoordinationStatus&gt; callback,  <br>      Int32 timeout = Timeout.Infinite) { <br> <br>      m_callback = callback; <br>      if (timeout != Timeout.Infinite) <br>         m_timer = new Timer(TimeExpired, null, timeout, Timeout.Infinite); <br>      JustEnded(); <br>   } <br> <br>   private void TimeExpired(Object o) { ReportStatus(CoordinationStatus.Timeout); } <br>   public void Cancel()               { ReportStatus(CoordinationStatus.Cancel); } <br> <br>   private void ReportStatus(CoordinationStatus status) { <br>      // If status has never been reported, report it; else ignore it <br>      if (Interlocked.Exchange(ref m_statusReported, 1) == 0)  <br>         m_callback(status); <br>   } <br>}<br>
<hr>
<A name=825></a><IMG src="CLRviaCsharp-825_1.jpg"><br>
<b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>807</b><br>
The most important field in this class is the m_opCount field. This field keeps track of the <br>number of asynchronous operations that are still outstanding. Just before each asynchronous <br>operation is started, AboutToBegin is called. This method calls Interlocked.Add to add the <br>number passed to it to the m_opCount field in an atomic way. Adding to m_opCount must <br>be performed atomically because Web servers could be responding on thread pool threads <br>as more operations are being started. As Web servers respond, JustEnded is called. This <br>method calls Interlocked.Decrement to atomically subtract 1 from m_opCount. Whichever <br>thread happens to set m_opCount to 0 calls<b> </b>ReportStatus.<br>
<b>Note  </b>The m_opCount field is initialized to 1 (not 0); this is critically important as it ensures that <br>AllDone is not invoked while the thread executing the constructor method is still issuing Web <br>server requests. Before the constructor calls AllBegun, there is no way that m_opCount will ever <br>reach 0. When the constructor calls AllBegun, AllBegun internally calls JustEnded, which  <br>decrements m_opCount and effectively undoes the effect of having initialized it to 1. Now,  <br>m_opCount can reach 0, but only after we know that all the Web server requests have been  <br>initiated.<br>
The ReportStatus method arbitrates the race that can occur among all the operations  <br>completing, the timeout occurring, and Cancel being called. ReportStatus must make sure <br>that only one of these conditions is considered the winner so that the m_callback method <br>is invoked only once. Arbitrating the winner is done via calling Interlocked.Exchange, <br>passing it a reference to the m_statusReported field. This field is really treated as a Boolean <br>variable; however, it can't actually be a Boolean variable because there are no Interlocked <br>methods that accept a Boolean variable. So I use an Int32 variable instead where 0 means <br>false and 1 means true.<br>
Inside ReportStatus, the Interlocked.Exchange call will change m_statusReported to 1. <br>But only the first thread to do this will see Interlocked.Exchange return a <b>0</b>, and only this <br>thread will invoke the callback method. Any other threads that call Interlocked.Exchange <br>will get a return value of 1, effectively notifying these threads that the callback method has <br>already been invoked and therefore it should not be invoked again.<br>
<b>Implementing a Simple Spin Lock</b><br>
The Interlocked methods are great but they mostly operate on Int32 values. What if you <br>need to manipulate a bunch of fields in a class object atomically? In this case, we need a <br>way to stop all threads but one from entering the region of code that manipulates the fields. <br>Using Interlocked methods, we can build a thread synchronization lock:<br>
<hr>
<A name=826></a><b>808 </b><br>
<b>Part V  Threading</b><br>
internal struct SimpleSpinLock { <br>   private Int32 m_ResourceInUse; // 0=false (default), 1=true <br> <br>   public void Enter() { <br>      // Set the resource to in-use and if this thread  <br>      // changed it from Free, then return <br>      while (Interlocked.Exchange(ref m_ResourceInUse, 1) != 0) { <br>         /* Black Magic goes here... */ <br>      } <br>   } <br> <br>   public void Leave() { <br>      // Mark the resource as Free <br>      Thread.VolatileWrite(ref m_ResourceInUse, 0); <br>   } <br>}<br>
And here is a class that shows how to use the SimpleSpinLock:<br>
public sealed class SomeResource { <br>   private SimpleSpinLock m_sl = new SimpleSpinLock(); <br> <br>   public void AccessResource() { <br>      m_sl.Enter(); <br>      // Only one thread at a time can get in here to access the resource... <br>      m_sl.Leave(); <br>   } <br>}<br>
The SimpleSpinLock implementation is very simple. If two threads call Enter at the same <br>time, Interlocked.Exchange ensures that one thread changes m_resourceInUse from 0 to <br>1 and sees that m_resourceInUse was 0, and this thread then returns from Enter so that it <br>can continue executing the code in the AccessResource method. The other thread wil  change <br>m_resourceInUse from a 1 to a 1. This thread wil  see that it did not change m_resourceInUse <br>from a 0, and this thread will now start spinning continuously cal ing Exchange until the first <br>thread cal s Leave.<br>
When the first thread is done manipulating the fields of the SomeResource object, it calls <br>Leave, which internally calls Thread.VolatileWrite and changes m_resourceInUse back <br>to a 0. This causes the spinning thread to then change m_resourceInUse from a 0 to a 1 and <br>this thread now gets to return from Enter so that it can access SomeResource object's fields.<br>
There you have it. This is a simple implementation of a thread synchronization lock. The big <br>potential problem with this lock is that it causes threads to spin when there is contention for <br>the lock. This spinning wastes precious CPU time, preventing the CPU from doing other, more <br>useful work. As a result, spin locks should only ever be used to guard regions of code that <br>execute very quickly.<br>
And spin locks should not typically be used on single-CPU machines, as the thread that holds <br>the lock can't quickly release it if the thread that wants the lock is spinning. The situation be-<br>
<hr>
<A name=827></a><hr>
<A name=828></a><hr>
<A name=829></a><b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>811</b><br>
The FCL also includes a System.Threading.SpinLock structure that is similar to my <br>SimpleSpinLock class shown earlier except that it uses the SpinWait structure to improve <br>performance. The SpinLock structure also offers timeout support. By the way, it is interesting <br>to note that my SimpleSpinLock and the FCL's SpinLock are both value types. This means <br>that they are lightweight, memory-friendly objects. A SpinLock is a good choice if you need <br>to associate a lock with each item in a collection, for example. However, you must make sure <br>that you do not pass SpinLock instances around because they are copied and you will lose <br>any and all synchronization. And while you can define instance SpinLock fields, do not mark <br>the field as readonly because its internal state must change as the lock is manipulated.<br>
<b>The Interlocked Anything Pattern</b><br>
Many people look at the Interlocked methods and wonder why Microsoft doesn't create  <br>a richer set of interlocked methods that can be used in a wider range of scenarios. For  <br>example, it would be nice if the Interlocked class offered Multiple, Divide, Minimum, <br>Maximum, And, Or, Xor, and a bunch of other methods. While the Interlocked class doesn't <br>offer these methods, there is a well-known pattern that allows you to perform any operation  <br>on an Int32 in an atomic way by using Interlocked.CompareExchange. In fact, since <br>Interlocked.CompareExchange has additional overloads that operate on Int64, Single, <br>Double, Object, and a generic reference type, this pattern will actually work for all these <br>types, too.<br>
Here is an example of the pattern that is being used to create an atomic Maximum method:<br>
public static Int32 Maximum(ref Int32 target, Int32 value) { <br>   Int32 currentVal = target, startVal, desiredVal; <br> <br>   // Don't access target in the loop except in an attempt  <br>   // to change it because another thread may be touching it  <br>   do { <br>      // Record this iteration's starting value <br>      startVal = currentVal; <br> <br>      // Calculate the desired value in terms of startVal and value <br>      desiredVal = Math.Max(startVal, value); <br> <br>      // NOTE: the thread could be preempted here! <br> <br>      // if (target == startVal) target = desiredVal <br>      // Value prior to potential change is returned <br>      currentVal = Interlocked.CompareExchange(ref target, desiredVal, startVal); <br> <br>      // If the starting value changed during this iteration, repeat  <br>   } while (startVal != currentVal); <br> <br>   // Return the maximum value when this thread tried to set it <br>   return desiredVal; <br>}<br>
<hr>
<A name=830></a><b>812 </b><br>
<b>Part V  Threading</b><br>
Now let me explain exactly what is going on here. Upon entering the method, currentVal <br>is initialized to the value in target at the moment the method starts executing. Then, inside <br>the loop, startVal is initialized to this same value. Using startVal, you can perform any <br>operation you desire. This operation can be extremely complex, consisting of thousands of <br>lines of code. But, ultimately, you must end up with a result that is placed into desiredVal. In <br>my example, I simply determine whether startVal or value contains the larger value.<br>
Now, while this operation is running, another thread could change the value in target. <br>It is unlikely that this will happen, but it is possible. If this does happen, then the value in <br>derivedVal is based off an old value in startVal, not the current value in target, and <br>therefore, we should not change the value in target. To ensure that the value in target is <br>changed to desiredVal if no thread has changed target behind our thread's back, we use <br>Interlocked.CompareExchange. This method checks if the value in target matches the <br>value in <b>startVal</b> (which identifies the value that we thought was in target before starting  <br>to perform the operation). If the value in target didn't change, then CompareExchange <br>changes it to the new value in desiredVal. If the value in target did change, then <br>CompareExchange does not alter the value in target at all.<br>
CompareExchange returns the value that is in target at the time when CompareExchange is <br>called, which I then place in currentVal. Then, a check is made comparing startVal with <br>the new value in currentVal. If these values are the same, then a thread did not change<b> <br></b>target behind our thread's back,<b> </b>target now contains the value in<b> </b>desiredVal, the<b> </b>while <br>loop does not loop around, and the method returns. If startVal is not equal to currentVal,  <br>then a thread did change the value in target behind our thread's back, target did not get <br>changed to our value in desiredVal, and the while loop wil  loop around and try the opera-<br>tion again, this time using the new value in currentVal that reflects the other thread's change.<br>
Personally, I have used this pattern in a lot of my own code and, in fact, I made a generic <br>method, Morph, which encapsulates this pattern7:<br>
delegate Int32 Morpher&lt;TResult, TArgument&gt;(Int32 startValue, TArgument argument,  <br>   out TResult morphResult); <br> <br>static TResult Morph&lt;TResult, TArgument&gt;(ref Int32 target, TArgument argument,  <br>   Morpher&lt;TResult, TArgument&gt; morpher) { <br> <br>   TResult morphResult; <br>   Int32 currentVal = target, startVal, desiredVal; <br>   do { <br>      startVal = currentVal; <br>      desiredVal = morpher(startVal, argument, out morphResult); <br>      currentVal = Interlocked.CompareExchange(ref target, desiredVal, startVal); <br>   } while (startVal != currentVal); <br>   return morphResult; <br>}<br>
7  Obviously, the Morph method incurs a performance penalty due to invoking the morpher callback method. For <br>
best performance, execute the operation inline, as in the Maximum example.<br>
<hr>
<A name=831></a><b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>813</b><br>
<b>Kernel-Mode Constructs</b><br>
Windows offers several kernel-mode constructs for synchronizing threads. The kernel-mode <br>constructs are much slower than the user-mode constructs because they require coordination <br>from the Windows operating system itself and because each method call on a kernel object <br>causes the calling thread to transition from managed code to native user-mode code to  <br>native kernel-mode code and then return all the way back. These transitions require a lot of <br>CPU time and, if performed frequently, can adversely affect the overall performance of your <br>application.<br>
However, the kernel-mode constructs offer some benefits over the primitive user-mode  <br>constructs, such as:<br>
  When a kernel-mode construct detects contention on a resource, Windows blocks the <br>
losing thread so that it is not spinning on a CPU, wasting processor resources.<br>
  Kernel-mode constructs can synchronize native and managed threads with each other.<br>
  Kernel-mode constructs can synchronize threads running in different processes on the <br>
same machine.<br>
  Kernel-mode constructs can have security applied to them to prevent unauthorized  <br>
accounts from accessing them.<br>
  A thread can block until all kernel-mode constructs in a set are available or until any <br>
one kernel-mode construct in a set has become available.<br>
  A thread can block on a kernel-mode construct specifying a timeout value; if the thread <br>
can't have access to the resource it desires in the specified amount of time, then the <br>thread is unblocked and can perform other tasks.<br>
The two primitive kernel-mode thread synchronization constructs are events and semaphores. <br>Other kernel-mode constructs, such as mutex, are built on top of the two primitive constructs. <br>For more information about the Windows kernel-mode constructs, see my book <i>Windows via <br>C/C++, 5th Edition</i> (Microsoft Press, 2007).<br>
The System.Threading namespace offers an abstract base class called WaitHandle. The <br>WaitHandle class is a simple class whose sole purpose is to wrap a Windows kernel object <br>handle. The FCL provides several classes derived from WaitHandle. All classes are defined in <br>the System.Threading namespace, and all classes are implemented in MSCorLib.dll except <br>for Semaphore, which is implemented in System.dll. The class hierarchy looks like this:<br>
   WaitHandle <br>      EventWaitHandle <br>         AutoResetEvent <br>         ManualResetEvent <br>      Semaphore <br>      Mutex<br>
<hr>
<A name=832></a><b>814 </b><br>
<b>Part V  Threading</b><br>
Internally, the WaitHandle base class has a SafeWaitHandle field that holds a Win32 kernel <br>object handle. This field is initialized when a concrete WaitHandle-derived class is constructed. <br>In addition, the WaitHandle class publicly exposes methods that are inherited by all the <br>derived classes. Every method called on a kernel-mode construct represents a full memory <br>fence. WaitHandle's interesting public methods are shown below (some overloads for some <br>methods are not shown):<br>
public abstract class WaitHandle : MarshalByRefObject, IDisposable { <br>   // Close &amp; Dispose internally call the Win32 CloseHandle function. <br>   public virtual void Close(); <br>   public void Dispose(); <br> <br>   // WaitOne internally calls the Win32 WaitForSingleObjectEx function.  <br>   public virtual Boolean WaitOne(); <br>   public virtual Boolean WaitOne(Int32 millisecondsTimeout); <br> <br>   // WaitAny internally calls the Win32 WaitForMultipleObjectsEx function  <br>   public static Int32 WaitAny(WaitHandle[] waitHandles); <br>   public static Int32 WaitAny(WaitHandle[] waitHandles, Int32 millisecondsTimeout); <br> <br>   // WaitAll internally calls the Win32 WaitForMultipleObjectsEx function  <br>   public static Boolean WaitAll(WaitHandle[] waitHandles); <br>   public static Boolean WaitAll(WaitHandle[] waitHandles, Int32 millisecondsTimeout); <br> <br>   // SignalAndWait internally calls the Win32 SignalObjectAndWait function  <br>   public static Boolean SignalAndWait(WaitHandle toSignal, WaitHandle toWaitOn); <br>   public static Boolean SignalAndWait(WaitHandle toSignal, WaitHandle toWaitOn, <br>      Int32 millisecondsTimeout, Boolean exitContext) <br> <br>   // Use this to get access to the raw Win32 handle <br>   public SafeWaitHandle SafeWaitHandle { get; set; } <br> <br>   // Returned from WaitAny if a timeout occurs <br>   public const Int32 WaitTimeout = 0x102;  <br>}<br>
There are a few things to note about these methods:<br>
  You call WaitHandle's Close (or IDisposable's parameterless Dispose method) <br>
to close the underlying kernel object handle. Internally, these methods call the Win32 <br>CloseHandle function.<br>
  You call WaitHandle's WaitOne method to have the calling thread wait for the  <br>
underlying kernel object to become signaled. Internally, this method calls the Win32 <br>WaitForSingleObjectEx function. The returned Boolean is true if the object became <br>signaled or false if a timeout occurs.<br>
  You call WaitHandle's static WaitAny method to have the calling thread wait for any <br>
one of the kernel objects specified in the WaitHandle[] to become signaled. The  <br>returned Int32 is the index of the array element corresponding to the kernel object <br>that became signaled, or WaitHandle.WaitTimeout if no object became signaled while <br>
<hr>
<A name=833></a><IMG src="CLRviaCsharp-833_1.jpg"><br>
<b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>815</b><br>
waiting. Internally, this method calls the Win32 WaitForMultipleObjectsEx function, <br>passing FALSE for the bWaitAll parameter.<br>
  You call WaitHandle's static WaitAll method to have the calling thread wait for all <br>
the kernel objects specified in the WaitHandle[] to become signaled. The returned <br>Boolean is true if all of the objects became signaled or false if a timeout occurs. <br>Internally, this method calls the Win32 WaitForMultipleObjectsEx function, passing <br>TRUE for the bWaitAll parameter.<br>
  The array that you pass to the WaitAny and WaitAll methods must contain no more <br>
than 64 elements or else the methods throw a System.NotSupportedException.<br>
  You call WaitHandle's static SignalAndWait method to atomically signal one kernel <br>
object and wait for another kernel object to become signaled. The returned Boolean is <br>true if the object became signaled or false if a timeout occurs. Internally, this method <br>calls the Win32 SignalObjectAndWait function.<br>
<b>Note  </b>In some cases, when a COM single-threaded apartment thread blocks, the thread can <br>wake up internally to pump messages. For example, the blocked thread will wake to process a <br>Windows message sent from another thread. This is done to support COM interoperability. For <br>most applications, this is not a problem--in fact, it is a good thing. However, if your code takes <br>another thread synchronization lock during the processing of the message, then deadlock could <br>occur. As you'll see in Chapter 29, all the hybrid locks call these methods internally, so the same <br>potential benefit or problem exists when using the hybrid locks as well.<br>
The versions of the WaitOne, WaitAll, and SignalAndWait that do not accept a timeout  <br>parameter should be prototyped as having a void return type, not Boolean. The reason  <br>is because these methods will return only true since the implied timeout is infinite  <br>(System.Threading.Timeout.Infinite). When you call any of these methods, you do  <br>not need to check their return value.<br>
As already mentioned, the AutoResetEvent, ManualResetEvent, Semaphore, and Mutex <br>classes are all derived from WaitHandle, so they inherit WaitHandle's methods and their <br>behavior. However, these classes introduce additional methods of their own, and I'll address <br>those now.<br>
First, the constructors for all of these classes internally cal  the Win32 CreateEvent (passing <br>FALSE for the bManualReset parameter) or CreateEvent (passing TRUE for the bManualReset <br>parameter), CreateSemaphore, or CreateMutex functions. The handle value returned from <br>all of these calls is saved in a private SafeWaitHandle field defined inside the WaitHandle <br>base class.<br>
Second, the EventWaitHandle, Semaphore, and Mutex classes all offer static OpenExisting <br>methods, which internally call the Win32 OpenEvent, OpenSemaphore, or OpenMutex func-<br>tions, passing a String argument that identifies an existing named kernel object. The handle <br>
<hr>
<A name=834></a><b>816 </b><br>
<b>Part V  Threading</b><br>
value returned from all of these functions is saved in a newly constructed object that is  <br>returned from the OpenExisting method. If no kernel object exists with the specified name, <br>a WaitHandleCannotBeOpenedException is thrown.<br>
A common usage of the kernel-mode constructs is to create the kind of application that  <br>allows only one instance of itself to execute at any given time. Examples of single-instance <br>applications are Microsoft Office Outlook, Windows Live Messenger, Windows Media Player, <br>and Windows Media Center. Here is how to implement a single-instance application:<br>
using System; <br>using System.Threading; <br> <br>public static class Program { <br>   public static void Main() { <br>      Boolean createdNew; <br>       <br>      // Try to create a kernel object with the specified name <br>      using (new Semaphore(0, 1, &quot;SomeUniqueStringIdentifyingMyApp&quot;, out createdNew)) { <br>         if (createdNew) { <br>            // This thread created the kernel object so no other instance of this <br>            // application must be running. Run the rest of the application here... <br>         } else { <br>            // This thread opened an existing kernel object with the same string name; <br>            // another instance of this application must be running now. <br>            // There is nothing to do in here, let's just return from Main to terminate <br>            // this second instance of the application. <br>         } <br>      } <br>   } <br>}<br>
In this code, I am using a Semaphore, but it would work just as well if I had used an <br>EventWaitHandle or a Mutex because I'm not actually using the thread synchronization <br>behavior that the object offers. However, I am taking advantage of some thread synchroniza-<br>tion behavior that the kernel offers when creating any kind of kernel object. Let me explain <br>how the code above works. Let's say that two instances of this process are started at the <br>same exact time. Each process will have its own thread, and both threads will attempt to  <br>create a Semaphore with the same string name ("SomeUniqueStringIdentifyingMyApp," in my <br>example). The Windows kernel ensures that only one thread actually creates a kernel object <br>with the specified name; the thread that created the object will have its createdNew variable <br>set to true.<br>
For the second thread, Windows will see that a kernel object with the specified name already <br>exists; the second thread does not get to create another kernel object with the same name, <br>although if this thread continues to run, it can access the same kernel object as the first  <br>process's thread. This is how threads in different processes can communicate with each other <br>via a single kernel object. However, in this example, the second process's thread sees that <br>its createdNew variable is set to false. This thread now knows that another instance of this <br>process is running, and the second instance of the process exits immediately.<br>
<hr>
<A name=835></a><b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>817</b><br>
<b>Event Constructs</b><br>
Events are simply Boolean variables maintained by the kernel. A thread waiting on an event <br>blocks when the event is false and unblocks when the event is true. There are two kinds of <br>events. When an auto-reset event is true, it wakes up just one blocked thread because the <br>kernel <i>automatically resets</i> the event back to false after unblocking the first thread. When a <br>manual-reset event is true, it unblocks all threads waiting for it because the kernel does not <br>automatically reset the event back to false; your code must <i>manually reset</i> the event back <br>to false. The classes related to events look like this:<br>
public class EventWaitHandle : WaitHandle { <br>   public Boolean Set();    // Sets Boolean to true; always returns true <br>   public Boolean Reset();  // Sets Boolean to false; always returns true <br>}  <br> <br>public sealed class AutoResetEvent : EventWaitHandle { <br>   public AutoResetEvent(Boolean initialState); <br>} <br> <br>public sealed class ManualResetEvent : EventWaitHandle { <br>   public ManualResetEvent(Boolean initialState); <br>}<br>
Using an auto-reset event, we can easily create a thread synchronization lock whose behavior <br>is similar to the SimpleSpinLock class I showed earlier:<br>
internal sealed class SimpleWaitLock : IDisposable { <br>   private AutoResetEvent m_ResourceFree = new AutoResetEvent(true); // Initially free <br> <br>   public void Enter() { <br>      // Block efficiently in the kernel for the resource to be free, then return <br>      m_ResourceFree.WaitOne(); <br>   } <br> <br>   public void Leave() {  <br>      m_ResourceFree.Set();// Mark the resource as Free <br>   } <br> <br>   public void Dispose() { m_ResourceFree.Dispose(); } <br>}<br>
You would use this SimpleWaitLock exactly the same way that you'd use the <br>SimpleSpinLock. In fact, the external behavior is exactly the same; however, the perfor-<br>mance of the two locks is radically different. When there is no contention on the lock, <br>the SimpleWaitLock is much slower than the SimpleSpinLock because every call to <br>SimpleWaitLock's Enter and Leave methods forces the calling thread to transition from <br>managed code to the kernel and back--which is bad. But when there is contention, the  <br>losing thread is blocked by the kernel and is not spinning and wasting CPU cycles--which is <br>good. Note also that constructing the AutoResetEvent object and calling Dispose on it also <br>
<hr>
<A name=836></a><b>818 </b><br>
<b>Part V  Threading</b><br>
cause managed to kernel transitions, affecting performance negatively. These calls usually <br>happen rarely, so they are usually not something to be too concerned about.<br>
To give you a better feel for the performance differences, I wrote the following code:<br>
public static void Main() { <br>   Int32 x = 0; <br>   const Int32 iterations = 10000000;  // 10 million <br> <br>   // How long does it take to increment x 10 million times? <br>   Stopwatch sw = Stopwatch.StartNew(); <br>   for (Int32 i = 0; i &lt; iterations; i++) { <br>      x++; <br>   } <br>   Console.WriteLine(&quot;Incrementing x: {0:N0}&quot;, sw.ElapsedMilliseconds); <br> <br>   // How long does it take to increment x 10 million times  <br>   // adding the overhead of calling a method that does nothing? <br>   sw.Restart(); <br>   for (Int32 i = 0; i &lt; iterations; i++) { <br>      M(); x++; M(); <br>   } <br>   Console.WriteLine(&quot;Incrementing x in M: {0:N0}&quot;, sw.ElapsedMilliseconds); <br> <br>   // How long does it take to increment x 10 million times  <br>   // adding the overhead of calling an uncontended SimpleSpinLock? <br>   SimpleSpinLock ssl = new SimpleSpinLock(); <br>   sw.Restart(); <br>   for (Int32 i = 0; i &lt; iterations; i++) { <br>      ssl.Enter(); x++; ssl.Leave(); <br>   } <br>   Console.WriteLine(&quot;Incrementing x in SimpleSpinLock: {0:N0}&quot;, sw.ElapsedMilliseconds); <br> <br>   // How long does it take to increment x 10 million times  <br>   // adding the overhead of calling an uncontended SimpleWaitLock? <br>   using (SimpleWaitLock swl = new SimpleWaitLock()) { <br>      sw.Restart(); <br>      for (Int32 i = 0; i &lt; iterations; i++) { <br>         swl.Enter(); x++; swl.Leave(); <br>      } <br>      Console.WriteLine(&quot;Incrementing x in SimpleWaitLock: {0:N0}&quot;, sw.ElapsedMilliseconds); <br>   } <br>} <br> <br>[MethodImpl(MethodImplOptions.NoInlining)] <br>private static void M() { /* This method does nothing but return */ }<br>
When I run the code above, I get the following output:<br>
Incrementing x: 8 <br>Incrementing x in M: 50 <br>Incrementing x in SimpleSpinLock: 219 <br>Incrementing x in SimpleWaitLock: 17,615<br>
<hr>
<A name=837></a><b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>819</b><br>
As you can clearly see, just incrementing x took only 8 milliseconds. To call a method around <br>incrementing x added another 42 milliseconds. Then, executing code in a method that uses <br>a user-mode construct caused the code to run 27 (219 / 8) times slower. But now see how <br>much slower the program ran using a kernel-mode construct: 2,201 (17,615 / 8) times slower! <br>So, if you can avoid thread synchronization, you should. If you need thread synchronization, <br>then try to use the user-mode constructs. Always try to avoid the kernel-mode constructs, as <br>this code ran 80 (17,615 / 219) times slower.<br>
<b>Semaphore Constructs</b><br>
Semaphores are simply Int32 variables maintained by the kernel. A thread waiting on a <br>semaphore blocks when the semaphore is 0 and unblocks when the semaphore is greater <br>than 0. When a thread waiting on a semaphore unblocks, the kernel automatically subtracts 1 <br>from the semaphore's count. Semaphores also have a maximum Int32 value associated with <br>them, and the current count is never allowed to go over the maximum count. Here is what <br>the Semaphore class looks like:<br>
public sealed class Semaphore : WaitHandle { <br>   public Semaphore(Int32 initialCount, Int32 maximumCount); <br>   public Int32 Release();   // Calls Release(1); returns previous count <br>   public Int32 Release(Int32 releaseCount);  // Returns previous count <br>}<br>
So now let me summarize how these three kernel-mode primitives behave:<br>
  When multiple threads are waiting on an auto-reset event, setting the event causes <br>
<i>only one</i> thread to become unblocked.<br>
  When multiple threads are waiting on a manual-reset event, setting the event causes <i>all</i> <br>
threads to become unblocked.<br>
  When multiple threads are waiting on a semaphore, releasing the semaphore causes <br>
releaseCount threads to become unblocked (where releaseCount is the argument <br>passed to Semaphore's Release method).<br>
Therefore, an auto-reset event behaves very similarly to a semaphore whose maximum  <br>count is 1. The difference between the two is that Set can be called multiple times  <br>consecutively on an auto-reset event and still only one thread will be unblocked, whereas <br>calling Release multiple times consecutively on a semaphore keeps incrementing its internal <br>count, which could unblock many threads. By the way, if you call Release on a semaphore <br>too many times, causing its count to exceed its maximum count, then Release will throw a <br>SemaphoreFullException.<br>
Using a semaphore, we can re-implement the SimpleWaitLock as follows, so that it gives <br>multiple threads concurrent access to a resource (which is not necessarily a safe thing to do <br>unless all threads access the resource in a read-only fashion):<br>
<hr>
<A name=838></a><b>820 </b><br>
<b>Part V  Threading</b><br>
public sealed class SimpleWaitLock : IDisposable { <br>   private Semaphore m_AvailableResources; <br> <br>   public SimpleWaitLock(Int32 maximumConcurrentThreads) { <br>      m_AvailableResources =  <br>         new Semaphore(maximumConcurrentThreads, maximumConcurrentThreads); <br>   } <br> <br>   public void Enter() { <br>      // Wait efficiently in the kernel for resource access, then return <br>      m_AvailableResources.WaitOne(); <br>   } <br> <br>   public void Leave() { <br>      // This thread doesn't need access anymore; another thread can have it <br>      m_ AvailableResources.Release(); <br>   } <br> <br>   public void Dispose() { m_AvailableResources.Close(); } <br>}<br>
<b>Mutex Constructs</b><br>
A mutex represents a mutual-exclusive lock. It works similar to an AutoResetEvent (or a <br>Semaphore with a count of 1) since all three constructs release only one waiting thread at a <br>time. Here is what the Mutex class looks like:<br>
public sealed class Mutex : WaitHandle { <br>   public Mutex(); <br>   public void ReleaseMutex(); <br>}<br>
Mutexes have some additional logic in them which makes them more complex than the <br>other constructs. First, Mutex objects record which thread obtained it by querying the calling <br>thread's Int32 ID. When a thread calls ReleaseMutex, the Mutex makes sure that the calling <br>thread is the same thread that obtained the Mutex. If the calling thread is not the thread that <br>obtained the Mutex, then the Mutex object's state is unaltered and ReleaseMutex throws a <br>System.ApplicationException. Also, if a thread owning a Mutex terminates for any reason, <br>then some thread waiting on the Mutex will be awakened by having a System.Threading.<br>AbandonedMutexException thrown. Usually, this exception will go unhandled, terminating <br>the whole process. This is good because a thread acquired the Mutex and it is likely that the <br>thread terminated before it finished updating the data that the Mutex was protecting. If a <br>thread catches AbandonedMutexException, then it could attempt to access the corrupt data, <br>leading to unpredictable results and security problems.<br>
Second, Mutex objects maintain a recursion count indicating how many times the owning <br>thread owns the  Mutex. If a thread currently owns a Mutex and then that thread waits on the <br>Mutex again, the recursion count is incremented and the thread is allowed to continue run-<br>ning. When that thread calls ReleaseMutex, the recursion count is decremented. Only when <br>the recursion count becomes 0 can another thread become the owner of the Mutex.<br>
<hr>
<A name=839></a><b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>821</b><br>
Most people do not like this additional logic. The problem is that these "features" have a cost <br>associated with them. The Mutex object needs more memory to hold the additional thread <br>ID and recursion count information. And, more importantly, the Mutex code has to maintain <br>this information, which makes the lock slower. If an application needs or wants these addi-<br>tional features, then the application code could have done this itself; the code doesn't have <br>to be built into the Mutex object. For this reason, a lot of people avoid using Mutex objects.<br>
Usually a recursive lock is needed when a method takes a lock and then calls another method <br>that also requires the lock, as the following code demonstrates:<br>
internal class SomeClass : IDisposable { <br>   private readonly Mutex m_lock = new Mutex(); <br> <br>   public void Method1() { <br>      m_lock.WaitOne(); <br>      // Do whatever... <br>      Method2();  // Method2 recursively acquires the lock <br>      m_lock.ReleaseMutex(); <br>   } <br> <br>   public void Method2() { <br>      m_lock.WaitOne(); <br>      // Do whatever... <br>      m_lock.ReleaseMutex(); <br>   } <br> <br>   public void Dispose() { m_lock.Dispose(); } <br>}<br>
In the code above, code that uses a SomeClass object could call Method1, which acquires the <br>Mutex, performs some thread-safe operation, and then calls Method2, which also performs  <br>some thread-safe operation. Since Mutex objects support recursion, the thread will acquire  <br>the lock twice and then release it twice before another thread can own the Mutex. If SomeClass <br>has used an AutoResetEvent instead of a Mutex, then the thread would block when it called <br>Method2's WaitOne method.<br>
If you need a recursive lock, then you could create one easily by using an AutoResetEvent:<br>
internal sealed class RecursiveAutoResetEvent : IDisposable { <br>   private AutoResetEvent m_lock = new AutoResetEvent(true); <br>   private Int32 m_owningThreadId = 0; <br>   private Int32 m_recursionCount = 0; <br> <br>   public void Enter() { <br>      // Obtain the calling thread's unique Int32 ID <br>      Int32 currentThreadId = Thread.CurrentThread.ManagedThreadId; <br> <br>      // If the calling thread owns the lock, increment the recursion count <br>      if (m_owningThreadId == currentThreadId) { <br>         m_recursionCount++;  <br>         return; <br>      } <br> <br>
<hr>
<A name=840></a><b>822 </b><br>
<b>Part V  Threading</b><br>
      // The calling thread doesn't own the lock, wait for it <br>      m_lock.WaitOne(); <br> <br>      // The calling now owns the lock, initialize the owning thread ID &amp; recursion count <br>      m_owningThreadId = currentThreadId; <br>      m_recursionCount--; <br>   } <br> <br>   public void Leave() { <br>      // If the calling thread doesn't own the lock, we have an error <br>      if (m_owningThreadId != Thread.CurrentThread.ManagedThreadId)  <br>         throw new InvalidOperationException(); <br> <br>      // Subtract 1 from the recursion count <br>      if (--m_recursionCount == 0) { <br>         // If the recursion count is 0, then no thread owns the lock <br>         m_owningThreadId = 0;  <br>         m_lock.Set();   // Wake up 1 waiting thread (if any) <br>      } <br>   } <br> <br>   public void Dispose() { m_lock.Dispose(); } <br>}<br>
While the behavior of the RecursiveAutoResetEvent class is identical to that of the Mutex <br>class, a RecursiveAutoResetEvent object will have far superior performance when a thread <br>tries to acquire the lock recursively because all the code that is required to track thread  <br>ownership and recursion is now in managed code. A thread has to transition into the <br>Windows kernel only when first acquiring the AutoResetEvent or when finally relinquishing <br>it to another thread.<br>
<b>Calling a Method When a Single Kernel Construct Becomes </b><br>
<b>Available</b><br>
Having a thread block indefinitely waiting for a kernel object to become available is waste-<br>ful of the thread's memory resources. Therefore, the thread pool offers a way to invoke a <br>method of yours when a kernel object becomes available by using the System.Threading.<br>ThreadPool class's static RegisterWaitForSingleObject method. There are several over-<br>loads of this method, but they are all very similar. Here is the prototype for one of the more <br>commonly used overloads:<br>
public static RegisteredWaitHandle RegisterWaitForSingleObject( <br>   WaitHandle waitObject, WaitOrTimerCallback callback, Object state, <br>   Int32 millisecondsTimeoutInterval, Boolean executeOnlyOnce);<br>
<hr>
<A name=841></a><b> </b><br>
<b>Chapter 28  Primitive Thread Synchronization Constructs </b><br>
<b>823</b><br>
When you call this method, the waitObject argument identifies the kernel object that <br>you want the thread pool to wait for. Since this parameter is of the abstract base class <br>WaitHandle, you can specify any class derived from this base class. Specifically, you can <br>pass a reference to a Semaphore, Mutex, AutoResetEvent, or ManualResetEvent object. <br>The second parameter, callback, identifies the method that you want the thread pool <br>thread to call. The callback method that you write must match the System.Threading.<br>WaitOrTimerCallback delegate, which is defined as follows:<br>
public delegate void WaitOrTimerCallback(Object state, Boolean timedOut);<br>
RegisterWaitForSingleObject's third parameter, state, allows you to specify some state <br>data that should be passed to the callback method when the thread pool thread calls it; pass <br>null if you have no special state data to pass. The fourth parameter, millisecondsTime-<br>outInterval, allows you to tell the thread pool how long it should wait for the kernel object <br>to become signaled. It is common to pass Timeout.Infinite (-1) here to indicate an  <br>infinite timeout. If the last parameter, executeOnlyOnce, is true, a thread pool thread will <br>execute the callback method just once. But if executeOnlyOnce is false, a thread pool <br>thread will execute the callback method every time the kernel object becomes signaled. This <br>is most useful when waiting for an AutoResetEvent object.<br>
When the callback method is called, it is passed state data and a Boolean value, timedOut.  <br>If timedOut is false, the method knows that it is being called because the kernel object  <br>became signaled. If timedOut is true, the method knows that it is being called because the <br>kernel object did not become signaled in the time specified. The callback method can per-<br>form whatever action it desires based on the value that it receives in the timedOut argument.<br>
You'll notice that the RegisterWaitForSingleObject method returns a reference to a <br>RegisteredWaitHandle object. This object identifies the kernel object that the thread pool <br>is waiting on. If, for some reason, your application wants to tell the thread pool to stop <br>watching the registered wait handle, your application can call RegisteredWaitHandle's <br>Unregister method:<br>
public Boolean Unregister(WaitHandle waitObject);<br>
The waitObject parameter indicates how you want to be notified when all queued work <br>items for the registered wait have executed. You should pass null for this parameter if you <br>don't want a notification. If you pass a valid reference to a WaitHandle-derived object, the <br>thread pool will signal the object when all pending work items for the registered wait handle <br>have executed.<br>
The code below demonstrates how to have a thread pool thread call a method whenever an <br>AutoResetEvent object becomes signaled:<br>
<hr>
<A name=842></a><b>824 </b><br>
<b>Part V  Threading</b><br>
internal static class RegisteredWaitHandleDemo { <br>   public static void Main() { <br>      // Construct an AutoResetEvent (initially false) <br>      AutoResetEvent are = new AutoResetEvent(false); <br> <br>      // Tell the thread pool to wait on the AutoResetEvent <br>      RegisteredWaitHandle rwh = ThreadPool.RegisterWaitForSingleObject( <br>         are,             // Wait on this AutoResetEvent <br>         EventOperation,  // When available, call the EventOperation method <br>         null,            // Pass null to EventOperation <br>         5000,            // Wait 5 seconds for the event to become true <br>         false);          // Call EventOperation every time the event is true <br> <br>      // Start our loop <br>      Char operation = (Char) 0; <br>      while (operation != 'Q') { <br>         Console.WriteLine(&quot;S=Signal, Q=Quit?&quot;); <br>         operation = Char.ToUpper(Console.ReadKey(true).KeyChar); <br>         if (operation == 'S') are.Set(); // User want to set the event <br>      } <br> <br>      // Tell the thread pool to stop waiting on the event <br>      rwh.Unregister(null); <br>   } <br> <br>   // This method is called whenever the event is true or <br>   // when 5 seconds have elapsed since the last callback/timeout <br>   private static void EventOperation(Object state, Boolean timedOut) { <br>      Console.WriteLine(timedOut ? &quot;Timeout&quot; : &quot;Event became true&quot;); <br>   } <br>}<br>
<hr>
<A name=843></a>Chapter 29<br><b>Hybrid Thread Synchronization </b><br>
<b>Constructs</b><br>
<b>In this chapter:<br>A Simple Hybrid Lock . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 826<br>Spinning, Thread Ownership, and Recursion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 827<br>A Potpourri of Hybrid Constructs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 829<br>The Famous Double-Check Locking Technique . . . . . . . . . . . . . . . . . . . . . . . . . . . 844<br>The Condition Variable Pattern. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 848<br>Using Collections to Avoid Holding a Lock for a Long Time . . . . . . . . . . . . . . . . 851<br>The Concurrent Collection Classes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 856</b><br>
In Chapter 28, "Primitive Thread Synchronization Constructs," I discussed the primitive user-<br>mode and kernel-mode thread synchronization constructs. From these primitive constructs, <br>all other thread synchronization constructs can be built. Typically, other thread synchroniza-<br>tion constructs are built by combining the user-mode and kernel-mode constructs, and I call <br>these <i>hybrid thread synchronization constructs</i>. Hybrid constructs provide the performance <br>benefit of the primitive user-mode constructs when there is no thread contention. Hybrid <br>constructs also use the primitive kernel-mode constructs to provide the benefit of not spin-<br>ning (wasting CPU time) when multiple threads are contending for the construct at the same <br>time. Since, in most applications, threads are rarely contending for a construct at the same <br>time, the performance improvements can help your application greatly.<br>
In this chapter, I will first show how hybrid constructs are built from the various primitive <br>constructs. Then, I will introduce you to many of the hybrid constructs that ship with the <br>Framework Class Library (FCL), describe their behavior, and give some insight as to how to <br>use these constructs correctly. I will also mention some constructs that I have created and <br>make available for free in Wintellect's Power Threading library, which can be downloaded <br>from <i>http://Wintellect.com/.</i><br>
Toward the end of the chapter, I show how to minimize resource usage and improve  <br>performance by using the FCL's concurrent collection classes instead of using some of the  <br>hybrid constructs. And finally, I discuss the Power Threading library's ReaderWriterGate and <br>SyncGate classes which offer reader-writer semantics without blocking any threads, thereby <br>also reducing resource consumption and improving performance.<br>
<b> </b><br>
<b> </b><br>
<b>825</b><br>
<hr>
<A name=844></a><b>826 </b><br>
<b>Part V  Threading</b><br>
<b>A Simple Hybrid Lock</b><br>
So, without further ado, let me start off by showing you an example of a hybrid thread  <br>synchronization lock:<br>
internal sealed class SimpleHybridLock : IDisposable { <br>   // The Int32 is used by the primitive user-mode constructs (Interlocked methods) <br>   private Int32 m_waiters = 0; <br> <br>   // The AutoResetEvent is the primitive kernel-mode construct <br>   private AutoResetEvent m_waiterLock = new AutoResetEvent(false); <br> <br>   public void Enter() { <br>      // Indicate that this thread wants the lock <br>      if (Interlocked.Increment(ref m_waiters) == 1) <br>         return; // Lock was free, no contention, just return <br> <br>      // Another thread is waiting. There is contention, block this thread <br>      m_waiterLock.WaitOne();  // Bad performance hit here <br>      // When WaitOne returns, this thread now has the lock <br>   } <br> <br>   public void Leave() { <br>      // This thread is releasing the lock <br>      if (Interlocked.Decrement(ref m_waiters) == 0) <br>         return; // No other threads are blocked, just return <br> <br>      // Other threads are blocked, wake 1 of them <br>      m_waiterLock.Set();  // Bad performance hit here <br>   } <br> <br>   public void Dispose() { m_waiterLock.Dispose(); } <br>}<br>
The SimpleHybridLock contains two fields: an Int32, which will be manipulated via the <br>primitive user-mode constructs, and an AutoResetEvent, which is a primitive kernel-mode <br>construct. To get great performance, the lock tries to use the Int32 and avoid using the <br>AutoResetEvent as much as possible. Just constructing a SimpleHybridLock object causes <br>the AutoResetEvent to be created, and this is a massive performance hit compared to <br>the overhead associated with the Int32 field. Later in this chapter, we'll see another hy-<br>brid construct (AutoResetEventSlim) that avoids the performance hit of creating the <br>AutoResetEvent until the first time contention is detected from multiple threads accessing <br>the lock at the same time. The Dispose method closes the AutoResetEvent, and this is also <br>a big performance hit compared to the overhead of destroying the Int32 field.<br>
While it would be nice to improve the performance of constructing and disposing of a <br>SimpleHybridLock object, it would be better to focus on the performance of its Enter and <br>Leave methods because these methods tend to be called many, many times over the object's <br>lifetime. Let's focus on these methods now.<br>
<hr>
<A name=845></a><IMG src="CLRviaCsharp-845_1.jpg"><br>
<b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>827</b><br>
The first thread to call Enter causes Interlocked.Increment to add one to the m_waiters  <br>field, making its value 1. This thread sees that there were zero threads waiting before for <br>this lock, so the thread gets to return from its call to Enter. The thing to appreciate here is <br>that the thread acquired the lock very quickly. Now, if another thread comes along and calls <br>Enter, this second thread increments m_waiters to 2 and sees that another thread has the <br>lock, so this thread blocks by calling WaitOne using the AutoResetEvent. Calling WaitOne <br>causes the thread to transition into the Windows' kernel, and this is a big performance hit. <br>However, the thread must stop running anyway, so it is not too bad to have a thread waste <br>some time to stop completely. The good news is that the thread is now blocked and so it is <br>not wasting CPU time by spinning on the CPU, which is what the SimpleSpinLock's Enter <br>method, introduced in Chapter 28, does.<br>
Now let's look at the Leave method. When a thread calls Leave, Interlocked.Decrement is <br>called to subtract 1 from the m_waiters field. If m_waiters is now 0, then no other threads <br>are blocked inside a call to Enter and the thread calling Leave can simply return. Again, <br>think about how fast this is: Leaving a lock means that a thread subtracts 1 from an Int32, <br>performs a quick if test, and then returns! On the other head, if the thread calling Leave <br>sees that m_waiters was not <b>1</b>, then the thread knows that there is contention and that there <br>is at least one other thread blocked in the kernel. This thread must wake up one (and only <br>one) of the blocked threads. It does this by calling Set on AutoResetEvent.<b> </b>This is a perfor-<br>mance hit, as the thread must transition into the kernel and back, but this transition occurs <br>only when there was contention. Of course, AutoResetEvent ensures that only one blocked <br>thread wakes up; any other threads blocked on the AutoResetEvent will continue to block <br>until the newly unblocked thread eventually calls Leave.<br>
<b>Note  </b>In reality, any thread could call Leave at any time since the Enter method does not keep <br>a record of which thread successfully acquired the lock. Adding the field and code to maintain <br>this information is easy to do but it would increase the memory required for the lock object itself <br>and hurt performance of the Enter and Leave methods because they would have to manipulate <br>this field. I would rather have a fast-performing lock and make sure that my code uses it the right <br>way. You'll notice that events and semaphores do not maintain this kind of information; only  <br>mutexes do.<br>
<b>Spinning, Thread Ownership, and Recursion</b><br>
Since transitions into the kernel incur such a big performance hit and threads tend to hold on <br>to a lock for very short periods of time, an application's overall performance can be improved <br>by having a thread spin in user mode for a little while before having the thread transition to <br>kernel mode. If the lock that the thread is waiting for becomes available while spinning, then <br>the transition to kernel mode is avoided.<br>
<hr>
<A name=846></a><b>828 </b><br>
<b>Part V  Threading</b><br>
In addition, some locks impose a limitation where the thread that acquires the lock must be <br>the thread that releases the lock. And some locks allow the currently owning thread to own <br>the lock recursively. The Mutex lock is an example of a lock that has these characteristics.1 <br>Using some fancy logic, it is possible to build a hybrid lock that offers spinning, thread own-<br>ership, and recursion. Here is what the code looks like:<br>
internal sealed class AnotherHybridLock : IDisposable { <br>   // The Int32 is used by the primitive user-mode constructs (Interlocked methods) <br>   private Int32 m_waiters = 0; <br> <br>   // The AutoResetEvent is the primitive kernel-mode construct <br>   private AutoResetEvent m_waiterLock = new AutoResetEvent(false); <br> <br>   // This field controls spinning in an effort to improve performance <br>   private Int32 m_spincount = 4000;   // Arbitrarily chosen count <br> <br>   // These fields indicate which thread owns the lock and how many times it owns it <br>   private Int32 m_owningThreadId = 0, m_recursion = 0; <br> <br>   public void Enter() { <br>      // If calling thread already owns the lock, increment recursion count and return <br>      Int32 threadId = Thread.CurrentThread.ManagedThreadId; <br>      if (threadId == m_owningThreadId) { m_recursion++; return; } <br> <br>      // The calling thread doesn't own the lock, try to get it <br>      SpinWait spinwait = new SpinWait(); <br>      for (Int32 spinCount = 0; spinCount &lt; m_spincount; spinCount++) { <br>         // If the lock was free, this thread got it; set some state and return <br>         if (Interlocked.CompareExchange(ref m_waiters, 1, 0) == 0) goto GotLock; <br> <br>         // Black magic: give other threads a chance to run  <br>         // in hopes that the lock will be released <br>         spinwait.SpinOnce(); <br>      } <br> <br>      // Spinning is over and the lock was still not obtained, try one more time <br>      if (Interlocked.Increment(ref m_waiters) &gt; 1) { <br>         // Other threads are blocked and this thread must block too <br>         m_waiterLock.WaitOne(); // Wait for the lock; performance hit <br>         // When this thread wakes, it owns the lock; set some state and return <br>      } <br> <br>   GotLock: <br>      // When a thread gets the lock, we record its ID and  <br>      // indicate that the thread owns the lock once <br>      m_owningThreadId = threadId; m_recursion = 1; <br>   } <br> <br>   public void Leave() { <br>      // If the calling thread doesn't own the lock, there is a bug <br>
1  Threads do not spin when waiting on a Mutex object because the Mutex's code is in the kernel. This means that <br>
the thread had to have already transitioned into the kernel to check the Mutex's state.<br>
<hr>
<A name=847></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>829</b><br>
      Int32 threadId = Thread.CurrentThread.ManagedThreadId; <br>      if (threadId != m_owningThreadId) <br>         throw new SynchronizationLockException(&quot;Lock not owned by calling thread&quot;); <br> <br>      // Decrement the recursion count. If this thread still owns the lock, just return <br>      if (--m_recursion &gt; 0) return; <br> <br>      m_owningThreadId = 0;   // No thread owns the lock now <br> <br>      // If no other threads are blocked, just return <br>      if (Interlocked.Decrement(ref m_waiters) == 0)  <br>         return; <br> <br>      // Other threads are blocked, wake 1 of them <br>      m_waiterLock.Set();     // Bad performance hit here <br>   } <br> <br>   public void Dispose() { m_waiterLock.Dispose(); } <br>}<br>
As you can see, adding extra behavior to the lock increases the number of fields it has, which <br>increases its memory consumption. The code is also more complex, and this code must  <br>execute, which decreases the lock's performance. In Chapter 28's "Event Constructs" section, I <br>compared the performance of incrementing an Int32 without any locking, with a primitive  <br>user-mode construct, and with a kernel-mode construct. I repeat the results of those per-<br>formance tests here and I include the results of using the SimpleHybridlock and the <br>AnotherHybridLock. The results are in fastest to slowest order:<br>
Incrementing x: 8                           Fastest <br>Incrementing x in M: 50                     6x slower  <br>Incrementing x in SimpleSpinLock: 210       26x slower  <br>Incrementing x in SimpleHybridLock: 211     26x slower (similar to SimpleSpinLock) <br>Incrementing x in AnotherHybridLock: 415    52x slower (due to ownership/recursion) <br>Incrementing x in SimpleWaitLock: 17,615    2,201x slower<br>
It is worth noting that the AnotherHybridLock takes twice as much time as the <br>SimpleHybridLock. This is due to the additional logic and error checking required managing <br>the thread ownership and recursion behaviors. As you see, every behavior added to a lock <br>impacts its performance.<br>
<b>A Potpourri of Hybrid Constructs</b><br>
The FCL ships with many hybrid constructs that use fancy logic to keep your threads in user <br>mode, improving your application's performance. Some of these hybrid constructs also avoid <br>creating the kernel-mode construct until the first time threads contend on the construct. If <br>threads never contend on the construct, then your application avoids the performance of <br>creating the object and also avoids allocating memory for the object. A number of the con-<br>structs also support the use of a CancellationToken (discussed in Chapter 26, "Compute-<br>
<hr>
<A name=848></a><b>830 </b><br>
<b>Part V  Threading</b><br>
Bound Asynchronous Operations") so that a thread can forcibly unblock other threads that <br>might be waiting on the construct. In this section, I introduce you to these hybrid constructs.<br>
<b>The </b>ManualResetEventSlim<b> and </b>SemaphoreSlim<b> Classes</b><br>
The first two hybrid constructs are System.Threading.ManualResetEventSlim and <br>System.Threading.SemaphoreSlim.2 These constructs work exactly like their kernel-mode <br>counterparts except that both employ spinning in user mode and they both defer creating <br>the kernel-mode construct until the first time contention occurs. Their Wait methods allow <br>you to pass a timeout and a CancellationToken. Here is what these classes look like (some <br>method overloads are not shown):<br>
public class ManualResetEventSlim : IDisposable { <br>   public ManualResetEventSlim(Boolean initialState, Int32 spinCount); <br>   public void Dispose(); <br>   public void Reset(); <br>   public void Set(); <br>   public Boolean Wait(Int32 millisecondsTimeout, CancellationToken cancellationToken); <br> <br>   public Boolean IsSet { get; } <br>   public Int32 SpinCount { get; } <br>   public WaitHandle WaitHandle { get; } <br>} <br>public class SemaphoreSlim : IDisposable { <br>   public SemaphoreSlim(Int32 initialCount, Int32 maxCount); <br>   public void Dispose(); <br>   public Int32 Release(Int32 releaseCount); <br>   public Boolean Wait(Int32 millisecondsTimeout, CancellationToken cancellationToken); <br> <br>   public Int32 CurrentCount { get; } <br>   public WaitHandle AvailableWaitHandle { get; } <br>}<br>
<b>The </b>Monitor<b> Class and Sync Blocks</b><br>
Probably the most-used hybrid thread synchronization construct is the Monitor class, which <br>provides a mutual-exclusive lock supporting spinning, thread ownership, and recursion. This <br>is the most-used construct because it has been around the longest, C# has a built-in keyword <br>to support it, the just-in-time (JIT) compiler has built-in knowledge of it, and the common <br>language runtime (CLR) itself uses it on your application's behalf. However, as you'll see, there <br>are many problems with this construct, making it easy to produce buggy code. I'll start by <br>explaining the construct, and then I'll show the problems and some ways to work around <br>these problems.<br>
2  While there is no AutoResetEventSlim class, in many situations you can construct a SemaphoreSlim object with <br>
a maxCount of 1.<br>
<hr>
<A name=849></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>831</b><br>
Every object on the heap can have a data structure, called a <i>sync block</i>, associated with it. A <br>sync block contains fields similar to that of the AnotherHybridLock class that appeared earlier <br>in this chapter. Specifically, it has fields for a kernel object, the owning thread's ID, a recursion  <br>count, and a waiting threads count. The Monitor class is a static class whose methods accept <br>a reference to any heap object, and these methods manipulate the fields in the specified  <br>object's sync block. Here is what the most commonly used methods of the Monitor class <br>look like:<br>
public static class Monitor { <br>   public static void Enter(Object obj); <br>   public static void Exit(Object obj); <br> <br>   // You can also specify a timeout when entered the lock (not commonly used): <br>   public static Boolean TryEnter(Object obj, Int32 millisecondsTimeout); <br> <br>   // I'll discuss the lockTaken argument later <br>   public static void Enter(Object obj, ref Boolean lockTaken); <br>   public static void TryEnter(Object obj, Int32 millisecondsTimeout,  <br>      ref Boolean lockTaken); <br>}<br>
Now obviously, associating a sync block data structure with every object in the heap is quite <br>wasteful, especially since most objects' sync blocks are never used. To reduce memory usage, <br>the CLR team uses a more efficient way to offer the functionality just described. Here's how <br>it works: When the CLR initializes, it allocates an array of sync blocks. As discussed elsewhere <br>in this book, whenever an object is created in the heap, it gets two additional overhead fields <br>associated with it. The first overhead field, the type object pointer, contains the memory  <br>address of the type's type object. The second overhead field, the <i>sync block index</i>, contains <br>an integer index into the array of sync blocks.<br>
When an object is constructed, the object's sync block index is initialized to -1, which indicates <br>that it doesn't refer to any sync block. Then, when Monitor.Enter is cal ed, the CLR finds a free <br>sync block in the array and sets the object's sync block index to refer to the sync block that was <br>found. In other words, sync blocks are associated with an object on the fly. When Exit is cal ed, <br>it checks to see if there are any more threads waiting to use the object's sync block. If there are <br>no threads waiting for it, the sync block is free, Exit sets the object's sync block index back to <br>-1, and the free sync block can be associated with another object in the future.<br>
Figure 29-1 shows the relationship between objects in the heap, their sync block indexes, and <br>elements in the CLR's sync block array. Object-A, Object-B, and Object-C all have their type <br>object pointer member set to refer to Type-T (a type object). This means that all three objects <br>are of the same type. As discussed in Chapter 4, "Type Fundamentals," a type object is also an <br>object in the heap, and like all other objects, a type object has the two overhead members: <br>a sync block index and a type object pointer. This means that a sync block can be associated <br>with a type object and a reference to a type object can be passed to Monitor's methods. By <br>the way, the sync block array is able to create more sync blocks if necessary, so you shouldn't <br>
<hr>
<A name=850></a><b>832 </b><br>
<b>Part V  Threading</b><br>
worry about the system running out of sync blocks if many objects are being synchronized <br>simultaneously.<br>
<b>Managed Heap</b><br>
<b>CLR's Array</b><br>
<b>of Sync Blocks</b><br>
Object-A<br>
Sync block #0<br>
Type object ptr<br>
Sync block index (0)<br>
Sync block #1<br>
Object's Instance Fields<br>
Sync block #2<br>
Sync block #3<br>
Object-B<br>
Type object ptr<br>
...<br>
Sync block index (-1)<br>
Object's Instance Fields<br>
Object-C<br>
Type-T<br>
Type object ptr<br>
Type object ptr<br>
Sync block index (2)<br>
Sync block index (3)<br>
Object's Instance Fields<br>
Type's Static Fields<br>
<b>FIGURE 29-1  </b>Objects in the heap (including type objects) can have their sync block indexes refer to an entry <br>in the CLR's sync block array<br>
Here is some code that demonstrates how the Monitor class was originally intended to be <br>used:<br>
internal sealed class Transaction { <br>   private DateTime m_timeOfLastTrans; <br> <br>   public void PerformTransaction() { <br>      Monitor.Enter(this); <br>      // This code has exclusive access to the data... <br>      m_timeOfLastTrans = DateTime.Now; <br>      Monitor.Exit(this); <br>   } <br> <br>   public DateTime LastTransaction { <br>      get { <br>         Monitor.Enter(this); <br>         // This code has shared access to the data... <br>         DateTime temp = m_timeOfLastTrans; <br>         Monitor.Exit(this); <br>         return temp; <br>      } <br>   } <br>}<br>
<hr>
<A name=851></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>833</b><br>
On the surface, this seems simple enough, but there is something wrong with this code. The <br>problem is that each object's sync block index is implicitly public. The code below demon-<br>strates the impact of this.<br>
public static void SomeMethod() { <br>   var t = new Transaction(); <br>   Monitor.Enter(t); // This thread takes the object's public lock <br> <br>   // Have a thread pool thread display the LastTransaction time <br>   // NOTE: The thread pool thread blocks until SomeMethod calls Monitor.Exit! <br>   ThreadPool.QueueUserWorkItem(o =&gt; Console.WriteLine(t.LastTransaction)); <br> <br>   // Execute some other code here...    <br>   Monitor.Exit(t); <br>}<br>
In this code, the thread executing SomeMethod calls Monitor.Enter, taking the Transaction <br>object's publicly exposed lock. When the thread pool thread queries the LastTransaction <br>property, this property also calls Monitor.Enter to acquire the same lock, causing the <br>thread pool thread to block until the thread executing SomeMethod calls Monitor.Exit. <br>Using a debugger, you can determine that the thread pool thread is blocked inside the <br>LastTransaction property, but it is very hard to determine which other thread has the lock. <br>If you do somehow figure out which thread has the lock, then you have to figure out what <br>code caused it to take the lock. This is very difficult, and even worse, if you do figure it out, <br>then the code might not be code that you have control over and you might not be able to <br>modify this code to fix the problem. Therefore, my suggestion to you is to always use a  <br>private lock instead. Here's how I'd fix the Transaction class:<br>
internal sealed class Transaction { <br>   private readonly Object m_lock = new Object(); // Each transaction has a PRIVATE lock now <br>   private DateTime m_timeOfLastTrans; <br> <br>   public void PerformTransaction() { <br>      Monitor.Enter(m_lock);     // Enter the private lock <br>      // This code has exclusive access to the data... <br>      m_timeOfLastTrans = DateTime.Now; <br>      Monitor.Exit(m_lock);      // Exit the private lock <br>   } <br> <br>   public DateTime LastTransaction { <br>      get { <br>         Monitor.Enter(m_lock);  // Enter the private lock <br>         // This code has shared access to the data... <br>         DateTime temp = m_timeOfLastTrans; <br>         Monitor.Exit(m_lock);   // Exit the private lock <br>         return temp; <br>      } <br>   } <br>}<br>
<hr>
<A name=852></a><b>834 </b><br>
<b>Part V  Threading</b><br>
If Transaction's members were static, then simply make the m_lock field static, too, and <br>now the static members are thread safe.<br>
It should be clear from this discussion that Monitor should not have been implemented as <br>a static class; it should have been implemented like all the other constructs: a class you in-<br>stantiate and call instance methods on. In fact, Monitor has many other problems associated <br>with it that are all because it is a static class. Here is a list of additional problems:<br>
  A variable can refer to a proxy object if the type of object it refers to is derived from <br>
the System.MarshalByRefObject class (discussed in Chapter 22, "CLR Hosting and <br>AppDomains"). When you call Monitor's methods, passing a reference to a proxy  <br>object, you are locking the proxy object, not the actual object that the proxy refers to.<br>
  If a thread calls Monitor.Enter, passing it a reference to a type object that has been <br>
loaded domain neutral (discussed in Chapter 22), the thread is taking a lock on that <br>type across all AppDomains in the process. This is a known bug in the CLR that violates <br>the isolation that AppDomains are supposed to provide. The bug is difficult to fix in a <br>high-performance way, so it never gets fixed. The recommendation is to never pass a <br>reference to a type object into Monitor's methods.<br>
  Because strings can be interned (as discussed in Chapter 14, "Chars, Strings, and <br>
Working with Text"), two completely separate pieces of code could unknowingly get <br>references to a single String object in memory. If they pass the reference to the <br>String object into Monitor's methods, then the two separate pieces of code are now <br>synchronizing their execution with each other unknowingly.<br>
  When passing a string across an AppDomain boundary, the CLR does not make a <br>
copy of the string; instead, it simply passes a reference to the string into the other <br>AppDomain. This improves performance, and in theory, it should be OK since String <br>objects are immutable. However, like all objects, String objects have a sync block <br>index associated with them, which is mutable, and this allows threads in different <br>AppDomains to synchronize with each other unknowingly. This is another bug in CLR's <br>AppDomain isolation story. The recommendation is never to pass String references to <br>Monitor's methods.<br>
  Since Monitor's methods take an Object, passing a value type causes the value type <br>
to get boxed, resulting in the thread taking a lock on the boxed object. Each time <br>Monitor.Enter is called, a lock is taken on a completely different object and you get <br>no thread synchronization at all.<br>
  Applying the [MethodImpl(MethodImplOptions.Synchronized)] attribute to a <br>
method causes the JIT compiler to surround the method's native code with calls to <br>Monitor.Enter and Monitor.Exit. If the method is an instance method, then this is <br>passed to these methods, locking the implicitly public lock. If the method is static, then <br>a reference to the type's type object is passed to these methods, potentially locking a <br>domain-neutral type. The recommendation is to never use this attribute.<br>
<hr>
<A name=853></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>835</b><br>
  When calling a type's type constructor (discussed in Chapter 8, "Methods"), the CLR <br>
takes a lock on the type's type object to ensure that only one thread initializes the type <br>object and its static fields. Again, this type could be loaded domain neutral, causing a <br>problem. For example, if the type constructor's code enters an infinite loop, then the <br>type is unusable by all AppDomains in the process. The recommendation here is to <br>avoid type constructors as much as possible or least keep them short and simple.<br>
Unfortunately, the story gets worse. Since it is so common for developers to take a lock, do <br>some work, and then release the lock within a single method, the C# language offers simpli-<br>fied syntax via its lock keyword. Suppose that you write a method like this:<br>
private void SomeMethod() { <br>   lock (this) { <br>      // This code has exclusive access to the data... <br>   } <br>}<br>
It is equivalent to having written the method like this:<br>
private void SomeMethod() { <br>   Boolean lockTaken = false; <br>   try { <br>      //  <br>      Monitor.Enter(this, ref lockTaken); <br>      // This code has exclusive access to the data... <br>   } <br>   finally { <br>      if (lockTaken) Monitor.Exit(this); <br>   } <br>}<br>
The first problem here is that the C# team felt that they were doing you a favor by calling <br>Monitor.Exit in a finally block. Their thinking was that this ensures that the lock is always <br>released no matter what happens inside the try block. However, this is not a good thing. If <br>an exception occurs inside the try block while changing state, then the state is now corrupted. <br>When the lock is exited in the finally block, another thread will now start manipulating <br>the corrupted state. It is better to have your application hang than it is to continue running <br>with a corrupted state and potential security holes. The second problem is that entering and <br>leaving a try block decreases the performance of the method. And some JIT compilers won't <br>inline a method that contains a try block in it, decreasing performance even more. So now <br>we have slower code that lets threads access corrupted state.3 The recommendation is not to <br>use C#'s lock statement.<br>
Now we get to the Boolean lockTaken variable. Here is the problem that this variable is try-<br>ing to solve. Let's say that a thread enters the try block and before calling Monitor.Enter, <br>
3  By the way, while still a performance hit, it is safe to release a lock in a finally block if the code in the try block <br>
reads the state without attempting to modify it.<br>
<hr>
<A name=854></a><b>836 </b><br>
<b>Part V  Threading</b><br>
the thread is aborted (as discussed in Chapter 22). Now the finally block is called, but its <br>code should not exit the lock. The lockTaken variable solves this problem. It is initialized to <br>false, which assumes that the lock has not been entered into. Then, if Monitor.Enter is <br>called and successfully takes the lock, it sets lockTaken to true. The finally block examines <br>lockTaken to know whether to call Monitor.Exit or not.4 By the way, the SpinLock struc-<br>ture also supports this lockTaken pattern.<br>
<b>The </b>ReaderWriterLockSlim<b> Class</b><br>
It is common to have threads simply read the contents of some data. If this data is protected <br>by a mutual exclusive lock (like the SimpleSpinLock, SimpleWaitLock, SimpleHybridLock, <br>AnotherHybridLock, Mutex, or Monitor), then if multiple threads attempt this access <br>concurrently, only one thread gets to run and all the other threads are blocked, which <br>can reduce scalability and throughput in your application substantially. However, if all <br>the threads want to access the data in a read-only fashion, then there is no need to block <br>them at all; they should all be able to access the data concurrently. On the other hand, if a <br>thread wants to modify the data, then this thread needs exclusive access to the data. The <br>ReaderWriterLockSlim construct encapsulates the logic to solve this problem. Specifically, <br>the construct controls threads like this:<br>
  When one thread is writing to the data, all other threads requesting access are blocked.<br>
  When one thread is reading from the data, other threads requesting read access are <br>
allowed to continue executing, but threads requesting write access are blocked.<br>
  When a thread writing to the data has completed, either a single writer thread is  <br>
unblocked so it can access the data or all the reader threads are unblocked so that all <br>of them can access the data concurrently. If no threads are blocked, then the lock is <br>free and available for the next reader or writer thread that wants it.<br>
  When all threads reading from the data have completed, a single writer thread is  <br>
unblocked so it can access the data. If no threads are blocked, then the lock is free  <br>and available for the next reader or writer thread that wants it.<br>
Here is what this class looks like (some method overloads are not shown):<br>
public class ReaderWriterLockSlim : IDisposable { <br>   public ReaderWriterLockSlim(LockRecursionPolicy recursionPolicy); <br>   public void Dispose(); <br> <br>   public void    EnterReadLock(); <br>   public Boolean TryEnterReadLock(Int32 millisecondsTimeout); <br>   public void    ExitReadLock(); <br> <br>
4  The try/finally blocks and the lockTaken variable are potentially useful if what you're passing to Monitor's <br>
methods is a reference to a domain-agile object, like a String, or a domain-neutral type object. Sure, state in one <br>AppDomain might get corrupted, but threads in other AppDomains will be allowed to keep running.<br>
<hr>
<A name=855></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>837</b><br>
   public void    EnterWriteLock(); <br>   public Boolean TryEnterWriteLock(Int32 millisecondsTimeout); <br>   public void    ExitWriteLock(); <br> <br>   // Most applications will never query any of these properties  <br>   public Boolean IsReadLockHeld              { get; } <br>   public Boolean IsWriteLockHeld             { get; } <br>   public Int32   CurrentReadCount            { get; } <br>   public Int32   RecursiveReadCount          { get; } <br>   public Int32   RecursiveWriteCount         { get; } <br>   public Int32   WaitingReadCount            { get; } <br>   public Int32   WaitingWriteCount           { get; } <br>   public LockRecursionPolicy RecursionPolicy { get; } <br>   // Members related to upgrading from a reader to a writer not shown <br>}<br>
Here is some code that demonstrates the use of this construct:<br>
internal sealed class Transaction : IDisposable { <br>   private readonly ReaderWriterLockSlim m_lock =  <br>      new ReaderWriterLockSlim(LockRecursionPolicy.NoRecursion); <br>   private DateTime m_timeOfLastTrans; <br> <br>   public void PerformTransaction() { <br>      m_lock.EnterWriteLock(); <br>      // This code has exclusive access to the data... <br>      m_timeOfLastTrans = DateTime.Now; <br>      m_lock.ExitWriteLock(); <br>   } <br> <br>   public DateTime LastTransaction { <br>      get { <br>         m_lock.EnterReadLock(); <br>         // This code has shared access to the data... <br>         DateTime temp = m_timeOfLastTrans; <br>         m_lock.ExitReadLock(); <br>         return temp; <br>      } <br>   } <br> <br>   public void Dispose() { m_lock.Dispose(); } <br>}<br>
There are a few concepts related to this construct that deserve special mention. First, <br>ReaderWriterLockSlim's constructor allows you to pass in a LockRecurionsPolicy flag, <br>which is defined as follows:<br>
public enum LockRecursionPolicy { NoRecursion, SupportsRecursion }<br>
If you pass the SupportsRecursion flag, then the lock will add thread ownership and recur-<br>sion behaviors to the lock. As discussed earlier in this chapter, these behaviors negatively <br>affect the lock's performance, so I recommend that you always pass LockRecursionPolicy.<br>NoRecursion to the constructor (as I've done). For a reader-writer lock, supporting thread <br>
<hr>
<A name=856></a><IMG src="CLRviaCsharp-856_1.jpg"><br>
<b>838 </b><br>
<b>Part V  Threading</b><br>
ownership and recursion is phenomenally expensive because the lock must keep track <br>of all the reader threads that it has let into the lock and keep a separate recursion count <br>for each reader thread. In fact, to maintain all this information in a thread-safe way, the <br>ReaderWriterLockSlim internally uses a mutually exclusive spinlock! No, I'm not kidding.<br>
The ReaderWriterLockSlim class offers additional methods (not shown earlier) that allow  <br>a reading thread to upgrade itself to a writer thread. Later, the thread can downgrade itself  <br>back to a reader thread. The thinking here is that a thread could start reading the data and <br>based on the data's contents, the thread might want to modify the data. To do this, the <br>thread would upgrade itself from a reader to a writer. Having the lock support this behavior <br>deteriorates the lock's performance, and I don't think that this is a useful feature at all. Here's <br>why: A thread can't just turn itself from a reader into a writer. Other threads may be reading,  <br>too, and these threads will have to exit the lock completely before the thread trying to up-<br>grade is allowed to become a writer. This is the same as having the reader thread exit the <br>lock and then immediately acquire it for writing.<br>
<b>Note  </b>The FCL also ships a ReaderWriterLock construct, which was introduced in the Microsoft <br>.NET Framework version 1.0. This construct had so many problems that Microsoft introduced the <br>ReaderWriterLockSlim construct in .NET Framework version 2.0. The team didn't improve the <br>ReaderWriterLock construct for fear of losing compatibility with applications that were using <br>it. Here are the problems with the ReaderWriterLock. Even without thread contention, it is very <br>slow. There is no way to opt out of the thread ownership and recursion behaviors, making the <br>lock even slower. It favors reader threads over writer threads, and therefore writer threads can <br>get queued up and are rarely serviced, resulting in denial of service problems.<br>
<b>The </b>OneManyLock<b> Class</b><br>
I have created my own reader-writer construct that is faster than the FCL's <br>ReaderWriterLockSlim class.5 My class is called OneManyLock because it allows access to <br>either one writer thread or many reader threads. The class basically looks like this:<br>
public sealed class OneManyLock : IDisposable { <br>   public OneManyLock(); <br>   public void Dispose(); <br> <br>   public void Enter(Boolean exclusive); <br>   public void Leave(); <br>}<br>
Now I'd like to give you a sense of how it works. Internally, the class has an Int32 field for the <br>state of the lock, a Semaphore object that reader threads block on, and an AutoResetEvent <br>
5  The code is inside the Ch29-1-HybridThreadSync.cs file that is part of the code that accompanies this book. You <br>
can download this code from <i>http://Wintellect.com/.</i><br>
<hr>
<A name=857></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>839</b><br>
object that writer threads block on. The Int32 state field is divided into five subfields as <br>follows:<br>
  Three bits (a number from 0 to 7) represent the state of the lock itself. The  <br>
possibilities are 0=Free, 1=OwnedByWriter, 2=OwnedByReaders, <br>3=OwnedByReadersAndWriterPending, and 4=ReservedForWriter. The values 5, 6,  <br>and 7 are unused.<br>
  Nine bits (a number from 0 to 511) represent the number of reader threads reading <br>
(RR) that the lock has currently allowed in.<br>
  Nine bits (a number from 0 to 511) represent the number of reader threads waiting <br>
(RW) to get into the lock. These threads block on the auto-reset event object.<br>
  Nine bits (a number from 0 to 511) represent the number of writer threads waiting <br>
(WW) to get into the lock. These threads block on the other semaphore<b> </b>object.<br>
  The two remaining bits are unused and always have a value of 0.<br>
Now, since all the information about the lock fits in a single Int32 field, I can manipulate this <br>field using the methods of the Interlocked class so the lock is incredibly fast and causes a <br>thread to block only when there is contention.<br>
Here's what happens when a thread enters the lock for shared access:<br>
  If the lock is Free: Set state to OwnedByReaders, RR=1, Return<br>
  If the lock is OwnedByReaders: RR++, Return<br>
  Else: RW++, Block reader thread. When the thread wakes, loop around and try again.<br>
Here's what happens when a thread that has shared access leaves the lock:<br>
  RR--<br>
  If RR &gt; 0: Return<br>
  If WW &gt; 0: Set state to ReservedForWriter, WW--, Release 1 blocked writer thread, <br>
Return<br>
  If RW==0 &amp;&amp; WW = 0: Set state to Free , Return<br>
Here's what happens when a thread enters the lock for exclusive access:<br>
  If the lock is Free: Set state to OwnedByWriter, Return<br>
  If the lock is ReservedForWriter: Set state to OwnedByWriter, Return<br>
  If the lock is OwnedByWriter: WW++, Block writer thread. When thread wakes, loop <br>
around and try again.<br>
  Else: Set state to OwnedByReadersAndWriterPending, WW++, Block writer thread. <br>
When thread wakes, loop around and try again.<br>
<hr>
<A name=858></a><b>840 </b><br>
<b>Part V  Threading</b><br>
Here's what happens when a thread that has exclusive access leaves the lock:<br>
  If WW==0 &amp;&amp; RW==0: Set state to Free, Return<br>
  If WW &gt; 0: Set state to ReservedForWriter, WW--, Release 1 blocked writer thread, <br>
Return<br>
  If WW==0 &amp;&amp; RW&gt;0: Set state to Free , RW=0, Wake all reader blocked read threads, <br>
Return<br>
Let's say that there is currently one thread reading from the lock and another thread wants to <br>enter the lock for writing. The writer thread will first check to see if the lock is Free, and since <br>it is not, the thread will advance to perform the next check. However, at this point, the reader <br>thread could leave the lock, and seeing that RR and WW are both 0, the thread could set the <br>lock's state to Free. This is a problem because the writer thread has already performed this <br>test and moved on. Basically what happened is that the reader thread changed the state that <br>the writer thread was accessing behind its back. I needed to solve this problem so that the <br>lock would function correctly.<br>
To solve the problem, all of these bit manipulations are performed using the technique I <br>showed in the "The Interlocked Anything Pattern" section from Chapter 28. If you recall, this <br>pattern lets you turn any operation into a thread-safe atomic operation. This is what allows <br>this lock to be so fast and have less state in it than other reader-writer locks. When I run  <br>performance tests comparing my OneManyLock against the FCL's ReaderWriterLockSlim <br>and ReaderWriterLock classes I get the following results:<br>
Incrementing x in OneManyLock: 406              Fastest <br>Incrementing x in ReaderWriterLockSlim: 999     ~2.5x slower  <br>Incrementing x in ReaderWriterLock: 2,051       ~5.0x slower<br>
Of course, since all reader-writer locks perform more logic than a mutually exclusive lock, <br>their performance can be slightly worse. However, you have to weigh this against the fact <br>that a reader-writer lock allows multiple readers into the lock simultaneously.<br>
Before leaving this section, I'll also mention that my Power Threading library (download-<br>able for free from <i>http://Wintellect.com/</i>) offers a slightly different version of this lock, called <br>OneManyResourceLock. This lock and others in the library offer many additional features <br>such as deadlock detection, the ability to turn on lock ownership and recursion (albeit at a <br>performance cost), a unified programming model for all locks, and the ability to observe the <br>runtime behavior of the locks. For observing behavior, you can see the maximum amount of <br>time that a thread ever waited to acquire a lock and you can see the minimum and maximum <br>amount of time that a lock was held.<br>
<hr>
<A name=859></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>841</b><br>
<b>The </b>CountdownEvent<b> Class</b><br>
The next construct is System.Threading.CountdownEvent. Internally, this construct uses <br>a ManualResetEventSlim object. This construct blocks a thread until its internal counter <br>reaches 0. In a way, this construct's behavior is the opposite of that of a Semaphore (which <br>blocks threads while its count is 0). Here is what this class looks like (some method overloads <br>are not shown):<br>
public class CountdownEvent : IDisposable { <br>   public CountdownEvent(Int32 initialCount); <br>   public void Dispose(); <br>   public void Reset(Int32 count);                // Set CurrentCount to count <br>   public void AddCount(Int32 signalCount);       // Increments CurrentCount by signalCount <br>   public Boolean TryAddCount(Int32 signalCount); // Increments CurrentCount by signalCount <br>   public Boolean Signal(Int32 signalCount);      // Decrements CurrentCount by signameCount <br>   public Boolean Wait(Int32 millisecondsTimeout, CancellationToken cancellationToken); <br> <br>   public Int32      CurrentCount { get; } <br>   public Boolean    IsSet        { get; }        // true if CurrentCount is 0 <br>   public WaitHandle WaitHandle   { get; } <br>}<br>
Once a CountdownEvent's CurrentCount reaches 0, it cannot be changed. The AddCount <br>method throws InvalidOperationException when CurrentCount is 0, while the <br>TryAddCount method simply returns false if<b> </b>CurrentCount is 0.<br>
<b>The </b>Barrier<b> Class</b><br>
The System.Threading.Barrier construct is designed to solve a very rare problem, so it <br>is unlikely that you will have a use for it. Barrier is used to control a set of threads that are <br>working together in parallel so that they can step through phases of the algorithm together. <br>Perhaps an example is in order: When the CLR is using the server version of its garbage  <br>collector, the GC algorithm creates one thread per core. These threads walk up different  <br>application threads' stacks, concurrently marking objects in the heap. As each thread  <br>completes its portion of the work, it must stop waiting for the other threads to complete <br>their portion of the work. After all threads have marked the objects, then the threads can <br>compact different portions of the heap concurrently. As each thread finishes compacting its <br>portion of the heap, the thread must block waiting for the other threads. After all the threads <br>have finished compacting their portion of the heap, then all the threads walk up the applica-<br>tion's threads' stacks, fixing up roots to refer to the new location of the compacted object. <br>Only after all the threads have completed this work is the garbage collector considered  <br>complete and the application's threads can be resumed.<br>
This scenario is easily solved using the Barrier class, which looks like this (some method <br>overloads are not shown):<br>
<hr>
<A name=860></a><b>842 </b><br>
<b>Part V  Threading</b><br>
public class Barrier : IDisposable { <br>   public Barrier(Int32 participantCount, Action&lt;Barrier&gt; postPhaseAction); <br>   public void Dispose(); <br>   public Int64 AddParticipants(Int32 participantCount);   // Adds participants <br>   public void RemoveParticipants(Int32 participantCount); // Subtracts participants <br>   public Boolean SignalAndWait(Int32 millisecondsTimeout, CancellationToken <br>     cancellationToken); <br> <br>   public Int64 CurrentPhaseNumber    { get; }  // Indicates phase in process (starts at 0) <br>   public Int32 ParticipantCount      { get; }  // Number of participants <br>   public Int32 ParticipantsRemaining { get; }  // # of threads needing to call  <br>     SignalAndWait <br>}<br>
When you construct a Barrier, you tell it how many threads are participating in the work, <br>and you can also pass an Action&lt;Barrier&gt; delegate referring to code that will be invoked  <br>whenever all participants complete a phase of the work. You can dynamically add and <br>remove participating threads from the Barrier by calling the AddParticipant and <br>RemoveParticipant methods but, in practice, this is rarely done. As each thread completes <br>its phase of the work, it should call SignalAndWait, which tells the Barrier that the thread <br>is done and the Barrier blocks the thread (using a ManualResetEventSlim). After all par-<br>ticipants call SignalAndWait, the Barrier invokes the delegate (using the last thread that <br>called SignalAndWait) and then unblocks all the waiting threads so they can begin the next <br>phase.<br>
<b>Thread Synchronization Construct Summary</b><br>
My recommendation always is to avoid writing code that blocks any threads. When perform-<br>ing asynchronous compute or I/O operations, hand the data off from thread to thread in <br>such a way to avoid the chance that multiple threads could access the data simultaneously. <br>I demonstrated this with the pipe server and client code shown in Chapter 27, "I/O-Bound <br>Asynchronous Operations." If you are unable to fully accomplish this, then try to use the <br>VolatileRead, VolatileWrite, and Interlocked methods because they are fast and <br>they also never block a thread. Unfortunately, these methods manipulate only simple types, <br>but you can perform rich operations on these types as described in the "The Interlocked <br>Anything Pattern" section.<br>
There are two main reasons why you would consider blocking threads:<br>
<b>  The programming model is simplified.  </b>By blocking a thread, you are sacrificing <br>
some resources and performance so that you can write your application code sequen-<br>tially without using callback methods.<br>
<b>  A thread has a dedicated purpose.  </b>Some threads must be used for specific tasks. <br>
The best example is an application's primary thread. If an application's primary thread <br>doesn't block, then it will eventually return and the whole process will terminate. <br>Another example is an application's GUI thread or threads. Windows requires that a <br>
<hr>
<A name=861></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>843</b><br>
window or control always be manipulated by the thread that created it, so we some-<br>times write code that blocks a GUI thread until some other operation is done and then <br>the GUI thread updates any windows and controls as needed. Of course, blocking the <br>GUI thread hangs the application and provides a bad end-user experience.<br>
To avoid blocking threads, don't mentally assign a label to your threads. For example, don't <br>create a spell-checking thread, a grammar-checking thread, a thread that handles this partic-<br>ular client request, and so on. The moment you assign a label to a thread, you have also said <br>to yourself that that thread can't do anything else. But threads are too expensive a resource <br>to have them dedicated to a particular purpose. Instead, you should use the thread pool to <br>rent threads for short periods of time. So a thread pool thread starts out spell checking, then <br>it changes to grammar checking, and then it changes again to perform work on behalf of a <br>client request, and so on.<br>
If, in spite of this discussion, you decide to block threads, then use the kernel object constructs <br>if you want to synchronize threads that are running in different AppDomains or processes. <br>To atomically manipulate state via a set of operations, use the Monitor class with a private <br>field.6 Alternatively, you could use a reader-writer lock instead of Monitor. Reader-writer locks <br>are generally slower than Monitor, but they allow multiple reader threads to execute concur-<br>rently, which improves overall performance and minimizes the chance of blocking threads.<br>
In addition, avoid using recursive locks (especially recursive reader-writer locks) because they <br>hurt performance. However, Monitor is recursive and its performance is very good.7 Also, <br>avoid releasing a lock in a finally block because entering and leaving exception-handling <br>blocks incurs a performance hit, and if an exception is thrown while mutating state, then the <br>state is corrupted and other threads that manipulate it will experience unpredictable behavior <br>and security bugs.<br>
Of course, if you do write code that holds a lock, your code should not hold the lock for a <br>long time because this increases the likelihood of threads blocking. In the "Using Collections <br>to Avoid Holding a Lock for a Long Time" section, I will show a technique that uses collection <br>classes as a way to avoid holding a lock for a long time.<br>
Finally, for compute-bound work, you can use tasks (discussed in Chapter 26) to avoid a lot <br>of the thread synchronization constructs. In particular, I love that each task can have one or <br>more continue-with tasks associated with it that execute via some thread pool thread when <br>some operation completes. This is much better than having a thread block waiting for some <br>operation to complete. For I/O-bound work, the Asynchronous Programming Model (APM) <br>invokes your callback method when the I/O operation completes; this is similar to a task's <br>continue-with task.<br>
6  You could use a SpinLock instead of Monitor because SpinLocks are slightly faster. But a SpinLock is potentially <br>
dangerous because it can waste CPU time and, in my opinion, it is not sufficiently faster than Monitor to justify its <br>use.<br>
7  This is partially because Monitor is actually implemented in native code, not managed code.<br>
<hr>
<A name=862></a><b>844 </b><br>
<b>Part V  Threading</b><br>
<b>The Famous Double-Check Locking Technique</b><br>
There is a famous technique called <i>double-check locking,</i> which is used by developers who <br>want to defer constructing a singleton object until an application requests it (sometimes <br>called <i>lazy initialization</i>). If the application never requests the object, it never gets constructed, <br>saving time and memory. A potential problem occurs when multiple threads request the <br>singleton object simultaneously. In this case, some form of thread synchronization must be <br>used to ensure that the singleton object gets constructed just once.<br>
This technique is not famous because it is particularly interesting or useful. It is famous  <br>because there has been much written about it. This technique was used heavily in Java, and <br>later it was discovered that Java couldn't guarantee that it would work everywhere. The  <br>famous document that describes the problem can be found on this Web page:  <br><i>www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html.</i><br>
Anyway, you'll be happy to know that the CLR supports the double-check locking technique <br>just fine because of its memory model and volatile field access (described in Chapter 28). Here <br>is code that demonstrates how to implement the double-check locking technique in C#:<br>
internal sealed class Singleton {  <br>   // s_lock is required for thread safety and having this object assumes that creating   <br>   // the singleton object is more expensive than creating a System.Object object and that  <br>   // creating the singleton object may not be necessary at all. Otherwise, it is more   <br>   // efficient and easier to just create the singleton object in a class constructor <br>   private static readonly Object s_lock = new Object();  <br>  <br>   // This field will refer to the one Singleton object <br>   private static Singleton s_value = null;   <br>     <br>   // Private constructor prevents any code outside this class from creating an instance  <br>   private Singleton() {  <br>      // Code to initialize the one Singleton object goes here... <br>   } <br>  <br>   // Public, static method that returns the Singleton object (creating it if necessary)  <br>   public static Singleton GetSingleton() {  <br>      // If the Singleton was already created, just return it (this is fast) <br>      if (s_value != null) return s_value; <br> <br>      Monitor.Enter(s_lock);  // Not created, let 1 thread create it <br>      if (s_value == null) {   <br>         // Still not created, create it <br>         Singleton temp = new Singleton(); <br> <br>         // Save the reference in s_value (see discussion for details) <br>         Interlocked.Exchange(ref s_value, temp);  <br>      } <br>      Monitor.Exit(s_lock); <br>  <br>      // Return a reference to the one Singleton object  <br>      return s_value;  <br>   }  <br>}<br>
<hr>
<A name=863></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>845</b><br>
The idea behind the double-check locking technique is that a call to the GetSingleton <br>method quickly checks the s_value field to see if the object has already been created, and <br>if it has, the method returns a reference to it. The beautiful thing here is that no thread syn-<br>chronization is required once the object has been constructed; the application will run very <br>fast. On the other hand, if the first thread that calls the GetSingleton method sees that the <br>object hasn't been created, it takes a thread synchronization lock to ensure that only one <br>thread constructs the single object. This means that a performance hit occurs only the first <br>time a thread queries the singleton object.<br>
Now, let me explain why this pattern didn't work in Java. The Java Virtual Machine read the <br>value of s_value into a CPU register at the beginning of the GetSingleton method and <br>then just queried the register when evaluating the second if statement, causing the second <br>if statement to always evaluate to true, and multiple threads ended up creating Singleton <br>objects. Of course, this happened only if multiple threads called GetSingleton at the exact <br>same time, which in most applications is very unlikely. This is why it went undetected in Java <br>for so long.<br>
In the CLR, calling any lock method is a full memory fence, and any variable writes you have <br>before the fence must complete before the fence and any variable reads after the fence must <br>start after it. For the GetSingleton method, this means that the s_value field must be  <br>reread after the call to Monitor.Enter; it cannot be cached in a register across this method <br>call.<br>
Inside GetSingleton, you see the call to Interlocked.Exchange. Here's the problem that <br>this is solving. Let's say that what you had inside the second if statement was the following <br>line of code:<br>
s_value = new Singleton();  // This is what you'd ideally like to write<br>
You would expect the compiler to produce code that allocates the memory for a Singleton, <br>calls the constructor to initialize the fields, and then assigns the reference into the s_value <br>field. Making a value visible to other threads is called <i>publishing</i>. But the compiler could do <br>this instead: allocate memory for the Singleton, publish (assign) the reference into s_value, <br>and then call the constructor. From a single thread's perspective, changing the order like this <br>has no impact. But what if, after publishing the reference into s_value and before calling the <br>constructor, another thread cal s the GetSingleton method? This thread wil  see that s_value <br>is not null and start to use the Singleton object, but its constructor has not finished ex-<br>ecuting yet! This can be a very hard bug to track down, especially since it is all due to timing.<br>
The call to Interlocked.Exchange fixes this problem. It ensures that the reference in temp <br>can be published into s_value only after the constructor has finished executing. Another <br>way to solve this problem would be to mark the s_value field with C#'s volatile keyword. <br>This makes the write to s_value volatile, and again, the constructor has to finish running be-<br>fore the write can happen. Unfortunately, this makes all reads volatile, too, and since there is <br>no need for this, you are hurting your performance with no benefit.<br>
<hr>
<A name=864></a><b>846 </b><br>
<b>Part V  Threading</b><br>
In the beginning of this section, I mentioned that the double-check locking technique is not <br>that interesting. In my opinion, developers think it is cool, and they use it far more often than <br>they should. In most scenarios, this technique actually hurts efficiency. Here is a much simpler <br>version of the Singleton class that behaves the same as the previous version. This version <br>does not use the double-check locking technique:<br>
internal sealed class Singleton {  <br>   private static Singleton s_value = new Singleton();   <br>     <br>   // Private constructor prevents any code outside this class from creating an instance  <br>   private Singleton() { <br>      // Code to initialize the one Singleton object goes here... <br>   }  <br> <br>   // Public, static method that returns the Singleton object (creating it if necessary)  <br>   public static Singleton GetSingleton() { return s_value; }  <br>}<br>
Since the CLR automatically calls a type's class constructor the first time code attempts to <br>access a member of the class, the first time a thread queries Singleton's GetSingleton <br>method, the CLR will automatically call the class constructor, which creates an instance of the <br>object. Furthermore, the CLR already ensures that calls to a class constructor are thread safe. <br>I explained all of this in Chapter 8. The one downside of this approach is that the type con-<br>structor is called when any member of a class is first accessed. If the Singleton type defined <br>some other static members, then the Singleton object would be created when any one of <br>them was accessed. Some people work around this problem by defining nested classes.<br>
Let me show you a third way of producing a single Singleton object:<br>
internal sealed class Singleton { <br>   private static Singleton s_value = null; <br> <br>   // Private constructor prevents any code outside this class from creating an instance  <br>   private Singleton() { <br>      // Code to initialize the one Singleton object goes here... <br>   } <br> <br>   // Public, static method that returns the Singleton object (creating it if necessary)  <br>   public static Singleton GetSingleton() { <br>      if (s_value != null) return s_value; <br> <br>      // Create a new Singleton and root it if another thread didn't do it first <br>      Singleton temp = new Singleton(); <br>      Interlocked.CompareExchange(ref s_value, temp, null); <br> <br>      // If this thread lost, then the second Singleton object gets GC'd <br> <br>      return s_value; // Return reference to the single object <br>   } <br>}<br>
<hr>
<A name=865></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>847</b><br>
If multiple threads call GetSingleton simultaneously, then this version might create two (or <br>more) Singleton objects. However, the call to Interlocked.CompareExchange ensures that <br>only one of the references is ever published into the s_value field. Any object not rooted <br>by this field will be garbage collected later on. Since, in most applications, it is unlikely that <br>multiple threads will call GetSingleton at the same time, it is unlikely that more than one <br>Singleton object will ever be created.<br>
Now it might upset you that multiple Singleton objects could be created, but there are <br>many benefits to this code. First, it is very fast. Second, it never blocks a thread; if a thread <br>pool thread is blocked on a Monitor or any other kernel-mode thread synchronization con-<br>struct, then the thread pool creates another thread to keep the CPUs saturated with work. So <br>now, another megabyte or more of memory is allocated and initialized and all the DLLs get a <br>thread attach notification. With CompareExchange, this can never happen. Of course, you can <br>use this technique only when the constructor has no side effects.<br>
The FCL offers two types that encapsulate the patterns described in this section. The generic <br>System.Lazy class looks like this (some methods are not shown):<br>
public class Lazy&lt;T&gt; { <br>   public Lazy(Func&lt;T&gt; valueFactory, LazyThreadSafetyMode mode); <br>   public Boolean IsValueCreated { get; } <br>   public T Value { get; } <br>}<br>
This code demonstrates how it works:<br>
public static void Main() { <br>   // Create a lazy-initialization wrapper around getting the DateTime <br>   Lazy&lt;String&gt; s = new Lazy&lt;String&gt;( <br>      () =&gt; DateTime.Now.ToLongTimeString(),  <br>      LazyThreadSafetyMode.PublicationOnly); <br> <br>   Console.WriteLine(s.IsValueCreated);   // Returns false since Value not queried yet <br>   Console.WriteLine(s.Value);            // The delegate is invoked now <br>   Console.WriteLine(s.IsValueCreated);   // Returns true since Value was queried <br>   Thread.Sleep(10000);                   // Wait 10 seconds and display the time again <br>   Console.WriteLine(s.Value);            // The delegate is NOT invoked now; same result <br>}<br>
When I run this, I get the following output:<br>
False <br>2:40:42 PM <br>True <br>2:40:42 PM      Notice that the time did not change 10 seconds later<br>
The code above constructed an instance of the Lazy class and passed one of the <br>LazyThreadSafetyMode flags into it. Here is what these flags look like and what they mean:<br>
<hr>
<A name=866></a><b>848 </b><br>
<b>Part V  Threading</b><br>
public enum LazyThreadSafetyMode {  <br>   None,                      // No thread-safety support at all (good for GUI apps) <br>   ExecutionAndPublication    // Uses the double-check locking technique <br>   PublicationOnly,           // Uses the Interlocked.CompareExchange technique <br>}<br>
In some memory-constrained scenarios, you might not even want to create an instance  <br>of the Lazy class. Instead, you can call static methods of the System.Threading.<br>LazyInitializer class. The class looks like this:<br>
public static class LazyInitializer { <br>   // These two methods use Interlocked.CompareExchange internally:  <br>   public static T EnsureInitialized&lt;T&gt;(ref T target) where T: class; <br>   public static T EnsureInitialized&lt;T&gt;(ref T target, Func&lt;T&gt; valueFactory) where T: class; <br> <br>   // These two methods pass the syncLock to Monitor's Enter and Exit methods internally <br>   public static T EnsureInitialized&lt;T&gt;(ref T target, ref Boolean initialized,  <br>      ref Object syncLock); <br>   public static T EnsureInitialized&lt;T&gt;(ref T target, ref Boolean initialized,  <br>      ref Object syncLock, Func&lt;T&gt; valueFactory); <br>}<br>
Also, being able to explicitly specify a synchronization object to the EnsureInitialized <br>method's syncLock parameter allows multiple initialization functions and fields to be  <br>protected by the same lock.<br>
Here is an example using a method from this class:<br>
public static void Main() { <br>   String name = null;  <br>   // Since name is null, the delegate runs and initializes name <br>   LazyInitializer.EnsureInitialized(ref name, () =&gt; &quot;Jeffrey&quot;);   <br>   Console.WriteLine(name);   // Displays &quot;Jeffrey&quot; <br> <br>   // Since name is not null, the delegate does not run; name doesn't change <br>   LazyInitializer.EnsureInitialized(ref name, () =&gt; &quot;Richter&quot;); <br>   Console.WriteLine(name);   // Also displays &quot;Jeffrey&quot;  <br>}<br>
<b>The Condition Variable Pattern</b><br>
Let's say that a thread wants to execute some code when a complex condition is true. One <br>option would be to let the thread spin continuously, repeatedly testing the condition. But  <br>this wastes CPU time, and it is also not possible to atomically test multiple variables that are <br>making up the complex condition. Fortunately, there is a pattern that allows threads to  <br>efficiently synchronize their operations based on a complex condition. This pattern is called <br>the <i>condition variable pattern,</i> and we use it via the following methods defined inside the <br>Monitor class:<br>
<hr>
<A name=867></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>849</b><br>
public static class Monitor { <br>   public static Boolean Wait(Object obj); <br>   public static Boolean Wait(Object obj, Int32 millisecondsTimeout); <br> <br>   public static void Pulse(Object obj); <br>   public static void PulseAll(Object obj); <br>}<br>
Here is what the pattern looks like:<br>
internal sealed class ConditionVariablePattern { <br>   private readonly Object m_lock = new Object(); <br>   private Boolean m_condition = false; <br> <br>   public void Thread1() { <br>      Monitor.Enter(m_lock);        // Acquire a mutual-exclusive lock <br> <br>      // While under the lock, test the complex condition &quot;atomically&quot; <br>      while (!m_condition) { <br>         // If condition is not met, wait for another thread to change the condition <br>         Monitor.Wait(m_lock);      // Temporarily release lock so other threads can get it <br>      } <br> <br>      // The condition was met, process the data... <br> <br>      Monitor.Exit(m_lock);         // Permanently release lock <br>   } <br> <br>   public void Thread2() { <br>      Monitor.Enter(m_lock);        // Acquire a mutual-exclusive lock <br> <br>      // Process data and modify the condition... <br>      m_condition = true; <br> <br>      // Monitor.Pulse(m_lock);     // Wakes one waiter AFTER lock is released <br>      Monitor.PulseAll(m_lock);     // Wakes all waiters AFTER lock is released <br> <br>      Monitor.Exit(m_lock);         // Release lock <br>   } <br>}<br>
In this code, the thread executing the Thread1 method enters a mutual-exclusive lock and <br>then tests a condition. Here, I am just checking a Boolean field, but this condition can be  <br>arbitrarily complex. For example, you could check to see if it is a Tuesday in March and if a <br>certain collection object has 10 elements in it. If the condition is false, then you want the <br>thread to spin on the condition, but spinning wastes CPU time, so instead, the thread calls <br>Wait. Wait releases the lock so that another thread can get it and blocks the calling thread.<br>
The Thread2 method shows code that the second thread executes. It calls Enter to take <br>ownership of the lock, processes some data, which results in changing the state of the  <br>condition, and then calls Pulse(All), which will unblock a thread from its Wait call. Pulse <br>unblocks the longest waiting thread (if any), while PulseAll unblocks all waiting threads <br>
<hr>
<A name=868></a><b>850 </b><br>
<b>Part V  Threading</b><br>
(if any). However, any unblocked threads don't wake up yet. The thread executing Thread2 <br>must call Monitor.Exit, allowing the lock to be owned by another thread. Also, if PulseAll <br>is called, the other threads do not unblock simultaneously. When a thread that called Wait <br>is unblocked, it becomes the owner of the lock, and since it is a mutual-exclusive lock, only <br>one thread at a time can own it. Other threads can get it after an owning thread calls Wait or <br>Exit.<br>
When the thread executing Thread1 wakes, it loops around and tests the condition again. <br>If the condition is still false, then it calls Wait again. If the condition is true, then it processes <br>the data as it likes and ultimately calls Exit, leaving the lock so other threads can get it. <br>The nice thing about this pattern is that it is possible to test several variables making up a <br>complex condition using simple synchronization logic (just one lock), and multiple waiting <br>threads can all unblock without causing any logic failure, although the unblocking threads <br>might waste some CPU time.<br>
Here is an example of a thread-safe queue that can have multiple threads enqueuing and <br>dequeuing items to it. Note that threads attempting to dequeue an item block until an item <br>is available for them to process.<br>
internal sealed class SynchronizedQueue&lt;T&gt; { <br>   private readonly Object m_lock = new Object(); <br>   private readonly Queue&lt;T&gt; m_queue = new Queue&lt;T&gt;(); <br> <br>   public void Enqueue(T item) { <br>      Monitor.Enter(m_lock); <br>    <br>      // After enqueuing an item, wake up any/all waiters <br>      m_queue.Enqueue(item); <br>      Monitor.PulseAll(m_lock); <br> <br>      Monitor.Exit(m_lock); <br>   } <br> <br>   public T Dequeue() { <br>      Monitor.Enter(m_lock); <br> <br>      // Loop while the queue is empty (the condition) <br>      while (m_queue.Count == 0)  <br>         Monitor.Wait(m_queue); <br> <br>      // Dequeue an item from the queue and return it for processing <br>      T item = m_queue.Dequeue(); <br>      Monitor.Exit(m_lock); <br>      return item; <br>   } <br>}<br>
<hr>
<A name=869></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>851</b><br>
<b>Using Collections to Avoid Holding a Lock for a Long </b><br>
<b>Time</b><br>
I'm not terribly fond of any of the thread synchronization constructs that use kernel-mode <br>primitives because all of these primitives exist to block a thread from running, and threads <br>are just too expensive to create and not have them run. Here is an example that hopefully <br>clarifies the problem.<br>
Imagine a Web site into which clients make requests. When a client request arrives, a thread <br>pool thread starts processing the client's request. Let's say that this client wants to modify <br>some data in the server in a thread-safe way, so it acquires a reader-writer lock for writing. <br>Let's pretend that this lock is held for a long time. As the lock is held, another client request <br>comes in, so that thread pool creates a new thread for the client request and then the thread <br>blocks trying to acquire the reader-writer lock for reading. In fact, as more and more client  <br>requests come in, the thread pool creates more and more threads and all these threads are <br>just blocking themselves on the lock. The server is spending all its time creating threads so <br>that they can stop running! This server does not scale well at all.<br>
Then, to make matters worse, when the writer thread releases the lock, all the reader threads <br>unblock simultaneously and get to run, but now there may be lots of threads trying to run <br>on relatively few CPUs, so Windows is context switching between the threads constantly. The <br>result is that the workload is not being processed as quickly as it could because of all the <br>overhead associated with the context switches.<br>
If you look over all the constructs shown in this chapter, many of the problems that these <br>constructs are trying to solve can be much better accomplished using the Task class  <br>discussed in Chapter 26. Take the Barrier class, for example: You could spawn several Task <br>objects to work on a phase and then, when all these tasks complete, you could continue with <br>one or more other Task objects. Compared to many of the constructs shown in this chapter, <br>tasks have many advantages:<br>
  Tasks use much less memory than threads and they take much less time to create and <br>
destroy.<br>
  The thread pool automatically scales the tasks across available CPUs.<br>
  As each task completes a phase, the thread running that task goes back to the thread <br>
pool where it can do other work if any is available for it.<br>
  The thread pool has a process-global view of tasks and, as such, it can better schedule <br>
these tasks, reducing the number of threads in the process and also reducing context <br>switching.<br>
<hr>
<A name=870></a><b>852 </b><br>
<b>Part V  Threading</b><br>
Reader-writer locks are very popular and useful.8 Trying to build one of these out of Task <br>objects would be quite challenging. However, my Power Threading library includes a non-<br>blocking read-writer class, which I call ReaderWriterGate. It looks like this (some methods <br>are not shown):<br>
public sealed class ReaderWriterGate : IDisposable { <br>   public ReaderWriterGate(); <br>   public void Dispose(); <br> <br>   public IAsyncResult BeginRead(ReaderWriterGateCallback callback, Object state,  <br>      AsyncCallback asyncCallback, Object asyncState); <br>   public Object EndRead(IAsyncResult result); <br> <br>   public IAsyncResult BeginWrite(ReaderWriterGateCallback callback, Object state,  <br>      AsyncCallback asyncCallback, Object asyncState); <br>   public Object EndWrite(IAsyncResult result); <br>}<br>
The ReaderWriterGateCallback is a delegate that looks like this:<br>
public delegate object ReaderWriterGateCallback(ReaderWriterGateReleaser releaser);<br>
The ReaderWriterGateReleaser class looks like this (some methods are not shown):<br>
public sealed class ReaderWriterGateReleaser : IDisposable { <br>   public Object State { get; }  // Returns the 'state' passed to BeginRead/BeginWrite <br>   public void Dispose(); <br>}<br>
The ReaderWriterGate makes a lock look just like an asynchronous I/O operation. In fact, <br>my class even offers BeginRead and BeginWrite methods that take an AsyncCallback  <br>delegate and return an IAsyncResult, as well as<b> </b>EndRead and<b> </b>EndWrite methods that ac-<br>cept an IAsyncResult. I designed the class to work exactly like the APM that was discussed <br>in Chapter 27.<br>
Here's how it works. Put the code that requires read access to a resource in its own method <br>and then call BeginRead, passing this method for the ReaderWriterGetCallback delegate <br>parameter. When it is safe to read from the resource, the ReaderWriterGate object will have <br>a thread pool thread invoke your method. Note that several thread pool threads could be <br>executing methods that read from the resource concurrently. Put the code that requires write <br>access to a resource in its own method and then call BeginWrite, passing this method for <br>the ReaderWriterGetCallback delegate parameter. When it is safe to write to the resource, <br>the ReaderWriterGate object will have a thread pool thread invoke your method. Note that <br>the ReaderWriterGate object ensures that there will be only one thread pool thread execut-<br>ing a method that writes to the resource at a particular time.<br>
8  Of course, if you only need mutual-exclusive access to a resource, you can always use a reader-writer lock and <br>
request only write access to the resource it protects.<br>
<hr>
<A name=871></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>853</b><br>
When your method finishes processing the resource and returns, the ReaderWriterGate  <br>object will invoke whatever method you passed to BeginRead's or BeginWrite's  <br>asyncCallback parameter; this is how you know when the operation completed.<br>
So now, let's return to our Web server discussion. A client makes a request to write to a  <br>resource, so a thread pool thread calls ReaderWriterGate's BeginWrite method. While the <br>thread is processing the callback method, another client makes a request. The thread pool <br>creates a new thread, and this thread calls BeginRead. The ReaderWriterGate object sees <br>that reading is not allowed at this time and it adds the callback delegate to an internal  <br>queue. The queue is a collection class, and it needs to be manipulated in a thread-safe way, <br>so a lock is taken around the manipulation of the collection. However, the lock is held only <br>while items are being added and removed from the queue, which requires a very short <br>amount of time. This means that other threads also using the ReaderWriterGate will not <br>block for long (if at all)!<br>
After the callback delegate has been added to the queue, the thread pool thread returns <br>to the pool. As more client requests come in, the <i>same</i> thread pool thread keeps waking up <br>and calling BeginRead, adding more and more delegates to the internal queue. So now the <br>server has only two threads in it doing all the work.<br>
When the first thread finishes writing to the resource, it returns from the callback method <br>to the ReaderWriterGate object. The ReaderWriterGate sees that there are a bunch of <br>delegates in its internal queue, so it posts all these delegates to the CLR's thread pool. Again, <br>a lock has to be taken around the manipulation of the queue, but the lock is held just long <br>enough to queue its callback delegates into the thread pool. The thread pool then spans <br>this work out over the cores using no more threads than there are cores, and so no context <br>switching occurs.9 Now, we have a scalable server that uses very little resources and runs with <br>great performance.<br>
A ReaderWriterGate object has another internal queue for delegates that wish to write to <br>the resource. When a write request shows up, any incoming reader delegates get queued so <br>that the current reader methods can finish and drain out of the gate. After the thread pool <br>threads have finished processing the previously queued reader methods, a single writer  <br>delegate is queued to the thread pool. This is how I ensure that only other thread is calling a <br>writer method at any given time.<br>
More details about the ReaderWriterGate can be found here: <i>http://msdn.microsoft.com <br>/en-us/magazine/cc163532.aspx.</i> After I came up with this idea, I sold the patent rights to <br>
9  This is assuming that other threads are not running on the computer which, most of the time, is true since most <br>
computers are running at far less than 100 percent CPU usage. And CPU usage can be at 100 percent and this <br>will still work as explained if the running threads have lower priorities. If other threads are running, then con-<br>text switching occurs. This is bad for performance reasons, but it is good for reliability reasons. Remember that <br>Windows gives each process at least one thread and performs context switches to ensure that a hung application <br>doesn't stop other applications from running.<br>
<hr>
<A name=872></a><b>854 </b><br>
<b>Part V  Threading</b><br>
Microsoft, and in 2009, the Patent Office issued the patent (Patent #7,603,502). However, <br>even though Microsoft owns the patent for this idea, the FCL does not provide any class that <br>implements this idea. However, I provide an implementation in my Power Threading library. <br>When I sold the rights to Microsoft, I acquired a license allowing Wintellect customers to use <br>this "invention" with the caveat that it can be used only on a Microsoft platform.10 By down-<br>loading the library from the Wintellect Web site, you are a Wintellect customer, and you can <br>use the library subject to the license restriction.<br>
In Chapter 27, I gave a brief introduction to my AsyncEnumerator class, which is also part <br>of my Power Threading library. This class enabled you to use a synchronous programming <br>model with classes that support the CLR's APM, and since my ReaderWriterGate supports <br>the APM, you can use it with the AsyncEnumerator. However, when I first tried this, I dis-<br>covered that I could simplify the programming model even more. So if you want to use my <br>AsyncEnumerator and also have multiple iterators accessing shared data in a thread-safe <br>way, use my SyncGate class instead of ReaderWriterGate. The SyncGate class is also in my <br>Power Threading library, and it looks like this:<br>
public sealed class SyncGate { <br>   public SyncGate(); <br>   public void BeginRegion(SyncGateMode mode,  <br>      AsyncCallback asyncCallback, Object asyncState); <br>   public void EndRegion(IAsyncResult result); <br>}<br>
You should see the samples in my Power Threading library for examples of using these <br>classes together, but I'll show a brief example here. I took the PipeServerAsyncEnumerator <br>method shown in Chapter 27 and modified it to record the timestamp of the most recent <br>client request in a static field accessible to all threads. Since multiple client requests can <br>be running simultaneously using various threads, updating the static field must be done <br>in a thread-safe way. To accomplish this, I create a static field that holds a reference to a <br>SyncGate object, and I call its BeginRegion and EndRegion methods to acquire and  <br>release exclusive access, respectively. Here is the new version of the code with the added <br>lines highlighted:<br>
// This field records the timestamp of the most recent client's request <br>private static DateTime s_lastClientRequestTimestamp = DateTime.MinValue; <br> <br>// The SyncGate enforces thread-safe access to the s_lastClientRequestTimestamp field <br>private static readonly SyncGate s_gate = new SyncGate(); <br> <br>private static IEnumerator&lt;Int32&gt; PipeServerAsyncEnumerator(AsyncEnumerator ae) { <br>   // Each server object performs asynchronous operations on this pipe <br>   using (var pipe = new NamedPipeServerStream( <br>
10 Silverlight is considered a Microsoft platform even if your Silverlight application is running in a non-Microsoft <br>
operating system. And, my Power Threading library does have a version of this class for Silverlight as well as the <br>Microsoft .NET Compact Framework.<br>
<hr>
<A name=873></a><hr>
<A name=874></a><b>856 </b><br>
<b>Part V  Threading</b><br>
<b>The Concurrent Collection Classes</b><br>
The FCL ships with four thread-safe collection classes, all of which are in the System.<br>Collections.Concurrent namespace. ConcurrentQueue, ConcurrentStack, and <br>ConcurrentDictionary are in MSCorLib.dll, while ConcurrentBag is in System.dll. Here is <br>what some of their most commonly used members look like:<br>
// Process items in a first-in, first-out order (FIFO) <br>public class ConcurrentQueue&lt;T&gt; : IProducerConsumerCollection&lt;T&gt;,  <br>   IEnumerable&lt;T&gt;, ICollection, IEnumerable { <br> <br>   public ConcurrentQueue(); <br>   public void Enqueue(T item); <br>   public Boolean TryDequeue(out T result); <br>   public Int32 Count { get; } <br>   public IEnumerator&lt;T&gt; GetEnumerator(); <br>} <br>// Process items in a last-in, first-out order (LIFO) <br>public class ConcurrentStack&lt;T&gt; : IProducerConsumerCollection&lt;T&gt;, <br>      IEnumerable&lt;T&gt;, ICollection, IEnumerable { <br> <br>   public ConcurrentStack(); <br>   public void Push(T item); <br>   public Boolean TryPop(out T result); <br>   public Int32 Count { get; } <br>   public IEnumerator&lt;T&gt; GetEnumerator(); <br>} <br>// An unordered set of items where duplicates are allowed <br>public class ConcurrentBag&lt;T&gt; : IProducerConsumerCollection&lt;T&gt;,  <br>   IEnumerable&lt;T&gt;, ICollection, IEnumerable { <br> <br>   public ConcurrentBag(); <br>   public void Add(T item); <br>   public Boolean TryTake(out T result); <br>   public Int32 Count { get; } <br>   public IEnumerator&lt;T&gt; GetEnumerator(); <br>} <br>// An unordered set of key/value pairs <br>public class ConcurrentDictionary&lt;TKey, TValue&gt; : IDictionary&lt;TKey, TValue&gt;, <br>   ICollection&lt;KeyValuePair&lt;TKey, TValue&gt;&gt;, IEnumerable&lt;KeyValuePair&lt;TKey, TValue&gt;&gt;,  <br>   IDictionary, ICollection, IEnumerable { <br> <br>   public ConcurrentDictionary(); <br>   public Boolean TryAdd(TKey key, TValue value); <br>   public Boolean TryGetValue(TKey key, out TValue value); <br>   public TValue this[TKey key] { get; set; } <br>   public Boolean TryUpdate(TKey key, TValue newValue, TValue comparisonValue); <br>   public Boolean TryRemove(TKey key, out TValue value); <br>   public TValue AddOrUpdate(TKey key, TValue addValue,  <br>      Func&lt;TKey, TValue&gt; updateValueFactory); <br>   public TValue GetOrAdd(TKey key, TValue value); <br>   public Int32 Count { get; } <br>   public IEnumerator&lt;KeyValuePair&lt;TKey, TValue&gt;&gt; GetEnumerator(); <br>}<br>
<hr>
<A name=875></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>857</b><br>
All these collection classes are non-blocking. That is, if a thread tries to extract an element <br>when no such element exists, the thread returns immediately; the thread does not block <br>waiting for an element to appear. This is why methods like TryDequeue, TryPop, TryTake, <br>and TryGetValue all return true if an item was obtained and false if not.<br>
These non-blocking collections are not necessarily lock-free. The ConcurrentDictionary <br>class uses Monitor internally, but the lock is held for a very short time while manipulating <br>the item in the collection. ConcurrentQueue and ConcurrentStack are lock-free; these both <br>internally use Interlocked methods to manipulate the collection. A single ConcurrentBag <br>object internally consists of a mini-collection object per thread. When a thread adds an item <br>to the bag, Interlocked methods are used to add the item to the calling thread's mini-<br>collection. When a thread tries to extract an element from the bag, the bag checks the call-<br>ing thread's mini-collection for the item. If the item is there, then an Interlocked method is <br>used to extract the item. If the thread's mini-collection doesn't have the item, then a Monitor <br>is taken internally to extract an item from another thread's mini-collection. We say that the <br>thread is <i>stealing</i> the item from another thread.<br>
You'll notice that all the concurrent classes offer a GetEnumerator method, which is typically  <br>used with C#'s foreach statement but can also be used with Language Integrated <br>Query (LINQ). For the ConcurrentStack, ConcurrentQueue, and ConcurrentBag, the <br>GetEnumerator method takes a snapshot of the collection's contents and returns elements <br>from this snapshot; the contents of the actual collection may change while enumerating over <br>the snapshot. ConcurrentDictionary's GetEnumerator method does not take a snapshot <br>of its contents, so the contents of the dictionary may change while enumerating over the <br>dictionary; beware of this. Also note that the Count property returns the number of elements <br>that are in the collection at the moment you query it. The count may immediately become <br>incorrect if other threads are adding or removing elements from the collection at the same <br>time.<br>
Three of the concurrent collection classes, ConcurrentStack, ConcurrentQueue, and <br>ConcurrentBag, implement the IProducerConsumerCollection interface, which is defined <br>as follows:<br>
public interface IProducerConsumerCollection&lt;T&gt; : IEnumerable&lt;T&gt;, ICollection, IEnumerable { <br>   Boolean TryAdd(T item); <br>   Boolean TryTake(out T item); <br>   T[] ToArray(); <br>   void CopyTo(T[] array, Int32 index); <br>}<br>
Any class that implements this interface can be turned into a blocking collection where <br>threads producing (adding) items will block if the collection is full and threads consuming  <br>(removing) items will block if the collection is empty. Of course, I'd try to avoid using  <br>blocking collections as their purpose in life is to block threads. To turn a non-blocking  <br>collection into a blocking collection, you construct a System.Collections.Concurrent.<br>
<hr>
<A name=876></a><b>858 </b><br>
<b>Part V  Threading</b><br>
BlockingCollection class, passing in a reference to a non-blocking col ection to its construc-<br>tor. The BlockingCollection class (defined in the System.dll assembly) looks like this (some <br>methods are not shown):<br>
public class BlockingCollection&lt;T&gt; : IEnumerable&lt;T&gt;, ICollection, IEnumerable, IDisposable { <br>   public BlockingCollection(IProducerConsumerCollection&lt;T&gt; collection, <br>      Int32 boundedCapacity); <br> <br>   public void Add(T item); <br>   public Boolean TryAdd(T item, Int32 msTimeout, CancellationToken cancellationToken); <br>   public void CompleteAdding(); <br> <br>   public T Take(); <br>   public Boolean TryTake(out T item, Int32 msTimeout, CancellationToken cancellationToken); <br> <br>   public Int32   BoundedCapacity   { get; } <br>   public Int32   Count             { get; } <br>   public Boolean IsAddingCompleted { get; }  // true if AddingComplete is called <br>   public Boolean IsCompleted       { get; }  // true if IsAddingComplete and Count==0 <br> <br>   public IEnumerable&lt;T&gt; GetConsumingEnumerable(CancellationToken cancellationToken); <br> <br>   public void CopyTo(T[] array, int index); <br>   public T[] ToArray(); <br>   public void Dispose(); <br>}<br>
When you construct a BlockingCollection, the boundedCapacity parameter indicates  <br>the maximum number of items that you want in the collection. If a thread calls Add when  <br>the underlying collection has reached its capacity, the producing thread will block. If  <br>preferred, the producing thread can call TryAdd, passing a timeout (in milliseconds) and/or  <br>a CancellationToken so that the thread blocks until the item is added, the timeout  <br>expires, or the CancellationToken is canceled (see Chapter 26 for more about the <br>CancellationToken class).<br>
The BlockingCollection class implements the IDisposable interface. When you <br>call Dispose, it calls Dispose on the underlying collection and also disposes of two <br>SemaphoreSlim objects that the class uses internally to block producers and consumers.<br>
When producers will not be adding any more items into the collection, a producer should <br>call the CompleteAdding method. This will signal the consumers that no more items will be <br>produced. Specifically, this causes a foreach loop that is using GetConsumingEnumerable  <br>to terminate. The example code below demonstrates how to set up a producer/consumer <br>scenario and signal completion:<br>
<hr>
<A name=877></a><b> </b><br>
<b>Chapter 29  Hybrid Thread Synchronization </b><br>
<b>859</b><br>
public static void Main() { <br>   var bl = new BlockingCollection&lt;Int32&gt;(new ConcurrentQueue&lt;Int32&gt;()); <br> <br>   // A thread pool thread will do the consuming <br>   ThreadPool.QueueUserWorkItem(ConsumeItems, bl); <br> <br>   // Add 5 items to the collection <br>   for (Int32 item = 0; item &lt; 5; item++) { <br>      Console.WriteLine(&quot;Producing: &quot; + item); <br>      bl.Add(item); <br>   } <br> <br>   // Tell the consuming thread(s) that no more items will be added to the collection <br>   bl.CompleteAdding(); <br> <br>   Console.ReadLine();  // For testing purposes <br>} <br> <br>private static void ConsumeItems(Object o) { <br>   var bl = (BlockingCollection&lt;Int32&gt;) o; <br> <br>   // Block until an item shows up, then process it <br>   foreach (var item in bl.GetConsumingEnumerable()) { <br>      Console.WriteLine(&quot;Consuming: &quot; + item); <br>   } <br> <br>   // The collection is empty and no more items are going into it <br>   Console.WriteLine(&quot;All items have been consumed&quot;); <br>}<br>
When I execute the above code, I get the following output:<br>
Producing: 0 <br>Producing: 1 <br>Producing: 2 <br>Producing: 3 <br>Producing: 4 <br>Consuming: 0 <br>Consuming: 1 <br>Consuming: 2 <br>Consuming: 3 <br>Consuming: 4 <br>All items have been consumed<br>
If you run this yourself, the Producing and Consuming lines could be interspersed, but the <br>All items have been consumed line will always be last.<br>
The BlockingCollection class also has static AddToAny, TryAddToAny, TakeFromAny, and <br>TryTakeFromAny methods. All of these methods take a BlockingCollection&lt;T&gt;[], as <br>well as an item, a timeout, and a CancellationToken. The (Try)AddToAny methods cycle <br>through all the collections in the array until they find a collection that can accept the item  <br>because it is below capacity. The (Try)TakeFromAny methods cycle through all the collections <br>in the array until they find a collection to remove an item from.<br>
<hr>
<A name=878></a><hr>
<A name=879></a><b>Index</b><br>
<b>Symbols and Numbers</b><br>
arity, defined, 284<br>Array class, 281, 385, 392<br>
.NET Framework. See Microsoft .NET Framework<br>
arrays<br>
access performance, 396­401<br>
<b>A</b><br>
casting, 390­391<br>defined, 385<br>
abstract keyword, 167, 187<br>
derived from Array class, 392<br>
accessor methods<br>
fixed-size, 401­403<br>
accessibility, 258<br>
implementing interfaces, 393­394<br>
AIP support, 241­242<br>
initializing elements, 388­389<br>
defined, 238<br>
jagged, 387<br>
generic, 258<br>
multidimensional, 387, 396<br>
parameterless properties and, 239­241<br>
non-zero-lower bounds, 395­396<br>
performance considerations, 257<br>
overview, 385­387<br>
Action delegate type, 422­423<br>
passing/returning, 394­395<br>
Address Space Layout Randomization (ASLR), 2<br>
SZ, 387, 396<br>
administrative control<br>
unsafe access, 401­403<br>
advanced, 84­89<br>
as operator, casting with, 95­97<br>
simple, 61­64<br>
ASLR (Address Space Layout Randomization), 2<br>
AIPs (automatically implemented properties), <br>
ASP.NET Web Form, 613­614, 770<br>
241­242<br>
Assembler Linker (AL.exe) utility<br>
AL.exe. See Assembler Linker utility<br>
adding resource files, 52­53<br>
anonymous types, 247­250<br>
building satellite assemblies, 59<br>
APM (Asynchronous Programming Model)<br>
command-line switches, 88<br>
AsyncEnumerator class and, 765­768<br>
creating assemblies, 50­52<br>
BeginXxx methods, 761­762, 769, 774, 776, 778<br>
delayed signaling, 78<br>
comparing to EAP, 788<br>
version resource information, 53­56<br>
compute-bound operations, 774­776<br>
assemblies. See also strongly named assemblies<br>
converting IAsyncResult to task, 783­784<br>
adding modules, 46<br>
drawbacks, 765­766, 776­780<br>
adding resource files, 52­53<br>
EndXxx methods, 761­762, 769, 774, 777­778<br>
adding to projects, 49­50<br>
exceptions and, 769­770<br>
application development examples, 20­21<br>
implementing servers asynchronously, 773­774<br>
binding, 77<br>
overview, 761­765<br>
building, 43, 45<br>
AppDomain class, 622<br>
characteristics, 43<br>
AppDomainManager class, 615<br>
class support, 68<br>
AppDomains<br>
combining managed code, 5­6<br>
accessing objects across boundaries, 597­608<br>
combining modules, 43­53<br>
advanced host control, 615­620<br>
controlling member access, 23­24<br>
first-chance exception notifications, 612<br>
creating with Assembly Linker, 50­52<br>
GC handle tables, 555­557<br>
culture tags, 58­59<br>
host support, 612­614<br>
defined, 5, 43, 101<br>
monitoring, 610­611<br>
delayed signaling, 77­79<br>
overview, 591, 594­597<br>
executing code, 9­17<br>
process performance, 16<br>
friend, 159­160<br>
unhandled exceptions, 509<br>
kinds of, 66­67<br>
unloading, 609­610<br>
namespaces and, 97­101<br>
arguments. See type arguments<br>
overriding, 689­690<br>
arithmetic operations, primitive types, 117­120<br>
packaging, 59­60<br>
<b> </b><br>
<b> </b><br>
<b>861</b><br>
<hr>
<A name=880></a><b>862 </b><br>
<b>Assembly class</b><br>
privately deployed, 59­60<br>
Barrier class, 841­842<br>
probing for, 62­64<br>
base classes<br>
reflection support, 628<br>
add-in support, 634­637<br>
registering, 75<br>
design considerations, 325­326<br>
satellite, 59<br>
before-field-init semantics, 198<br>
self-describing, 6<br>
binary operators, 202<br>
version resource information, 53­58<br>
binding<br>
Assembly class, 622<br>
assemblies, 77<br>
assembly display names, 68<br>
memory management and, 658­659<br>
assembly loading, 621­625<br>
type members, 650­659<br>
AssemblyDef metadata table, 45<br>
types, 83<br>
assemblyIdentity element, 85­86<br>
BindingFlags enumerated type, 643­644<br>
AssemblyName class, 68<br>
bindingRedirect element, 85­86<br>
AssemblyRef metadata table, 38, 621<br>
bit flags, 379­383<br>
assignment operator, 223<br>
Boolean type, 114, 181<br>
AsyncEnumerator class, 765­768<br>
boxed value types<br>
asynchronous exceptions, 509<br>
changing fields, 140­142<br>
asynchronous operations. See also APM <br>
nullable, 463<br>
(Asynchronous Programming Model)<br>
object equality/identity, 143­146<br>
applications and threading models, 770­773<br>
overview, 127­140<br>
AsyncEnumerator class and, 765­768<br>
Byte type, 114, 181<br>
cache lines, 752­754<br>
bytes, encoding/decoding, 361­369<br>
cancelling, 778<br>cooperative cancellation, 722­726<br>dedicated threads and, 704­705<br>
<b>C</b><br>
event-based patterns, 784­788<br>
cache lines, 752­754<br>
execution contexts, 721­722<br>
call (IL) instruction, 168­170<br>
false sharing, 752­754<br>
callback functions, 405­406<br>
I/O operations, 755­760<br>
callback methods<br>
I/O request priorities, 780­782<br>
delegate chains, 415­419<br>
implementing servers, 773­774<br>
FirstChanceException, 612<br>
managing threads, 750­752<br>
invoking, 259, 408­410<br>
memory consumption, 778<br>
callvirt (IL) instruction, 168­170<br>
Parallel class, 739­743<br>
CancellationTokenSource class, 723­726<br>
Parallel LINQ, 743­747<br>
cancelling<br>
periodic, 747­749<br>
asynchronous operations, 778<br>
simple, 719­720<br>
operations, 722­726<br>
tasks supported, 726­739<br>
tasks, 729­730<br>
thread pool and, 718­719<br>
CAS (code access security), 165<br>
Asynchronous Programming Model. See APM <br>
casting<br>
(Asynchronous Programming Model)<br>
arrays, 390­391<br>
Attribute class<br>
between types, 93­95<br>
derived classes, 438<br>
generic type variables, 302<br>
matching instances, 448­451<br>
with as operator, 95­97<br>
methods supported, 445­446<br>
with is operator, 95­97<br>
attributes. See custom attributes<br>
catch block, 469­470, 494­495<br>
AttributeUsageAttribute class, 440­442<br>
CERs (constrained execution regions), 509­512<br>
automatic memory management. See garbage <br>
Char type, 114, 181, 327­329<br>
collection<br>
characters<br>
automatically implemented properties (AIPs), <br>
encoding/decoding, 361­369<br>
241­242<br>
examining, 343­345<br>
child tasks, 733<br>
<b>B</b><br>
class libraries, 793­794<br>classes. See also specific types of classes<br>
background threads, 713­714<br>
assembly support, 68<br>
<hr>
<A name=881></a><b> </b><br>
<b>CSP (Component Software Programming) </b><br>
<b>863</b><br>
attribute, 438<br>
Common Type System (CTS), 22­24<br>
defining, 174<br>
compilers<br>
generic, 280<br>
checking type definitions, 98<br>
inheritance and, 308<br>
CLR support, 2<br>
instance constructors and, 187­190<br>
compiling source code, 1­4<br>
non-generic, 287<br>
executing methods, 10­12<br>
partial, 164<br>
generics infrastructure, 282<br>
static, 162­163<br>
implementing events, 266­268<br>
CLI (Common Language Infrastructure), 22<br>
namespace considerations, 101<br>
closed keyword, 173<br>
switch settings, 8, 13, 34­36<br>
closed types, 283­285<br>
Component Software Programming (CSP), 165­167<br>
CLR (common language runtime)<br>
components. See also assemblies<br>
compiler support, 2<br>
attributes of, 165<br>
defined, 1<br>
defined, 5<br>
determining versions installed, 6<br>
versioning considerations, 166­167<br>
loading, 6­9<br>
condition variable pattern, 848­850<br>
programming language support, 10<br>
conditional attribute classes, 454­455<br>
CLR hosting<br>
constants<br>
advanced control, 615­620<br>
declaring methods as, 235<br>
ASP.NET web forms, 613­614<br>
declaring parameters as, 235<br>
controlling threads, 617­620<br>
defined, 155, 181<br>
defined, 591<br>
constrained execution regions (CERs), 509­512<br>
executable applications, 612­613<br>
constraints<br>
managing via managed code, 615<br>
constructor, 301­302<br>
Microsoft SQL Server, 614<br>
defined, 285<br>
overview, 592­594<br>
generics and, 318­319<br>
Silverlight support, 613<br>
interface, 318­319<br>
using AppDomains, 612­614<br>
primary, 299­300<br>
writing robust host applications, 616­617<br>
secondary, 300­301<br>
XML Web services, 613­614<br>
verifiability and, 296­305<br>
CLR Profiler tool, 590<br>
constructor constraints, 301­302<br>
CLRCreateInstance function, 593<br>
constructors. See also specific types of constructors<br>
CLRVer.exe utility, 6<br>
defined, 187<br>
CLS (Common Language Specification)<br>
defining for custom attributes, 443<br>
binary operator support, 202<br>
reference types and, 187<br>
custom attribute classes, 438<br>
value types and, 191<br>
exception considerations, 472­473<br>
Contract class, 513<br>
operator overloads, 156<br>
contract reference assembly, 518<br>
overview, 25­28<br>
contravariant type arguments, 291­292<br>
unary operator support, 201<br>
conversion operator methods<br>
code access security (CAS), 165<br>
defined, 156, 205<br>
Code Analysis tool (FxCopCmd.exe), 174<br>
overview, 204­207<br>
code explosion, 288­289<br>
CorFlags.exe utility, 7<br>
codeBase element, 44, 80, 85<br>
corrupted state exceptions (CSEs), 503<br>
collection classes<br>
CountdownEvent class, 841<br>
concurrent, 856­859<br>
covariant type argument, 291­292<br>
considerations for holding locks, 851­854<br>
CPU speeds<br>
generic, 280<br>
NUMA considerations, 700­703<br>
initializing, 245­247<br>
trends in, 699­700<br>
Power Collections library, 281­282<br>
CreateProcess function, 595<br>
Common Language Infrastructure (CLI), 22<br>
CriticalFinalizerObject class, 532<br>
common language runtime. See CLR (common <br>
Crypto API, 77<br>
language runtime)<br>
CSC.exe tool, 34, 53, 75<br>
Common Language Specification. See CLS (Common <br>
CSEs (corrupted state exceptions), 503<br>
Language Specification)<br>
CSP (Component Software Programming), 165­167<br>
<hr>
<A name=882></a><b>864 </b><br>
<b>CTS (Common Type System)</b><br>
CTS (Common Type System), 22­24<br>
controlling data, 673­678<br>
culture<br>
defined, 661<br>
assembly culture tags, 58­59<br>
objects as different objects, 682­684<br>
string considerations, 351­354<br>
overriding assemblies/types, 689­690<br>
custom attributes<br>
overview, 661­667<br>
applying, 435­439<br>
streaming contexts, 680­681<br>
conditional classes, 454­455<br>
dispose pattern<br>
defined, 435<br>
defined, 544<br>
defining classes, 439­442<br>
forcing clean up, 544­548<br>
defining constructors, 443<br>
types implementing, 548­551<br>
detecting, 444­448, 451­453<br>
Dns class, 761<br>
matching instances, 448­451<br>
Double type, 114, 181<br>
SerializableAttribute, 668<br>
double-check locking, 844­848<br>
CustomAttributeData class, 451­453<br>
DumpBin.exe utility, 7<br>dynamic expressions, 151<br>
<b>D</b><br>
dynamic keyword, 151, 224<br>dynamic primitive type, 115, 148­153<br>
Data Execution Prevention (DEP), 2<br>
dynamification, 152<br>
deadlock, defined, 795<br>debugging<br>
<b>E</b><br>
exceptions, 504­506<br>garbage collection and, 527­529<br>
EAP (Event-based Asynchronous Pattern), 784­788<br>
generics infrastructure and, 283<br>
ECMA-334 specification, 22<br>
memory problems, 590<br>
ECMA-335 specification, 22, 202<br>
PDB file support, 13<br>
EIMI (explicit interface method implementation)<br>
Decimal type, 114, 181, 207<br>
defined, 315<br>
decoding characters/bytes, 361­369<br>
improving compile-time type safety, 320­322<br>
default keyword, 221<br>
ramifications using, 320­322<br>
DefaultMember attribute, 257<br>
Enum type, 374­379<br>
DefaultParameterValue attribute, 222<br>
Enumerable class, 212<br>
delayed signaling, 77­79<br>
enumerated types<br>
delegate chains<br>
adding methods, 383­384<br>
controlling invocation, 419­422<br>
BindingFlags, 643­644<br>
overview, 415­419<br>
overview, 373­379<br>
programming language support, 419<br>
ephemeral garbage collectors, 568­573<br>
Delegate class, 431<br>
epiloguecode, 102<br>
delegate keyword, 410<br>
equality operator, 200<br>
delegates<br>
Escalation Policy, 616<br>
callback functions and, 405<br>
EventArgs class, 261<br>
callback methods and, 408­409<br>
Event-based Asynchronous Pattern (EAP), 784­788<br>
defined, 259, 406<br>
EventDef metadata table, 37<br>
generic, 290, 422­423<br>
events<br>
overview, 405­407, 410­415<br>
asynchronous patterms, 784­788<br>
reflection and, 431­432<br>
defined, 23, 156<br>
syntax overview, 423­429<br>
defining members, 262<br>
type parameters, 291­292<br>
exposing, 260­266<br>
DEP (Data Execution Prevention), 2<br>
implementing, 266­268<br>
dependentAssembly element, 85­86<br>
implementing explicitly, 271­274<br>
deployment<br>
listening for, 269­271<br>
.NET Framework goals, 32­33<br>
overview, 259­260<br>
building types into modules, 33­34<br>
raising in thread-safe way, 264­265<br>
kinds of, 66­67<br>
thread synchronization and, 819<br>
privately deployed assemblies, 59­60, 80<br>
translating input, 266<br>
deserialization<br>
virtual, 167­171<br>
controlling, 668­672<br>
Exception class, 474­477, 631<br>
<hr>
<A name=883></a><b> </b><br>
<b>functions </b><br>
<b>865</b><br>
exception classes<br>
generics support, 280­281<br>
defining, 481­483<br>
mapping primitive types, 113­115<br>
Exception class, 474­477<br>
MSCorLib.dll support, 98<br>
FCL-defined, 478­480<br>
on thread safety, 793<br>
exception handling<br>
overview, 20­22<br>
catch block, 469­470, 494­495<br>
thread considerations, 703<br>
code contracts, 512­518<br>
Feedback delegate, 407, 431<br>
constrained execution regions, 509­512<br>
FieldDef metadata table, 37<br>
defined, 467<br>
fields<br>
Escalation Policy, 616<br>
defined, 23, 155, 183<br>
finally block, 470­472, 492­494<br>
defining attribute constructors, 443<br>
guidelines/best practices, 492­499<br>
initializing, 196<br>
hiding implementation detail, 497­499<br>
mapping constructs, 28<br>
maintaining state, 496­497<br>
modifiers supported, 183­185<br>
overview, 467­468<br>
private, 174, 238<br>
performance considerations, 506­508<br>
properties and, 242<br>
recovering gracefully, 495­496<br>
File type, 379<br>
trading reliability for productivity, 484­492<br>
FileAttributes type, 379­380, 383­384<br>
try block, 468<br>
FileDef metadata table, 45<br>
exception notifications, 612<br>
FileStream class, 756­757, 780<br>
exceptions<br>
filtering type members, 643­644<br>
APM and, 769­770<br>
finalization<br>
asynchronous, 509<br>
calling methods, 540­541<br>
CLS considerations, 472­473<br>
CriticalFinalizerObject type, 532<br>
debugging, 504­506<br>
defined, 531<br>
defining, 466­467<br>
forcing clean up, 544­548<br>
recovering gracefully, 495­496<br>
overview, 541­544<br>
throwing, 480­481<br>
releasing native resources, 530­531<br>
types derived from, 631<br>
resurrection and, 566­568<br>
unhandled, 500­503, 509<br>
SafeHandle class, 532­535<br>
execution process<br>
with managed resources, 537­540<br>
assemblies, 9­17<br>
finalization lists, 541<br>
methods, 10­12<br>
finally block, 470­472, 492­494<br>
multiple applications, 16<br>
FirstChanceException callback methods, 612<br>
simple administrative control, 61­64<br>
fixed statement, 559<br>
ExecutionContext class, 721<br>
float primitive type, 114<br>
explicit interface method implementation. See EIMI <br>
For method (Parallel), 739­743<br>
(explicit interface method implementation)<br>
ForEach method (Parallel), 739­743<br>
explicit keyword, 206<br>
foreground threads, 713­714<br>
ExportedTypesDef metadata table, 45<br>
formatters<br>
Extensible Markup Language (XML), 61<br>
custom, 356­359<br>
extension methods<br>
defined, 663<br>
extending types, 211­212<br>
multiple objects, 355­356<br>
overview, 207­209<br>
serializing type instances, 672­673<br>
rules and guidelines, 210­211<br>
specifying, 351­354<br>
this keyword, 213<br>
Framework Class Library. See FCL (Framework Class <br>
ExtensionAttribute class, 213<br>
Library)<br>
freachable queues, 542­544<br>
<b>F</b><br>
friend assemblies, 159­160<br>Func delegate type, 422­423<br>
false sharing, 752­754<br>
functions<br>
FCL (Framework Class Library)<br>
callback, 405­406<br>
canceling operations, 722­726<br>
synchronous I/O support, 762<br>
exception classes, 478­480<br>general namespaces, 21­22<br>
<hr>
<A name=884></a><b>866 </b><br>
<b>GACUtil.exe tool</b><br>
<b>G</b><br>
<b>I</b><br>
GACUtil.exe tool, 73­75<br>
IAsyncResult interface, 769, 783­788<br>
garbage collection. See also finalization<br>
ICLRMetaHost interface, 592<br>
algorithm overview, 523­527<br>
ICLRRuntimeHost interface, 593<br>
allocating resources, 520­521<br>
ICLRRuntimeInfo interface, 593<br>
controlling object lifetime, 555­566<br>
ICollection interface, 393­394<br>
debugging and, 527­529<br>
IConvertible interface, 677<br>
dependency issue, 554<br>
IDL (Interface Definition Language), 4<br>
dispose pattern, 544­551<br>
IEnumerable interface, 393­394<br>
generational, 568­573<br>
IFormatterConverter interface, 677<br>
interoperability with unmanaged code, 537­540<br>
IL (Intermediate Language)<br>
large objects, 588<br>
call instruction, 168­170<br>
modes supported, 585­587<br>
callvirt instruction, 168­170<br>
monitoring, 589­590<br>
defined, 9<br>
native resource support, 574­577<br>
generics infrastructure, 282<br>
predicting successful operation, 578­579<br>
newjob instruction, 520<br>
programmatic control, 580­583<br>
newobj instruction, 522<br>
resurrection and, 566­568<br>
protecting intellectual property, 17<br>
steps for accessing resources, 520­521<br>
vector considerations, 387<br>
suspending threads and, 696<br>
verification support, 15­16<br>
thread hijacking, 583­584<br>
IL Assembler, 9<br>
using statement, 551­553<br>
IL Disassembler tool (ILDasm.exe), 28, 38­41, 43<br>
GC handle tables, 555­557<br>
IList interface, 393­394<br>
GC type, 540, 580<br>
implicit keyword, 206<br>
GCNotification class, 538, 573<br>
IndexerName attribute, 257<br>
generational garbage collectors, 568­573<br>
inequality operator, 200<br>
generic types<br>
inheritance<br>
casting variables, 302<br>
class, 308<br>
code explosion, 288­289<br>
generic types and, 285­287<br>
comparing variables, 303­304<br>
instance constructors, 187<br>
inheritance and, 285­287<br>
interface, 308, 310­311<br>
open/closed, 283­285<br>
initializing<br>
setting variable default values, 303<br>
array elements, 388­389<br>
syntax considerations, 287­288<br>
collection classes, 245­247<br>
using variables as operands, 304<br>
fields, 196<br>
generics<br>
objects, 245­247<br>
delegate support, 290, 422­423<br>
instance constructors<br>
FCL support, 280­281<br>
classes and, 187­190<br>
infrastructure, 282­289<br>
defined, 155<br>
interface support, 289­290, 315­319<br>
structures and, 191­194<br>
other members and, 296<br>
instance methods, 102, 409<br>
overview, 275­280<br>
int primitive type, 114<br>
Power Collections library, 281­282<br>
Int16 type, 114, 181<br>
type arguments, 291­292<br>
Int32 type, 114, 181<br>
verifiability/constraints, 296­305<br>
Int64 type, 114, 181<br>
GetRuntime function, 593<br>
intellectual property, 17­18<br>
Global Assembly Cache, 73­75<br>
Interface Definition Language (IDL), 4<br>
globally deployed assemblies, 67<br>
interface methods<br>
GlobalMemoryStatusEx function, 565<br>
calling, 312­313<br>calling via nullable value type, 464<br>
<b>H</b><br>
implementing, 314­315<br>
interfaces<br>
hash codes, 146­148<br>
add-in support, 634­637<br>applying type constructors, 194<br>arrays implementing, 393­394<br>
<hr>
<A name=885></a><b> </b><br>
<b>ModuleDef metadata table </b><br>
<b>867</b><br>
compile-time type safety, 320­322<br>
initialized, 568<br>
defining, 308­310<br>
runtime relationships, 102­111<br>
design considerations, 325­326<br>
manifest, 43, 45­47<br>
discovering for types, 644­646<br>
ManifestResourceDef metadata table, 45<br>
generic, 289­290, 315­319<br>
ManualResetEventSlim class, 830<br>
identical method name/signature, 319­320<br>
MarshalByRefType type, 601­605<br>
inheriting, 308, 310­311<br>
MarshalByValType type, 606­608<br>
partial, 164<br>
MBCS (Multi-Byte Character Set), 361<br>
Tuple type and, 251<br>
MemberInfo class, 638­642<br>
type parameters, 291­292<br>
MemberRef metadata table, 38<br>
internal accessibility, 161<br>
memory management<br>
invariant type parameter, 291<br>
asynchronous operations and, 778<br>
Invoke method (Parallel), 739­743<br>
binding and, 658­659<br>
is operator, casting with, 95­97<br>
debugging and, 590<br>
ISerializable interface, 673­680<br>
MemoryFailPoint class, 578­579<br>
ISerializationSurrogate interface, 685­687, 689<br>
metadata<br>
ISurrogateSelector interface, 688<br>
defined, 4, 37, 156<br>functionality, 4<br>
<b>J</b><br>
manifest support, 43<br>verification process and, 17<br>
jagged arrays, 387<br>
viewing, 38<br>
JIT (just-in-time) compiler<br>
metadata tables<br>
executing methods, 10­12<br>
common definition, 37<br>
generics infrastructure, 282<br>
common reference, 37­38<br>
optimizing native code, 13<br>
generics infrastructure, 282<br>
performance considerations, 14­15<br>
MethodDef metadata table, 37<br>
type constructor performance, 198<br>
methods. See also specific kinds of methods<br>
JITCompiler function, 11<br>
adding to enumerated types, 383­384<br>calling first time, 49<br>declaring as constants, 235<br>
<b>K</b><br>
defined, 23, 156<br>
keywords, component versioning and, 166<br>
defining as generic, 135<br>defining to raise events, 263<br>executing, 10­12<br>
<b>L</b><br>
generic, 293­295<br>interface, 312­315<br>
large objects, 588<br>
mapping constructs, 28<br>
lazy initialization, 844<br>
passing/returning arrays, 394­395<br>
LINQ (Language Integrated Query), 743<br>
properties as, 242<br>
listening for events, 269­271<br>
runtime relationships, 102<br>
livelock, defined, 795<br>
thread synchronization and, 822­823<br>
local variables, implicitly typed, 223­224<br>
thread-safe, 793<br>
long primitive type, 114<br>
Microsoft .NET Framework<br>
combining managed modules, 5­6<br>
<b>M</b><br>
compiling source code, 1­4<br>Framework Class Library, 20­22<br>
Machine.config file, 63<br>
installing multiple versions, 6<br>
managed code/modules<br>
interoperability with unmanaged code, 29<br>
combining into assemblies, 5­6<br>
loading common language runtime, 6­9<br>
compilation switch settings, 8<br>
NGen.exe tool, 18­19<br>
compiling source code, 1­4<br>
Microsoft Authenticode technology, 76<br>
defined, 2<br>
Microsoft Spy++, 708<br>
managing CLR via, 615<br>
Microsoft SQL Server, 614<br>
parts, 3<br>
Microsoft.CSharp.dll assembly, 152<br>
managed heap<br>
ModuleDef metadata table, 37<br>
allocating resources, 520­521<br>
<hr>
<A name=886></a><b>868 </b><br>
<b>ModuleRef metadata table</b><br>
ModuleRef metadata table, 38<br>
converting types, 204­207<br>
modules. See also managed code/modules<br>
deserializing, 682­684<br>
building types into, 33­34, 43<br>
discovering types, 93<br>
combining to form assemblies, 43­53<br>
forcing clean up, 544­548<br>
Monitor class, 830­835<br>
formatting into strings, 355­356<br>
monitoring<br>
hash codes, 146­148<br>
AppDomains, 610­611<br>
initializing, 245­247<br>
garbage collection, 589­590<br>
large, 588<br>
MSCorEE.dll file, 6, 592<br>
parsing strings, 359­361<br>
MSCorLib.dll file, 34, 98<br>
runtime relationships, 102­111<br>
MSI (Windows Installer) tool, 74<br>
string representation, 350­359<br>
Multi-Byte Character Set (MBCS), 361<br>
OneManyLock class, 838­840<br>
multidimensional arrays, 387, 396<br>
OOP (object-oriented programming), 165, 174, 275<br>
Mutex class, 820­822<br>
open types, 283­285<br>operator keyword, 206<br>
<b>N</b><br>
operator overload methods<br>
boxing/unboxing, 133<br>
naked type constraints, 300<br>
defined, 156, 200<br>
namespaces<br>
language interoperability, 203<br>
assemblies and, 97­101<br>
name rules, 203­204<br>
creating, 21, 100<br>
overview, 200­202<br>
defined, 97­98<br>
primitive types and, 202<br>
FCL, 21­22<br>
operators. See also specific operators<br>
Native Code Generator (NGen.exe) tool<br>
assignment, 223<br>
intellectual property, 18<br>
binary, 202<br>
overview, 18<br>
equality/inequality, 200<br>
security, 19<br>
null-coalescing, 462<br>
synchronization, 19<br>
relational, 460<br>
new keyword, 167, 187, 221<br>
unary, 201<br>
new operator, 92­93, 410<br>
Optional attribute, 222<br>
newjob (IL) instruction, 520<br>
out keyword, 221, 225­228<br>
newobj (IL) instruction, 522<br>
override keyword, 167, 187<br>
NonSerializedAttribute custom attribute, 669<br>NOP (no-operation) instructions, 13<br>
<b>P</b><br>
nullable value types, 457­464<br>null-coalescing operator, 462<br>
packaging assemblies, 59­60<br>
NUMA architecture machines, 700­703, 754<br>
Parallel class, 739­743<br>Parallel LINQ, 743<br>
<b>O</b><br>
parallel query, 743<br>ParallelEnumerable class, 743­745<br>
object lifetime, 555­566<br>
ParamDef metadata table, 37<br>
Object type<br>
ParameterizedThreadStart delegate, 704, 719<br>
class inheritance, 308<br>
parameters<br>
compiler restrictions, 162<br>
declaring as constants, 235<br>
defined, 114<br>
DefaultParameterValue attribute, 222<br>
deriving types from, 91­93<br>
implicitly typed local variables, 223­224<br>
instance constructors and, 188<br>
named, 219­220<br>
object equality/identity, 143­146<br>
optional, 219­220<br>
object hash codes, 146­148<br>
Optional attribute, 222<br>
protected methods, 92<br>
passing by reference, 225­230<br>
public methods, 91­92<br>
passing variable number, 231­233<br>
ToString method, 350­359<br>
return type guidelines, 233­235<br>
object-oriented programming (OOP), 165, 174, 275<br>
rules and guidelines, 220­222, 233­235<br>
objects<br>
type, 276<br>
accessing across boundaries, 597­608<br>
params keyword, 231­233<br>
<hr>
<A name=887></a><b> </b><br>
<b>response files </b><br>
<b>869</b><br>
Parse method, 359­361<br>
publishing assemblies, 60<br>
parsing strings, 359­361<br>
prologuecode, 102<br>
partial keyword, 164<br>
properties<br>
partial methods<br>
accessor accessibility, 258<br>
overview, 213­216<br>
anonymous types, 247­250<br>
rules and guidelines, 216­217<br>
as methods, 242­243<br>
partial signaling, 77­79<br>
automatically implemented, 241­242<br>
payload code, 149<br>
defined, 23, 156<br>
PDB (Program Database) files, 13<br>
defining attribute constructors, 443<br>
PerfMon.exe tool, 589<br>
defining intelligently, 242­244<br>
performance considerations<br>
object/collection initializers, 245­247<br>
accessing instance fields, 605­606<br>
parameterful, 252­257<br>
arrays, 396­401<br>
parameterless, 237­241<br>
boxing/unboxing, 129<br>
Tuple type, 250­252<br>
exception handling, 506­508<br>
virtual, 167­171<br>
executing multiple applications, 16<br>
Visual Studio Debugger and, 244<br>
generics, 277<br>
PropertyDef metadata table, 37<br>
JIT compiling, 14­15<br>
protected accessibility, 161<br>
property accessor methods, 257<br>
protected internal accessibility, 161<br>
reflection, 627­634<br>
public accessibility, 161<br>
sealed classes, 172<br>
public key tokens<br>
threads, 696­699<br>
defined, 68<br>
type constructors, 198­200<br>
security considerations, 71<br>
PEVerify.exe utility, 17<br>
viewing, 69<br>
policy control, publisher, 87­89<br>
publisher policy control, 87­89<br>
polymorphism, 165­167<br>
publisherPolicy element, 86<br>
Power Collections library, 281­282<br>Pratschner, Steven, 594<br>precise semantics, 198<br>
<b>Q</b><br>
primary constraints, 299­300<br>
qsort function, 405<br>
primitive types<br>
quantum, defined, 694<br>
checked/unchecked operations, 117­120<br>defined, 113<br>defining constants, 181<br>
<b>R</b><br>
dynamic, 148­153<br>
ReaderWriterLockSlim class, 836­838<br>
mapping, 113­115<br>
readonly keyword, 183<br>
operator overload methods and, 202<br>
recursion, 827­829<br>
overview, 113­117<br>
ref keyword, 221, 225­228<br>
private accessibility, 161, 194, 238<br>
reference types<br>
privately deployed assemblies<br>
instance constructors and classes, 187­190<br>
defined, 67<br>
overview, 121­125<br>
overview, 59­60, 80<br>
resolving, 81­84<br>
probing element, 85<br>
reflection<br>
process, defined, 692<br>
defined, 444<br>
programming languages<br>
delegates and, 431­432<br>
APM considerations, 788­790<br>
discovering type members, 637­659<br>
defining runtime binders, 152<br>
dynamically extensible applications, 626<br>
delegate chain support, 419<br>
generics infrastructure, 283<br>
generics infrastructure, 282<br>
performance considerations, 627­634<br>
mapping primitive types, 113­117<br>
registry keys<br>
nullable value types, 459­461<br>
adding assemblies, 50<br>
operator interoperability, 203<br>
determining .NET Framework installs, 6<br>
type safety, 148<br>
relational operators, 460<br>
projects<br>
resource files, adding to assemblies, 52­53<br>
adding assemblies, 49­50<br>
response files, 34­36<br>
<hr>
<A name=888></a><b>870 </b><br>
<b>resurrection</b><br>
resurrection, 566­568<br>
.NET Framework interoperability, 29<br>
return type guidelines, 233­235<br>
code contracts, 512­518<br>
RFC 1766, 58<br>
code explosion, 288­289<br>
runtime binders, 152<br>
compiling, 1­4<br>
RuntimeType type, 629<br>
epiloguecode, 102<br>generics and, 277<br>
<b>S</b><br>
partial keyword, 164<br>payload, 149<br>
safe code, 16<br>
prologuecode, 102<br>
safe point, 584<br>
safe, 16<br>
SafeHandle class<br>
unsafe, 16­17<br>
derived types, 532­535<br>
SqlCommand class, 761<br>
dispose pattern and, 545­548<br>
state management<br>
interoperating with unmanaged code, 535­537<br>
constrained execution regions, 509­512<br>
satellite assemblies, 59<br>
corrupted state exceptions, 503<br>
SByte type, 114, 181<br>
maintaining state, 496­497<br>
scheduling<br>
static classes, 162­163, 188<br>
tasks, 737­739<br>
static keyword, 102, 183, 205<br>
threads, 708­713<br>
static methods, call back, 408­409<br>
sealed keyword, 167, 172, 187<br>
StreamingContext structure, 680­681<br>
secondary constraints, 300­301<br>
StreamWriter type, 362<br>
SecureString class, 369­372<br>
String type<br>
security<br>
comparing strings, 334­340<br>
assembly considerations, 45<br>
constant support, 181<br>
deployment considerations, 32<br>
constructing strings, 330­333, 346­350<br>
NGen.exe considerations, 19<br>
description, 114, 330<br>
public key tokens and, 71<br>
examining characters, 343­345<br>
sealed classes, 173<br>
immutable nature, 333<br>
string considerations, 369­372<br>
methods for copying strings, 346<br>
Semaphore class, 819<br>
Parse method, 359­361<br>
SemaphoreSlim class, 830<br>
security considerations, 369­372<br>
sequential query, 743<br>
string interning, 340­342<br>
SerializableAttribute custom attribute, 668<br>
string pooling, 343<br>
serialization<br>
StringBuilder class, 207­209, 346­350<br>
controlling, 668­672<br>
strings<br>
controlling data, 673­678<br>
comparing, 334­340<br>
defined, 661<br>
constructing, 330­333, 346­350<br>
for types, 667­668<br>
custom formatting, 356­359<br>
overview, 661­667<br>
encoding/decoding, 361­369<br>
streaming contexts, 680­681<br>
formatting multiple objects, 355­356<br>
surrogates, 684­687<br>
methods for copying, 346<br>
type instances, 672­673<br>
object representation, 350<br>
types as different types, 682­684<br>
parsing, 359­361<br>
SerializationBinder class, 689<br>
security considerations, 369­372<br>
SerialPort class, 761<br>
Strong Name (SN.exe) utility, 70, 77<br>
servers, implementing asynchronously, 773­774<br>
strongly named assemblies<br>
servicings, 165<br>
as tamper-resistant, 76­77<br>
short primitive type, 114<br>
creating, 69­70<br>
Silverlight, 613, 770<br>
defined, 68<br>
Single type, 114, 181<br>
overview, 67­72<br>
Singleton class, 683, 846­847<br>
privately deploying, 80<br>
SN.exe (Strong Name) utility, 70, 77<br>
recommendations, 67<br>
Socket class, 761<br>
referencing, 75­76<br>
SOS Debugging Extension (SOS.dll), 590<br>
structures<br>
source code<br>
generic, 293<br>
<hr>
<A name=889></a><b> </b><br>
<b>type parameter constraints </b><br>
<b>871</b><br>
instance constructors and, 191­194<br>
recursion, 827­829<br>
partial, 164<br>
semaphore constructs, 819<br>
SurrogateSelector class, 688<br>
user-mode constructs, 796­797<br>
symbolic names, 383­384<br>
volatile constructs, 797­803<br>
sync blocks, 830­835<br>
ThreadPool class, 719­720, 726<br>
synchronization. See thread synchronization<br>
threads<br>
SynchronizationContext class, 771­772<br>
application models, 770­773<br>
synchronous operations, 755­760, 779<br>
asynchronous operations and, 704­705<br>
System Monitor control, 589<br>
blocking, 842­843<br>
SZ arrays, 387, 396<br>
CLR considerations, 703<br>controlling, 617­620<br>
<b>T</b><br>
CPU trends and, 699­700<br>delaying processing, 809­811<br>
task factories, 735­737<br>
execution contexts, 721­722<br>
Task Manager (Windows), 697­698<br>
foreground versus background, 713­714<br>
tasks<br>
garbage collection and, 696<br>
cancelling, 729­730<br>
hijacking, 583­584<br>
converting EAP, 786<br>
managing, 750­752<br>
converting IAsyncResult, 783­784<br>
NUMA considerations, 700­703<br>
defined, 726<br>
overhead considerations, 692­696<br>
internal components, 733­735<br>
performance considerations, 696­699<br>
overview, 726­727<br>
priority considerations, 708­713<br>
scheduling, 737­739<br>
rationale for supporting, 691­692<br>
starting automatically, 731­732<br>
reasons for using, 706­708<br>
starting child tasks, 733<br>
runtime relationships, 102­111<br>
waiting for completion of, 727­729<br>
scheduling, 708­713<br>
TaskScheduler type, 737, 743<br>
worker, 751­752<br>
TEB (thread environment block), 693<br>
ThreadsSharingData class, 801<br>
this keyword, 210, 213<br>
throwing exceptions, 480­481<br>
Thread class, 800<br>
Timer class, 747­749<br>
thread environment block (TEB), 693<br>
TimerCallback delegate type, 719, 747<br>
thread ownership, 827­829<br>
ToString method, 350­359, 381<br>
thread pool<br>
try block, 468<br>
APM considerations, 776­777<br>
Tuple type, 247, 250­252<br>
calling methods asynchronously, 720<br>
type arguments<br>
managing threads, 750­752<br>
code explosion, 288­289<br>
overview, 718­719<br>
contravariant/covariant, 291­292<br>
setting limits, 750­751<br>
defined, 277<br>
thread synchronization<br>
type constructors<br>
blocking threads, 842­843<br>
calling, 195<br>
calling methods, 822­823<br>
defined, 155, 194<br>
class libraries and, 793­794<br>
overview, 194­197<br>
concurrent collection classes, 856­859<br>
performance considerations, 198­200<br>
condition variable pattern, 848­850<br>
type inference, 294­295<br>
considerations for holding locks, 851­854<br>
type members<br>
double-check locking, 844­848<br>
accessibility, 160­162, 172­174<br>
event constructs, 817­819<br>
binding, 650­659<br>
hybrid constructs, 829­843<br>
discovering, 637­659<br>
hybrid locks, 826­829<br>
filtering, 643­644<br>
implementing spin locks, 807­811<br>
invoking, 646­650<br>
interlocked constructs, 803­807, 811­812<br>
kinds supported, 155­158<br>
kernel-mode constructs, 813­816<br>
partial keyword, 164<br>
mutex constructs and, 820­822<br>
static classes, 162­163<br>
overview, 791­793<br>
type objects, 283, 628­631<br>
primitive constructs, 794­796<br>
type parameter constraints, 300<br>
<hr>
<A name=890></a><b>872 </b><br>
<b>type parameters</b><br>
type parameters<br>
unmanaged code<br>
arity and, 284<br>
.NET Framework interoperability, 29<br>
contravariant/covariant, 291­292<br>
SafeHandle class interoperability, 535­537<br>
defined, 276<br>
unsafe code, 16­17<br>
type safety<br>
ushort primitive type, 114<br>
casting between types, 93­95<br>
using directive, 98­99, 115<br>
generics and, 277<br>
using statement, 551­553<br>
improving compile-time, 320­322<br>programming languages and, 148<br>quiz about, 96­97<br>
<b>V</b><br>
Type type, 628<br>
value types<br>
TypeDef metadata table, 37<br>
boxing/unboxing, 127­140<br>
TypeRef metadata table, 38, 621<br>
changing fields, 140­142<br>
types. See also specific types<br>
enumerated types, 383­384<br>
arity of, 284<br>
instance constructors and structures, 191­194<br>
binding, 83<br>
nullable, 457­464<br>
building into modules, 33­34, 43<br>
object equality/identity, 143­146<br>
casting between, 93­95<br>
overview, 121­125<br>
casting with is/as operators, 95­97<br>
var keyword, 151, 224<br>
constructing instances, 632­634<br>
variables<br>
controlling field layout, 126­127<br>
generic type, 302­305<br>
controlling member access, 23­24<br>
local, 223­224<br>
CTS examples, 24<br>
type parameters, 276<br>
defined, 156<br>
vectors, 387, 396<br>
deriving from System.Object, 91­93<br>
verifiability and constraints, 296­305<br>
design considerations, 172­174<br>
verification process (IL), 15­16<br>
discovering interfaces, 644­646<br>
version numbers<br>
exception-derived, 631<br>
assembly resource information, 53­58<br>
exposing events, 260­266<br>
format of, 57­58<br>
extending, 211­212<br>
type considerations, 45<br>
functionality, 22<br>
versioning<br>
listening for events, 269­271<br>
challenges, 66<br>
making serializable, 667­668<br>
component considerations, 166­167, 172<br>
overriding, 689­690<br>
design considerations, 325<br>
runtime relationships, 102­111<br>
servicing components, 165­166<br>
serializing, 682­684<br>
types, 175­179<br>
serializing instances, 672­673<br>
virtual events, 167­171<br>
versioning, 175­179<br>
virtual keyword, 167, 187<br>
visibility considerations, 158, 172­174<br>
virtual methods<br>
calling, 102, 167­171, 188<br>
<b>U</b><br>
versioning types and, 175­179<br>
virtual properties, 167­171<br>
uint primitive type, 114<br>
visibility, type, 158<br>
UInt16 type, 114, 181<br>
Visual Studio<br>
UInt32 type, 114, 181<br>
adding assemblies to projects, 49­50<br>
UInt64 type, 114, 181<br>
Code Analysis tool, 174<br>
ulong primitive type, 114<br>
code contracts, 513<br>
unary operators, 201<br>
code spitters, 164<br>
unboxed value types<br>
debugger properties, 244<br>
nullable, 463<br>
debugging exceptions, 504­506<br>
object equality/identity, 143­146<br>
generics infrastructure and, 283<br>
overview, 127­140<br>
publishing assemblies, 60<br>
unhandled exceptions, 500­503, 509<br>
volatile keyword, 183<br>
Unicode characters, 361<br>union, explicit layout and, 126<br>unloading AppDomains, 609­610<br>
<hr>
<A name=891></a><b> </b><br>
<b>XML Web services </b><br>
<b>873</b><br>
<b>W<br></b>WaitCallback delegate, 719<br>Windows Installer (MSI), 74<br>Windows Presentation Foundation (WPF), 612, 770<br>Windows Task Manager, 697­698<br>Wintellect Power Collections library, 281­282<br>Wintellect Power Threading Library, 715<br>worker threads, 751­752<br>WoW64 technology, 8<br>WPF (Windows Presentation Foundation), 612, 770<br>writing robust host applications, 616­617<br>
<b>X<br></b>XML (Extensible Markup Language), 61<br>XML Web services, 613­614, 770<br>
<hr>
<A name=892></a><hr>
<A name=893></a><IMG src="CLRviaCsharp-893_1.jpg"><br>
<b>About the Author</b><br>
Jeffrey Richter is a cofounder of Wintellect (<i>http://www.Wintellect.com/</i>),  <br>a training, consulting, and debugging company dedicated to helping  <br>companies produce better software faster. Wintellect also offers its own <br>twice-yearly Devscovery conference (<i>http://Devscovery.com/</i>). Jeffrey has <br>written many books about Win32 and Microsoft .NET Framework program-<br>ming, including <i>CLR via C#, 3rd Edition</i> (Microsoft Press, 2010),<i> Windows <br>via C/C++, 5th Edition </i>(Microsoft Press, 2007), and <i>Programming Server-Side <br>Applications for Microsoft Windows 2000 </i>(Microsoft Press, 2000). Jeffrey is a <br>contributing editor for <i>MSDN Magazine</i>, where he has written numerous  <br>feature articles and has been the <i>Win32 Q&amp;A</i> columnist, <i>.NET Q&amp;A</i> colum-<br>
nist, and <i>Concurrent Affairs</i> columnist. Jeffrey also speaks at various trade conferences world-<br>wide, including Wintellect's Devscovery, VSLive!, and Microsoft's TechEd and Professional <br>Developers Conference.<br>
Jeffrey has consulted for many companies, including AT&amp;T, DreamWorks, General Electric, <br>Hewlett-Packard, IBM, and Intel. His code has shipped in many Microsoft products, among <br>them Microsoft Visual Studio, Microsoft Golf, Windows Sound System, and various versions  <br>of Microsoft Windows. Jeff consulted with the .NET Framework team for eight years and <br>maintains an ongoing close relationship with that team as well as the Windows team.<br>
On the personal front, Jeffrey holds both airplane and helicopter pilot licenses, though he <br>never gets to fly as often as he'd like. He is also a member of the International Brotherhood <br>of Magicians and enjoys showing friends sleight-of-hand card tricks from time to time. Jeff's <br>other hobbies include music (especially jazz and progressive rock from the 1970s), drumming, <br>model railroading, and karate. He also enjoys traveling and theater. He lives in Kirkland, <br>Washington, with his wife, Kristin, and his two sons, Aidan and Grant..<br>
<hr>
<A name=894></a><hr>
<A name=895></a><b>If you like the book you'll love the training</b><br>
<b>WINTELLECT TRAINING COURSES BY JEFFREY RICHTER</b><br>
<b>Effective Threading in C#: Mastering Responsive, Reliable and Scalable Applications</b><br>
<b>Duration and Format: </b>2 Day On-Site/ Virtual<br>
<b>Syllabus</b><br>
<b>Day 1</b><br>
<b>Day 2</b><br>
<b>Mastering the .NET Framework</b><br>
<b>Duration and Format: </b>5 Day On-Site/ 3 Day On-Site/ Virtual<br>
<b>Syllabus</b>   <br>
Day 1 <br>
Day 2<br>
Day 3 <br>
Day 4 <br>
Day 5<br>
<hr>
<A name=896></a>What do  <br>
you think of  <br>
this book?<br>We want to hear from you! <br>To participate in a brief online survey, please visit: <br>
<b>microsoft.com/learning/booksurvey </b><br>
Tell us how well this book meets your needs --what works effectively, and what we can  <br>do better. Your feedback will help us continually improve our books and learning <br>resources for you.   <br>
Thank you in advance for your input!<br>
Stay in touch!<br>To subscribe to the <i>Microsoft Press® Book Connection Newsletter</i>--for news on upcoming <br>books, events, and special offers--please visit: <br>
<b>microsoft.com/learning/books/newsletter </b><br>
<hr>
<A name="outline"></a><h1>Document Outline</h1>
<ul><li><A href="CLRviaCsharps.html#1">Cover</A>
<ul><li><A href="CLRviaCsharps.html#2">Copyright Page</A>
</ul><li><A href="CLRviaCsharps.html#3">Table of Contents</A>
<li><A href="CLRviaCsharps.html#13">Foreword</A>
<li><A href="CLRviaCsharps.html#15">Introduction</A>
<ul><li><A href="CLRviaCsharps.html#15">Who This Book Is For</A>
<li><A href="CLRviaCsharps.html#17">Dedication</A>
<li><A href="CLRviaCsharps.html#17">Acknowledgments</A>
<li><A href="CLRviaCsharps.html#17">Support for This Book</A>
<li><A href="CLRviaCsharps.html#18">We Want to Hear from You</A>
</ul><li><A href="CLRviaCsharps.html#19">þÿ</A>
<ul><li><A href="CLRviaCsharps.html#19">Compiling Source Code into Managed Modules</A>
<li><A href="CLRviaCsharps.html#23">Combining Managed Modules into Assemblies</A>
<li><A href="CLRviaCsharps.html#24">Loading the Common Language Runtime</A>
<li><A href="CLRviaCsharps.html#27">þÿ</A>
<ul><li><A href="CLRviaCsharps.html#33">IL and Verification</A>
<li><A href="CLRviaCsharps.html#34">Unsafe Code</A>
</ul><li><A href="CLRviaCsharps.html#36">The Native Code Generator Tool: NGen.exe</A>
<li><A href="CLRviaCsharps.html#38">The Framework Class Library</A>
<li><A href="CLRviaCsharps.html#40">The Common Type System</A>
<li><A href="CLRviaCsharps.html#43">The Common Language Specification</A>
<li><A href="CLRviaCsharps.html#47">Interoperability with Unmanaged Code</A>
</ul><li><A href="CLRviaCsharps.html#49">Chapter 2: Building, Packaging, Deploying, and Administering Applications and Types</A>
<ul><li><A href="CLRviaCsharps.html#50">.NET Framework Deployment Goals</A>
<li><A href="CLRviaCsharps.html#51">Building Types into a Module</A>
<ul><li><A href="CLRviaCsharps.html#52">Response Files</A>
</ul><li><A href="CLRviaCsharps.html#54">A Brief Look at Metadata</A>
<li><A href="CLRviaCsharps.html#61">Combining Modules to Form an Assembly</A>
<ul><li><A href="CLRviaCsharps.html#67">Adding Assemblies to a Project by Using the Visual Studio IDE</A>
<li><A href="CLRviaCsharps.html#68">Using the Assembly Linker</A>
<li><A href="CLRviaCsharps.html#70">Adding Resource Files to an Assembly</A>
</ul><li><A href="CLRviaCsharps.html#71">Assembly Version Resource Information</A>
<ul><li><A href="CLRviaCsharps.html#75">Version Numbers</A>
</ul><li><A href="CLRviaCsharps.html#76">Culture</A>
<li><A href="CLRviaCsharps.html#77">Simple Application Deployment (Privately Deployed Assemblies)</A>
<li><A href="CLRviaCsharps.html#79">Simple Administrative Control (Configuration)</A>
</ul><li><A href="CLRviaCsharps.html#83">Chapter 3: Shared Assemblies and Strongly Named Assemblies</A>
<ul><li><A href="CLRviaCsharps.html#84">Two Kinds of Assemblies, Two Kinds of Deployment</A>
<li><A href="CLRviaCsharps.html#85">Giving an Assembly a Strong Name</A>
<li><A href="CLRviaCsharps.html#91">The Global Assembly Cache</A>
<li><A href="CLRviaCsharps.html#93">Building an Assembly That References a Strongly Named Assembly</A>
<li><A href="CLRviaCsharps.html#94">Strongly Named Assemblies Are Tamper-Resistant</A>
<li><A href="CLRviaCsharps.html#95">Delayed Signing</A>
<li><A href="CLRviaCsharps.html#98">Privately Deploying Strongly Named Assemblies</A>
<li><A href="CLRviaCsharps.html#99">How the Runtime Resolves Type References</A>
<li><A href="CLRviaCsharps.html#102">Advanced Administrative Control (Configuration)</A>
<ul><li><A href="CLRviaCsharps.html#105">Publisher Policy Control</A>
</ul></ul><li><A href="CLRviaCsharps.html#109">Chapter 4: Type Fundamentals</A>
<ul><li><A href="CLRviaCsharps.html#109">All Types Are Derived from System.Object</A>
<li><A href="CLRviaCsharps.html#111">Casting Between Types</A>
<ul><li><A href="CLRviaCsharps.html#113">Casting with the C# is and as Operators</A>
</ul><li><A href="CLRviaCsharps.html#115">Namespaces and Assemblies</A>
<li><A href="CLRviaCsharps.html#120">How Things Relate at Runtime</A>
</ul><li><A href="CLRviaCsharps.html#131">Chapter 5: Primitive, Reference, and Value Types</A>
<ul><li><A href="CLRviaCsharps.html#131">Programming Language Primitive Types</A>
<ul><li><A href="CLRviaCsharps.html#135">Checked and Unchecked Primitive Type Operations</A>
</ul><li><A href="CLRviaCsharps.html#139">Reference Types and Value Types</A>
<li><A href="CLRviaCsharps.html#145">Boxing and Unboxing Value Types</A>
<ul><li><A href="CLRviaCsharps.html#158">þÿ</A>
<li><A href="CLRviaCsharps.html#161">Object Equality and Identity</A>
</ul><li><A href="CLRviaCsharps.html#164">Object Hash Codes</A>
<li><A href="CLRviaCsharps.html#166">The dynamic Primitive Type</A>
</ul><li><A href="CLRviaCsharps.html#173">Chapter 6: Type and Member Basics</A>
<ul><li><A href="CLRviaCsharps.html#173">The Different Kinds of Type Members</A>
<li><A href="CLRviaCsharps.html#176">Type Visibility</A>
<ul><li><A href="CLRviaCsharps.html#177">Friend Assemblies</A>
</ul><li><A href="CLRviaCsharps.html#178">Member Accessibility</A>
<li><A href="CLRviaCsharps.html#180">Static Classes</A>
<li><A href="CLRviaCsharps.html#182">Partial Classes, Structures, and Interfaces</A>
<li><A href="CLRviaCsharps.html#183">Components, Polymorphism, and Versioning</A>
<ul><li><A href="CLRviaCsharps.html#185">How the CLR Calls Virtual Methods, Properties, and Events</A>
<li><A href="CLRviaCsharps.html#190">Using Type Visibility and Member Accessibility Intelligently</A>
<li><A href="CLRviaCsharps.html#193">Dealing with Virtual Methods When Versioning Types</A>
</ul></ul><li><A href="CLRviaCsharps.html#199">Chapter 7: Constants and Fields</A>
<ul><li><A href="CLRviaCsharps.html#199">Constants</A>
<li><A href="CLRviaCsharps.html#201">Fields</A>
</ul><li><A href="CLRviaCsharps.html#205">Chapter 8: Methods</A>
<ul><li><A href="CLRviaCsharps.html#205">Instance Constructors and Classes (Reference Types)</A>
<li><A href="CLRviaCsharps.html#209">Instance Constructors and Structures (Value Types)</A>
<li><A href="CLRviaCsharps.html#212">Type Constructors</A>
<ul><li><A href="CLRviaCsharps.html#216">Type Constructor Performance</A>
</ul><li><A href="CLRviaCsharps.html#218">Operator Overload Methods</A>
<ul><li><A href="CLRviaCsharps.html#221">Operators and Programming Language Interoperability</A>
</ul><li><A href="CLRviaCsharps.html#222">Conversion Operator Methods</A>
<li><A href="CLRviaCsharps.html#225">Extension Methods</A>
<ul><li><A href="CLRviaCsharps.html#228">Rules and Guidelines</A>
<li><A href="CLRviaCsharps.html#229">Extending Various Types with Extension Methods</A>
<li><A href="CLRviaCsharps.html#231">The Extension Attribute</A>
</ul><li><A href="CLRviaCsharps.html#231">Partial Methods</A>
<ul><li><A href="CLRviaCsharps.html#234">Rules and Guidelines</A>
</ul></ul><li><A href="CLRviaCsharps.html#237">Chapter 9: Parameters</A>
<ul><li><A href="CLRviaCsharps.html#237">Optional and Named Parameters</A>
<ul><li><A href="CLRviaCsharps.html#238">Rules and Guidelines</A>
<li><A href="CLRviaCsharps.html#240">The DefaultParameterValue and Optional Attributes</A>
</ul><li><A href="CLRviaCsharps.html#241">Implicitly Typed Local Variables</A>
<li><A href="CLRviaCsharps.html#243">Passing Parameters by Reference to a Method</A>
<li><A href="CLRviaCsharps.html#249">Passing a Variable Number of Arguments to a Method</A>
<li><A href="CLRviaCsharps.html#251">Parameter and Return Type Guidelines</A>
<li><A href="CLRviaCsharps.html#253">Const-ness</A>
</ul><li><A href="CLRviaCsharps.html#255">Chapter 10: Properties</A>
<ul><li><A href="CLRviaCsharps.html#255">Parameterless Properties</A>
<ul><li><A href="CLRviaCsharps.html#259">Automatically Implemented Properties</A>
<li><A href="CLRviaCsharps.html#260">Defining Properties Intelligently</A>
<li><A href="CLRviaCsharps.html#263">Object and Collection Initializers</A>
<li><A href="CLRviaCsharps.html#265">Anonymous Types</A>
<li><A href="CLRviaCsharps.html#268">The System.Tuple Type</A>
</ul><li><A href="CLRviaCsharps.html#270">Parameterful Properties</A>
<li><A href="CLRviaCsharps.html#275">The Performance of Calling Property Accessor Methods</A>
<li><A href="CLRviaCsharps.html#276">Property Accessor Accessibility</A>
<li><A href="CLRviaCsharps.html#276">Generic Property Accessor Methods</A>
</ul><li><A href="CLRviaCsharps.html#277">Chapter 11: Events</A>
<ul><li><A href="CLRviaCsharps.html#278">Designing a Type That Exposes an Event</A>
<ul><li><A href="CLRviaCsharps.html#279">Step #1: Define a type that will hold any additional information that should be sent to receivers of the event notification</A>
<li><A href="CLRviaCsharps.html#280">Step #2: Define the event member</A>
<li><A href="CLRviaCsharps.html#281">Step #3: Define a method responsible for raising the event to notify registered objects that the event has occurred</A>
<li><A href="CLRviaCsharps.html#284">Step #4: Define a method that translates the input into the desired event</A>
</ul><li><A href="CLRviaCsharps.html#284">How the Compiler Implements an Event</A>
<li><A href="CLRviaCsharps.html#287">Designing a Type That Listens for an Event</A>
<li><A href="CLRviaCsharps.html#289">Explicitly Implementing an Event</A>
</ul><li><A href="CLRviaCsharps.html#293">Chapter 12: Generics</A>
<ul><li><A href="CLRviaCsharps.html#298">Generics in the Framework Class Library</A>
<li><A href="CLRviaCsharps.html#299">þÿ</A>
<li><A href="CLRviaCsharps.html#300">Generics Infrastructure</A>
<ul><li><A href="CLRviaCsharps.html#301">Open and Closed Types</A>
<li><A href="CLRviaCsharps.html#303">Generic Types and Inheritance</A>
<li><A href="CLRviaCsharps.html#305">Generic Type Identity</A>
<li><A href="CLRviaCsharps.html#306">Code Explosion</A>
</ul><li><A href="CLRviaCsharps.html#307">Generic Interfaces</A>
<li><A href="CLRviaCsharps.html#308">Generic Delegates</A>
<li><A href="CLRviaCsharps.html#309">Delegate and Interface Contravariant and Covariant Generic Type Arguments</A>
<li><A href="CLRviaCsharps.html#311">Generic Methods</A>
<ul><li><A href="CLRviaCsharps.html#312">Generic Methods and Type Inference</A>
</ul><li><A href="CLRviaCsharps.html#314">Generics and Other Members</A>
<li><A href="CLRviaCsharps.html#314">Verifiability and Constraints</A>
<ul><li><A href="CLRviaCsharps.html#317">Primary Constraints</A>
<li><A href="CLRviaCsharps.html#318">Secondary Constraints</A>
<li><A href="CLRviaCsharps.html#319">Constructor Constraints</A>
<li><A href="CLRviaCsharps.html#320">Other Verifiability Issues</A>
</ul></ul><li><A href="CLRviaCsharps.html#325">Chapter 13: Interfaces</A>
<ul><li><A href="CLRviaCsharps.html#326">Class and Interface Inheritance</A>
<li><A href="CLRviaCsharps.html#326">Defining an Interface</A>
<li><A href="CLRviaCsharps.html#328">Inheriting an Interface</A>
<li><A href="CLRviaCsharps.html#330">More About Calling Interface Methods</A>
<li><A href="CLRviaCsharps.html#332">þÿ</A>
<li><A href="CLRviaCsharps.html#333">Generic Interfaces</A>
<li><A href="CLRviaCsharps.html#336">Generics and Interface Constraints</A>
<li><A href="CLRviaCsharps.html#337">Implementing Multiple Interfaces That Have the Same Method Name and Signature</A>
<li><A href="CLRviaCsharps.html#338">Improving Compile-Time Type Safety with Explicit Interface Method Implementations</A>
<li><A href="CLRviaCsharps.html#340">Be Careful with Explicit Interface Method Implementations</A>
<li><A href="CLRviaCsharps.html#343">Design: Base Class or Interface?</A>
</ul><li><A href="CLRviaCsharps.html#345">Chapter 14: Chars, Strings, and Working with Text</A>
<ul><li><A href="CLRviaCsharps.html#345">Characters</A>
<li><A href="CLRviaCsharps.html#348">The System.String Type</A>
<ul><li><A href="CLRviaCsharps.html#348">Constructing Strings</A>
<li><A href="CLRviaCsharps.html#351">Strings Are Immutable</A>
<li><A href="CLRviaCsharps.html#352">Comparing Strings</A>
<li><A href="CLRviaCsharps.html#358">String Interning</A>
<li><A href="CLRviaCsharps.html#361">String Pooling</A>
<li><A href="CLRviaCsharps.html#361">þÿ</A>
<li><A href="CLRviaCsharps.html#364">Other String Operations</A>
</ul><li><A href="CLRviaCsharps.html#364">Constructing a String Efficiently</A>
<ul><li><A href="CLRviaCsharps.html#365">Constructing a StringBuilder Object</A>
<li><A href="CLRviaCsharps.html#366">StringBuilder Members</A>
</ul><li><A href="CLRviaCsharps.html#368">Obtaining a String Representation of an Object: ToString</A>
<ul><li><A href="CLRviaCsharps.html#369">Specific Formats and Cultures</A>
<li><A href="CLRviaCsharps.html#373">Formatting Multiple Objects into a Single String</A>
<li><A href="CLRviaCsharps.html#374">Providing Your Own Custom Formatter</A>
</ul><li><A href="CLRviaCsharps.html#377">Parsing a String to Obtain an Object: Parse</A>
<li><A href="CLRviaCsharps.html#379">Encodings: Converting Between Characters and Bytes</A>
<ul><li><A href="CLRviaCsharps.html#385">Encoding and Decoding Streams of Characters and Bytes</A>
<li><A href="CLRviaCsharps.html#386">Base-64 String Encoding and Decoding</A>
</ul><li><A href="CLRviaCsharps.html#387">Secure Strings</A>
</ul><li><A href="CLRviaCsharps.html#391">Chapter 15: Enumerated Types and Bit Flags</A>
<ul><li><A href="CLRviaCsharps.html#391">Enumerated Types</A>
<li><A href="CLRviaCsharps.html#397">Bit Flags</A>
<li><A href="CLRviaCsharps.html#401">Adding Methods to Enumerated Types</A>
</ul><li><A href="CLRviaCsharps.html#403">Chapter 16: Arrays</A>
<ul><li><A href="CLRviaCsharps.html#406">Initializing Array Elements</A>
<li><A href="CLRviaCsharps.html#408">Casting Arrays</A>
<li><A href="CLRviaCsharps.html#410">All Arrays Are Implicitly Derived from System.Array</A>
<li><A href="CLRviaCsharps.html#411">All Arrays Implicitly Implement IEnumerable, ICollection, and IList</A>
<li><A href="CLRviaCsharps.html#412">Passing and Returning Arrays</A>
<li><A href="CLRviaCsharps.html#413">þÿ</A>
<li><A href="CLRviaCsharps.html#414">Array Access Performance</A>
<li><A href="CLRviaCsharps.html#419">Unsafe Array Access and Fixed-Size Array</A>
</ul><li><A href="CLRviaCsharps.html#423">Chapter 17: Delegates</A>
<ul><li><A href="CLRviaCsharps.html#423">A First Look at Delegates</A>
<li><A href="CLRviaCsharps.html#426">Using Delegates to Call Back Static Methods</A>
<li><A href="CLRviaCsharps.html#427">Using Delegates to Call Back Instance Methods</A>
<li><A href="CLRviaCsharps.html#428">Demystifying Delegates</A>
<li><A href="CLRviaCsharps.html#433">Using Delegates to Call Back Many Methods (Chaining)</A>
<ul><li><A href="CLRviaCsharps.html#437">þÿ</A>
<li><A href="CLRviaCsharps.html#437">Having More Control over Delegate Chain Invocation</A>
</ul><li><A href="CLRviaCsharps.html#440">Enough with the Delegate Definitions Already (Generic Delegates)</A>
<li><A href="CLRviaCsharps.html#441">þÿ</A>
<ul><li><A href="CLRviaCsharps.html#442">Syntactical Shortcut #1: No Need to Construct a Delegate Object</A>
<li><A href="CLRviaCsharps.html#442">Syntactical Shortcut #2: No Need to Define a Callback Method</A>
<li><A href="CLRviaCsharps.html#446">Syntactical Shortcut #3: No Need to Wrap Local Variables in a Class Manually to Pass Them to a Callback Method</A>
</ul><li><A href="CLRviaCsharps.html#449">Delegates and Reflection</A>
</ul><li><A href="CLRviaCsharps.html#453">Chapter 18: Custom Attributes</A>
<ul><li><A href="CLRviaCsharps.html#453">Using Custom Attributes</A>
<li><A href="CLRviaCsharps.html#457">Defining Your Own Attribute Class</A>
<li><A href="CLRviaCsharps.html#461">Attribute Constructor and Field/Property Data Types</A>
<li><A href="CLRviaCsharps.html#462">Detecting the Use of a Custom Attribute</A>
<li><A href="CLRviaCsharps.html#466">Matching Two Attribute Instances Against Each Other</A>
<li><A href="CLRviaCsharps.html#469">Detecting the Use of a Custom Attribute Without Creating Attribute-Derived Objects</A>
<li><A href="CLRviaCsharps.html#472">Conditional Attribute Classes</A>
</ul><li><A href="CLRviaCsharps.html#475">Chapter 19: Nullable Value Types</A>
<ul><li><A href="CLRviaCsharps.html#477">þÿ</A>
<li><A href="CLRviaCsharps.html#480">þÿ</A>
<li><A href="CLRviaCsharps.html#481">The CLR Has Special Support for Nullable Value Types</A>
<ul><li><A href="CLRviaCsharps.html#481">Boxing Nullable Value Types</A>
<li><A href="CLRviaCsharps.html#481">Unboxing Nullable Value Types</A>
<li><A href="CLRviaCsharps.html#482">Calling GetType via a Nullable Value Type</A>
<li><A href="CLRviaCsharps.html#482">Calling Interface Methods via a Nullable Value Type</A>
</ul></ul><li><A href="CLRviaCsharps.html#483">Chapter 20: Exceptions and State Management</A>
<ul><li><A href="CLRviaCsharps.html#484">þÿ</A>
<li><A href="CLRviaCsharps.html#485">Exception-Handling Mechanics</A>
<ul><li><A href="CLRviaCsharps.html#486">The try Block</A>
<li><A href="CLRviaCsharps.html#487">The catch Block</A>
<li><A href="CLRviaCsharps.html#488">The finally Block</A>
</ul><li><A href="CLRviaCsharps.html#492">The System.Exception Class</A>
<li><A href="CLRviaCsharps.html#496">FCL-Defined Exception Classes</A>
<li><A href="CLRviaCsharps.html#498">Throwing an Exception</A>
<li><A href="CLRviaCsharps.html#499">Defining Your Own Exception Class</A>
<li><A href="CLRviaCsharps.html#502">Trading Reliability for Productivity</A>
<li><A href="CLRviaCsharps.html#510">Guidelines and Best Practices</A>
<ul><li><A href="CLRviaCsharps.html#510">Use finally Blocks Liberally</A>
<li><A href="CLRviaCsharps.html#512">þÿ</A>
<li><A href="CLRviaCsharps.html#513">Recovering Gracefully from an Exception</A>
<li><A href="CLRviaCsharps.html#514">þÿ</A>
<li><A href="CLRviaCsharps.html#515">þÿ</A>
</ul><li><A href="CLRviaCsharps.html#518">Unhandled Exceptions</A>
<li><A href="CLRviaCsharps.html#522">Debugging Exceptions</A>
<li><A href="CLRviaCsharps.html#524">Exception-Handling Performance Considerations</A>
<li><A href="CLRviaCsharps.html#527">Constrained Execution Regions (CERs)</A>
<li><A href="CLRviaCsharps.html#530">Code Contracts</A>
</ul><li><A href="CLRviaCsharps.html#537">Chapter 21: Automatic Memory Management (Garbage Collection)</A>
<ul><li><A href="CLRviaCsharps.html#538">Understanding the Basics of Working in a Garbage-Collected Platform</A>
<ul><li><A href="CLRviaCsharps.html#539">Allocating Resources from the Managed Heap</A>
</ul><li><A href="CLRviaCsharps.html#541">The Garbage Collection Algorithm</A>
<li><A href="CLRviaCsharps.html#545">Garbage Collections and Debugging</A>
<li><A href="CLRviaCsharps.html#548">Using Finalization to Release Native Resources</A>
<ul><li><A href="CLRviaCsharps.html#550">Guaranteed Finalization Using CriticalFinalizerObject Types</A>
<li><A href="CLRviaCsharps.html#553">Interoperating with Unmanaged Code by Using SafeHandle Types</A>
</ul><li><A href="CLRviaCsharps.html#555">Using Finalization with Managed Resources</A>
<li><A href="CLRviaCsharps.html#558">What Causes Finalize Methods to Be Called?</A>
<li><A href="CLRviaCsharps.html#559">Finalization Internals</A>
<li><A href="CLRviaCsharps.html#562">The Dispose Pattern: Forcing an Object to Clean Up</A>
<li><A href="CLRviaCsharps.html#566">Using a Type That Implements the Dispose Pattern</A>
<li><A href="CLRviaCsharps.html#569">þÿ</A>
<li><A href="CLRviaCsharps.html#572">An Interesting Dependency Issue</A>
<li><A href="CLRviaCsharps.html#573">Monitoring and Controlling the Lifetime of Objects Manually</A>
<li><A href="CLRviaCsharps.html#584">Resurrection</A>
<li><A href="CLRviaCsharps.html#586">Generations</A>
<li><A href="CLRviaCsharps.html#592">Other Garbage Collection Features for Use with Native Resources</A>
<li><A href="CLRviaCsharps.html#596">Predicting the Success of an Operation that Requires a Lot of Memory</A>
<li><A href="CLRviaCsharps.html#598">Programmatic Control of the Garbage Collector</A>
<li><A href="CLRviaCsharps.html#601">Thread Hijacking</A>
<li><A href="CLRviaCsharps.html#603">Garbage Collection Modes</A>
<li><A href="CLRviaCsharps.html#606">Large Objects</A>
<li><A href="CLRviaCsharps.html#607">Monitoring Garbage Collections</A>
</ul><li><A href="CLRviaCsharps.html#609">Chapter 22: CLR Hosting and AppDomains</A>
<ul><li><A href="CLRviaCsharps.html#610">CLR Hosting</A>
<li><A href="CLRviaCsharps.html#612">AppDomains</A>
<ul><li><A href="CLRviaCsharps.html#615">Accessing Objects Across AppDomain Boundaries</A>
</ul><li><A href="CLRviaCsharps.html#627">AppDomain Unloading</A>
<li><A href="CLRviaCsharps.html#628">AppDomain Monitoring</A>
<li><A href="CLRviaCsharps.html#630">AppDomain First-Chance Exception Notifications</A>
<li><A href="CLRviaCsharps.html#630">How Hosts Use AppDomains</A>
<ul><li><A href="CLRviaCsharps.html#630">Executable Applications</A>
<li><A href="CLRviaCsharps.html#631">Microsoft Silverlight Rich Internet Applications</A>
<li><A href="CLRviaCsharps.html#631">Microsoft ASP.NET Web Forms and XML Web Services Applications</A>
<li><A href="CLRviaCsharps.html#632">Microsoft SQL Server</A>
<li><A href="CLRviaCsharps.html#632">Your Own Imagination</A>
</ul><li><A href="CLRviaCsharps.html#633">Advanced Host Control</A>
<ul><li><A href="CLRviaCsharps.html#633">Managing the CLR by Using Managed Code</A>
<li><A href="CLRviaCsharps.html#634">Writing a Robust Host Application</A>
<li><A href="CLRviaCsharps.html#635">How a Host Gets Its Thread Back</A>
</ul></ul><li><A href="CLRviaCsharps.html#639">Chapter 23: Assembly Loading and Reflection</A>
<ul><li><A href="CLRviaCsharps.html#639">Assembly Loading</A>
<li><A href="CLRviaCsharps.html#644">Using Reflection to Build a Dynamically Extensible Application</A>
<li><A href="CLRviaCsharps.html#645">Reflection Performance</A>
<ul><li><A href="CLRviaCsharps.html#646">Discovering Types Defined in an Assembly</A>
<li><A href="CLRviaCsharps.html#646">What Exactly Is a Type Object?</A>
<li><A href="CLRviaCsharps.html#649">Building a Hierarchy of Exception-Derived Types</A>
<li><A href="CLRviaCsharps.html#650">Constructing an Instance of a Type</A>
</ul><li><A href="CLRviaCsharps.html#652">Designing an Application That Supports Add-Ins</A>
<li><A href="CLRviaCsharps.html#655">þÿ</A>
<ul><li><A href="CLRviaCsharps.html#656">þÿ</A>
<li><A href="CLRviaCsharps.html#661">BindingFlags: Filtering the Kinds of Members That Are Returned</A>
<li><A href="CLRviaCsharps.html#662">þÿ</A>
<li><A href="CLRviaCsharps.html#664">þÿ</A>
<li><A href="CLRviaCsharps.html#668">Bind Once, Invoke Multiple Times</A>
<li><A href="CLRviaCsharps.html#676">þÿ</A>
</ul></ul><li><A href="CLRviaCsharps.html#679">Chapter 24: Runtime Serialization</A>
<ul><li><A href="CLRviaCsharps.html#680">Serialization/Deserialization Quick Start</A>
<li><A href="CLRviaCsharps.html#685">Making a Type Serializable</A>
<li><A href="CLRviaCsharps.html#686">Controlling Serialization and Deserialization</A>
<li><A href="CLRviaCsharps.html#690">How Formatters Serialize Type Instances</A>
<li><A href="CLRviaCsharps.html#691">Controlling the Serialized/Deserialized Data</A>
<ul><li><A href="CLRviaCsharps.html#696">þÿ</A>
</ul><li><A href="CLRviaCsharps.html#698">Streaming Contexts</A>
<li><A href="CLRviaCsharps.html#700">Serializing a Type as a Different Type and Deserializing an Object as a Different Object</A>
<li><A href="CLRviaCsharps.html#702">Serialization Surrogates</A>
<ul><li><A href="CLRviaCsharps.html#706">Surrogate Selector Chains</A>
</ul><li><A href="CLRviaCsharps.html#707">Overriding the Assembly and/or Type When Deserializing an Object</A>
</ul><li><A href="CLRviaCsharps.html#709">Chapter 25: Thread Basics</A>
<ul><li><A href="CLRviaCsharps.html#709">Why Does Windows Support Threads?</A>
<li><A href="CLRviaCsharps.html#710">Thread Overhead</A>
<li><A href="CLRviaCsharps.html#714">Stop the Madness</A>
<li><A href="CLRviaCsharps.html#717">CPU Trends</A>
<li><A href="CLRviaCsharps.html#718">NUMA Architecture Machines</A>
<li><A href="CLRviaCsharps.html#721">CLR Threads and Windows Threads</A>
<li><A href="CLRviaCsharps.html#722">Using a Dedicated Thread to Perform an Asynchronous Compute-Bound Operation</A>
<li><A href="CLRviaCsharps.html#724">Reasons to Use Threads</A>
<li><A href="CLRviaCsharps.html#726">Thread Scheduling and Priorities</A>
<li><A href="CLRviaCsharps.html#731">Foreground Threads versus Background Threads</A>
<li><A href="CLRviaCsharps.html#733">What Now?</A>
</ul><li><A href="CLRviaCsharps.html#735">Chapter 26: Compute-Bound Asynchronous Operations</A>
<ul><li><A href="CLRviaCsharps.html#736">þÿ</A>
<li><A href="CLRviaCsharps.html#737">Performing a Simple Compute-Bound Operation</A>
<li><A href="CLRviaCsharps.html#739">Execution Contexts</A>
<li><A href="CLRviaCsharps.html#740">Cooperative Cancellation</A>
<li><A href="CLRviaCsharps.html#744">Tasks</A>
<ul><li><A href="CLRviaCsharps.html#745">Waiting for a Task to Complete and Getting Its Result</A>
<li><A href="CLRviaCsharps.html#747">Cancelling a Task</A>
<li><A href="CLRviaCsharps.html#749">Starting a New Task Automatically When Another Task Completes</A>
<li><A href="CLRviaCsharps.html#751">A Task May Start Child Tasks</A>
<li><A href="CLRviaCsharps.html#751">Inside a Task</A>
<li><A href="CLRviaCsharps.html#753">Task Factories</A>
<li><A href="CLRviaCsharps.html#755">Task Schedulers</A>
</ul><li><A href="CLRviaCsharps.html#757">þÿ</A>
<li><A href="CLRviaCsharps.html#761">Parallel Language Integrated Query</A>
<li><A href="CLRviaCsharps.html#765">Performing a Periodic Compute-Bound Operation</A>
<ul><li><A href="CLRviaCsharps.html#767">So Many Timers, So Little Time</A>
</ul><li><A href="CLRviaCsharps.html#768">How the Thread Pool Manages Its Threads</A>
<ul><li><A href="CLRviaCsharps.html#768">Setting Thread Pool Limits</A>
<li><A href="CLRviaCsharps.html#769">How Worker Threads Are Managed</A>
</ul><li><A href="CLRviaCsharps.html#770">Cache Lines and False Sharing</A>
</ul><li><A href="CLRviaCsharps.html#773">Chapter 27: I/O-Bound Asynchronous Operations</A>
<ul><li><A href="CLRviaCsharps.html#773">How Windows Performs I/O Operations</A>
<li><A href="CLRviaCsharps.html#779">þÿ</A>
<li><A href="CLRviaCsharps.html#783">The AsyncEnumerator Class</A>
<li><A href="CLRviaCsharps.html#787">The APM and Exceptions</A>
<li><A href="CLRviaCsharps.html#788">Applications and Their Threading Models</A>
<li><A href="CLRviaCsharps.html#791">Implementing a Server Asynchronously</A>
<li><A href="CLRviaCsharps.html#792">The APM and Compute-Bound Operations</A>
<li><A href="CLRviaCsharps.html#794">APM Considerations</A>
<ul><li><A href="CLRviaCsharps.html#794">Using the APM Without the Thread Pool</A>
<li><A href="CLRviaCsharps.html#795">Always Call the EndXxx Method, and Call It Only Once</A>
<li><A href="CLRviaCsharps.html#796">Always Use the Same Object When Calling the EndXxx Method</A>
<li><A href="CLRviaCsharps.html#796">Using ref, out, and params Arguments with BeginXxx and EndXxx Methods</A>
<li><A href="CLRviaCsharps.html#796">þÿ</A>
<li><A href="CLRviaCsharps.html#796">Memory Consumption</A>
<li><A href="CLRviaCsharps.html#797">Some I/O Operations Must Be Done Synchronously</A>
<li><A href="CLRviaCsharps.html#798">FileStream-Specific Issues</A>
</ul><li><A href="CLRviaCsharps.html#798">I/O Request Priorities</A>
<li><A href="CLRviaCsharps.html#801">Converting the IAsyncResult APM to a Task</A>
<li><A href="CLRviaCsharps.html#802">The Event-Based Asynchronous Pattern</A>
<ul><li><A href="CLRviaCsharps.html#804">Converting the EAP to a Task</A>
<li><A href="CLRviaCsharps.html#806">Comparing the APM and the EAP</A>
</ul><li><A href="CLRviaCsharps.html#806">Programming Model Soup</A>
</ul><li><A href="CLRviaCsharps.html#809">Chapter 28: Primitive Thread Synchronization Constructs</A>
<ul><li><A href="CLRviaCsharps.html#811">Class Libraries and Thread Safety</A>
<li><A href="CLRviaCsharps.html#812">Primitive User-Mode and Kernel-Mode Constructs</A>
<li><A href="CLRviaCsharps.html#814">User-Mode Constructs</A>
<ul><li><A href="CLRviaCsharps.html#815">Volatile Constructs</A>
<li><A href="CLRviaCsharps.html#821">Interlocked Constructs</A>
<li><A href="CLRviaCsharps.html#825">Implementing a Simple Spin Lock</A>
<li><A href="CLRviaCsharps.html#829">The Interlocked Anything Pattern</A>
</ul><li><A href="CLRviaCsharps.html#831">Kernel-Mode Constructs</A>
<ul><li><A href="CLRviaCsharps.html#835">Event Constructs</A>
<li><A href="CLRviaCsharps.html#837">Semaphore Constructs</A>
<li><A href="CLRviaCsharps.html#838">Mutex Constructs</A>
<li><A href="CLRviaCsharps.html#840">Calling a Method When a Single Kernel Construct Becomes Available</A>
</ul></ul><li><A href="CLRviaCsharps.html#843">Chapter 29: Hybrid Thread Synchronization Constructs</A>
<ul><li><A href="CLRviaCsharps.html#844">A Simple Hybrid Lock</A>
<li><A href="CLRviaCsharps.html#845">Spinning, Thread Ownership, and Recursion</A>
<li><A href="CLRviaCsharps.html#847">A Potpourri of Hybrid Constructs</A>
<ul><li><A href="CLRviaCsharps.html#848">The ManualResetEventSlim and SemaphoreSlim Classes</A>
<li><A href="CLRviaCsharps.html#848">The Monitor Class and Sync Blocks</A>
<li><A href="CLRviaCsharps.html#854">The ReaderWriterLockSlim Class</A>
<li><A href="CLRviaCsharps.html#856">The OneManyLock Class</A>
<li><A href="CLRviaCsharps.html#859">The CountdownEvent Class</A>
<li><A href="CLRviaCsharps.html#859">The Barrier Class</A>
<li><A href="CLRviaCsharps.html#860">Thread Synchronization Construct Summary</A>
</ul><li><A href="CLRviaCsharps.html#862">The Famous Double-Check Locking Technique</A>
<li><A href="CLRviaCsharps.html#866">The Condition Variable Pattern</A>
<li><A href="CLRviaCsharps.html#869">Using Collections to Avoid Holding a Lock for a Long Time</A>
<li><A href="CLRviaCsharps.html#874">The Concurrent Collection Classes</A>
</ul><li><A href="CLRviaCsharps.html#879">Index</A>
<li><A href="CLRviaCsharps.html#893">About the Author</A>
</ul><hr>
</BODY>
</HTML>
